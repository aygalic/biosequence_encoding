{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import chain\n",
    "import itertools\n",
    "import random\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.function import Function\n",
    "import torch.nn.utils.prune as prune\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn, einsum\n",
    "import logging\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "import matplotlib as mp\n",
    "import time\n",
    "from scipy.signal import savgol_filter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "from utils import data_handler\n",
    "from utils import benchmark\n",
    "from utils import visualisation\n",
    "from utils.models.VQ_VAE import Model\n",
    "importlib.reload(data_handler) # to allow modification of the script without restarting the whole session\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e152fd",
   "metadata": {},
   "source": [
    "# instead, we plug in our OWN datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_genes_file_1 = '../../data/PD_genes_of_interest/signif_de_Disease_status_IDIOPATHIC_PD_01.tsv'\n",
    "suggested_genes_file_2 = '../../data/PD_genes_of_interest/signif_de_PD_DIAGNOSIS_0.1.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1\n",
    "x_train, filenames, n_genes, gene_names = data_handler.generate_dataset_transcripts(\n",
    "    feature_selection_threshold = 5, \n",
    "    gene_selection_file = None)\n",
    "\n",
    "data_1 = np.concatenate(list(x_train.as_numpy_iterator()), axis=0)\n",
    "\n",
    "feature_num_1 = data_1.shape[1]\n",
    "data_num_1 = data_1.shape[0]\n",
    "dat_1 = data_1.reshape(-1,1,feature_num_1)\n",
    "\n",
    "\n",
    "x_train, filenames, n_genes, gene_names = data_handler.generate_dataset(\n",
    "    feature_selection_threshold = 2, \n",
    "    gene_selection_file = None)\n",
    "\n",
    "data_2 = np.concatenate(list(x_train.as_numpy_iterator()), axis=0)\n",
    "\n",
    "feature_num_2 = data_2.shape[1]\n",
    "data_num_2 = data_2.shape[0]\n",
    "dat_2 = data_2.reshape(-1,1,feature_num_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 2\n",
    "x_train, filenames, n_genes, gene_names = data_handler.generate_dataset_transcripts(\n",
    "    feature_selection_threshold = 0, \n",
    "    gene_selection_file = suggested_genes_file_1)\n",
    "\n",
    "data_1 = np.concatenate(list(x_train.as_numpy_iterator()), axis=0)\n",
    "\n",
    "feature_num_1 = data_1.shape[1]\n",
    "data_num_1 = data_1.shape[0]\n",
    "dat_1 = data_1.reshape(-1,1,feature_num_1)\n",
    "\n",
    "\n",
    "x_train, filenames, n_genes, gene_names = data_handler.generate_dataset(\n",
    "    feature_selection_threshold = 0, \n",
    "    gene_selection_file = suggested_genes_file_1)\n",
    "\n",
    "data_2 = np.concatenate(list(x_train.as_numpy_iterator()), axis=0)\n",
    "\n",
    "feature_num_2 = data_2.shape[1]\n",
    "data_num_2 = data_2.shape[0]\n",
    "dat_2 = data_2.reshape(-1,1,feature_num_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 3\n",
    "x_train, filenames, n_genes, gene_names = data_handler.generate_dataset_transcripts(\n",
    "    feature_selection_threshold = 0, \n",
    "    gene_selection_file = suggested_genes_file_2)\n",
    "\n",
    "data_1 = np.concatenate(list(x_train.as_numpy_iterator()), axis=0)\n",
    "\n",
    "feature_num_1 = data_1.shape[1]\n",
    "data_num_1 = data_1.shape[0]\n",
    "dat_1 = data_1.reshape(-1,1,feature_num_1)\n",
    "\n",
    "\n",
    "x_train, filenames, n_genes, gene_names = data_handler.generate_dataset(\n",
    "    feature_selection_threshold = 0, \n",
    "    gene_selection_file = suggested_genes_file_2)\n",
    "\n",
    "data_2 = np.concatenate(list(x_train.as_numpy_iterator()), axis=0)\n",
    "\n",
    "feature_num_2 = data_2.shape[1]\n",
    "data_num_2 = data_2.shape[0]\n",
    "dat_2 = data_2.reshape(-1,1,feature_num_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52b0c1",
   "metadata": {},
   "source": [
    "## End of experiment choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6279dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, data1, data2 ,transform = None):\n",
    "        self.transform = transform\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.datanum = len(data1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        out_data1 = torch.tensor(self.data1[idx]).float()\n",
    "        out_data2 = torch.tensor(self.data2[idx]).float()\n",
    "        if self.transform:\n",
    "            out_data1 = self.transform(out_data1)\n",
    "            out_data2 = self.transform(out_data2)\n",
    "\n",
    "        return out_data1,out_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, test_1 = train_test_split(dat_1, test_size = 0.1,random_state = 66)\n",
    "print('train_data_1:',len(train_1))\n",
    "print('test_data_1:',len(test_1))\n",
    "\n",
    "train_2, test_2 = train_test_split(dat_2, test_size = 0.1,random_state = 66)\n",
    "print('train_data_2:',len(train_2))\n",
    "print('test_data_2:',len(test_2))\n",
    "\n",
    "train_data_set = Mydatasets(data1 = train_1, data2 = train_2)\n",
    "test_data_set = Mydatasets(data1 = test_1, data2 = test_2)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data_set, batch_size = 256, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_set, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f493b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = rearrange(inputs, 'b c l -> b l c')\n",
    "        inputs = inputs.contiguous()\n",
    "        #inputs = inputs.permute(0, 2, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        quantized = rearrange(quantized, 'b c l -> b l c')\n",
    "        quantized = quantized.contiguous()\n",
    "        \n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        #return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings\n",
    "        return loss, quantized, perplexity, encodings\n",
    "    \n",
    "class VectorQuantizerEMA(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5):\n",
    "        super(VectorQuantizerEMA, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.normal_()\n",
    "        self._commitment_cost = commitment_cost\n",
    "        \n",
    "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
    "        self._ema_w = nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
    "        self._ema_w.data.normal_()\n",
    "        \n",
    "        self._decay = decay\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = rearrange(inputs, 'b c l -> b l c')\n",
    "        inputs = inputs.contiguous()\n",
    "        #inputs = inputs.permute(0, 2, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Use EMA to update the embedding vectors\n",
    "        if self.training:\n",
    "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
    "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
    "            \n",
    "            # Laplace smoothing of the cluster size\n",
    "            n = torch.sum(self._ema_cluster_size.data)\n",
    "            self._ema_cluster_size = (\n",
    "                (self._ema_cluster_size + self._epsilon)\n",
    "                / (n + self._num_embeddings * self._epsilon) * n)\n",
    "            \n",
    "            dw = torch.matmul(encodings.t(), flat_input)\n",
    "            self._ema_w = nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
    "            \n",
    "            self._embedding.weight = nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        loss = self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        # Straight Through Estimator\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        quantized = rearrange(quantized, 'b c l -> b l c')\n",
    "        quantized = quantized.contiguous()\n",
    "        \n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "               \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        #return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings\n",
    "        return loss, quantized, perplexity, encodings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self, encoder_dim):\n",
    "        super(ResidualStack, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, encoder_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size_1, encoder_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.lay1 = nn.Sequential(\n",
    "            nn.Linear(input_size_1, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.lay2 = nn.Sequential(\n",
    "            nn.Linear(2048, encoder_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self._residual_stack = ResidualStack(encoder_dim)\n",
    "\n",
    "    def forward(self, inputs_1):\n",
    "        x_1 = self.lay1(inputs_1)\n",
    "        x_1 = self.lay2(x_1)\n",
    "        x_1 = self._residual_stack(x_1)\n",
    "        return x_1\n",
    "\n",
    "    def forward(self, inputs_2):\n",
    "        x_1 = self.lay1(inputs_2)\n",
    "        x_1 = self.lay2(x_1)\n",
    "        x_1 = self._residual_stack(x_1)\n",
    "        return x_1\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, input_size_1, encoder_dim, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.lay0 = nn.Sequential(\n",
    "            nn.Linear(num_embeddings, encoder_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self._residual_stack = ResidualStack(encoder_dim)\n",
    "        \n",
    "        self.lay1 = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.lay2 = nn.Sequential(\n",
    "            nn.Linear(2048, input_size_1),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.lay0(inputs)\n",
    "        x = self._residual_stack(x)\n",
    "        x_1 = self.lay1(x)\n",
    "        x_1 = self.lay2(x_1)\n",
    "        return x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes, input_size_1, input_size_2, encoder_dim_b, encoder_dim_t, num_embeddings_b, num_embeddings_t, embedding_dim_b, embedding_dim_t, commitment_cost, dropout, decay=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self._encoder_b = Encoder(input_size_1, encoder_dim_b, dropout)\n",
    "        self._encoder_b2 = Encoder(input_size_2, encoder_dim_b, dropout)\n",
    "        self._encoder_t = Encoder(encoder_dim_b, encoder_dim_t, dropout)\n",
    "        \n",
    "        self._pre_vq_conv_b = nn.Linear(encoder_dim_b, num_embeddings_b)\n",
    "        self._pre_vq_conv_t = nn.Linear(encoder_dim_t, num_embeddings_t)\n",
    "        \n",
    "        if decay > 0.0:\n",
    "            self._vq_vae_b = VectorQuantizerEMA(num_embeddings_b, embedding_dim_b, commitment_cost, decay)\n",
    "            self._vq_vae_t = VectorQuantizerEMA(num_embeddings_t, embedding_dim_t, commitment_cost, decay)\n",
    "        else:\n",
    "            self._vq_vae_b = VectorQuantizer(num_embeddings_b, embedding_dim_b, commitment_cost)\n",
    "            self._vq_vae_t = VectorQuantizer(num_embeddings_t, embedding_dim_t, commitment_cost)\n",
    "        \n",
    "        self._upsample = nn.Linear(num_embeddings_t, num_embeddings_b)\n",
    "        \n",
    "        self._decoder_t = Decoder(num_embeddings_t, encoder_dim_b, encoder_dim_t, dropout)   \n",
    "        self._decoder_b = Decoder(num_embeddings_b, input_size_1, encoder_dim_b, dropout)\n",
    "        self._decoder_b2 = Decoder(num_embeddings_b, input_size_2, encoder_dim_b, dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        #Top level\n",
    "        z_b = self._encoder_b(x1)\n",
    "        z_t = self._encoder_t(z_b)\n",
    "        z_t = self._pre_vq_conv_t(z_t)\n",
    "        vq_loss_t, quantized_t, perplexity_t, _ = self._vq_vae_t(z_t)\n",
    "        recon_t = self._decoder_t(quantized_t)\n",
    "        \n",
    "        #Bottom level\n",
    "        z_b2 = self._encoder_b2(x2)\n",
    "        z_final = z_b + z_b2 + recon_t\n",
    "        z_final = self._pre_vq_conv_b(z_final)\n",
    "        vq_loss_b, quantized_b, perplexity_b, _ = self._vq_vae_b(z_final)\n",
    "        recon_b = self._decoder_b(quantized_b + self._upsample(quantized_t))\n",
    "        recon_b2 = self._decoder_b2(quantized_b + self._upsample(quantized_t))\n",
    "        variance_z_b = torch.var(z_b)\n",
    "        return vq_loss_b, vq_loss_t, recon_b, recon_b2, recon_t, z_b, z_final, quantized_b, perplexity_b, variance_z_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58ebab",
   "metadata": {},
   "source": [
    "## Preping labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"../../METADATA_200123.xlsx\"\n",
    "\n",
    "meta_data = pd.read_excel(metadata_path, header = 1, usecols = range(1,10) )\n",
    "patient_ids = [int(name.split(\".\")[1]) for name in filenames]\n",
    "\n",
    "# Create a dictionary to map 'Patient Number' to 'Disease Status'\n",
    "patient_disease_status = dict(zip(meta_data['Patient Number'], meta_data['Disease Status']))\n",
    "\n",
    "label = [patient_disease_status.get(patient_id, None) for patient_id in patient_ids]\n",
    "label = pd.Series(label)\n",
    "num_classes = len(pd.Series(label).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b89613",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "VQ_VAE = Model(\n",
    "            dropout = 0.0,\n",
    "            num_classes = num_classes,\n",
    "            input_size_1 = feature_num_1,\n",
    "            input_size_2 = feature_num_2,\n",
    "            encoder_dim_b = 64,\n",
    "            encoder_dim_t = 32,\n",
    "            num_embeddings_b = 64,\n",
    "            num_embeddings_t = 32,\n",
    "            embedding_dim_b = 64,\n",
    "            embedding_dim_t = 32, \n",
    "            commitment_cost = 1\n",
    "           ).to(DEVICE)\n",
    "\n",
    "Classifier_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(VQ_VAE.parameters(), lr=1e-4, amsgrad=False)\n",
    "data_variance_1 = np.var(dat_1)\n",
    "data_variance_2 = np.var(dat_2)\n",
    "\n",
    "#VQ_VAE.load_state_dict(torch.load('VQ_2_disc'),strict=False)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71243a01",
   "metadata": {},
   "source": [
    "we need a proper training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22780f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 700\n",
    "train_res_recon_error = []\n",
    "train_res_perplexity = []\n",
    "\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "ac_list = []\n",
    "VQ_VAE.train()\n",
    "\n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    quantized_merge = torch.empty(0, 1, 64).to(DEVICE)\n",
    "\n",
    "    for _, (inputs1, inputs2) in enumerate(train_dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs1 = inputs1.to(DEVICE)\n",
    "        inputs2 = inputs2.to(DEVICE)\n",
    "        vq_loss_b, vq_loss_t, recon_b, recon_b2, recon_t, z_b, z_final, quantized_b, perplexity, variance_z_b = VQ_VAE(inputs1, inputs2)\n",
    "        recon_error_b = F.mse_loss(recon_b, inputs1) / data_variance_1\n",
    "        recon_error_b2 = F.mse_loss(recon_b2, inputs2) / data_variance_2\n",
    "        recon_error_t = F.mse_loss(recon_t, z_b) / variance_z_b\n",
    "        loss = recon_error_b + recon_error_b2 + recon_error_t + vq_loss_b + vq_loss_t\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "\n",
    "        # Append the training loss values for monitoring\n",
    "        train_res_recon_error.append(recon_error_b.item() + recon_error_t.item())\n",
    "        train_res_perplexity.append(perplexity.item())\n",
    "\n",
    "        # Print training statistics\n",
    "        if count % 5 == 0:  # Adjust this frequency as needed\n",
    "            print(  f'Epoch [{epoch + 1}/{EPOCH}],'\n",
    "                    f'Recon Error: {recon_error_b.item() + recon_error_t.item():.4f}, '\n",
    "                    f'Perplexity: {perplexity.item():.4f}')\n",
    "\n",
    "# After training, you can print or log other relevant information as needed\n",
    "print('Training completed.')\n",
    "plt.plot(train_res_recon_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ebda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lat = []\n",
    "en_quantized = []\n",
    "en_labels = []\n",
    "\n",
    "data_set = Mydatasets(data1 = dat_1, data2 = dat_2)\n",
    "data_set = torch.utils.data.DataLoader(data_set, batch_size = 256, shuffle=True)\n",
    "\n",
    "for i in range(len(dat_1)):\n",
    "    en_data1 = data_set.dataset[i][0]\n",
    "    en_data2 = data_set.dataset[i][1]\n",
    "\n",
    "    _, _, _, _, _, latent_1, latent_2, _, _, _ = VQ_VAE(en_data1.view(1, 1, feature_num_1).float().to(DEVICE), en_data2.view(1, 1, feature_num_2).float().to(DEVICE))\n",
    "    en_quantized.append(latent_2.cpu().detach().numpy())\n",
    "    en_lat.append(latent_1.cpu().detach().numpy())\n",
    "    en_quantized.append(latent_2.cpu().detach().numpy())\n",
    "\n",
    "encode_out = np.array(en_lat)\n",
    "encode_out = encode_out.reshape(len(dat_1), -1)\n",
    "quantized_out = np.array(en_quantized)\n",
    "quantized_out = quantized_out.reshape(len(dat_1), -1)\n",
    "print('encode_out:', encode_out.shape)\n",
    "print('quantized_out:', quantized_out.shape)\n",
    "\n",
    "latent_Z = encode_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc67f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compatibility between notebooks\n",
    "compressed_dataframe = encode_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce529496",
   "metadata": {},
   "source": [
    "# First, analyse all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(visualisation)\n",
    "importlib.reload(helpers)\n",
    "\n",
    "print(\"######################## OG Groups : \")\n",
    "TSNE_params = {\n",
    "            \"early_exaggeration\" : 50,\n",
    "            \"learning_rate\" : 500, \n",
    "            #\"perplexity\" : 75, \n",
    "            \"perplexity\" : 100, \n",
    "            \"min_grad_norm\" : 1e-7, \n",
    "            \"n_iter\" : 2000,\n",
    "            \"n_components\" : 2\n",
    "        }\n",
    "visualisation.plot_clusters(compressed_dataframe, label, TSNE_params)\n",
    "benchmark.print_metrics(compressed_dataframe, label)\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(compressed_dataframe)\n",
    "visualisation.plot_clusters(compressed_dataframe, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(compressed_dataframe, kmeans_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18027859",
   "metadata": {},
   "source": [
    "## Second, Check if control group leads to any clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering data\n",
    "clinical_info_series = pd.Series(label)\n",
    "filenames_series = pd.Series(filenames)\n",
    "\n",
    "# Create boolean masks for filtering\n",
    "clinical_mask = clinical_info_series == \"Healthy Control\"\n",
    "\n",
    "\n",
    "# Apply the mask to your dataset\n",
    "filtered_dat = compressed_dataframe[clinical_mask]\n",
    "filtered_clinical_info = clinical_info_series[clinical_mask]\n",
    "\n",
    "# Check the shape of the filtered dataset\n",
    "print(filtered_dat.shape)\n",
    "print(filtered_clinical_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(visualisation)\n",
    "importlib.reload(helpers)\n",
    "\n",
    "print(\"######################## OG Groups : \")\n",
    "TSNE_params = {\n",
    "            \"early_exaggeration\" : 50,\n",
    "            \"learning_rate\" : 500, \n",
    "            \"perplexity\" : 50, \n",
    "            \"min_grad_norm\" : 1e-7, \n",
    "            \"n_iter\" : 2000,\n",
    "            \"n_components\" : 2\n",
    "        }\n",
    "visualisation.plot_clusters(filtered_dat, filtered_clinical_info, TSNE_params)\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(filtered_dat)\n",
    "visualisation.plot_clusters(filtered_dat, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(filtered_dat, kmeans_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd464a",
   "metadata": {},
   "source": [
    "## Third : check for clusters in the Idiopathic PD group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering data\n",
    "# Convert clinical_info and filenames to Series for easy filtering\n",
    "clinical_info_series = pd.Series(label)\n",
    "filenames_series = pd.Series(filenames)\n",
    "\n",
    "# Create boolean masks for filtering\n",
    "clinical_mask = clinical_info_series == \"Idiopathic PD\"\n",
    "\n",
    "\n",
    "# Apply the mask to your dataset\n",
    "filtered_dat = compressed_dataframe[clinical_mask]\n",
    "filtered_clinical_info = clinical_info_series[clinical_mask]\n",
    "\n",
    "# Check the shape of the filtered dataset\n",
    "print(filtered_dat.shape)\n",
    "print(filtered_clinical_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(visualisation)\n",
    "importlib.reload(helpers)\n",
    "\n",
    "print(\"######################## OG Groups : \")\n",
    "params = {\"early_exaggeration\":10,\n",
    "              \"learning_rate\":700, \n",
    "              \"perplexity\":15, \n",
    "              \"min_grad_norm\":1e-7, \n",
    "              \"n_iter\":1000,\n",
    "              \"n_components\":2}\n",
    "visualisation.plot_clusters(filtered_dat, filtered_clinical_info, TSNE_params)\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(filtered_dat)\n",
    "visualisation.plot_clusters(filtered_dat, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(filtered_dat, kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d7445",
   "metadata": {},
   "source": [
    "## Last : Check for Genetic PD groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fe488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering data\n",
    "# Convert clinical_info and filenames to Series for easy filtering\n",
    "clinical_info_series = pd.Series(label)\n",
    "filenames_series = pd.Series(filenames)\n",
    "\n",
    "# Create boolean masks for filtering\n",
    "clinical_mask = clinical_info_series == \"Genetic PD\"\n",
    "\n",
    "\n",
    "# Apply the mask to your dataset\n",
    "filtered_dat = compressed_dataframe[clinical_mask]\n",
    "filtered_clinical_info = clinical_info_series[clinical_mask]\n",
    "\n",
    "# Check the shape of the filtered dataset\n",
    "print(filtered_dat.shape)\n",
    "print(filtered_clinical_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(visualisation)\n",
    "importlib.reload(helpers)\n",
    "\n",
    "print(\"######################## OG Groups : \")\n",
    "params = {\"early_exaggeration\":5,\n",
    "              \"learning_rate\":100, \n",
    "              \"perplexity\":30, \n",
    "              \"min_grad_norm\":1e-7, \n",
    "              \"n_iter\":5000,\n",
    "              \"n_components\":2}\n",
    "visualisation.plot_clusters(filtered_dat, filtered_clinical_info, TSNE_params)\n",
    "\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(filtered_dat)\n",
    "visualisation.plot_clusters(filtered_dat, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(filtered_dat, kmeans_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

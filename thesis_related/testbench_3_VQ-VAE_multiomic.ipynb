{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import chain\n",
    "import itertools\n",
    "import random\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.function import Function\n",
    "import torch.nn.utils.prune as prune\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn, einsum\n",
    "import logging\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "import matplotlib as mp\n",
    "import time\n",
    "from scipy.signal import savgol_filter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "import helpers\n",
    "sys.path.append('../src')\n",
    "from utils import data_handler\n",
    "from utils import benchmark\n",
    "from utils import visualisation\n",
    "from models.VQ_VAE_2 import Model\n",
    "importlib.reload(data_handler) # to allow modification of the script without restarting the whole session\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e152fd",
   "metadata": {},
   "source": [
    "# instead, we plug in our OWN datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../workfiles/transcript_ds_experiment_1.pkl', 'rb') as f:\n",
    "    dat_1, metadata_1 = pickle.load(f)\n",
    "\n",
    "with open('../workfiles/gene_ds_experiment_1.pkl', 'rb') as f:\n",
    "    dat_2, metadata_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../workfiles/transcript_ds_experiment_2.pkl', 'rb') as f:\n",
    "    dat_1, metadata_1 = pickle.load(f)\n",
    "\n",
    "with open('../workfiles/gene_ds_experiment_2.pkl', 'rb') as f:\n",
    "    dat_2, metadata_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041ad16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../workfiles/transcript_ds_experiment_3.pkl', 'rb') as f:\n",
    "    dat_1, metadata_1 = pickle.load(f)\n",
    "\n",
    "with open('../workfiles/gene_ds_experiment_3.pkl', 'rb') as f:\n",
    "    dat_2, metadata_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbfa51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff52b0c1",
   "metadata": {},
   "source": [
    "## End of experiment choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_names = metadata_1[\"seq_names\"]\n",
    "feature_num_1 = metadata_1[\"n_features\"]\n",
    "feature_num_2 = metadata_2[\"n_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6279dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, data1, data2 ,transform = None):\n",
    "        self.transform = transform\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.datanum = len(data1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        out_data1 = torch.tensor(self.data1[idx]).float()\n",
    "        out_data2 = torch.tensor(self.data2[idx]).float()\n",
    "        if self.transform:\n",
    "            out_data1 = self.transform(out_data1)\n",
    "            out_data2 = self.transform(out_data2)\n",
    "\n",
    "        return out_data1,out_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, test_1 = train_test_split(dat_1, test_size = 0.1,random_state = 66)\n",
    "print('train_data_1:',len(train_1))\n",
    "print('test_data_1:',len(test_1))\n",
    "\n",
    "train_2, test_2 = train_test_split(dat_2, test_size = 0.1,random_state = 66)\n",
    "print('train_data_2:',len(train_2))\n",
    "print('test_data_2:',len(test_2))\n",
    "\n",
    "train_data_set = Mydatasets(data1 = train_1, data2 = train_2)\n",
    "test_data_set = Mydatasets(data1 = test_1, data2 = test_2)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data_set, batch_size = 256, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_set, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58ebab",
   "metadata": {},
   "source": [
    "## Preping labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"../../METADATA_200123.xlsx\"\n",
    "\n",
    "meta_data = pd.read_excel(metadata_path, header = 1, usecols = range(1,10) )\n",
    "patient_ids = [int(name.split(\".\")[1]) for name in seq_names]\n",
    "\n",
    "# Create a dictionary to map 'Patient Number' to 'Disease Status'\n",
    "patient_disease_status = dict(zip(meta_data['Patient Number'], meta_data['Disease Status']))\n",
    "\n",
    "label = [patient_disease_status.get(patient_id, None) for patient_id in patient_ids]\n",
    "label = pd.Series(label)\n",
    "num_classes = len(pd.Series(label).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd64266",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b89613",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = torch.device(\"mps\")\n",
    "\n",
    "VQ_VAE = Model(\n",
    "            dropout = 0.0,\n",
    "            num_classes = num_classes,\n",
    "            input_size_1 = feature_num_1,\n",
    "            input_size_2 = feature_num_2,\n",
    "            encoder_dim_b = 64,\n",
    "            encoder_dim_t = 32,\n",
    "            num_embeddings_b = 64,\n",
    "            num_embeddings_t = 32,\n",
    "            embedding_dim_b = 64,\n",
    "            embedding_dim_t = 32, \n",
    "            commitment_cost = 1\n",
    "           ).to(DEVICE)\n",
    "\n",
    "Classifier_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(VQ_VAE.parameters(), lr=1e-4, amsgrad=False)\n",
    "data_variance_1 = np.var(dat_1)\n",
    "data_variance_2 = np.var(dat_2)\n",
    "\n",
    "#VQ_VAE.load_state_dict(torch.load('VQ_2_disc'),strict=False)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71243a01",
   "metadata": {},
   "source": [
    "we need a proper training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22780f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 200\n",
    "train_res_recon_error = []\n",
    "train_res_perplexity = []\n",
    "\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "ac_list = []\n",
    "VQ_VAE.train()\n",
    "\n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    quantized_merge = torch.empty(0, 1, 64).to(DEVICE)\n",
    "\n",
    "    for _, (inputs1, inputs2) in enumerate(train_dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs1 = inputs1.to(DEVICE)\n",
    "        inputs2 = inputs2.to(DEVICE)\n",
    "        vq_loss_b, vq_loss_t, recon_b, recon_b2, recon_t, z_b, z_final, quantized_b, perplexity, variance_z_b = VQ_VAE(inputs1, inputs2)\n",
    "        recon_error_b = F.mse_loss(recon_b, inputs1) / data_variance_1\n",
    "        recon_error_b2 = F.mse_loss(recon_b2, inputs2) / data_variance_2\n",
    "        recon_error_t = F.mse_loss(recon_t, z_b) / variance_z_b\n",
    "        loss = recon_error_b + recon_error_b2 + recon_error_t + vq_loss_b + vq_loss_t\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "\n",
    "        # Append the training loss values for monitoring\n",
    "        train_res_recon_error.append(recon_error_b.item() + recon_error_t.item())\n",
    "        train_res_perplexity.append(perplexity.item())\n",
    "\n",
    "        # Print training statistics\n",
    "\n",
    "\n",
    "# After training, you can print or log other relevant information as needed\n",
    "print('Training completed.')\n",
    "plt.plot(train_res_recon_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ebda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lat = []\n",
    "en_quantized = []\n",
    "en_labels = []\n",
    "\n",
    "data_set = Mydatasets(data1 = dat_1, data2 = dat_2)\n",
    "data_set = torch.utils.data.DataLoader(data_set, batch_size = 256, shuffle=True)\n",
    "\n",
    "for i in range(len(dat_1)):\n",
    "    en_data1 = data_set.dataset[i][0]\n",
    "    en_data2 = data_set.dataset[i][1]\n",
    "\n",
    "    _, _, _, _, _, latent_1, latent_2, _, _, _ = VQ_VAE(en_data1.view(1, 1, feature_num_1).float().to(DEVICE), en_data2.view(1, 1, feature_num_2).float().to(DEVICE))\n",
    "    en_quantized.append(latent_2.cpu().detach().numpy())\n",
    "    en_lat.append(latent_1.cpu().detach().numpy())\n",
    "    en_quantized.append(latent_2.cpu().detach().numpy())\n",
    "\n",
    "encode_out = np.array(en_lat)\n",
    "encode_out = encode_out.reshape(len(dat_1), -1)\n",
    "quantized_out = np.array(en_quantized)\n",
    "quantized_out = quantized_out.reshape(len(dat_1), -1)\n",
    "print('encode_out:', encode_out.shape)\n",
    "print('quantized_out:', quantized_out.shape)\n",
    "\n",
    "latent_Z = encode_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc67f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compatibility between notebooks\n",
    "compressed_dataframe = encode_out\n",
    "\n",
    "# filtering data\n",
    "clinical_info_series = pd.Series(label)\n",
    "filenames_series = pd.Series(seq_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce529496",
   "metadata": {},
   "source": [
    "# First, analyse all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"######################## OG Groups : \")\n",
    "TSNE_params = {\n",
    "            \"early_exaggeration\" : 50,\n",
    "            \"learning_rate\" : 500, \n",
    "            #\"perplexity\" : 75, \n",
    "            \"perplexity\" : 100, \n",
    "            \"min_grad_norm\" : 1e-7, \n",
    "            \"n_iter\" : 2000,\n",
    "            \"n_components\" : 2\n",
    "        }\n",
    "visualisation.plot_clusters(compressed_dataframe, label, TSNE_params)\n",
    "benchmark.print_metrics(compressed_dataframe, label)\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(compressed_dataframe)\n",
    "visualisation.plot_clusters(compressed_dataframe, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(compressed_dataframe, kmeans_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18027859",
   "metadata": {},
   "source": [
    "## Second, Check if control group leads to any clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean masks for filtering\n",
    "clinical_mask = clinical_info_series == \"Healthy Control\"\n",
    "\n",
    "\n",
    "# Apply the mask to your dataset\n",
    "filtered_dat = compressed_dataframe[clinical_mask]\n",
    "filtered_clinical_info = clinical_info_series[clinical_mask]\n",
    "\n",
    "# Check the shape of the filtered dataset\n",
    "print(filtered_dat.shape)\n",
    "print(filtered_clinical_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"######################## OG Groups : \")\n",
    "TSNE_params = {\n",
    "            \"early_exaggeration\" : 50,\n",
    "            \"learning_rate\" : 500, \n",
    "            \"perplexity\" : 50, \n",
    "            \"min_grad_norm\" : 1e-7, \n",
    "            \"n_iter\" : 2000,\n",
    "            \"n_components\" : 2\n",
    "        }\n",
    "visualisation.plot_clusters(filtered_dat, filtered_clinical_info, TSNE_params)\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(filtered_dat)\n",
    "visualisation.plot_clusters(filtered_dat, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(filtered_dat, kmeans_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd464a",
   "metadata": {},
   "source": [
    "## Third : check for clusters in the Idiopathic PD group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean masks for filtering\n",
    "clinical_mask = clinical_info_series == \"Idiopathic PD\"\n",
    "\n",
    "\n",
    "# Apply the mask to your dataset\n",
    "filtered_dat = compressed_dataframe[clinical_mask]\n",
    "filtered_clinical_info = clinical_info_series[clinical_mask]\n",
    "\n",
    "# Check the shape of the filtered dataset\n",
    "print(filtered_dat.shape)\n",
    "print(filtered_clinical_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"######################## OG Groups : \")\n",
    "params = {\"early_exaggeration\":10,\n",
    "              \"learning_rate\":700, \n",
    "              \"perplexity\":15, \n",
    "              \"min_grad_norm\":1e-7, \n",
    "              \"n_iter\":1000,\n",
    "              \"n_components\":2}\n",
    "visualisation.plot_clusters(filtered_dat, filtered_clinical_info, TSNE_params)\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(filtered_dat)\n",
    "visualisation.plot_clusters(filtered_dat, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(filtered_dat, kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d7445",
   "metadata": {},
   "source": [
    "## Last : Check for Genetic PD groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fe488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean masks for filtering\n",
    "clinical_mask = clinical_info_series == \"Genetic PD\"\n",
    "\n",
    "\n",
    "# Apply the mask to your dataset\n",
    "filtered_dat = compressed_dataframe[clinical_mask]\n",
    "filtered_clinical_info = clinical_info_series[clinical_mask]\n",
    "\n",
    "# Check the shape of the filtered dataset\n",
    "print(filtered_dat.shape)\n",
    "print(filtered_clinical_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"######################## OG Groups : \")\n",
    "params = {\"early_exaggeration\":5,\n",
    "              \"learning_rate\":100, \n",
    "              \"perplexity\":30, \n",
    "              \"min_grad_norm\":1e-7, \n",
    "              \"n_iter\":5000,\n",
    "              \"n_components\":2}\n",
    "visualisation.plot_clusters(filtered_dat, filtered_clinical_info, TSNE_params)\n",
    "\n",
    "\n",
    "print(\"######################## KNMEANS : \")\n",
    "kmeans_labels = helpers.auto_kMean(filtered_dat)\n",
    "visualisation.plot_clusters(filtered_dat, kmeans_labels, TSNE_params)\n",
    "benchmark.print_metrics(filtered_dat, kmeans_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ba286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe0b450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import chain\n",
    "import itertools\n",
    "import random\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.function import Function\n",
    "import torch.nn.utils.prune as prune\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fftshift\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn, einsum\n",
    "import logging\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "import matplotlib as mp\n",
    "import time\n",
    "from scipy.signal import savgol_filter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('BRCA.csv')\n",
    "dat = dat.drop(dat.columns[[0]], axis=1)\n",
    "dat = dat.T\n",
    "feature_num = dat.shape[1]\n",
    "data_num = dat.shape[0]\n",
    "dat = dat.values.reshape(-1,1,feature_num)\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I'm plugging my own dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "from utils import data_handler\n",
    "from utils import benchmark\n",
    "from utils import visualisation\n",
    "from utils.models import vanilla_autoencoder\n",
    "\n",
    "importlib.reload(data_handler) # to allow modification of the script without restarting the whole session\n",
    "\n",
    "\n",
    "as_time_series = True\n",
    "x_train, filenames, n_genes, gene_names = data_handler.generate_dataset_cancer(\n",
    "    feature_selection_threshold = 2, \n",
    "    batch_size = 32, \n",
    "    normalization = False,\n",
    "    log1p = True,\n",
    "    min_max = True)\n",
    "\n",
    "data = np.concatenate(list(x_train.as_numpy_iterator()), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding my own labels :\n",
    "\n",
    "filenames_ = [fn.split(\"/\")[-1] for fn in filenames]\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"/Users/aygalic/Thesis/data/cancer/metadata.cart.2023-09-11.json\", 'r') as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "\n",
    "# Read clinical data from TSV file\n",
    "clinical = pd.read_csv(\"/Users/aygalic/Thesis/data/cancer/clinical.cart.2023-09-11/clinical.tsv\", sep='\\t')\n",
    "\n",
    "\n",
    "def get_clinical_info(given_filename):\n",
    "    matching_index = None\n",
    "\n",
    "    # Loop through metadata to find a match\n",
    "    for i, item in enumerate(metadata):\n",
    "        if item[\"file_name\"] == given_filename:\n",
    "            matching_index = i\n",
    "            break\n",
    "    \n",
    "    case_id = metadata[matching_index][\"associated_entities\"][0][\"case_id\"]\n",
    "    return clinical[clinical[\"case_id\"] == case_id][\"tissue_or_organ_of_origin\"].values[0]\n",
    "\n",
    "clinical_info = [get_clinical_info(filename) for filename in tqdm(filenames_)]\n",
    "clinical_info[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(data)\n",
    "feature_num = dat.shape[1]\n",
    "data_num = dat.shape[0]\n",
    "dat = dat.values.reshape(-1,1,feature_num)\n",
    "print(dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, data1 ,transform = None):\n",
    "        self.transform = transform\n",
    "        self.data1 = data1\n",
    "        self.datanum = len(data1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        out_data1 = torch.tensor(self.data1[idx]).float() \n",
    "        if self.transform:\n",
    "            out_data1 = self.transform(out_data1)\n",
    "\n",
    "        return out_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dat, test_size = 0.3,random_state = 66)\n",
    "print('train data:',len(train_data))\n",
    "print('test data:',len(test_data))\n",
    "train_data_set = Mydatasets(data1 = train_data)\n",
    "test_data_set = Mydatasets(data1 = test_data)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data_set, batch_size = 256, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_set, batch_size = 32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
    "        self._commitment_cost = commitment_cost\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = rearrange(inputs, 'b c l -> b l c')\n",
    "        inputs = inputs.contiguous()\n",
    "        #inputs = inputs.permute(0, 2, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        quantized = rearrange(quantized, 'b c l -> b l c')\n",
    "        quantized = quantized.contiguous()\n",
    "        \n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        #return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings\n",
    "        return loss, quantized, perplexity, encodings\n",
    "    \n",
    "class VectorQuantizerEMA(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5):\n",
    "        super(VectorQuantizerEMA, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.normal_()\n",
    "        self._commitment_cost = commitment_cost\n",
    "        \n",
    "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
    "        self._ema_w = nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
    "        self._ema_w.data.normal_()\n",
    "        \n",
    "        self._decay = decay\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = rearrange(inputs, 'b c l -> b l c')\n",
    "        inputs = inputs.contiguous()\n",
    "        #inputs = inputs.permute(0, 2, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Use EMA to update the embedding vectors\n",
    "        if self.training:\n",
    "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
    "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
    "            \n",
    "            # Laplace smoothing of the cluster size\n",
    "            n = torch.sum(self._ema_cluster_size.data)\n",
    "            self._ema_cluster_size = (\n",
    "                (self._ema_cluster_size + self._epsilon)\n",
    "                / (n + self._num_embeddings * self._epsilon) * n)\n",
    "            \n",
    "            dw = torch.matmul(encodings.t(), flat_input)\n",
    "            self._ema_w = nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
    "            \n",
    "            self._embedding.weight = nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        loss = self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        # Straight Through Estimator\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        quantized = rearrange(quantized, 'b c l -> b l c')\n",
    "        quantized = quantized.contiguous()\n",
    "        \n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "               \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        #return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings\n",
    "        return loss, quantized, perplexity, encodings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self, encoder_dim):\n",
    "        super(ResidualStack, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, encoder_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, encoder_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.lay1 = nn.Sequential(\n",
    "            nn.Linear(input_size, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.lay2 = nn.Sequential(\n",
    "            nn.Linear(2048, encoder_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self._residual_stack = ResidualStack(encoder_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.lay1(inputs)\n",
    "        x = self.lay2(x)        \n",
    "        x = self._residual_stack(x)\n",
    "        return x \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_embeddings, input_size, encoder_dim, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.lay0 = nn.Sequential(\n",
    "            nn.Linear(num_embeddings, encoder_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self._residual_stack = ResidualStack(encoder_dim)\n",
    "        \n",
    "        self.lay1 = nn.Sequential(\n",
    "            nn.Linear(encoder_dim, 2048),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        self.lay2 = nn.Sequential(\n",
    "            nn.Linear(2048, input_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.lay0(inputs)\n",
    "        x = self._residual_stack(x)\n",
    "        x = self.lay1(x)\n",
    "        x = self.lay2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, encoder_dim, num_embeddings, embedding_dim, commitment_cost, dropout, decay=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self._encoder = Encoder(input_size, encoder_dim, dropout)\n",
    "        \n",
    "        self._pre_vq_conv = nn.Linear(encoder_dim, num_embeddings)\n",
    "        \n",
    "        if decay > 0.0:\n",
    "            self._vq_vae = VectorQuantizerEMA(num_embeddings, embedding_dim, commitment_cost, decay)\n",
    "        else:\n",
    "            self._vq_vae = VectorQuantizer(num_embeddings, embedding_dim, commitment_cost)\n",
    "            \n",
    "        self._decoder = Decoder(num_embeddings, input_size, encoder_dim, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self._encoder(x)\n",
    "        z = self._pre_vq_conv(z)\n",
    "        loss, quantized, perplexity, _ = self._vq_vae(z)\n",
    "        x_recon = self._decoder(quantized)\n",
    "        return loss, x_recon, perplexity, _, quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "out_dim = 512   \n",
    "VQ_VAE = Model(\n",
    "            dropout = 0.0,\n",
    "            input_size = feature_num, \n",
    "            encoder_dim = out_dim,\n",
    "            num_embeddings = 64,  \n",
    "            embedding_dim = 64,   \n",
    "            commitment_cost = 1\n",
    "           ).to(DEVICE)\n",
    "\n",
    "Classifier_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(VQ_VAE.parameters(), lr=1e-3, amsgrad=False)\n",
    "data_variance = np.var(dat)\n",
    "\n",
    "# no pre train\n",
    "# VQ_VAE.load_state_dict(torch.load('VQ_VAE_disc'),strict=False)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "train_res_recon_error = []\n",
    "train_res_perplexity = []\n",
    "\n",
    "loss_list=[]\n",
    "val_loss_list=[]\n",
    "ac_list=[]\n",
    "\n",
    "VQ_VAE.train()\n",
    "\n",
    "\n",
    "for epoch in tqdm.tqdm(range(EPOCH)):\n",
    "    running_loss = 0.0\n",
    "    count=0\n",
    "    quantized_merge = torch.empty(0,1,64).to(DEVICE)\n",
    "    for labels, (inputs) in enumerate(train_dataloader, 0):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        #labels = labels.to(DEVICE) # prob a mistake from dev\n",
    "                \n",
    "        vq_loss, data_recon, perplexity, _, quantized = VQ_VAE(inputs)\n",
    "        recon_error = F.mse_loss(data_recon, inputs) / data_variance\n",
    "        loss = recon_error + vq_loss \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lat = []\n",
    "en_quantized = []\n",
    "data_set = Mydatasets(data1 = dat)\n",
    "data_set = torch.utils.data.DataLoader(data_set, batch_size = 256, shuffle=True)\n",
    "\n",
    "for i in range(len(dat)):\n",
    "    en_data = data_set.dataset[i][0]\n",
    "    latent_1 = VQ_VAE._encoder(en_data.view(1, 1, feature_num).float().to(DEVICE))\n",
    "    _, _, _, _,latent_2 = VQ_VAE(en_data.view(1, 1, feature_num).float().to(DEVICE))\n",
    "    en_lat.append(latent_1.cpu().detach().numpy())\n",
    "    en_quantized.append(latent_2.cpu().detach().numpy())\n",
    "\n",
    "encode_out = np.array(en_lat)\n",
    "encode_out = encode_out.reshape(len(dat), -1)\n",
    "quantized_out = np.array(en_quantized)\n",
    "quantized_out = quantized_out.reshape(len(dat), -1)\n",
    "print('encode_out:', encode_out.shape)\n",
    "print('quantized_out:', quantized_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_Z = encode_out\n",
    "\n",
    "tsne = TSNE(early_exaggeration=50,\n",
    "              learning_rate=500, \n",
    "              perplexity=50, \n",
    "              min_grad_norm=1e-7, \n",
    "              n_iter=3000,\n",
    "              n_components=2).fit_transform(latent_Z)\n",
    "x_min, x_max = np.min(tsne, 0), np.max(tsne, 0)\n",
    "tsne = tsne / (x_max - x_min)\n",
    "print('TSNE_out:', tsne.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index = pd.read_csv('BRCA-label.csv', header=0)\n",
    "#index = index[0 :data_num].astype(int)\n",
    "#label = index.values.tolist()  \n",
    "\n",
    "True_labels = pd.DataFrame({\"Labels\" : clinical_info})\n",
    "n_labels = 5 # only legend the top 5 cases\n",
    "label_counts = True_labels['Labels'].value_counts()\n",
    "top_labels = label_counts.index[:n_labels]\n",
    "True_labels['Labels'] = True_labels['Labels'].apply(lambda x: x if x in top_labels else 'other')\n",
    "\n",
    "\n",
    "TSNE_result = pd.DataFrame(tsne, columns=['TSNE_Dim1', 'TSNE_Dim2'])\n",
    "TSNE_result['Subtype'] = True_labels\n",
    "#tsne of learened feature\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.set(style='darkgrid',context='notebook')\n",
    "sns.scatterplot(data = TSNE_result, x='TSNE_Dim1', y='TSNE_Dim2',hue='Subtype',palette='RdBu',s = 70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_result['Subtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#PCA of learened feature\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(latent_Z)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_)\n",
    "pca_result = pca.transform(latent_Z)\n",
    "print('pca_result:',pca_result.shape)\n",
    "\n",
    "sns.set(style='darkgrid',context='notebook')\n",
    "plt.figure(figsize=(6,6)) \n",
    "\n",
    "my_cmap = plt.get_cmap('viridis', len(TSNE_result['Subtype'].unique()))\n",
    "# Map string labels to numeric values\n",
    "subtype_labels = TSNE_result['Subtype'].unique()\n",
    "subtype_to_numeric = {subtype: i for i, subtype in enumerate(subtype_labels)}\n",
    "colors = [my_cmap(subtype_to_numeric[subtype]) for subtype in TSNE_result['Subtype']]\n",
    "\n",
    "a = plt.scatter(pca_result[:, 0], pca_result[:, 1], marker='o', cmap=my_cmap,c=colors,s=20)\n",
    "\n",
    "L = plt.legend(*a.legend_elements(),\n",
    "           borderaxespad = 1,\n",
    "           title_fontsize = 13,\n",
    "           fontsize = 13,\n",
    "           loc = (0,1.01),\n",
    "           ncol = 5,\n",
    "           title=\"Subtype\")\n",
    "\n",
    "plt.xlabel(\"PCA_dim1\", size=24)  \n",
    "plt.ylabel(\"PCA_dim2\", size=24)\n",
    "plt.tick_params(axis='x', which='both', labelsize=25)\n",
    "plt.tick_params(axis='y', which='both', labelsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = sns.jointplot(x=TSNE_result.TSNE_Dim1, y=TSNE_result.TSNE_Dim2, cmap=\"Blues\", fill=True, kind='kde',height=6,\n",
    "                 marginal_kws={\"alpha\":.2},thresh=0.05, alpha=.8)\n",
    "f.ax_joint.set_xlabel(\"TSNE_dim1\",fontsize=25)\n",
    "f.ax_joint.set_ylabel(\"TSNE_dim2\",fontsize=25)\n",
    "f.ax_joint.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.jointplot(x=TSNE_result.TSNE_Dim1, y=TSNE_result.TSNE_Dim2, fill=True, kind='kde',hue=TSNE_result.Subtype,height=6,marginal_kws={\"alpha\":.2},thresh=0.05, alpha=.9)\n",
    "\n",
    "f.ax_joint.legend_._visible=False\n",
    "f.ax_joint.set_xlabel(\"TSNE_dim1\",fontsize=25)\n",
    "f.ax_joint.set_ylabel(\"TSNE_dim2\",fontsize=25)\n",
    "f.ax_joint.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(quantized_out)\n",
    "corr = df.corr(method = 'spearman')\n",
    "sns.clustermap(pd.DataFrame(corr),cmap = 'mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN architecture\n",
    "\n",
    "\n",
    "In this notebook, we aim to evaluate the performance of the Convolutional Autoencoder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# data analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pytorch specific\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# project specific\n",
    "sys.path.append('../')\n",
    "from src import config\n",
    "from src.utils import experiment, helpers\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.options.display.width = 1000\n",
    "DEVICE = torch.device(config[\"DEVICE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid\n",
    "\n",
    "Here we define the parametters to search through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first set the parametters that we do no want to change\n",
    "\n",
    "data_params = { \n",
    "    \"LS_threshold\" : 0.0023,\n",
    "    \"MAD_threshold\" : 1, \n",
    "    \"MT_removal\" : True, \n",
    "    \"expression_threshold\" : 0.1}\n",
    "\n",
    "# or we can use a pre loaded dataset to save time\n",
    "data_params = '../workfiles/light_BRCA_ds.pkl'\n",
    "\n",
    "model_params = {\n",
    "    \"dropout\" : 0.2,\n",
    "    \"latent_dim\" : 64,\n",
    "    \"variational\" : False,\n",
    "    \"convolution\": True,\n",
    "    \"transformer\" : False\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(helpers)\n",
    "\n",
    "\n",
    "dynamic_params = {\n",
    "    \"dropout\" : [0.1, 0.3, 0.5],\n",
    "    \"latent_dim\": [16, 32, 64, 128],\n",
    "    # ... (any other uncoupled parameters)\n",
    "    # Coupled parameters are passed as tuples within the list\n",
    "    \"conv_params\": [\n",
    "        ((\"padding\", 3), (\"kernel_size\", 7)),\n",
    "        ((\"padding\", 2), (\"kernel_size\", 5)),\n",
    "        ((\"padding\", 1), (\"kernel_size\", 3))\n",
    "    ]\n",
    "    # Note: The key \"conv_params\" is only a placeholder and won't appear in the final configs.\n",
    "}\n",
    "\n",
    "configurations = helpers.generate_config(model_params, dynamic_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(configurations[0])\n",
    "print(len(configurations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(experiment)\n",
    "experiments = []\n",
    "\n",
    "for config in configurations:\n",
    "    e = experiment.Experiment(data_param=data_params, model_param=config, n_epoch= 3000)\n",
    "    e.run()\n",
    "\n",
    "    experiment_data = {**config,'score': e.metric}\n",
    "    experiments.append(experiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(experiments)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../workfiles/CNN_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the experiment with the highest score.\n",
    "best_experiment = max(experiments, key=lambda exp: exp['score'])\n",
    "\n",
    "# 'best_experiment' now holds the dictionary with the highest 'score' value.\n",
    "best_config = best_experiment\n",
    "highest_score = best_experiment['score']\n",
    "\n",
    "# You can print or otherwise use 'best_config' and 'highest_score' as needed.\n",
    "print(\"Best configuration:\", best_config)\n",
    "print(\"Highest score:\", highest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

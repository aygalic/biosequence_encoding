{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# data analysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pytorch specific\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# project specific\n",
    "sys.path.append('../src')\n",
    "from utils import data_handler\n",
    "from utils import visualisation\n",
    "from models import torch_vanilla_AE\n",
    "\n",
    "pd.options.display.width = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../workfiles/BRCA_ds.pkl', 'rb') as f:\n",
    "    data, metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = data\n",
    "print(dat.shape)\n",
    "feature_num = dat.shape[1]\n",
    "dat = dat.reshape(-1,1,feature_num)\n",
    "print(dat.shape)\n",
    "label = metadata[\"PAM50_labels\"]\n",
    "feature_num = metadata[\"n_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, data1 ,transform = None):\n",
    "        self.transform = transform\n",
    "        self.data1 = data1\n",
    "        self.datanum = len(data1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        out_data1 = torch.tensor(self.data1[idx]).float() \n",
    "        if self.transform:\n",
    "            out_data1 = self.transform(out_data1)\n",
    "\n",
    "        return out_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dat, test_size = 0.1, random_state = 66)\n",
    "print('train data:',len(train_data))\n",
    "print('test data:',len(test_data))\n",
    "train_data_set = Mydatasets(data1 = train_data)\n",
    "test_data_set = Mydatasets(data1 = test_data)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data_set, batch_size = 32, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_set, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# For m1 Mac\n",
    "DEVICE = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(torch_vanilla_AE)\n",
    "\n",
    "latent_dim = 32\n",
    "model = torch_vanilla_AE.Autoencoder(\n",
    "    shape = feature_num,\n",
    "    dropout = 0.1,\n",
    "    latent_dim= 64).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, amsgrad=False)\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_recon_error = []\n",
    "perplexities = []\n",
    "frames = []\n",
    "n_frames = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', min_lr= 0.000001)\n",
    "print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(EPOCH)):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "    quantized_merge = torch.empty(0, 1, 64).to(DEVICE)\n",
    "    \n",
    "    # Training loop\n",
    "    for _, inputs in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        data_recon = model(inputs)\n",
    "        loss = F.mse_loss(data_recon, inputs) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate and store training loss for this epoch\n",
    "    train_loss = running_loss / count\n",
    "    train_res_recon_error.append(train_loss)\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        en_lat = []\n",
    "        en_reconstruction = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        data_set = Mydatasets(data1 = dat)\n",
    "        data_set = torch.utils.data.DataLoader(data_set, batch_size = 256, shuffle=False) \n",
    "\n",
    "\n",
    "        for i in range(len(dat)):\n",
    "            en_data = data_set.dataset[i][0]\n",
    "            latent_1 = model._encoder(en_data.view(1, 1, feature_num).float().to(DEVICE))\n",
    "            data_recon = model(en_data.view(1, 1, feature_num).float().to(DEVICE))\n",
    "            en_lat.append(latent_1.cpu().detach().numpy())\n",
    "            en_reconstruction.append(data_recon.cpu().detach().numpy())\n",
    "\n",
    "        encode_out = np.array(en_lat).reshape(len(dat), -1)\n",
    "        reconstruction_out = np.array(en_reconstruction).reshape(len(dat), -1)\n",
    "\n",
    "\n",
    "        \n",
    "        # PCA of the latent space\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(encode_out)\n",
    "        pca_result = pca.transform(encode_out)\n",
    "\n",
    "        index_column = np.full((pca_result.shape[0], 1), n_frames, dtype=int)\n",
    "\n",
    "        pca_result_with_index = np.hstack((index_column, pca_result))\n",
    "\n",
    "        frames.append(pca_result_with_index)\n",
    "        n_frames += 1\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "\n",
    "            # stacking a single observation as well as its reconstruction in order to evaluate the results\n",
    "            stack = np.vstack([dat[0].reshape(1, -1), reconstruction_out[0].reshape(1, -1)])\n",
    "\n",
    "            # prepping a 1x4 plot to monitor the model through training\n",
    "            fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "\n",
    "\n",
    "            # Plot the line plot in the second subplot\n",
    "            axs[0].plot(train_res_recon_error, label='Training Loss')\n",
    "            axs[0].set_title('Training Loss Plot')\n",
    "            #axs[0].set_xticks([])\n",
    "\n",
    "            sns.heatmap(stack, ax=axs[1], cbar=False)\n",
    "            axs[1].set_title('Stacked heatmap of two samples')\n",
    "            axs[1].set_xticks([])\n",
    "            axs[1].set_yticks([])\n",
    "\n",
    "\n",
    "            sns.heatmap(encode_out, ax = axs[2], cbar=False)\n",
    "            axs[2].set_title('Heatmap of hole quantized dataset')\n",
    "            axs[2].set_xticks([])\n",
    "            axs[2].set_yticks([])\n",
    "\n",
    "\n",
    "            sns.scatterplot(x = pca_result[:, 0], y = pca_result[:, 1], c=label, ax=axs[3])\n",
    "            axs[3].set_title('PCA')\n",
    "            axs[3].set_xticks([])\n",
    "            axs[3].set_yticks([])\n",
    "\n",
    "            plt.subplots_adjust(wspace=0)  \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Plot training and validation loss curves\n",
    "epochs = np.arange(1, EPOCH + 1)\n",
    "plt.plot(epochs, train_res_recon_error, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(optimizer.param_groups[0]['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "en_lat = []\n",
    "en_reconstruction = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data_set = Mydatasets(data1 = dat)\n",
    "data_set = torch.utils.data.DataLoader(data_set, batch_size = 256, shuffle=False) \n",
    "\n",
    "\n",
    "for i in range(len(dat)):\n",
    "    en_data = data_set.dataset[i][0]\n",
    "    latent_1 = model._encoder(en_data.view(1, 1, feature_num).float().to(DEVICE))\n",
    "    data_recon = model(en_data.view(1, 1, feature_num).float().to(DEVICE))\n",
    "    en_lat.append(latent_1.cpu().detach().numpy())\n",
    "    en_reconstruction.append(data_recon.cpu().detach().numpy())\n",
    "\n",
    "encode_out = np.array(en_lat).reshape(len(dat), -1)\n",
    "reconstruction_out = np.array(en_reconstruction).reshape(len(dat), -1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PCA of the latent space\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(encode_out)\n",
    "pca_result = pca.transform(encode_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# stacking a single observation as well as its reconstruction in order to evaluate the results\n",
    "stack = np.vstack([dat[0].reshape(1, -1), reconstruction_out[0].reshape(1, -1)])\n",
    "\n",
    "# prepping a 1x4 plot to monitor the model through training\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "\n",
    "# Plot the line plot in the second subplot\n",
    "axs[0,0].plot(train_res_recon_error, label='Training Loss')\n",
    "axs[0,0].set_title('Training Loss Plot')\n",
    "\n",
    "\n",
    "sns.heatmap(stack, ax=axs[0,1], cbar=False)\n",
    "axs[0,1].set_title('Stacked heatmap of two samples')\n",
    "axs[0,1].set_xticks([])\n",
    "axs[0,1].set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(x = pca_result[:, 0], y = pca_result[:, 1], c=label, ax=axs[0,2])\n",
    "axs[0,2].set_title('PCA')\n",
    "axs[0,2].set_xticks([])\n",
    "axs[0,2].set_yticks([])\n",
    "\n",
    "\n",
    "sns.heatmap(data, ax = axs[1,0], cbar=False)\n",
    "axs[1,0].set_title('Heatmap of the hole dataset')\n",
    "axs[1,0].set_xticks([])\n",
    "axs[1,0].set_yticks([])\n",
    "\n",
    "sns.heatmap(encode_out, ax = axs[1,1], cbar=False)\n",
    "axs[1,1].set_title('Heatmap of the hole latent space')\n",
    "axs[1,1].set_xticks([])\n",
    "axs[1,1].set_yticks([])\n",
    "\n",
    "sns.heatmap(reconstruction_out, ax = axs[1,2], cbar=False)\n",
    "axs[1,2].set_title('Heatmap of the hole recontruction')\n",
    "axs[1,2].set_xticks([])\n",
    "axs[1,2].set_yticks([])\n",
    "\n",
    "plt.subplots_adjust(wspace=0)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "#%matplotlib notebook\n",
    "\n",
    "# Create a figure and axis for the animation\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Define an update function for the animation\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    ax.set_title(f'Frame {frame}')\n",
    "    \n",
    "    # Get the PCA result for the current frame\n",
    "    pca_result = frames[frame]\n",
    "    \n",
    "    # Scatter plot of PCA results with color based on index\n",
    "    scatter = ax.scatter(pca_result[:, 1], pca_result[:, 2], c=label)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, update, frames=n_frames, repeat=True)\n",
    "\n",
    "# Display the animation as HTML\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('../img/GDS_pca_vanilla_AE_0.mp4', writer='ffmpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../workfiles/torch_AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

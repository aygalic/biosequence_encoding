{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks  \n",
    "\n",
    "# project specific\n",
    "from utils import data_handler\n",
    "from utils.models import cnn_encoder\n",
    "\n",
    "%load_ext tensorboard\n",
    "!rm -rf ../workfiles/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading samples...\n",
      "loaded 1585 samples\n",
      "selecting genes based on median absolute deviation threshold:  2 ...\n",
      "number of genes selected :  14864\n",
      "normalizing data...\n",
      "normalization done\n",
      "number of seq to be analized : 1585\n",
      "number of actual individual to be studied : 317\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(data_handler) # to allow modification of the script without restarting the whole session\n",
    "\n",
    "sgdc_params = {\n",
    "            #'penalty':[\"elasticnet\", \"l1\", \"l2\"],\n",
    "            'penalty':[\"l1\"],\n",
    "            #'l1_ratio':np.linspace(0.1, 1, 5),\n",
    "            'alpha':np.linspace(0.1, 0.5, 5),\n",
    "        }\n",
    "\n",
    "x_train, filenames, n_genes = data_handler.generate_timeseries_dataset(feature_selection_threshold = 2, \n",
    "                                                   #feature_selection_proceedure = \"LASSO\", \n",
    "                                                   retain_phases=\"Both\", \n",
    "                                                   #retain_phases=None, \n",
    "                                                   return_id = True,\n",
    "                                                   sgdc_params = sgdc_params,\n",
    "                                                   #subsample = 100,\n",
    "                                                   #class_balancing = \"match_smaller_sample\")\n",
    "                                                   class_balancing = \"balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cnn_encoder) # to allow modification of the script without restarting the whole session\n",
    "\n",
    "latent_dim = 64\n",
    "sequence_length = 5\n",
    "t_shape = (sequence_length, n_genes)\n",
    "\n",
    "\n",
    "autoencoder = cnn_encoder.generate_model(t_shape, latent_dim)\n",
    "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '../workfiles/simple_ae/checkpoint'\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                              patience=25, min_lr=0.00001)\n",
    "\n",
    "early_stopping_callback = callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "\n",
    "log_dir = \"../workfiles/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "cb = [model_checkpoint_callback, \n",
    "      reduce_lr, \n",
    "      early_stopping_callback, \n",
    "      tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.build(input_shape = (None, sequence_length, n_genes))\n",
    "#autoencoder.encoder.summary()\n",
    "#autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "5/5 [==============================] - 25s 6s/step - loss: 6.6310e-05 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.3925e-05"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.fit(x_train, epochs=2000, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(checkpoint_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "print(hist.history['loss'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 6161), dtype=float32, numpy=\n",
       "array([[  28.0786,   48.2889,   31.8768, ...,   21.601 ,   14.5302,\n",
       "          43.2891],\n",
       "       [  34.8483,   55.0274,   36.8456, ...,   28.7308,   33.4212,\n",
       "          42.899 ],\n",
       "       [  31.6444,   57.4141,   41.5785, ...,   37.2859,   22.7498,\n",
       "          95.4406],\n",
       "       ...,\n",
       "       [  29.2446,   57.8746,   54.0729, ...,   83.0774,   39.6068,\n",
       "         172.727 ],\n",
       "       [  42.2485,   58.0206,   36.2277, ...,   65.3682,   19.7801,\n",
       "         115.36  ],\n",
       "       [1085.74  ,   54.7478,   37.7932, ...,   68.5695,   75.1809,\n",
       "         106.025 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = iter(x_train).next()\n",
    "z = autoencoder.encoder(e)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 64), dtype=float32, numpy=\n",
       "array([[0.0000000e+00, 1.1011568e+00, 8.5003336e-24, ..., 5.6258583e-33,\n",
       "        6.5438644e+01, 0.0000000e+00],\n",
       "       [0.0000000e+00, 8.4733200e+01, 1.3865252e-31, ..., 0.0000000e+00,\n",
       "        5.2268614e-14, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.2151521e+01, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 2.0064553e-29],\n",
       "       ...,\n",
       "       [5.5866787e-33, 5.3734863e+01, 4.0491797e-14, ..., 1.0285117e-18,\n",
       "        5.3045254e+01, 3.3808381e-09],\n",
       "       [1.8548418e-27, 6.9199547e+01, 6.2420300e-17, ..., 0.0000000e+00,\n",
       "        9.0398363e-15, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0115930e+02, 3.0693047e-25, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(autoencoder.decoder(z))\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../workfiles/cnn_autoencoer_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../workfiles/cnn_autoencoer_model/assets\n"
     ]
    }
   ],
   "source": [
    "autoencoder.encoder.save('../workfiles/cnn_autoencoer_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "compressed_dataframe = autoencoder.encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(compressed_dataframe)\n",
    "df[\"name\"] = filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../workfiles/compressed_data_cnn_autoencoder_phase_2.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

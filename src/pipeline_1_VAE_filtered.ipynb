{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_path = '/Users/aygalic/OneDrive/polimi/Thesis/data/quant/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting entries ready\n",
    "# each couple of entries correspond to one patient\n",
    "\n",
    "entries = os.listdir(absolute_path)\n",
    "entries_transcripts = [e for e in entries if \"transcripts\" in e ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a TensorFlow input pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to build a tf.Dataset from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from filename to tensor\n",
    "\n",
    "def load_patient_data(filename):\n",
    "  #specify read types for our data\n",
    "  read_types = [float()]\n",
    "  # get a first sample to base everything of\n",
    "  text = pathlib.Path(absolute_path + filename).read_text()\n",
    "  lines = text.split('\\n')[1:-1]\n",
    "  features = tf.io.decode_csv(lines, record_defaults=read_types, field_delim = \"\\t\", select_cols=[3]) \n",
    "  data = tf.convert_to_tensor(features)[0]\n",
    "\n",
    "  return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed it into a net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we build a tf.dataset with all patients inside\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into a list using the first pipeline\n",
    "\n",
    "train_ds = [load_patient_data(e) for e in entries_transcripts]\n",
    "train_ds = [e for e in train_ds if e.shape == (95309)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  6.55631,  0.     , ..., 21.601  , 14.5302 , 43.2891 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    ,  2.6901,  0.    , ..., 28.7308, 33.4212, 42.899 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  3.11716,  56.9107 ,  12.8459 , ..., 346.531  , 649.73   ,\n",
       "        311.662  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.80586 ,  0.365711, ..., 37.2859  , 22.7498  ,\n",
       "        95.4406  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.58126 ,  0.120558, ..., 63.181   , 12.8496  ,\n",
       "        84.2115  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  7.04612 ,  0.365312, ..., 45.6259  , 32.0575  ,\n",
       "        60.2416  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   7.51996,   3.75277, ..., 131.13   , 137.239  ,\n",
       "        149.522  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.57237 ,   0.192618, ...,  52.8186  ,  24.75    ,\n",
       "        101.512   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.89136 ,  0.106125, ..., 42.2366  , 14.1289  ,\n",
       "        77.0653  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 11.9634  ,  0.400998, ..., 61.666   , 25.4996  ,\n",
       "        99.7885  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.83306 ,  0.292078, ..., 22.2433  , 20.2181  ,\n",
       "        41.9403  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.593857,   5.99637 ,   0.343176, ...,  83.0846  ,  19.3211  ,\n",
       "        119.742   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    ,  3.4772,  0.    , ..., 41.4236, 37.313 , 66.9816],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  19.954   ,   0.523544, ..., 117.159   ,  23.6683  ,\n",
       "        156.688   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  6.35145 ,  0.565537, ..., 35.2414  , 33.0365  ,\n",
       "        87.4962  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.296953,  4.45643 ,  0.261944, ..., 41.8635  , 20.685   ,\n",
       "        78.4352  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.26813e+00, 9.60314e-02, ..., 5.28380e+01,\n",
       "        1.43818e+01, 9.93591e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.158555,  2.42192 ,  0.482246, ..., 27.8172  , 22.3089  ,\n",
       "        57.1071  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.157895,  7.56427 ,  0.363052, ..., 68.6042  , 40.3444  ,\n",
       "        95.9703  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  26.5144,   0.    , ..., 114.772 ,  23.0126, 142.976 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.04215 ,   0.897513, ...,  96.0767  ,  32.5303  ,\n",
       "        212.069   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.234005,  2.38931 ,  0.      , ..., 34.2729  , 20.4012  ,\n",
       "        49.5444  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.39634e+01, 1.08411e-01, ..., 6.22510e+01,\n",
       "        1.89159e+01, 1.56040e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.35432 ,   0.538733, ..., 100.452   ,  41.7194  ,\n",
       "        210.335   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.317793,  2.9193  ,  0.247105, ..., 35.3111  , 20.9814  ,\n",
       "        57.407   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.49078,  0.     , ..., 44.0542 , 17.3915 , 63.3757 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.15215 ,   0.478678, ...,  68.6561  ,  51.0609  ,\n",
       "        213.607   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.87875e-01, 4.04515e+01, 2.56917e-01, ..., 2.25547e+02,\n",
       "        7.54829e+01, 2.93644e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  15.8444  ,   0.214052, ...,  50.8796  ,  17.3907  ,\n",
       "        130.758   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.85792,  0.12965, ..., 33.135  , 17.4346 , 58.0181 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   52.9981,   11.0452, ..., 1970.69  , 4761.56  ,\n",
       "        1692.5   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  1.53189  ,  0.0725633, ..., 17.5463   , 14.8966   ,\n",
       "        44.4485   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.38147 ,   0.107929, ...,  63.7768  ,  54.7074  ,\n",
       "        101.357   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  21.9321 ,   1.25419, ..., 218.096  , 148.937  ,\n",
       "        281.607  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.255367,  2.01473 ,  0.319336, ..., 44.007   , 26.3546  ,\n",
       "        80.0729  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.3146  ,   0.231283, ...,  80.4348  ,  40.4693  ,\n",
       "        123.82    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.14589e+00, 5.42321e-02, ..., 4.15617e+01,\n",
       "        1.72645e+01, 1.05260e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.9951 ,  0.33697, ..., 37.5662 , 17.8211 , 69.5301 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.62069 ,   0.461617, ...,  60.2409  ,  35.3183  ,\n",
       "        117.631   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.406864,  4.25337 ,  0.      , ..., 55.0661  , 30.538   ,\n",
       "        96.0313  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.767734,  4.79852 ,  0.396912, ..., 73.3469  , 50.3276  ,\n",
       "        98.6084  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.25693e-02, 2.88205e+01, 7.97771e+00, ..., 1.92304e+02,\n",
       "        3.13896e+02, 2.54058e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.253828,   3.55486 ,   0.14318 , ...,  74.3347  ,  24.1552  ,\n",
       "        120.468   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.29311 ,  0.254515, ..., 18.2888  , 11.6245  ,\n",
       "        31.604   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.04673 ,   0.135996, ...,  66.7315  ,  15.0778  ,\n",
       "        125.874   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.52081 ,  0.291539, ..., 32.5038  ,  9.09329 ,\n",
       "        69.4767  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  40.39   ,   3.30527, ..., 388.917  , 396.134  ,\n",
       "        559.902  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  6.03424 ,  0.597459, ..., 48.0304  , 43.4481  ,\n",
       "        62.6743  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.85903e-04, 8.34345e+01, 7.72825e+00, ..., 7.78410e+02,\n",
       "        1.57111e+03, 6.72837e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  14.5053,   2.4963, ...,  73.8023,  63.6201, 113.474 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  8.93163,  2.13773, ..., 68.6406 , 61.6137 , 70.9909 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  1.41738  ,  0.0699459, ..., 16.6697   , 11.0548   ,\n",
       "        53.0822   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  6.12214,  0.     , ..., 35.446  , 22.356  , 48.6648 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.31179 ,  0.402837, ..., 38.1754  ,  9.42997 ,\n",
       "        97.1694  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  14.0061,   1.0539, ...,  93.4923,  58.2739, 187.972 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.416324,   6.12571 ,   0.528857, ...,  70.2686  ,  19.9068  ,\n",
       "        189.698   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.52496e+00, 4.97950e-02, ..., 3.38549e+01,\n",
       "        1.63035e+01, 5.30473e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.3491  ,   0.275208, ..., 104.977   ,  43.8784  ,\n",
       "        185.725   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  11.0282,   70.7692,   18.8401, ..., 1919.88  , 3579.63  ,\n",
       "        1728.82  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.69757e-01, 1.02720e+01, 1.55287e+00, ..., 3.01922e+02,\n",
       "        6.13345e+02, 3.82971e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.26471 ,   0.662419, ...,  86.4198  ,  46.9379  ,\n",
       "        159.307   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.42722e+00, 1.07160e-01, ..., 5.85088e+01,\n",
       "        2.61087e+01, 1.15978e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.81606 ,   0.995707, ..., 120.043   ,  74.038   ,\n",
       "        189.543   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  25.9941,   0.    , ..., 135.166 ,  61.9944, 173.719 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.75893,  0.     , ..., 14.8131 , 11.9455 , 34.1282 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,   6.5724,   0.    , ...,  43.1697,  21.7064, 113.907 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.44045 ,  0.653007, ..., 53.9031  , 39.7726  ,\n",
       "        54.7235  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.174556,   2.16811 ,   0.249737, ...,  53.9253  ,  23.9886  ,\n",
       "        104.045   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.42737e+00, 9.77387e-02, ..., 5.37938e+01,\n",
       "        2.65168e+01, 9.80659e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  9.63347 ,  0.171607, ..., 41.8769  , 21.4832  ,\n",
       "        51.3704  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.08575 ,   0.277047, ...,  69.5825  ,  39.1581  ,\n",
       "        108.149   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.81555 ,   0.411249, ..., 147.121   ,  50.6978  ,\n",
       "        214.758   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.338988,  4.84538 ,  0.486112, ..., 57.0506  , 38.4159  ,\n",
       "        94.6489  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.59305 ,   0.617123, ...,  92.1367  ,  39.3103  ,\n",
       "        155.281   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.5324  ,   0.301893, ...,  85.6156  ,  30.4878  ,\n",
       "        102.996   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  83.238 ,  16.7706, ..., 528.491 , 887.625 , 472.762 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     , 112.044  ,   3.47407, ..., 295.732  , 132.246  ,\n",
       "        471.975  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   8.06744,   0.     , ...,  61.8762 ,  28.9246 ,\n",
       "        100.163  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  18.6642  ,   0.275201, ...,  84.0052  ,  29.4218  ,\n",
       "        131.321   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   4.22668,   34.3951 ,    5.19982, ...,  853.228  , 1607.05   ,\n",
       "         775.398  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.75556,  0.41589, ..., 60.8072 , 26.0419 , 95.4516 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.37527 ,  0.451112, ..., 56.3396  , 32.6315  ,\n",
       "        57.2057  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.70055 ,   0.331994, ...,  95.3975  ,  25.4377  ,\n",
       "        157.53    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.73832,   0.25561, ...,  70.8938 ,  48.0226 ,\n",
       "        135.536  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.21286 ,  1.9829  ,  0.244269, ..., 27.2089  , 16.2396  ,\n",
       "        42.5194  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.51345,  0.19844, ..., 39.1472 , 32.6232 , 41.0369 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  40.0214,   0.    , ..., 163.804 , 267.965 , 175.489 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  43.9384 ,   1.25925, ..., 126.448  ,  70.5959 ,\n",
       "        203.781  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     , 27.1311 ,  0.     , ..., 23.533  ,  9.55031, 38.9379 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 21.7268  ,  0.158545, ..., 57.9228  , 15.8739  ,\n",
       "        91.8628  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.63745e+00, 1.69564e-01, ..., 1.54353e+02,\n",
       "        3.46091e+01, 3.73468e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.727481,  4.37231 ,  1.04822 , ..., 58.334   , 83.0469  ,\n",
       "        90.6189  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  34.2668  ,   0.181104, ...,  58.6351  ,  17.4279  ,\n",
       "        117.362   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.29562 ,  3.04737 ,  0.242157, ..., 30.1287  , 34.0368  ,\n",
       "        38.2469  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.11842,  31.2604 ,   5.86635, ..., 179.598  , 269.233  ,\n",
       "        192.877  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  4.82798  ,  0.0711008, ..., 29.6907   , 14.9883   ,\n",
       "        41.4585   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.59772 ,   0.542367, ...,  93.4505  ,  39.8612  ,\n",
       "        189.553   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 9.48976e+00, 6.94799e-02, ..., 6.40681e+01,\n",
       "        1.11880e+01, 9.74672e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.58855e-01, 2.19774e+01, 3.63604e-01, ..., 1.77784e+02,\n",
       "        7.69843e+01, 3.43017e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  16.5671  ,   0.686189, ...,  65.7123  ,  14.6844  ,\n",
       "        124.379   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.260574,  3.05953 ,  0.899366, ..., 54.3682  , 32.2189  ,\n",
       "        78.5147  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.68642,  0.     , ..., 37.3124 , 26.0787 , 64.3694 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  24.2666 ,   1.15277, ...,  74.8995 ,  43.9153 ,\n",
       "        107.929  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  5.98577,  25.5227 ,   2.70556, ..., 227.035  , 442.693  ,\n",
       "        269.078  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   8.51147,   1.65451, ...,  74.0023 ,  42.5777 ,\n",
       "        126.184  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.679562, 15.1754  ,  0.72364 , ..., 88.2746  , 93.7938  ,\n",
       "        56.2384  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.09170e-01, 3.53651e+01, 5.27926e-01, ..., 9.86514e+01,\n",
       "        4.43526e+01, 2.16703e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.93546,   0.     , ...,  70.1565 ,  28.6536 ,\n",
       "        201.238  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.76772,  0.     , ..., 46.3241 ,  6.93688, 82.5077 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.81871 ,   0.510818, ..., 123.679   , 137.383   ,\n",
       "        234.421   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.71182e+00, 1.49355e-01, ..., 7.45598e+01,\n",
       "        3.14743e+01, 1.75570e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.91891 ,   0.372489, ...,  83.0774  ,  39.6068  ,\n",
       "        172.727   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.86984e-01, 2.59836e+00, 3.22315e-01, ..., 1.46778e+02,\n",
       "        1.94533e+02, 1.67795e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.69421,   0.     , ...,  65.3682 ,  19.7801 ,\n",
       "        115.36   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  1.3726   ,  0.0575788, ..., 23.6591   , 11.7351   ,\n",
       "        55.0348   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.85958,  0.     , ..., 36.6519 , 16.0095 , 76.5149 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   9.43948,   1.01983, ...,  68.5695 ,  75.1809 ,\n",
       "        106.025  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.34667,  0.10836, ..., 10.1002 ,  9.85647, 22.114  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.14148 ,   0.170821, ...,  80.8434  ,  27.8837  ,\n",
       "        142.756   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.19141 ,  0.153869, ..., 23.1374  , 15.7968  ,\n",
       "        39.2018  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  14.3121 ,   1.17502, ..., 262.931  , 465.423  ,\n",
       "        224.967  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.62159e+01, 1.15336e+00, ..., 9.22383e+02,\n",
       "        2.17442e+03, 9.40699e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  48.6005  ,   0.409264, ...,  90.6202  ,  44.4595  ,\n",
       "        132.      ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  22.4335  ,   0.508843, ..., 118.694   ,  36.9477  ,\n",
       "        186.735   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  31.8694  ,   0.228278, ...,  81.4318  ,  43.5617  ,\n",
       "        140.255   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.18071,   0.45272, ..., 123.32   , 111.41   ,\n",
       "        206.883  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.44135,  0.     , ..., 32.7896 , 13.6476 , 87.3475 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  4.98268,  74.11   ,  16.295  , ..., 313.828  , 534.771  ,\n",
       "        303.555  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.63892e-01, 4.07459e+00, 2.81519e-01, ..., 4.82460e+01,\n",
       "        2.99992e+01, 1.78845e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.39647 ,   0.238194, ...,  82.5332  ,  31.1412  ,\n",
       "        160.524   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.361986,  14.1235  ,   0.629243, ..., 105.884   , 109.417   ,\n",
       "        153.048   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  0.879233 ,  0.0867448, ..., 34.9461   , 13.2647   ,\n",
       "        66.7048   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.246061,   5.76037 ,   0.280603, ...,  54.202   ,  29.614   ,\n",
       "        106.838   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  28.4192  ,   0.289822, ...,  81.6719  ,  28.0121  ,\n",
       "        121.308   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.41823,  1.073  ,  0.     , ..., 40.8886 , 20.9861 , 83.9525 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 11.7124  ,  0.130281, ..., 49.2827  , 20.6114  ,\n",
       "        70.7139  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.290651,  1.92735 ,  1.01627 , ..., 57.5542  , 13.9488  ,\n",
       "        84.2435  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.65095 ,   0.273574, ...,  68.2562  ,  25.4392  ,\n",
       "        154.294   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.65821,  0.     , ..., 58.9488 , 32.4752 , 88.1751 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.57394,   0.     , ...,  77.0281 ,  32.1483 ,\n",
       "        113.953  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      , 103.653   ,   0.515613, ..., 245.727   ,  87.078   ,\n",
       "        510.726   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.80201 ,   0.274078, ...,  66.9871  ,  12.6188  ,\n",
       "        115.498   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   73.1792,    6.7157, ..., 2652.01  , 3786.51  ,\n",
       "        1851.35  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  6.59278 ,  0.124649, ..., 44.2617  , 28.6289  ,\n",
       "        68.6695  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.15903 ,  2.68198 ,  0.185222, ..., 23.3916  , 28.4018  ,\n",
       "        47.3717  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.57279 ,   0.214969, ...,  43.4256  ,  15.7355  ,\n",
       "        105.079   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.48472,  0.     , ..., 37.6401 , 22.0196 , 49.4232 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.08767 ,   0.612603, ..., 108.919   ,  33.4268  ,\n",
       "        159.179   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.47638 ,  0.247029, ..., 38.575   , 29.5495  ,\n",
       "        60.3831  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.32328,  0.     , ..., 38.7611 , 13.5367 , 65.2885 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.18891 ,   0.353521, ...,  70.1688  ,  21.6817  ,\n",
       "        114.424   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.260158, 11.1471  ,  0.      , ..., 63.5715  , 18.4233  ,\n",
       "        86.6755  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.34464 ,  0.124694, ..., 63.0405  , 19.9661  ,\n",
       "        60.1289  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.67238 ,  0.245156, ..., 31.0867  ,  9.05987 ,\n",
       "        50.8195  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.696   ,   0.159843, ...,  58.603   ,  20.5575  ,\n",
       "        126.317   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.77468 ,  0.197071, ..., 44.4479  , 11.0398  ,\n",
       "        91.064   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.7459  ,  0.135215, ..., 39.9635  , 23.9421  ,\n",
       "        75.6378  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.3922  ,  0.164355, ..., 56.4216  , 26.4577  ,\n",
       "        98.3616  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.43962 ,   0.964954, ...,  93.3224  ,  98.6167  ,\n",
       "        164.16    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.167055,  2.30249 ,  0.2838  , ..., 27.0118  , 22.5788  ,\n",
       "        51.4826  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.29146e+01, 3.07738e-01, ..., 2.11122e+02,\n",
       "        9.33830e+01, 3.58468e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.239885 ,  2.07928  ,  0.0690252, ..., 21.9542   ,  7.02861  ,\n",
       "        64.6031   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   76.2643,   13.8311, ..., 2193.11  , 4724.83  ,\n",
       "        1413.06  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.513175,  0.621423, ..., 31.5524  ,  7.12006 ,\n",
       "        86.928   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  19.9403  ,   0.324321, ..., 155.05    , 121.838   ,\n",
       "        230.925   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.93333 ,  28.2058  ,   0.975115, ...,  97.0349  ,  32.7927  ,\n",
       "        154.111   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.5898  ,   0.187234, ...,  51.2803  ,  44.9219  ,\n",
       "        117.314   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  7.30611,  0.     , ..., 54.5958 , 19.5247 , 80.645  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.575605,   5.6876  ,   1.24535 , ...,  57.2342  ,  37.5986  ,\n",
       "        113.985   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.85276 ,  0.416961, ..., 43.3326  , 17.5724  ,\n",
       "        52.1862  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  43.4963 ,   7.53199, ..., 192.414  , 138.852  ,\n",
       "        246.076  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  62.2656 ,   6.70045, ..., 565.987  , 735.597  ,\n",
       "        608.913  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.14844 ,   0.366118, ...,  86.4485  ,  48.2499  ,\n",
       "        178.806   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.86097,  40.866  ,   4.13665, ..., 116.176  , 187.804  ,\n",
       "        154.649  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    , 11.1014,  0.    , ..., 24.1771, 18.8292, 48.6031],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   68.3308,   19.436 , ..., 1239.4   , 2457.09  ,\n",
       "         993.701 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.83861,  0.     , ..., 39.6681 , 25.9705 , 61.7989 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.627568,  7.49864 ,  0.237252, ..., 43.688   , 35.3714  ,\n",
       "        70.4185  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   3.63854,   0.20874, ...,  46.4533 ,  19.7656 ,\n",
       "        129.935  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   8.84541 ,   0.219808, ...,  57.6433  ,  17.7932  ,\n",
       "        121.81    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.159347 ,  1.61202  ,  0.0905669, ..., 34.2686   , 43.29     ,\n",
       "        57.0898   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.43839,   0.39854, ...,  89.9807 ,  37.5111 ,\n",
       "        181.57   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.42171e-01, 1.72389e+01, 1.95576e+00, ..., 5.53987e+02,\n",
       "        1.24713e+03, 5.33417e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.1779  ,   0.322402, ...,  62.068   ,  21.4782  ,\n",
       "        129.678   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  22.7001 ,   2.66685, ..., 157.772  , 123.951  ,\n",
       "        187.802  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  59.2869,   0.    , ..., 247.807 ,  58.7004, 348.118 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.00682 ,   0.536737, ..., 112.204   ,  45.3139  ,\n",
       "        221.608   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.53079,   1.08225, ...,  93.4704 ,  59.6066 ,\n",
       "        210.177  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   5.33421,   1.31047, ...,  88.3067 ,  35.9281 ,\n",
       "        127.213  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 38.3365  ,  0.208596, ..., 67.3484  , 30.5026  ,\n",
       "        99.5969  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.16440e+01, 4.77788e-02, ..., 2.36119e+02,\n",
       "        4.09839e+01, 2.74591e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  20.7965 ,   4.59196, ..., 125.319  ,  81.5939 ,\n",
       "        107.482  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.51596 ,  0.209954, ..., 44.039   , 17.4914  ,\n",
       "        94.6147  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.7267  ,   0.342854, ...,  58.4123  ,  21.5273  ,\n",
       "        102.633   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.94688 ,  0.157662, ..., 32.5794  , 25.0609  ,\n",
       "        51.4009  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  17.6182  ,   0.470452, ...,  73.7468  ,  33.8513  ,\n",
       "        115.742   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.99137,  10.6726 ,   1.87453, ...,  75.1047 ,  80.5581 ,\n",
       "        111.251  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  37.9163  ,   0.314448, ..., 197.901   ,  69.4436  ,\n",
       "        287.915   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   1.05329,   1.06535, ...,  71.9403 ,  49.3713 ,\n",
       "        134.441  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.08417 ,   0.134318, ...,  70.3416  ,  65.2039  ,\n",
       "        116.576   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 10.7174  ,  0.458906, ..., 41.1087  , 15.6065  ,\n",
       "        64.8437  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.5914  ,   0.256084, ...,  89.037   , 132.124   ,\n",
       "         92.7064  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.80917 ,   0.263396, ...,  48.4072  ,  20.9117  ,\n",
       "        133.085   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.4378  ,   0.464483, ...,  69.2951  ,  34.6719  ,\n",
       "        156.617   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  23.0056,   2.7859, ...,  80.3191, 126.539 , 108.357 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  23.6694  ,   0.868917, ...,  64.9243  ,  47.2398  ,\n",
       "        133.161   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.85178 ,  0.508806, ..., 19.2761  ,  7.01777 ,\n",
       "        31.8899  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.33711,  0.     , ..., 29.1087 , 30.202  , 51.4158 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.03457,  0.     , ..., 45.3875 , 13.8609 , 58.6535 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  37.3627  ,   0.696032, ..., 131.298   ,  42.343   ,\n",
       "        175.842   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  5.08494,  89.696  ,   6.29827, ..., 519.034  , 390.267  ,\n",
       "        672.174  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.9395  ,   0.562678, ..., 132.248   , 105.828   ,\n",
       "        228.328   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.08612e-01, 4.78168e+01, 5.31310e-01, ..., 2.71181e+02,\n",
       "        6.14339e+01, 3.90335e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 14.8035  ,  0.555164, ..., 43.1075  , 25.605   ,\n",
       "        80.8374  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.55917 ,  0.078235, ..., 36.8473  , 14.2945  ,\n",
       "        61.5693  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.295355,  2.98282 ,  0.      , ..., 28.3329  , 16.363   ,\n",
       "        50.5397  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  29.5337 ,   1.58499, ..., 169.735  , 283.042  ,\n",
       "        202.926  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.57031e+01, 1.33712e-01, ..., 9.44765e+01,\n",
       "        4.22817e+01, 1.42792e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   1.25204,   33.5057 ,    1.55404, ...,  649.172  , 1182.3    ,\n",
       "         735.821  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  13.3388 ,   0.31025, ..., 126.524  ,  64.0792 ,\n",
       "        276.91   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.72933 ,  0.182849, ..., 30.466   , 17.7637  ,\n",
       "        69.8968  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.01496e+00, 1.57503e-01, ..., 6.60238e+01,\n",
       "        2.29945e+01, 1.93347e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  13.0792  ,   0.544096, ..., 191.171   ,  44.2386  ,\n",
       "        433.273   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 10.9471 ,  57.0821 ,   8.54395, ..., 213.336  , 293.45   ,\n",
       "        239.347  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.56219 ,   0.132969, ...,  73.0078  ,  35.5619  ,\n",
       "        113.46    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.39928 ,  0.473753, ..., 62.769   , 41.9189  ,\n",
       "        74.4206  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   1.41951,   0.     , ..., 121.667  ,  77.8104 ,\n",
       "        196.016  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.8485  ,   0.168152, ...,  66.9144  ,  59.9184  ,\n",
       "        103.59    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  26.3373 ,   4.91228, ..., 213.781  , 313.111  ,\n",
       "        216.379  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.13433 ,   0.744086, ...,  58.2678  ,  20.2501  ,\n",
       "        101.732   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  6.07984 ,  0.638155, ..., 36.4213  , 29.0359  ,\n",
       "        33.2821  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   8.55102 ,   0.414927, ...,  99.8409  ,  47.076   ,\n",
       "        226.732   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.227671,  4.19974 ,  0.      , ..., 37.7827  , 19.4523  ,\n",
       "        57.481   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.81554e+01, 1.73396e-01, ..., 1.24349e+02,\n",
       "        2.11243e+01, 2.02711e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.9799  ,  0.511243, ..., 45.3211  , 14.8512  ,\n",
       "        73.0088  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.55587 ,   0.414847, ...,  51.4568  ,  30.2754  ,\n",
       "        113.133   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.2947  ,   0.410496, ..., 138.518   ,  34.5451  ,\n",
       "        219.133   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.60306,   0.     , ...,  71.9097 ,  36.1788 ,\n",
       "        204.313  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  29.3533  ,   0.509037, ..., 182.057   ,  74.3282  ,\n",
       "        321.854   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.239047 ,  3.61479  ,  0.0691962, ..., 22.8976   , 25.4245   ,\n",
       "        35.7774   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  40.5889 ,   5.76057, ..., 243.757  , 376.149  ,\n",
       "        220.775  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.621156,  29.2161  ,   0.427405, ..., 133.235   ,  77.8688  ,\n",
       "        192.84    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.02717 ,   0.348806, ...,  80.5945  ,  31.3731  ,\n",
       "        147.479   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.198486,  2.38055 ,  0.      , ..., 18.6022  , 12.0674  ,\n",
       "        25.439   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.49635 ,   0.387147, ...,  99.9592  ,  34.0236  ,\n",
       "        138.934   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  10.5836,   0.    , ...,  92.5859,  47.103 , 198.357 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  0.932407 ,  0.0357878, ..., 12.8117   ,  5.02855  ,\n",
       "        23.4345   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   8.83424 ,   0.511864, ...,  84.3015  ,  28.7768  ,\n",
       "        216.62    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  10.611  ,   0.40757, ...,  80.3069 ,  44.9887 ,\n",
       "        194.761  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.555939,  15.3481  ,   0.701905, ..., 118.48    , 149.287   ,\n",
       "        144.008   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.964092,  0.      , ..., 23.8234  , 10.9098  ,\n",
       "        68.638   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.13622 ,  12.3988  ,   0.257929, ...,  98.0558  ,  89.8223  ,\n",
       "        164.011   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  6.93636 ,  0.414061, ..., 45.4781  , 12.3244  ,\n",
       "        71.5233  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  27.9057,  190.48  ,   31.5861, ..., 1080.98  , 2007.9   ,\n",
       "        1019.84  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.81442e+00, 7.75683e-02, ..., 6.80071e+01,\n",
       "        2.36739e+01, 9.76426e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.52493,  5.63447,  1.67203, ..., 50.0932 , 52.4708 , 92.2127 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   8.01296 ,   0.724447, ..., 237.702   , 464.949   ,\n",
       "        266.355   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  7.84758 ,  0.590708, ..., 40.5007  , 25.3612  ,\n",
       "        81.6625  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.10267 ,  0.402133, ..., 40.5661  , 25.7398  ,\n",
       "        59.9711  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.81399,  0.     , ..., 29.1971 , 13.9487 , 66.8772 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.08611 ,   0.330707, ..., 104.016   ,  62.1672  ,\n",
       "        206.685   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.734936,   8.5724  ,   0.637357, ..., 146.732   , 346.197   ,\n",
       "        177.837   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.69727 ,  0.136524, ..., 70.6835  , 28.84    ,\n",
       "        95.0717  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.9577  ,   0.494752, ..., 101.478   ,  74.9466  ,\n",
       "        149.796   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.67976 ,  0.373676, ..., 45.019   , 10.7844  ,\n",
       "        72.9098  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([5.35329e-01, 1.36610e+02, 3.77690e-01, ..., 3.11520e+02,\n",
       "        1.71777e+02, 5.02689e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.319782,   9.5645  ,   0.36126 , ...,  66.3378  ,  28.1327  ,\n",
       "        127.11    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.18448 ,   0.245154, ...,  74.7123  ,  25.6674  ,\n",
       "        134.238   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.98774,  29.3489 ,   2.55284, ..., 194.011  , 201.844  ,\n",
       "        279.892  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  34.3005 ,   1.67594, ..., 303.596  , 187.577  ,\n",
       "        445.415  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  5.12713,  0.     , ..., 44.9534 , 23.278  , 79.544  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 1.0922  ,  4.23274 ,  0.375068, ..., 40.9212  , 24.6655  ,\n",
       "        51.7109  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.85189 ,  0.757671, ..., 40.7023  , 17.2699  ,\n",
       "        63.1627  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.59339 ,  0.439399, ..., 48.8203  , 16.7214  ,\n",
       "        86.644   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  3.74396  ,  0.0557812, ..., 17.4422   , 11.0926   ,\n",
       "        35.395    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.00124,  25.0688 ,   3.55802, ..., 133.676  , 143.424  ,\n",
       "        196.029  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.76714 ,  0.259085, ..., 38.0787  , 37.9822  ,\n",
       "        98.2153  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.40883,   5.94525,   0.35971, ...,  62.2265 ,  49.1418 ,\n",
       "        105.533  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([5.13784e-01, 8.25945e+00, 7.56117e-01, ..., 2.75853e+02,\n",
       "        5.93237e+02, 3.14377e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.56615e+01, 7.44699e-02, ..., 4.51473e+01,\n",
       "        2.87313e+01, 9.11794e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.3662  ,  0.192666, ..., 51.6121  , 24.9887  ,\n",
       "        92.575   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.736198,  3.32442 ,  0.752568, ..., 37.1208  , 30.2947  ,\n",
       "        45.3369  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.05781,  0.7553 , ..., 48.0945 , 31.9268 , 82.7427 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.31018,  0.61204, ..., 51.5703 , 16.2904 , 87.5025 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.33816 ,   0.103539, ...,  49.4643  ,  28.0314  ,\n",
       "        102.356   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.14013 ,   0.306801, ...,  62.0449  ,  22.3702  ,\n",
       "        109.21    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.76711 ,  0.445004, ..., 43.1267  , 22.3575  ,\n",
       "        63.3721  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.939757,  5.18859 ,  0.270225, ..., 48.0485  , 23.8976  ,\n",
       "        77.8224  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.7206  ,   0.266547, ...,  91.387   ,  42.5358  ,\n",
       "        160.663   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.33875 ,  0.127276, ..., 50.5713  , 11.2964  ,\n",
       "        91.4988  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.30785 ,   0.241524, ...,  89.6252  ,  22.5523  ,\n",
       "        122.278   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.11035 ,  0.260639, ..., 40.3955  , 20.758   ,\n",
       "        59.5988  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.11497 ,  0.297539, ..., 28.6187  , 25.6365  ,\n",
       "        40.083   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  7.79263,  0.2228 , ..., 42.5407 , 27.61   , 49.3609 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.3814  ,   0.461905, ...,  88.2506  ,  89.1476  ,\n",
       "        131.683   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.75055,   0.     , ..., 112.439  ,  27.8349 ,\n",
       "        215.563  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  10.1801,   0.    , ...,  97.9738,  20.4624, 160.838 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  11.2071  ,   0.583397, ...,  59.9652  , 110.649   ,\n",
       "         68.7825  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.620925,  3.79458 ,  0.39858 , ..., 73.6825  , 29.7173  ,\n",
       "        87.221   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  8.92382 ,  0.307953, ..., 48.3607  , 23.6859  ,\n",
       "        73.4417  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  22.0985  ,   0.235144, ...,  84.0139  ,  26.0009  ,\n",
       "        131.252   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.49350e-01, 6.14998e+01, 0.00000e+00, ..., 2.64523e+02,\n",
       "        8.32463e+01, 3.99043e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.94885 ,   0.794594, ..., 100.722   , 146.002   ,\n",
       "        102.782   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.50789,  0.14483, ..., 69.8894 , 29.4624 , 98.7782 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  32.0803 ,   0.30954, ..., 120.494  ,  44.2837 ,\n",
       "        249.97   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  3.50538,  28.5883 ,   5.51206, ..., 224.662  , 335.349  ,\n",
       "        234.921  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 20.9573  ,  0.584353, ..., 30.5105  , 31.1725  ,\n",
       "        54.8234  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  10.4185 ,   1.02839, ...,  99.1092 ,  75.4143 ,\n",
       "        132.656  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.378948 ,  2.30914  ,  0.0712426, ..., 31.3913   , 34.0839   ,\n",
       "        49.8269   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.62713 ,   0.623046, ...,  74.603   ,  22.6965  ,\n",
       "        102.6     ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.70458 ,  0.354493, ..., 60.6236  , 33.928   ,\n",
       "        84.0875  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.5614  ,   0.450016, ...,  84.5821  ,  28.7008  ,\n",
       "        141.1     ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.35185e-03, 4.81782e+00, 5.56404e-01, ..., 5.71696e+01,\n",
       "        3.90473e+01, 8.25024e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.304336,  3.17031 ,  0.173979, ..., 40.512   , 17.7324  ,\n",
       "        59.0239  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.68888 ,  0.181142, ..., 38.2221  , 31.0604  ,\n",
       "        43.5523  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.93952e+00, 6.96127e-02, ..., 7.46005e+01,\n",
       "        2.62161e+01, 1.13129e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.172267,  0.943143,  0.196492, ..., 32.7515  , 14.9771  ,\n",
       "        89.0039  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.80289 ,   0.189182, ...,  43.7932  ,  30.843   ,\n",
       "        128.116   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  17.8985  ,   0.173238, ...,  53.9852  ,  32.4595  ,\n",
       "        112.04    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.95222 ,  0.375358, ..., 22.7418  , 11.4391  ,\n",
       "        39.8435  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.245001,  12.0884  ,   0.491512, ..., 109.15    , 137.535   ,\n",
       "        140.628   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.0793  ,  0.580228, ..., 46.0125  , 18.179   ,\n",
       "        83.8407  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  39.3164  ,   0.379601, ..., 150.688   ,  26.5463  ,\n",
       "        320.407   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  5.79809,  0.     , ..., 24.511  , 19.1977 , 57.0365 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.10536 ,   0.378995, ...,  72.8213  ,  30.6781  ,\n",
       "        111.397   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  4.33729,  45.3438 ,   2.44177, ..., 379.726  , 252.794  ,\n",
       "        516.926  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.15191 ,   0.770305, ...,  71.3031  , 103.645   ,\n",
       "         81.7893  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.8378  ,  0.585044, ..., 52.7813  , 16.9502  ,\n",
       "        98.5958  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  50.333   ,   0.914889, ..., 205.607   ,  82.2039  ,\n",
       "        285.692   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.16999 ,   0.226572, ...,  53.1924  ,  18.8751  ,\n",
       "        147.564   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.57281 ,   0.444219, ...,  76.6143  ,  12.7349  ,\n",
       "        111.275   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    ,  0.9859,  0.    , ..., 11.7898, 10.3705, 29.0057],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.     ,   38.7025 ,    3.79793, ..., 1376.3    , 2397.66   ,\n",
       "        1233.01   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.66796 ,   0.511998, ..., 104.687   , 132.386   ,\n",
       "        122.153   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.64563,  0.     , ..., 57.4174 , 76.5436 , 75.1564 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.790087,  0.350931, ..., 20.984   ,  3.39123 ,\n",
       "        32.7186  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.297913,  6.69298 ,  0.240017, ..., 32.4512  , 11.0209  ,\n",
       "        69.7079  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.69716 ,   0.241385, ...,  73.7918  ,  27.2817  ,\n",
       "        114.003   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   8.54607 ,   0.887706, ...,  63.844   ,  58.071   ,\n",
       "        118.175   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.51122,  2.60822,  0.     , ..., 45.2367 , 25.6086 , 66.1346 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  15.9335 ,   4.88946, ..., 167.097  , 232.559  ,\n",
       "        184.09   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   60.3045,   10.6271, ..., 2515.49  , 3973.49  ,\n",
       "        2238.53  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.82829 ,   0.203186, ...,  49.6822  ,  25.2427  ,\n",
       "        129.844   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.76137,  0.     , ..., 24.2952 , 21.5269 , 49.3921 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.94419 ,  0.928163, ..., 32.1874  , 21.562   ,\n",
       "        95.7089  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   8.37549,   1.40698, ...,  97.7966 ,  66.8443 ,\n",
       "        174.596  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  11.0642  ,   0.409165, ...,  59.2366  ,  27.8417  ,\n",
       "        109.571   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.34379 ,  0.237515, ..., 56.4884  , 30.1522  ,\n",
       "        89.4453  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  9.04822,  2.1437 , ..., 46.6421 , 57.3798 , 57.5448 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 20.8593  ,  0.205167, ..., 68.8378  , 35.6731  ,\n",
       "        98.9121  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.213038, 15.0304  ,  0.      , ..., 36.3071  , 15.4202  ,\n",
       "        46.7168  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  4.92135  ,  0.0936932, ..., 49.1538   , 16.8849   ,\n",
       "        74.4381   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.899302,  0.      , ..., 18.1916  ,  9.2453  ,\n",
       "        47.1441  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.309129,   6.11346 ,   0.177   , ...,  65.0158  ,  14.5729  ,\n",
       "        125.838   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.67095 ,   0.189774, ...,  66.389   ,  64.6205  ,\n",
       "        114.697   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  20.2236 ,   1.76605, ..., 105.62   ,  65.6743 ,\n",
       "        196.59   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.13588e+02, 5.29783e-01, ..., 4.19769e+02,\n",
       "        1.36222e+02, 6.96215e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.11003 ,  0.206405, ..., 37.7659  , 16.3117  ,\n",
       "        75.404   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.81001 ,  0.401811, ..., 28.9049  , 13.7314  ,\n",
       "        49.851   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    ,  1.6228,  0.    , ..., 71.5404, 17.8658, 72.1119],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.261814,   4.76904 ,   0.301729, ..., 107.214   ,  48.2326  ,\n",
       "        241.815   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   3.90806,   0.44994, ...,  80.0668 ,  43.1557 ,\n",
       "        241.256  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    ,  2.5109,  0.    , ..., 49.6489, 38.9526, 53.0984],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  49.1471  ,   0.257613, ...,  84.524   ,  25.3482  ,\n",
       "        147.073   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.     ,   33.5802 ,    5.59314, ...,  842.456  , 1431.03   ,\n",
       "         792.582  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  34.8259 ,   4.25125, ..., 269.389  , 472.93   ,\n",
       "        250.212  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.613674,   9.91138 ,   0.807112, ..., 112.596   , 132.011   ,\n",
       "        132.458   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.08304 ,   0.459459, ...,  70.1963  ,  28.8939  ,\n",
       "        119.23    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.65268 ,  0.711885, ..., 60.5135  , 40.6109  ,\n",
       "        79.4901  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.26722 ,   0.152919, ...,  78.1811  ,  18.4192  ,\n",
       "        115.628   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.37078 ,   0.970985, ...,  81.6221  ,  25.8702  ,\n",
       "        141.575   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.34254,  18.7684 ,   5.14442, ..., 249.574  , 405.146  ,\n",
       "        230.489  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.16634 ,  0.303117, ..., 50.7744  , 29.3199  ,\n",
       "        96.3896  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 39.3522  ,  0.534849, ..., 31.9158  ,  9.27899 ,\n",
       "        61.425   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.84618 ,  0.287855, ..., 28.0428  , 28.2815  ,\n",
       "        58.7745  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  21.953   ,   0.720967, ..., 106.481   ,  41.2317  ,\n",
       "        223.208   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 11.6443  ,  0.221059, ..., 41.5449  ,  9.81381 ,\n",
       "        64.6423  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.52096,  15.5389 ,   3.73692, ..., 119.094  , 183.371  ,\n",
       "        117.308  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 17.8711  ,  0.327204, ..., 40.3339  , 33.0083  ,\n",
       "        88.1368  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 6.27733e+00, 6.31891e-02, ..., 4.55369e+01,\n",
       "        2.22143e+01, 7.98956e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.06993 ,  0.272658, ..., 42.84    , 16.3529  ,\n",
       "        60.2845  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  75.1689,  18.1904, ..., 181.206 , 540.131 , 250.601 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.96236 ,   0.400163, ...,  64.1607  ,  17.9762  ,\n",
       "        123.887   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.415179,  2.88043 ,  0.11847 , ..., 45.3207  , 19.6988  ,\n",
       "        82.0474  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.59407,  0.     , ..., 21.682  ,  8.39284, 37.7299 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.26348e+00, 6.14543e-02, ..., 4.67885e+01,\n",
       "        3.16064e+01, 7.24625e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  35.6407,   0.    , ...,  59.11  ,  29.1309, 112.015 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 37.5027  ,  0.668969, ..., 91.5761  , 29.4483  ,\n",
       "        94.4986  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.76221e+00, 8.31467e-02, ..., 8.43653e+01,\n",
       "        4.88087e+01, 1.73693e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.320917,  20.7352  ,   0.41954 , ...,  67.964   ,  36.2821  ,\n",
       "        104.282   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.83827 ,   0.927787, ..., 212.946   , 459.327   ,\n",
       "        212.574   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.241173,   5.10175 ,   0.279475, ...,  72.1532  ,  32.1377  ,\n",
       "        128.333   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 13.3421,  84.3564,  13.2889, ..., 450.626 , 619.048 , 471.814 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    , 19.1364,  0.    , ..., 46.6732, 28.9911, 60.2851],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  88.8549,   0.    , ..., 202.103 ,  92.6926, 299.441 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.66789 ,   0.284247, ...,  55.007   ,  29.0182  ,\n",
       "        113.647   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   1.80363,   0.     , ...,  52.939  ,  20.479  ,\n",
       "        116.165  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.07902,  0.28966, ..., 28.1512 , 11.2824 , 43.6641 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.32811e-01, 1.70098e+01, 6.63644e-02, ..., 5.34674e+01,\n",
       "        2.39538e+01, 7.83167e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.65783 ,  0.241811, ..., 35.858   , 19.183   ,\n",
       "        64.9518  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.10813,  11.3047 ,   3.00387, ...,  94.882  , 107.272  ,\n",
       "        161.051  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.242663,  2.66548 ,  0.602921, ..., 61.3406  , 31.8594  ,\n",
       "        99.9072  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.89997,  0.     , ..., 12.4521 , 10.3218 , 36.5805 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.30334,   0.29598, ...,  63.2472 ,  14.7495 ,\n",
       "        145.056  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.14009 ,  0.133525, ..., 44.8526  , 24.0703  ,\n",
       "        74.2119  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.16017 ,   0.259448, ...,  61.8098  ,  28.7581  ,\n",
       "        140.085   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  3.03072  ,  0.0543709, ...,  8.36371  ,  7.06788  ,\n",
       "        22.3448   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([5.01683e-01, 1.20130e+01, 9.87110e-02, ..., 1.74783e+02,\n",
       "        3.77469e+01, 3.18317e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.15659 ,   0.637004, ..., 157.103   ,  48.2576  ,\n",
       "        204.976   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.43365e+00, 1.00053e-01, ..., 7.58325e+01,\n",
       "        2.70855e+01, 1.76979e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.920137,  0.332325, ..., 35.0657  , 21.8169  ,\n",
       "        61.3393  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.61007 ,  0.140135, ..., 47.0888  , 22.1656  ,\n",
       "        43.5085  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.293077,  2.54547 ,  0.169531, ..., 76.6249  , 44.9878  ,\n",
       "        97.4665  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.13519,  0.     , ..., 52.1342 , 34.0839 , 64.3427 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  12.3427 ,   1.28122, ..., 420.027  , 852.102  ,\n",
       "        321.327  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.44351 ,   0.207302, ...,  64.0733  ,  21.7491  ,\n",
       "        106.987   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.0043  ,   0.274425, ...,  66.0189  ,  30.1416  ,\n",
       "        153.199   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.38678 ,  0.230491, ..., 48.2482  , 26.3545  ,\n",
       "        94.2951  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.94888,  10.945  ,   2.57243, ..., 161.428  , 174.66   ,\n",
       "        243.879  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.10715e-01, 5.73578e+01, 1.32826e-01, ..., 1.30001e+02,\n",
       "        4.69490e+01, 2.69450e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.20016e+00, 1.62783e-01, ..., 1.24351e+02,\n",
       "        1.70358e+02, 1.86783e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.07331,  0.     , ..., 31.3497 , 29.9669 , 42.6226 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.00579 ,  0.251116, ..., 42.3944  , 16.3134  ,\n",
       "        61.4814  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,   6.2172,   0.    , ..., 137.937 ,  36.8705, 213.297 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.8497  ,   0.340358, ...,  60.1249  ,  29.3655  ,\n",
       "        130.801   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.69751,  0.     , ..., 21.7243 , 13.8078 , 34.5961 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.58938 ,  0.448337, ..., 63.5614  , 32.8175  ,\n",
       "        99.709   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.339861,  2.23244 ,  0.      , ..., 32.7658  , 19.5318  ,\n",
       "        58.5359  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.519679,  2.37704 ,  0.202551, ..., 61.6788  , 78.3285  ,\n",
       "        89.5699  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.04733e+00, 1.61463e-01, ..., 8.46610e+01,\n",
       "        3.38206e+01, 1.94671e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.800247,   8.40544 ,   0.232162, ...,  51.1679  ,  26.6558  ,\n",
       "        122.584   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.251888,  3.78064 ,  0.358218, ..., 41.7231  , 29.839   ,\n",
       "        82.3533  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,   1.6569,   0.    , ...,  69.0647,  29.1707, 106.971 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.69312,   0.     , ...,  76.5145 ,  20.5658 ,\n",
       "        195.947  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.71547,  0.12526, ..., 40.1138 ,  8.49549, 77.424  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  49.3783,  13.4407, ..., 245.84  , 394.695 , 231.11  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.71886,   0.35558, ...,  66.3387 ,  36.1588 ,\n",
       "        127.987  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     , 18.3561 ,  0.55603, ..., 53.7882 , 19.847  , 74.0941 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.82733,  0.     , ..., 36.4276 , 18.3707 , 50.9754 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.581574,  3.60143 ,  0.166511, ..., 65.1636  , 27.6938  ,\n",
       "        86.7561  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     , 152.565  ,   5.09883, ..., 460.284  , 475.52   ,\n",
       "        660.188  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.379631,  5.34811 ,  0.667845, ..., 46.7915  , 36.7312  ,\n",
       "        99.3619  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.92012 ,  1.96681 ,  0.858571, ..., 26.9493  , 20.5301  ,\n",
       "        51.3639  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.20574 ,   0.740698, ..., 109.593   ,  46.2515  ,\n",
       "        168.306   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.66299 ,   0.214369, ...,  62.478   ,  30.5501  ,\n",
       "        173.105   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.48387e-01, 8.57195e+00, 1.40675e-01, ..., 1.04964e+02,\n",
       "        5.14908e+01, 1.77869e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.65584,  48.2289 ,   1.11108, ..., 172.315  , 171.967  ,\n",
       "        214.844  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  13.4804  ,   0.338252, ...,  59.7715  ,  26.2673  ,\n",
       "        124.503   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.45206 ,   8.95943 ,   0.548581, ...,  58.9815  ,  36.5333  ,\n",
       "        135.021   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.58616e+00, 1.11423e-01, ..., 7.43511e+01,\n",
       "        4.34376e+01, 1.46871e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  7.13648 ,  0.990038, ..., 50.1428  , 35.4573  ,\n",
       "        75.401   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.198021,   3.42515 ,   0.668298, ...,  65.0334  ,  33.759   ,\n",
       "        148.512   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.39814,  0.     , ..., 47.5029 , 19.2199 , 93.6552 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.60753 ,  0.565861, ..., 29.9098  , 28.8013  ,\n",
       "        42.6145  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.16025e+01, 1.60326e-01, ..., 1.74628e+02,\n",
       "        5.20939e+01, 2.74755e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.60362e+01, 7.70502e-02, ..., 1.27425e+02,\n",
       "        1.97515e+01, 1.67727e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.05479 ,   0.295307, ...,  70.5088  ,  37.5     ,\n",
       "        102.823   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   3.09634,   48.22   ,   11.4309 , ...,  706.38   , 1083.17   ,\n",
       "         686.628  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.240218,   6.5578  ,   0.274126, ...,  87.8047  ,  49.5285  ,\n",
       "        150.508   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.5232  ,   0.305461, ...,  52.6409  ,  22.9819  ,\n",
       "        148.733   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   2.72276,   36.7651 ,    4.73561, ...,  708.912  , 1163.44   ,\n",
       "         730.171  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.451695,  3.67119 ,  0.329223, ..., 51.5302  , 34.1712  ,\n",
       "        81.9815  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  29.1845 ,   3.43592, ..., 130.226  , 153.654  ,\n",
       "        153.824  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.53900e-01, 7.28192e+00, 7.27188e-02, ..., 5.09511e+01,\n",
       "        1.81650e+01, 9.91065e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  11.073   ,   0.905438, ..., 112.235   , 144.115   ,\n",
       "        152.18    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  8.48652,  58.0187 ,   7.88432, ..., 292.077  , 396.253  ,\n",
       "        308.879  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.59837,  0.     , ..., 19.9443 ,  9.95035, 42.5168 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.70090e-01, 1.07083e+02, 0.00000e+00, ..., 2.67741e+02,\n",
       "        5.91919e+01, 4.36906e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.03223e+00, 6.18640e-02, ..., 4.58261e+01,\n",
       "        2.50358e+01, 1.25886e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   34.5946,   10.0752, ...,  488.61  , 1073.04  ,\n",
       "         638.127 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.22746e+01, 1.89281e-01, ..., 1.40663e+02,\n",
       "        8.26680e+01, 2.99040e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.400483,   2.11196 ,   0.288032, ...,  48.8306  ,  30.2606  ,\n",
       "        102.993   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  37.5064  ,   0.370768, ...,  63.8902  ,  22.0332  ,\n",
       "        103.99    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.46016,  0.24145, ..., 30.0172 , 19.8866 , 40.0205 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.6533 ,  0.     , ...,  7.28528,  1.37195, 16.1242 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  64.2689 ,   1.90445, ..., 259.875  , 248.202  ,\n",
       "        283.711  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.82133,   0.44877, ...,  88.829  ,  30.4131 ,\n",
       "        204.597  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.29341 ,   0.880951, ...,  94.1383  , 113.537   ,\n",
       "        132.433   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.165458,   4.39242 ,   0.      , ...,  58.2401  ,  16.023   ,\n",
       "        103.183   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.315177,  11.523   ,   0.241267, ...,  91.8185  ,  15.3467  ,\n",
       "        226.969   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.13058,  0.53856, ..., 50.7117 , 12.9677 , 92.3332 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  29.2734 ,   7.45038, ..., 189.412  , 213.496  ,\n",
       "        163.199  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.44744 ,  0.120782, ..., 19.0482  , 16.5493  ,\n",
       "        35.5058  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.549279,   1.85888 ,   0.545778, ...,  80.1467  ,  29.6668  ,\n",
       "        105.377   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 6.09306e+00, 6.32478e-02, ..., 7.98285e+01,\n",
       "        6.33601e+01, 1.19009e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.85566 ,  0.231868, ..., 51.2034  , 23.886   ,\n",
       "        96.951   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.9228  ,   0.264577, ..., 102.38    ,  44.3121  ,\n",
       "        258.815   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.222971,   7.64744 ,   0.      , ...,  77.4472  ,  23.1572  ,\n",
       "        160.475   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  14.7307  ,   0.332365, ..., 140.912   , 126.421   ,\n",
       "        231.769   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  21.314   ,   0.608546, ..., 115.574   ,  34.1473  ,\n",
       "        172.114   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.83365e-01, 1.35939e+01, 1.70998e-01, ..., 1.24704e+02,\n",
       "        3.20748e+01, 2.33303e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  6.75427,  0.     , ..., 36.8176 , 20.0609 , 88.0269 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([5.62815e-03, 5.59375e+01, 2.97146e+00, ..., 5.30240e+02,\n",
       "        9.13320e+02, 6.51304e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.42483e-01, 1.94271e+02, 1.25427e-02, ..., 3.87188e+02,\n",
       "        8.95490e+01, 6.66169e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.86407 ,  0.211372, ..., 37.6862  , 15.8287  ,\n",
       "        62.766   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.68121e+00, 4.10700e-02, ..., 4.55442e+01,\n",
       "        1.34967e+01, 1.29634e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.13119 ,  0.937002, ..., 45.7347  , 29.235   ,\n",
       "        46.0924  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   7.30097,   0.67203, ...,  68.0481 ,  34.9093 ,\n",
       "        168.946  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     , 11.8766 ,  0.50069, ..., 41.1227 , 16.0583 , 45.9982 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.29156 ,  0.485527, ..., 48.5443  , 18.7518  ,\n",
       "        69.2359  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   8.09424,   0.     , ...,  57.3501 ,  30.1055 ,\n",
       "        146.065  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.80917,  0.     , ..., 18.4184 ,  7.38432, 35.4529 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  27.586  ,   4.21892, ..., 145.224  , 134.673  ,\n",
       "        174.524  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 1.54061, 10.8011 ,  1.75563, ..., 71.6292 , 57.4837 , 89.5769 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  64.0217 ,   4.11332, ..., 124.216  , 261.966  ,\n",
       "        187.339  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.25018 ,  0.228302, ..., 31.8252  , 20.0366  ,\n",
       "        85.6924  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.09495 ,  0.617136, ..., 45.3157  , 17.6765  ,\n",
       "        83.7628  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  1.63767  ,  0.0859067, ..., 44.4358   , 20.1532   ,\n",
       "        58.5661   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.47276,   0.20796, ...,  60.2241 ,  16.3965 ,\n",
       "        107.989  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.04505,  0.     , ..., 30.0989 , 18.1094 , 38.941  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.363954,  3.35035 ,  0.741777, ..., 47.5869  , 19.5223  ,\n",
       "        79.4373  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.07385e-01, 4.75117e+00, 6.08639e-02, ..., 4.34269e+01,\n",
       "        1.86741e+01, 1.15719e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    , 10.9555,  0.4672, ..., 66.8355, 25.261 , 67.3502],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.2808  ,   9.80978 ,   0.621435, ...,  68.4385  ,  61.1289  ,\n",
       "        111.414   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  18.1855,   0.    , ..., 118.679 ,  22.5605, 220.1   ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.66813 ,   0.211852, ...,  66.3665  ,  43.1756  ,\n",
       "        107.537   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.99009,  0.     , ..., 27.0024 , 22.6807 , 58.6227 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  16.3793  ,   0.872025, ..., 150.598   , 104.758   ,\n",
       "        151.879   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.18243 ,   0.454951, ..., 112.785   ,  38.1837  ,\n",
       "        173.21    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  5.40659,  0.     , ..., 53.377  , 29.0248 , 90.7036 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.911611,  16.2018  ,   1.21111 , ..., 199.309   ,  76.4659  ,\n",
       "        254.341   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.96402,  0.     , ..., 40.7384 , 29.6743 , 98.8129 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.58992e+00, 8.38040e-02, ..., 3.64714e+01,\n",
       "        1.48230e+01, 1.09417e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.19338 ,  0.221072, ..., 28.8865  , 12.5236  ,\n",
       "        78.0282  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.27132 , 13.6626  ,  0.514239, ..., 49.5113  , 36.029   ,\n",
       "        70.6712  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   5.47283,   0.     , ...,  56.7879 ,  15.6956 ,\n",
       "        149.999  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.488882, 14.6076  ,  3.25696 , ..., 85.1691  , 66.1415  ,\n",
       "        86.3072  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  24.6299,   0.    , ..., 183.799 ,  42.425 , 298.653 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.7664  ,   0.552671, ...,  82.5688  ,  78.0377  ,\n",
       "        111.599   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.11886 ,   0.604828, ...,  77.2043  ,  21.9787  ,\n",
       "        152.51    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  7.3758  ,  0.322878, ..., 55.2956  , 19.0794  ,\n",
       "        91.7341  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.20583 ,  0.378848, ..., 13.535   ,  8.58005 ,\n",
       "        24.2611  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  3.01919  ,  0.0737336, ..., 18.3947   , 14.2046   ,\n",
       "        31.5127   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  8.3713  ,  0.545689, ..., 63.2104  , 33.274   ,\n",
       "        84.1467  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.94846 ,  0.159378, ..., 29.5943  , 12.6303  ,\n",
       "        80.5747  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.0342  ,   0.479928, ...,  81.8706  ,  29.1998  ,\n",
       "        197.695   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    ,  4.1431,  0.    , ..., 21.7382, 11.4584, 37.495 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.54116 ,  0.381392, ..., 49.9597  , 21.1711  ,\n",
       "        85.834   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.263954,   5.0227  ,   0.603698, ...,  61.2492  ,  34.7768  ,\n",
       "        104.606   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.25808 ,  0.312013, ..., 27.2085  , 12.1118  ,\n",
       "        31.8512  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  9.15564 ,  0.195383, ..., 35.0969  , 10.9151  ,\n",
       "        58.1476  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.5554  ,   0.491716, ...,  94.4519  ,  37.7403  ,\n",
       "        172.365   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.801724,  0.      , ..., 24.8738  , 10.3369  ,\n",
       "        48.018   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  9.16114 ,  0.118967, ..., 47.8637  , 25.023   ,\n",
       "        88.2504  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.270365,   4.27454 ,   0.662941, ...,  82.9512  ,  31.0327  ,\n",
       "        202.136   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.73804 ,  0.167713, ..., 40.6481  , 35.0732  ,\n",
       "        64.2351  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  1.61511  ,  0.0708654, ..., 37.9693   , 11.0906   ,\n",
       "        47.7947   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.84175 ,  0.137644, ..., 40.3022  , 13.9243  ,\n",
       "        82.9735  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  34.1866  ,   0.152457, ...,  63.7281  ,  17.1115  ,\n",
       "        105.862   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  32.6757  ,   0.841135, ..., 272.783   , 120.076   ,\n",
       "        407.046   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  11.1593 ,   1.18745, ..., 253.519  , 402.483  ,\n",
       "        292.588  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.559603,  12.6323  ,   0.186447, ...,  83.9441  ,  62.0869  ,\n",
       "        136.899   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  29.9788 ,   0.55067, ..., 113.969  ,  50.1398 ,\n",
       "        198.658  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  11.8331  ,   0.895692, ...,  94.2681  ,  75.8235  ,\n",
       "        141.945   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.25419 ,  0.131562, ..., 54.1722  , 15.7966  ,\n",
       "        86.1519  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.303432,  11.6161  ,   0.59199 , ...,  92.3707  ,  49.2307  ,\n",
       "        133.471   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.59172 ,  0.296884, ..., 18.2983  ,  4.66763 ,\n",
       "        37.7745  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  13.3906,   0.    , ..., 122.513 ,  36.3582, 184.981 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 12.6339  ,  0.161259, ..., 50.4209  , 20.6179  ,\n",
       "        74.0904  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([5.10353e-01, 9.49985e+01, 3.01684e+00, ..., 5.90759e+02,\n",
       "        9.15773e+02, 5.24283e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.896276,   5.71734 ,   0.171267, ..., 107.619   , 114.829   ,\n",
       "        130.5     ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.00703 ,   0.211869, ...,  50.94    ,  22.1147  ,\n",
       "        116.069   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  13.6694 ,   0.55815, ...,  87.6192 ,  41.7432 ,\n",
       "        129.945  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    ,  4.1016,  0.    , ..., 50.1753, 15.4917, 82.5352],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.81920e-01, 7.08557e+01, 2.00540e-01, ..., 2.14241e+02,\n",
       "        4.21998e+01, 3.47235e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.     ,   36.3635 ,    8.80078, ..., 1677.63   , 3322.09   ,\n",
       "        1330.84   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.92711,  0.     , ..., 42.5867 ,  9.52787, 69.3622 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.26574 ,  2.81743 ,  0.269596, ..., 27.052   ,  9.68685 ,\n",
       "        48.4067  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  17.5275  ,   0.251499, ..., 100.788   ,  34.9016  ,\n",
       "        124.432   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.81809 ,   0.283438, ...,  83.3393  ,  41.0988  ,\n",
       "        135.355   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.90783,  82.9164 ,  11.0436 , ..., 305.011  , 604.799  ,\n",
       "        284.603  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.5566  ,   0.214514, ...,  55.031   ,  37.0125  ,\n",
       "        122.349   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.73296 ,  0.198538, ..., 45.0335  , 11.6671  ,\n",
       "        88.2743  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.296933,   2.39471 ,   0.296071, ...,  37.6415  ,  30.2596  ,\n",
       "        102.869   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.12645 ,   0.665756, ...,  90.1599  ,  51.6508  ,\n",
       "        104.662   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  5.67011,  0.     , ..., 61.0796 ,  9.4111 , 95.4126 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  3.43081,  31.2176 ,   2.88585, ..., 106.54   ,  81.0887 ,\n",
       "        132.786  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.19786e+00, 1.03790e-01, ..., 1.24170e+02,\n",
       "        1.06600e+02, 1.98190e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  1.91822  ,  0.0735153, ..., 46.4185   , 20.0011   ,\n",
       "        71.9539   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  12.8656,   1.067 , ..., 107.324 ,  69.2384, 149.934 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    , 13.2493,  0.    , ..., 55.8638, 15.8517, 89.6355],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  6.56659,  0.     , ..., 50.233  , 40.4777 , 70.3838 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.41513e+01, 5.06931e-02, ..., 5.99050e+01,\n",
       "        2.93924e+01, 5.84021e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 5.55621e+01, 2.19713e-01, ..., 1.70061e+02,\n",
       "        4.89307e+01, 2.99325e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.10644e+02, 2.62115e-02, ..., 3.02478e+02,\n",
       "        1.00681e+02, 4.06475e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.404696,  3.4244  ,  0.      , ..., 44.9128  , 23.3595  ,\n",
       "        53.385   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.51459,  11.1207 ,   1.51371, ..., 103.003  ,  41.702  ,\n",
       "        186.808  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  48.5691 ,   9.96592, ..., 368.665  , 623.981  ,\n",
       "        379.446  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.11235 ,   0.377209, ...,  75.5251  ,  25.606   ,\n",
       "        181.872   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.21184 ,  0.165466, ..., 31.8992  , 28.3176  ,\n",
       "        35.2177  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.27542e+00, 4.55641e-02, ..., 4.23685e+01,\n",
       "        2.17666e+01, 1.20718e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.17047e+01, 9.95390e-02, ..., 1.00079e+02,\n",
       "        2.11286e+01, 2.07379e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.37852 ,   0.361215, ..., 133.146   ,  50.0386  ,\n",
       "        222.536   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.35552 ,   0.449185, ...,  78.3364  ,  35.5763  ,\n",
       "        147.663   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.191199,  16.932   ,   0.525088, ...,  93.3736  ,  21.2842  ,\n",
       "        153.848   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  79.0774  ,   0.505838, ..., 210.293   , 111.784   ,\n",
       "        351.274   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 17.1871  ,  0.906124, ..., 54.3975  , 55.1101  ,\n",
       "        95.4932  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.94749e+01, 1.34089e-01, ..., 1.08482e+02,\n",
       "        5.77576e+01, 1.55491e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.196501,  3.14522 ,  0.168504, ..., 28.1149  , 18.3086  ,\n",
       "        65.2235  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.     ,   26.1883 ,    8.21931, ..., 1636.5    , 2737.31   ,\n",
       "        1279.17   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.27286,  0.     , ..., 43.2143 , 18.1908 , 90.7733 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  66.1057  ,   0.498452, ..., 196.314   ,  74.4379  ,\n",
       "        365.045   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.55223 ,   3.83895 ,   0.636677, ...,  49.924   ,  37.0611  ,\n",
       "        100.371   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.     ,   52.0597 ,    2.88495, ..., 1021.82   , 1501.63   ,\n",
       "        1003.13   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  3.53668,  51.0077 ,   5.03099, ..., 332.129  , 341.687  ,\n",
       "        408.382  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.86159 ,  0.232165, ..., 43.9587  , 28.4648  ,\n",
       "        76.6984  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.9766  ,   0.519646, ..., 112.289   ,  47.1276  ,\n",
       "        307.716   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.212623,   5.89887 ,   0.551577, ..., 110.726   ,  37.703   ,\n",
       "        153.364   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.56863 ,   0.149945, ...,  73.4048  ,  22.2238  ,\n",
       "        145.025   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    , 16.6421,  0.    , ..., 41.8625, 40.5138, 65.0881],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.543848,  14.1084  ,   0.420595, ...,  76.4599  ,  43.7993  ,\n",
       "        143.195   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.770683,  3.9115  ,  0.233651, ..., 34.4067  , 43.1755  ,\n",
       "        49.7347  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  11.4109 ,   1.14871, ..., 123.843  , 170.878  ,\n",
       "        135.949  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  6.42741 ,  0.157895, ..., 35.9595  , 10.0444  ,\n",
       "        45.8329  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  3.4467 ,  87.0174 ,   7.37749, ..., 272.924  , 451.15   ,\n",
       "        350.497  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.36197,  0.     , ..., 54.074  , 20.6326 , 89.0122 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.03027e+00, 6.11281e-02, ..., 4.53422e+01,\n",
       "        2.02292e+01, 6.67441e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   3.83285,   1.08234, ...,  97.7127 ,  71.3238 ,\n",
       "        204.009  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 9.82073e+01, 5.00995e-01, ..., 4.87169e+02,\n",
       "        1.32804e+02, 7.05835e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  12.588  ,   1.73684, ..., 126.908  ,  47.9338 ,\n",
       "        217.657  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 8.59052e+01, 2.21550e-01, ..., 3.38968e+02,\n",
       "        6.66168e+01, 6.07090e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.69486 ,   0.505647, ..., 104.05    ,  44.1683  ,\n",
       "        228.645   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.58639 ,   0.691189, ...,  47.0524  ,   6.32653 ,\n",
       "        100.78    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.94799 ,  0.184716, ..., 54.1603  , 39.1807  ,\n",
       "        69.2941  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  3.45805  ,  0.0437835, ..., 24.5201   , 16.5482   ,\n",
       "        28.8509   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.68166,  66.877  ,   5.98406, ..., 586.985  , 947.463  ,\n",
       "        658.533  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   6.94854,   1.83565, ...,  79.5968 ,  51.3178 ,\n",
       "        110.308  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.55423 ,  0.709462, ..., 34.7613  , 20.1604  ,\n",
       "        68.581   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.04357 ,  0.174491, ..., 26.947   , 17.908   ,\n",
       "        63.2443  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.473989, 16.2082  ,  0.339775, ..., 54.7404  , 28.6893  ,\n",
       "        82.0929  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.2692  ,  0.308087, ..., 11.2923  ,  9.9208  ,\n",
       "        25.6959  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.81391 ,   0.269667, ...,  70.3796  ,  61.7745  ,\n",
       "        156.284   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.837248,  2.37047 ,  0.44392 , ..., 40.7099  , 13.3216  ,\n",
       "        62.1423  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.550919,   6.66039 ,   0.415212, ...,  98.5861  ,  33.2742  ,\n",
       "        161.058   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.511114,  8.3136  ,  0.858685, ..., 55.8753  , 43.3619  ,\n",
       "        64.1622  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.794902,  2.84168 ,  0.246614, ..., 28.8658  , 24.1974  ,\n",
       "        59.5617  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.16694 ,  0.542416, ..., 53.9336  , 19.9428  ,\n",
       "        84.1153  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.11582 ,  0.469832, ..., 26.2071  , 18.3401  ,\n",
       "        44.2023  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.48436 ,   0.348779, ...,  55.3789  ,  34.7321  ,\n",
       "        121.362   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.7908  ,  0.682967, ..., 47.3711  , 20.3151  ,\n",
       "        81.7125  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.91708 ,  0.477883, ..., 32.9488  , 23.7884  ,\n",
       "        62.235   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.58167 ,   0.561817, ..., 103.006   ,  30.9648  ,\n",
       "        188.698   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.85302 ,   0.332336, ...,  56.1743  ,  49.148   ,\n",
       "        127.909   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.22924e-01, 4.79703e+01, 3.64117e-01, ..., 1.34058e+02,\n",
       "        5.22565e+01, 2.52255e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.05259 ,   0.380552, ...,  53.8478  ,  22.7326  ,\n",
       "        126.661   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.17822 ,  2.02823 ,  0.207776, ..., 20.8144  ,  6.56157 ,\n",
       "        40.1611  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.98672 ,   0.254211, ...,  82.0441  ,  60.6498  ,\n",
       "        169.936   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.43577 ,   0.160579, ...,  55.5282  ,  20.9043  ,\n",
       "        102.718   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.48562 ,   0.254871, ...,  67.8395  ,  14.8193  ,\n",
       "        114.114   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  13.2025  ,   0.279853, ...,  92.37    ,  88.6069  ,\n",
       "        129.515   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   5.60267,   0.     , ...,  73.2534 ,  40.8843 ,\n",
       "        137.491  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.76614e+00, 1.49453e-01, ..., 9.60186e+01,\n",
       "        3.16462e+01, 1.69875e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([4.09023e-01, 3.34591e+01, 1.18383e-01, ..., 2.12568e+02,\n",
       "        8.06265e+01, 3.56761e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.29948,  0.     , ..., 44.4838 , 31.8229 , 86.3483 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.265126,  7.12172 ,  0.223164, ..., 49.4255  , 28.1344  ,\n",
       "        51.9269  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.01909 ,   0.740513, ..., 171.037   , 242.717   ,\n",
       "        262.903   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.79303 ,   0.984703, ...,  65.4023  ,  34.6377  ,\n",
       "        176.564   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   1.50169,   0.     , ...,  51.1007 ,  25.9007 ,\n",
       "        131.475  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.208179,   3.41802 ,   0.858824, ...,  79.1184  ,  36.6423  ,\n",
       "        193.779   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.80970e-01, 2.79351e+00, 1.53124e-01, ..., 1.18146e+02,\n",
       "        8.39356e+01, 2.48409e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.78417,  46.1674 ,   1.38169, ..., 318.778  , 362.582  ,\n",
       "        432.371  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.922   ,  0.374725, ..., 32.8345  , 11.9081  ,\n",
       "        50.0543  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.7725 ,  0.38134, ..., 43.631  , 21.7066 , 44.4383 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.35134 ,  0.106527, ..., 36.1465  , 10.9699  ,\n",
       "        52.1077  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.82566 ,   0.295568, ...,  92.8522  ,  39.2164  ,\n",
       "        155.121   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.40226,   9.92448,   1.52662, ..., 100.697  , 109.739  ,\n",
       "        149.775  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     , 41.0493 ,  1.25722, ..., 64.9697 , 23.5294 , 88.3359 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.64622 ,   0.292032, ...,  41.0668  ,  27.5963  ,\n",
       "        108.102   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  65.8922  ,   0.491165, ..., 144.642   ,  46.5547  ,\n",
       "        261.696   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 36.4651  ,  0.447862, ..., 51.4538  , 19.299   ,\n",
       "        79.9568  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  67.9206,   0.    , ..., 185.82  ,  49.9023, 286.71  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.20245 ,  0.456988, ..., 38.6649  , 16.4354  ,\n",
       "        86.3138  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.4608 ,  0.22612, ..., 35.6297 , 37.8394 , 56.8557 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 5.25200e+01, 6.26048e-02, ..., 1.60189e+02,\n",
       "        5.03940e+01, 3.14632e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.12405 ,  0.371442, ..., 24.6134  ,  8.15077 ,\n",
       "        45.4066  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.39204 ,  0.106812, ..., 14.6005  , 10.3322  ,\n",
       "        32.6674  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  58.6452,   2.6843, ..., 401.281 , 435.694 , 444.063 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   8.4637 ,   2.16671, ..., 108.87   ,  71.3177 ,\n",
       "        232.546  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.424835, 35.1916  ,  0.693105, ..., 49.6009  , 36.2439  ,\n",
       "        74.4546  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.362564,  11.6825  ,   0.478818, ..., 106.342   ,  87.7507  ,\n",
       "        191.046   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.76016 ,  0.294866, ..., 33.3374  , 14.5446  ,\n",
       "        62.7326  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.19288 ,   0.543306, ...,  92.7049  ,  26.6777  ,\n",
       "        145.305   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.26467e+01, 8.17195e-02, ..., 7.52927e+01,\n",
       "        2.63519e+01, 1.28042e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.17612 ,   0.189652, ...,  80.2305  ,  34.8588  ,\n",
       "        136.635   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.32234 ,   0.386559, ...,  43.0323  ,  42.3474  ,\n",
       "        142.512   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.98406 ,  0.128769, ..., 36.8031  , 25.7678  ,\n",
       "        59.9466  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.49845 ,   0.331035, ...,  75.485   ,  24.4497  ,\n",
       "        128.096   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.944369,  8.01851 ,  0.391822, ..., 39.4532  , 12.8758  ,\n",
       "        57.3049  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.68009e+01, 6.90615e-02, ..., 6.91557e+01,\n",
       "        3.26118e+01, 1.37240e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.254292,  2.62821 ,  0.      , ..., 25.0455  ,  9.64044 ,\n",
       "        46.0997  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.146573,  2.63104 ,  0.126397, ..., 48.0182  , 18.8727  ,\n",
       "        80.2059  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 7.03655e+00, 5.39383e-02, ..., 5.13550e+01,\n",
       "        1.85917e+01, 6.11605e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.68385e-01, 4.64522e+00, 4.67751e-02, ..., 3.51982e+01,\n",
       "        3.35055e+01, 5.90206e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.249993, 19.2006  ,  0.354463, ..., 52.9466  , 45.3527  ,\n",
       "        97.7534  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.542424,  1.98735 ,  0.364602, ..., 35.9259  , 22.623   ,\n",
       "        39.2564  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 3.73577,  9.68038,  1.45626, ..., 63.3816 , 48.5629 , 99.7276 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  68.4084  ,   0.582741, ..., 171.613   ,  49.3915  ,\n",
       "        278.256   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.90046e-01, 2.17737e+01, 3.40881e+00, ..., 4.49956e+02,\n",
       "        1.00060e+03, 3.53807e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.320389 ,  3.93542  ,  0.0913456, ..., 28.3977   , 16.1993   ,\n",
       "        41.4647   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  6.9344 ,  64.406  ,   6.16823, ..., 336.591  , 385.667  ,\n",
       "        429.244  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.47123,  1.16912, ..., 49.1833 , 63.9203 , 66.8031 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.95809e+00, 1.10771e-01, ..., 3.50319e+01,\n",
       "        2.31455e+01, 1.19265e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  0.92312,  0.     , ..., 37.0481 , 24.1477 , 74.7217 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.38906 ,   0.500316, ...,  88.292   ,  36.1354  ,\n",
       "        115.483   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.64133,  10.4674 ,   2.30595, ..., 107.448  ,  90.3349 ,\n",
       "        163.707  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.67147,  0.16919, ..., 39.8096 , 20.1106 , 82.3353 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  8.58341 ,  0.163355, ..., 37.162   , 19.8343  ,\n",
       "        51.5859  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.51524 ,   0.388126, ...,  97.2802  ,  68.64    ,\n",
       "        146.515   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.88892,  0.     , ..., 36.2424 , 29.4753 , 71.4867 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.0076 ,  28.4552 ,   2.22155, ..., 152.95   , 100.208  ,\n",
       "        308.031  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  8.4374  ,  0.334846, ..., 46.5872  , 21.1497  ,\n",
       "        97.4133  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.45509 ,   0.218009, ...,  52.2041  ,  13.2775  ,\n",
       "        107.824   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  40.5862,   5.1523, ..., 208.171 , 339.002 , 225.68  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.82777 ,  0.188891, ..., 16.212   ,  8.53291 ,\n",
       "        46.8851  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.2929  ,   0.400493, ..., 106.394   ,  30.3447  ,\n",
       "        140.053   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.0997  ,  0.324005, ..., 33.7053  , 20.2824  ,\n",
       "        60.5104  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 3.914  , 21.6231 ,  4.12186, ..., 42.8147 , 66.6802 , 49.0933 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   5.69377,   99.0455 ,   11.5904 , ...,  654.586  , 1112.93   ,\n",
       "         499.645  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.6223  ,   0.419142, ...,  90.1289  ,  25.3895  ,\n",
       "        146.66    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  4.96983  ,  0.0604943, ..., 27.0492   , 23.9074   ,\n",
       "        49.7395   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  12.5874 ,   87.9707 ,    4.09705, ...,  826.208  , 1227.61   ,\n",
       "         763.056  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.947346,  2.45531 ,  0.      , ..., 27.8999  , 25.5568  ,\n",
       "        45.9428  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.00146 ,  0.349814, ..., 21.965   ,  7.67451 ,\n",
       "        37.384   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.800504,   5.73026 ,   0.600824, ...,  92.1043  ,  36.4572  ,\n",
       "        239.935   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.83284 ,   0.316353, ...,  58.0558  ,  12.9083  ,\n",
       "        104.941   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  3.64122,  0.     , ..., 21.1502 , 15.1614 , 46.9787 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.99103 ,   0.273239, ...,  76.2094  ,  32.4282  ,\n",
       "        192.421   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 11.0263  ,  0.651854, ..., 51.3848  , 15.8183  ,\n",
       "        87.4634  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.08161 ,  0.222362, ..., 23.1408  , 13.3077  ,\n",
       "        31.8541  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.73378 ,  0.113393, ..., 43.5418  , 22.0391  ,\n",
       "        83.7946  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.00345 ,   0.276698, ...,  47.9247  ,  24.7137  ,\n",
       "        100.058   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  67.9047  ,   0.591527, ...,  66.0791  ,  20.1738  ,\n",
       "        103.064   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  14.7523 ,   3.74728, ..., 101.844  , 174.272  ,\n",
       "        130.12   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.82467,  0.     , ..., 26.594  , 15.8021 , 42.4701 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.14503 ,  0.172722, ..., 44.5463  , 14.9111  ,\n",
       "        63.9443  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.248952,  9.954   ,  0.349512, ..., 41.3131  , 13.931   ,\n",
       "        67.0363  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.388636,  4.9693  ,  0.221369, ..., 45.0998  , 24.8539  ,\n",
       "        93.581   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.206181,   2.99052 ,   0.464537, ...,  77.3225  ,  31.3494  ,\n",
       "        107.093   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.03463e+01, 9.71502e-02, ..., 8.76541e+01,\n",
       "        2.79686e+01, 1.88666e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  0.660759,  0.      , ..., 41.2388  , 36.3576  ,\n",
       "        78.8408  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.79691,  0.     , ..., 28.4466 , 34.8016 , 38.4037 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.228773,  2.08176 ,  0.272853, ..., 44.9625  , 26.6465  ,\n",
       "        86.8318  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.128128 ,  2.39706  ,  0.0735244, ..., 16.8225   ,  8.60743  ,\n",
       "        57.8423   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  8.64406 ,  0.533526, ..., 31.0244  , 26.9112  ,\n",
       "        74.7474  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   7.516   ,   0.466835, ...,  50.5821  ,  13.9682  ,\n",
       "        123.25    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 1.37837 ,  7.59129 ,  0.447202, ..., 70.8089  , 26.7359  ,\n",
       "        83.1292  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 6.08091e+01, 2.60067e-01, ..., 3.19516e+02,\n",
       "        6.13925e+01, 5.50784e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.63890e-05, 3.38933e+01, 3.93693e+00, ..., 4.64907e+02,\n",
       "        1.59641e+03, 5.24562e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.48181 ,  0.255797, ..., 61.3321  , 44.2635  ,\n",
       "        96.0147  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.51874e+00, 8.83319e-02, ..., 6.88913e+01,\n",
       "        2.92869e+01, 9.93834e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  80.7352 ,   9.64169, ..., 290.297  , 684.784  ,\n",
       "        377.46   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 8.88086e+00, 8.31916e-02, ..., 4.93865e+01,\n",
       "        2.28639e+01, 1.15035e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.453853,  5.23257 ,  0.319991, ..., 24.2011  , 19.1944  ,\n",
       "        48.4899  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.65772 ,   0.397266, ..., 132.213   ,  36.4416  ,\n",
       "        250.556   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.269188,   3.02603 ,   0.69022 , ...,  55.1721  ,  19.7053  ,\n",
       "        109.068   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.53825 ,   0.363033, ...,  55.77    ,  38.8162  ,\n",
       "        107.575   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.91531 ,   0.327495, ...,  73.1457  ,  29.6955  ,\n",
       "        117.911   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   6.27272,   1.94909, ..., 135.753  , 196.367  ,\n",
       "        166.983  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.63847 ,   0.215698, ...,  53.2067  ,  22.7014  ,\n",
       "        107.148   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  19.8895,   0.    , ..., 106.383 ,  32.3915, 114.844 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.82438,  0.67236, ..., 56.1346 , 31.526  , 95.857  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  14.7174 ,   1.49561, ..., 104.612  ,  83.5705 ,\n",
       "        172.931  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   8.43627,   0.     , ...,  81.6259 ,  28.8077 ,\n",
       "        144.298  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.13128e+01, 9.28068e-02, ..., 1.06655e+02,\n",
       "        5.04833e+01, 1.08371e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.44154 ,   0.344083, ...,  72.3649  ,  20.6158  ,\n",
       "        160.847   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.223337,  6.02133 ,  0.383427, ..., 39.7225  , 11.7137  ,\n",
       "        81.1882  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.65066,  0.     , ..., 32.4281 , 10.6758 , 58.5101 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.00283e+02, 7.17804e-01, ..., 5.09908e+02,\n",
       "        1.44979e+02, 8.25010e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.3622  ,   0.220358, ...,  57.6651  ,  20.6348  ,\n",
       "        126.435   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 26.0083  ,  0.198358, ..., 29.0235  , 14.3367  ,\n",
       "        56.9985  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.00266 ,  0.176068, ..., 34.0083  , 15.2107  ,\n",
       "        74.0302  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  7.12882 ,  0.406784, ..., 29.5787  , 15.5775  ,\n",
       "        51.0521  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.382024,  8.51887 ,  0.377351, ..., 52.9865  , 30.084   ,\n",
       "        64.0036  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.78483 ,  0.891929, ..., 54.8858  , 26.8787  ,\n",
       "        69.8181  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.996006,  2.7212  ,  0.305287, ..., 44.178   , 36.5644  ,\n",
       "        62.9592  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.51592 ,   0.493876, ..., 111.38    ,  54.7152  ,\n",
       "        135.27    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  7.94758  ,  0.0936063, ..., 25.8278   ,  9.62198  ,\n",
       "        32.9227   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.66674,  0.     , ..., 40.0375 , 20.9204 , 57.5983 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.107313,  3.47723 ,  0.346931, ..., 40.9116  , 30.5869  ,\n",
       "        45.9002  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.08416 ,  0.265125, ..., 36.5992  , 37.9545  ,\n",
       "        71.2756  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.1994  ,   0.363861, ...,  82.1955  ,  50.0191  ,\n",
       "        131.545   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 2.83324e+00, 9.01004e-02, ..., 6.69562e+01,\n",
       "        2.18449e+01, 1.08433e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     , 100.771  ,   3.10215, ..., 394.782  , 459.158  ,\n",
       "        512.192  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   2.71461,   0.13175, ...,  79.8566 ,  82.5187 ,\n",
       "        107.953  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.402405,  4.02023 ,  0.15704 , ..., 40.5925  , 25.0454  ,\n",
       "        67.4326  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([9.87971e-02, 5.85739e+00, 1.05397e-01, ..., 7.72272e+01,\n",
       "        4.44365e+01, 1.15194e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  58.0484  ,   0.794206, ..., 109.576   ,  38.6468  ,\n",
       "        224.768   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  5.22551,  27.7153 ,   1.62401, ..., 149.389  , 208.063  ,\n",
       "        187.943  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   7.71676,   0.     , ..., 104.525  ,  37.5742 ,\n",
       "        207.637  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.14292e-01, 5.58087e+00, 8.46277e-01, ..., 7.46979e+01,\n",
       "        5.06079e+01, 1.53471e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  40.2303 ,   0.51199, ..., 107.841  ,  97.473  ,\n",
       "        143.261  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.83565e+00, 1.54006e-01, ..., 1.15151e+02,\n",
       "        4.29340e+01, 2.74674e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.63609e-01, 2.37975e+01, 3.27420e-01, ..., 1.18801e+02,\n",
       "        5.79224e+01, 2.76339e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.21660e-02, 1.73785e+01, 3.47554e+00, ..., 7.71582e+01,\n",
       "        7.43198e+01, 9.46493e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.256777,   2.85291 ,   0.      , ...,  63.4264  ,  15.4711  ,\n",
       "        134.221   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.164074,  1.96314 ,  0.228471, ..., 32.9229  ,  9.94364 ,\n",
       "        86.7635  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       , 26.1425   ,  0.0998806, ..., 38.3225   , 17.3416   ,\n",
       "        75.1286   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.97568 ,  0.177555, ..., 47.7367  , 33.378   ,\n",
       "        86.3841  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  10.4747,   0.    , ...,  95.3248,  90.7332, 120.836 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.     ,   20.5242 ,    3.05311, ..., 1037.45   , 2334.68   ,\n",
       "        1053.02   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.25735 ,   0.221447, ...,  78.9112  , 131.016   ,\n",
       "         97.2138  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.834941,   5.67981 ,   0.411067, ...,  46.0611  ,  15.9701  ,\n",
       "        107.011   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  0.322494 ,  0.0699604, ..., 26.8084   , 11.0653   ,\n",
       "        50.4046   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  56.1356  ,   0.617839, ..., 204.019   ,  79.4001  ,\n",
       "        349.782   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.980408,  2.07833 ,  0.113471, ..., 34.4655  , 19.0364  ,\n",
       "        56.0687  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.40443,  0.     , ..., 18.096  ,  5.36651, 45.9776 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   4.50995,   88.1682 ,    7.53746, ...,  976.004  , 1817.89   ,\n",
       "         887.523  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  8.32821 ,  0.313829, ..., 37.2463  , 15.2376  ,\n",
       "        66.976   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.53237 ,  0.411578, ..., 37.6008  , 14.4856  ,\n",
       "        68.4447  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.535154,  10.5672  ,   0.541334, ...,  90.0395  ,  20.3559  ,\n",
       "        118.38    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.09324,  0.     , ..., 50.5384 , 47.7937 , 98.644  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.597402,  8.96825 ,  0.981988, ..., 75.1391  , 91.6394  ,\n",
       "        60.2218  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 35.2535  ,  0.468198, ..., 39.571   , 14.1653  ,\n",
       "        66.6541  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.54174 ,  0.476769, ..., 23.0289  ,  4.73227 ,\n",
       "        40.0621  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.54778 ,  0.572086, ..., 29.8108  , 16.7428  ,\n",
       "        49.8307  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   4.7478,   40.6745,   10.4256, ..., 1686.24  , 2841.64  ,\n",
       "        1437.93  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.219812,  6.00549 ,  1.17304 , ..., 60.9181  , 14.4108  ,\n",
       "        95.0702  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.299985,  59.3316  ,   0.      , ..., 156.765   ,  49.9263  ,\n",
       "        292.413   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.19837 ,   0.326296, ...,  47.9023  ,  16.8159  ,\n",
       "        110.477   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.239084,   4.15752 ,   0.201626, ...,  72.0225  ,  23.7047  ,\n",
       "        174.379   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.36031,  0.     , ..., 33.0543 , 23.3136 , 59.7479 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.54420e+02, 3.20341e-01, ..., 8.26551e+02,\n",
       "        3.84257e+02, 1.20071e+03], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 4.17948e+00, 1.55758e-01, ..., 8.65237e+01,\n",
       "        3.47055e+01, 1.92686e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.537263,   3.9771  ,   0.602878, ...,  50.8162  ,  28.4435  ,\n",
       "        133.989   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.541977,  4.38942 ,  0.194341, ..., 32.3878  , 18.1453  ,\n",
       "        52.7194  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.837168,  4.44507 ,  0.472442, ..., 79.1303  , 58.3576  ,\n",
       "        96.4488  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.483416, 12.3436  ,  0.62662 , ..., 33.233   , 14.6195  ,\n",
       "        53.9108  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.13691e+01, 3.87163e-01, ..., 2.79611e+02,\n",
       "        5.48562e+02, 3.50403e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   8.12015,   0.     , ...,  68.4897 ,  41.5581 ,\n",
       "        153.017  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.92503,  22.3409 ,   3.72493, ..., 133.126  , 158.878  ,\n",
       "        233.032  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.18507,   3.06509,   0.     , ...,  62.5059 ,  23.1457 ,\n",
       "        126.239  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.55693,  0.49147, ..., 37.8088 , 22.8019 , 35.4454 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.952539,  12.9224  ,   2.4054  , ...,  65.4311  ,  44.2121  ,\n",
       "        117.944   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  3.77141  ,  0.0892452, ..., 35.9141   , 22.811    ,\n",
       "        55.2781   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.265286,  22.1866  ,   3.49603 , ..., 118.437   , 158.      ,\n",
       "         88.0619  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  11.279  ,   1.91596, ...,  90.1968 ,  65.4752 ,\n",
       "        128.685  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.53885 ,   0.380923, ...,  91.2554  ,  31.8761  ,\n",
       "        143.311   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.22354 ,   0.270048, ...,  62.2952  ,   8.48424 ,\n",
       "        109.271   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.16021 ,  0.212627, ..., 22.1835  ,  3.30686 ,\n",
       "        34.8499  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  3.34537,  41.385  ,   1.78336, ..., 119.058  , 125.833  ,\n",
       "        151.013  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.76536 ,   0.421582, ...,  86.7534  ,  47.6718  ,\n",
       "        148.644   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.12805 ,  6.15948 ,  0.108833, ..., 44.5794  , 36.752   ,\n",
       "        91.8256  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.97635,  0.     , ..., 67.149  , 37.3846 , 95.2938 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 12.7026  ,  0.121614, ..., 45.0929  , 19.9832  ,\n",
       "        68.3314  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  51.3316,  12.2345, ..., 216.466 , 356.644 , 175.907 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.26169 ,  0.182138, ..., 13.1121  , 12.1109  ,\n",
       "        26.3588  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.72539 ,   0.169916, ...,  84.3583  ,  43.8543  ,\n",
       "        108.666   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  7.62051 ,  0.389869, ..., 48.0049  , 30.3486  ,\n",
       "        63.4453  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   90.4284,    7.2663, ..., 1851.69  , 3423.24  ,\n",
       "        1818.55  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.2984  ,   0.481231, ..., 120.787   ,  31.2729  ,\n",
       "        150.413   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.205993,   2.24334 ,   0.235608, ...,  71.4685  ,  38.6884  ,\n",
       "        142.389   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  70.3244,   0.    , ..., 222.38  ,  51.4791, 361.351 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  4.43992,   8.96737,   3.24093, ..., 192.732  , 361.092  ,\n",
       "        172.52   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.33142 ,   3.41052 ,   0.250942, ...,  45.6449  ,  19.3838  ,\n",
       "        108.126   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.384071,   2.82848 ,   0.58406 , ...,  94.013   ,  39.637   ,\n",
       "        177.095   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.92084e-01, 3.72059e+00, 4.27068e-02, ..., 6.31475e+01,\n",
       "        3.35531e+01, 9.25896e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  32.7857,  11.6902, ..., 187.521 , 232.726 , 290.052 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.786006,  4.17737 ,  0.682222, ..., 43.2094  , 63.3352  ,\n",
       "        58.9867  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.29406 ,   0.501423, ...,  68.5695  ,  45.3784  ,\n",
       "        132.834   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.21013 ,   0.470283, ...,  59.125   ,  29.1113  ,\n",
       "        102.261   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.11243,  1.04163, ..., 45.4692 , 33.2544 , 70.6777 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 16.8879  ,  0.283785, ..., 45.2949  , 15.5775  ,\n",
       "        90.5802  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.617651,  4.61312 ,  0.962608, ..., 47.0192  , 24.5473  ,\n",
       "        98.8215  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  5.83646,  0.     , ..., 45.5909 , 29.4317 , 61.2558 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.62289,  50.5759 ,   3.5186 , ..., 169.011  , 196.119  ,\n",
       "        266.112  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.327696,  1.8259  ,  0.155753, ..., 48.4187  , 63.617   ,\n",
       "        95.2316  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.197736,  1.22347 ,  0.      , ..., 27.6546  ,  9.8457  ,\n",
       "        61.5517  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.273773,   7.86026 ,   0.223028, ...,  97.3407  ,  41.5567  ,\n",
       "        181.639   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.03353 ,   0.461507, ...,  64.6769  ,  66.5377  ,\n",
       "        121.111   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.13154,  20.6938 ,   3.68437, ..., 228.24   , 428.39   ,\n",
       "        242.112  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.48716 ,  3.36059 ,  0.451395, ..., 52.7688  , 42.8164  ,\n",
       "        83.1022  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 13.9817  ,  0.571699, ..., 48.515   , 14.581   ,\n",
       "        84.9027  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  2.20273  ,  0.0918823, ..., 18.7343   , 15.1332   ,\n",
       "        24.5031   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.06896 ,  0.182198, ..., 57.5394  , 35.455   ,\n",
       "        92.3135  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.901208,  1.28596 ,  0.      , ..., 47.6672  , 48.1472  ,\n",
       "        62.8968  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   6.16447,   0.     , ..., 121.892  , 168.271  ,\n",
       "        234.196  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.179721,  0.959916,  0.224054, ..., 13.3384  ,  5.37956 ,\n",
       "        23.25    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  19.8038 ,   3.15674, ..., 311.614  , 560.368  ,\n",
       "        424.73   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.81098e-01, 3.13980e+01, 4.78558e-02, ..., 6.71506e+01,\n",
       "        2.44273e+01, 9.39717e+01], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  8.37111 ,  0.512017, ..., 43.3596  , 27.3662  ,\n",
       "        77.7265  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.23096 ,   0.363198, ...,  46.8018  ,  26.0138  ,\n",
       "        101.527   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  24.1906  ,   0.423289, ...,  51.5145  ,  22.6662  ,\n",
       "        109.712   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  29.4622  ,   0.399982, ...,  92.7565  ,  25.1149  ,\n",
       "        130.411   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.13708 ,  0.896315, ..., 43.8899  , 28.3685  ,\n",
       "        75.4371  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  1.58005,  0.16431, ..., 21.4418 ,  8.50096, 40.3399 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  24.3225 ,   0.17705, ...,  83.7606 ,  27.4874 ,\n",
       "        160.593  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([6.05943e-01, 4.38080e+00, 5.72826e-02, ..., 5.60164e+01,\n",
       "        1.98039e+01, 1.06373e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.79263 ,   0.467073, ..., 121.15    ,  33.8441  ,\n",
       "        188.684   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.52358 ,   3.29475 ,   0.519907, ...,  61.864   ,  29.8389  ,\n",
       "        100.788   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.10408 ,  0.528794, ..., 25.228   ,  9.65396 ,\n",
       "        48.597   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.183932,  1.38592 ,  0.106368, ..., 41.1528  , 16.2359  ,\n",
       "        87.4373  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.227427,  1.77913 ,  0.586476, ..., 35.2834  , 11.0356  ,\n",
       "        53.5438  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  22.9816 ,   1.10144, ..., 148.957  ,  83.4368 ,\n",
       "        211.847  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.204519,  2.01558 ,  0.176908, ..., 33.9255  , 17.0275  ,\n",
       "        76.4713  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.17725 ,  0.163972, ..., 48.4799  , 30.3621  ,\n",
       "        67.5124  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   9.23298 ,   0.612419, ...,  84.5795  ,  32.8393  ,\n",
       "        176.53    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  83.3498  ,   0.617302, ..., 283.979   , 101.168   ,\n",
       "        373.959   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.68276,  0.     , ..., 39.6351 , 28.0281 , 99.5494 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.180203,   1.95603 ,   0.414491, ...,  62.6824  ,  26.7325  ,\n",
       "        120.812   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.609036,  23.3992  ,   0.339107, ..., 109.23    ,  35.3594  ,\n",
       "        186.028   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.195957,  3.67447 ,  0.186423, ..., 33.4786  , 17.6781  ,\n",
       "        52.357   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.19056 ,  0.320946, ..., 54.1576  , 16.1351  ,\n",
       "        89.5734  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  21.0266  ,   0.471075, ..., 156.091   ,  79.4982  ,\n",
       "        182.83    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.09391 ,   0.431384, ..., 112.705   ,  33.7496  ,\n",
       "        162.369   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  2.92407,  0.39019, ..., 25.9247 , 24.6424 , 49.1061 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.42764e-01, 4.16470e+01, 2.23610e-01, ..., 1.82861e+02,\n",
       "        3.13583e+01, 3.14302e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  61.809 ,   0.    , ..., 268.236 ,  35.6045, 467.406 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.56362 ,  0.523927, ..., 42.9923  , 48.0445  ,\n",
       "        45.6146  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.27575 ,   0.355062, ...,  56.4314  ,  23.6898  ,\n",
       "        104.663   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  58.5087  ,   0.283623, ..., 177.786   ,  76.5699  ,\n",
       "        273.89    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.     ,   10.474  ,    3.40138, ..., 1125.6    , 2137.88   ,\n",
       "        1071.58   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.53871, 110.271  ,   4.00326, ..., 292.693  , 275.384  ,\n",
       "        308.487  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.196854,  6.3087  ,  0.113857, ..., 34.8807  , 14.9535  ,\n",
       "        75.0395  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.213989,  5.74727 ,  0.98937 , ..., 29.909   , 18.2977  ,\n",
       "        37.276   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  6.88623,  0.     , ..., 50.7486 , 28.7357 , 66.154  ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.87639e-01, 1.45962e+01, 1.58569e-01, ..., 8.84719e+01,\n",
       "        3.62217e+01, 2.62268e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  23.369   ,   0.240857, ...,  81.5411  ,  27.6831  ,\n",
       "        135.168   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   2.85422 ,   0.398592, ...,  51.0331  ,  19.7501  ,\n",
       "        115.45    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.993565,  3.89399 ,  0.316336, ..., 54.8155  , 22.8149  ,\n",
       "        85.64    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.45039 ,  0.395341, ..., 21.4356  , 13.303   ,\n",
       "        77.6419  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.71725 ,  0.164921, ...,  6.32827 ,  4.63586 ,\n",
       "        14.6447  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.       ,  1.29254  ,  0.0924793, ..., 18.5338   ,  8.77052  ,\n",
       "        40.7679   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   1.85302 ,   0.366195, ...,  28.033   ,  20.7755  ,\n",
       "        101.37    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.03297,   0.     , ...,  83.4273 ,  25.8026 ,\n",
       "        141.843  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 20.7522,  68.1713,  12.5262, ..., 329.749 , 415.702 , 271.776 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  71.9965 ,   4.74166, ..., 316.171  , 343.513  ,\n",
       "        371.794  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.01488 ,  0.335492, ..., 66.131   , 33.3341  ,\n",
       "        73.5414  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.06154e+01, 2.19534e-01, ..., 1.23605e+02,\n",
       "        4.77683e+01, 2.47273e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.89992e+00, 1.21967e-01, ..., 9.64653e+01,\n",
       "        3.32351e+01, 2.74925e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.635429,  2.28906 ,  1.19153 , ..., 35.674   , 26.5811  ,\n",
       "        51.1474  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.324   ,  0.149289, ..., 44.5752  , 17.9063  ,\n",
       "        65.0153  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  13.0892 ,   1.33644, ...,  98.1673 ,  63.906  ,\n",
       "        176.867  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.    , 18.2355,  0.    , ..., 23.6302, 14.3656, 40.9178],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   9.22495,   0.     , ...,  93.4394 ,  11.0711 ,\n",
       "        101.236  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.52185 ,  0.103579, ..., 39.3409  ,  6.51347 ,\n",
       "        96.987   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 15.4061  ,  0.215221, ..., 50.6285  , 77.1026  ,\n",
       "        96.374   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([3.34128e-01, 4.07369e+01, 1.37509e-01, ..., 7.43179e+01,\n",
       "        1.92898e+01, 1.41158e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.18172e+02, 2.19505e-01, ..., 3.54424e+02,\n",
       "        9.45166e+01, 5.17332e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.122149,   3.67928 ,   0.785537, ...,  57.0931  ,  15.9757  ,\n",
       "        109.3     ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.528287,  6.34256 ,  0.398113, ..., 35.4992  , 19.7579  ,\n",
       "        60.9422  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 6.18916e+00, 9.59933e-02, ..., 9.39917e+01,\n",
       "        5.39577e+01, 2.30437e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.03371 ,  0.307259, ..., 47.8755  , 24.4825  ,\n",
       "        92.2385  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.59631 ,   0.317372, ...,  69.3647  ,  31.054   ,\n",
       "        113.36    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.191488,  7.06169 ,  0.107842, ..., 42.9722  , 18.9326  ,\n",
       "        70.8435  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  14.0513 ,   2.17235, ..., 157.207  , 213.682  ,\n",
       "        211.902  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  13.39    ,   0.678256, ..., 111.498   ,  42.535   ,\n",
       "        183.394   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.00674 ,  0.193213, ..., 43.9351  , 23.8125  ,\n",
       "        75.3285  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  10.9943,   0.    , ...,  69.5803,  16.941 , 104.651 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  5.23313 ,  0.117144, ..., 28.0138  ,  8.85546 ,\n",
       "        56.5209  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  5.07276,  0.76361, ..., 39.625  ,  9.01526, 67.7048 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 3.21569e+00, 2.25785e-01, ..., 1.16825e+02,\n",
       "        5.00396e+01, 3.20553e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.8899  ,  0.113602, ..., 29.3148  , 13.6271  ,\n",
       "        46.9376  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.12197 ,   0.245637, ...,  92.5251  ,  95.092   ,\n",
       "        194.      ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([   0.    ,   51.5176,   12.0188, ...,  851.264 , 1307.46  ,\n",
       "         958.855 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.07908 ,   0.217289, ...,  69.0488  ,  43.7458  ,\n",
       "        109.188   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.41904 ,   0.240594, ...,  71.5906  ,  24.8807  ,\n",
       "        165.83    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.57951 ,   0.261773, ...,  66.207   ,  22.3978  ,\n",
       "        158.278   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  13.3706 ,   2.50805, ..., 194.613  , 305.634  ,\n",
       "        205.192  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.937   ,   0.626898, ..., 111.416   , 114.697   ,\n",
       "        144.785   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.424017,   4.54537 ,   0.457499, ...,  80.2587  ,  66.5201  ,\n",
       "        138.587   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.210118,  2.42213 ,  0.65929 , ..., 35.7361  , 15.8835  ,\n",
       "        66.0145  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.09284 ,  0.128894, ..., 47.8155  , 30.5781  ,\n",
       "        99.9311  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  4.50701 ,  0.165438, ..., 26.6039  , 15.8855  ,\n",
       "        48.8206  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.95106 ,  0.169745, ..., 10.7218  ,  7.80941 ,\n",
       "        21.6037  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.35111 ,  0.153083, ..., 48.5624  , 18.4384  ,\n",
       "        76.2322  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   4.13918 ,   0.647531, ...,  58.786   ,  21.9047  ,\n",
       "        132.107   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.251892,  2.84039 ,  0.143632, ..., 35.8238  , 10.536   ,\n",
       "        66.002   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  12.2381  ,   0.355406, ..., 118.866   ,  70.2109  ,\n",
       "        215.83    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  13.9204,   0.    , ...,  73.5565,  15.4369, 204.479 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.18625 ,  0.341392, ..., 27.7201  , 19.7017  ,\n",
       "        48.0904  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.     ,  4.97142,  0.     , ..., 43.8805 , 26.456  , 74.3193 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.74583 ,   0.384998, ...,  89.1006  ,  49.1177  ,\n",
       "        166.824   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.    ,  51.5559,   0.    , ..., 238.469 ,  74.6412, 507.248 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.260841,   9.38221 ,   0.250621, ...,  82.6019  ,  22.5921  ,\n",
       "        144.      ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  10.7245  ,   0.329443, ...,  76.454   ,  31.592   ,\n",
       "        105.801   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 12.877   ,  0.653403, ..., 40.5646  , 25.3987  ,\n",
       "        49.9262  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.841408,  27.9224  ,   4.23406 , ...,  72.5019  , 132.899   ,\n",
       "         98.3912  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 11.3237  ,  0.354389, ..., 31.2496  , 15.2     ,\n",
       "        62.1417  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 8.55214e+01, 2.84762e-01, ..., 1.90357e+02,\n",
       "        5.03456e+01, 3.07331e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  3.71902 ,  0.320979, ..., 49.4546  , 39.6464  ,\n",
       "        59.9711  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   5.0118  ,   0.453109, ...,  75.1076  ,  35.4312  ,\n",
       "        124.289   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  1.17473,  46.8458 ,   5.17773, ..., 244.827  , 311.904  ,\n",
       "        242.856  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  50.9554  ,   0.589611, ..., 148.197   ,  44.7839  ,\n",
       "        236.854   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   6.97363 ,   0.266221, ..., 103.004   ,  36.7781  ,\n",
       "        174.363   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 1.50615e+00, 6.33065e-02, ..., 6.31784e+01,\n",
       "        9.43161e+00, 1.01921e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([1.67486e-01, 6.37324e+00, 9.53986e-02, ..., 6.42733e+01,\n",
       "        1.28141e+01, 1.51127e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      , 29.6802  ,  0.148025, ..., 38.5886  , 13.0618  ,\n",
       "        80.24    ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,  79.0451  ,   0.699595, ..., 290.832   , 127.611   ,\n",
       "        448.728   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.240712,  1.48152 ,  0.      , ..., 35.8847  , 10.633   ,\n",
       "        67.9006  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.334701,  2.9412  ,  0.191828, ..., 49.5674  , 12.2894  ,\n",
       "        59.8662  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  1.35724 ,  0.196215, ..., 33.3596  , 10.9795  ,\n",
       "        79.3315  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.76825 ,   0.398454, ...,  69.7003  ,  27.5369  ,\n",
       "        136.964   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([0.00000e+00, 7.65768e+00, 1.85171e-01, ..., 6.66625e+01,\n",
       "        2.18125e+01, 2.02624e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.      ,   3.41929 ,   0.324966, ...,  93.9192  ,  27.5484  ,\n",
       "        119.961   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   6.64495,   0.     , ...,  47.1209 ,  14.4507 ,\n",
       "        134.854  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,   4.15033,   0.     , ...,  63.716  ,  16.9751 ,\n",
       "        110.464  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  0.     ,  13.6827 ,   1.16963, ..., 130.399  , 177.057  ,\n",
       "        138.689  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([ 0.      ,  2.31502 ,  0.283433, ..., 50.2115  , 21.991   ,\n",
       "        91.1672  ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([2.42003e-01, 3.15755e+01, 3.38761e-01, ..., 2.00619e+02,\n",
       "        4.67393e+01, 3.93328e+02], dtype=float32)>,\n",
       " <tf.Tensor: shape=(95309,), dtype=float32, numpy=\n",
       " array([  2.30456,  10.2168 ,   1.30327, ...,  84.3014 ,  57.3535 ,\n",
       "        119.991  ], dtype=float32)>,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array(train_ds)\n",
    "MAD = scipy.stats.median_abs_deviation(data_array)\n",
    "gene_selected = [True if val > 10 else False for val in MAD]\n",
    "data_selected = data_array[:,gene_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2735"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = sum(gene_selected)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected = data_array[:,gene_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4755, 2735)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# turn it into a tf.data.Dataset object\n",
    "x_train = tf.data.Dataset.from_tensor_slices(data_selected)\n",
    "\n",
    "dataset = x_train.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(None, 2735), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2735)]       0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2735)         0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " unit_normalization (UnitNormal  (None, 2735)        0           ['flatten[0][0]']                \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          700416      ['unit_normalization[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 64)           16448       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 64)           16448       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 64)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 799,104\n",
      "Trainable params: 799,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "t_shape = (p)\n",
    "encoder_inputs = keras.Input(shape=t_shape)\n",
    "x = layers.Flatten()(encoder_inputs)\n",
    "#x = layers.BatchNormalization()(x)\n",
    "x = layers.UnitNormalization()(x) # to avoid overloading float32\n",
    "x = layers.Dense(256, activation = \"relu\")(x)\n",
    "x = layers.Dense(256, activation = \"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2735)              702895    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 719,535\n",
      "Trainable params: 719,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(256, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(256, activation=\"relu\")(latent_inputs)\n",
    "decoder_outputs = layers.Dense(p, activation=\"relu\")(x)\n",
    "\n",
    "#decoder_outputs = layers.Reshape((1, 95309))(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_sum(\n",
    "                    keras.losses.mean_squared_error(data, reconstruction), axis=(0)\n",
    "                )\n",
    "            reconstruction_loss = keras.losses.mean_squared_error(data, reconstruction) # which one is right ???\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 16:58:21.470518: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 8ms/step - loss: 2734207.6151 - reconstruction_loss: 2500634.2500 - kl_loss: 10212.5312\n",
      "Epoch 2/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 2059610.0411 - reconstruction_loss: 1641173.8750 - kl_loss: 54393.0078\n",
      "Epoch 3/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 1174872.9572 - reconstruction_loss: 953048.3125 - kl_loss: 68460.2891\n",
      "Epoch 4/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 915676.3635 - reconstruction_loss: 821054.7500 - kl_loss: 54003.9219\n",
      "Epoch 5/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 881749.7747 - reconstruction_loss: 808474.1250 - kl_loss: 42299.5508\n",
      "Epoch 6/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 867953.5247 - reconstruction_loss: 805305.3750 - kl_loss: 34325.1016\n",
      "Epoch 7/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 860675.9104 - reconstruction_loss: 804033.2500 - kl_loss: 29279.8926\n",
      "Epoch 8/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 855463.8882 - reconstruction_loss: 803113.7500 - kl_loss: 25509.3184\n",
      "Epoch 9/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 851633.4071 - reconstruction_loss: 802535.9375 - kl_loss: 22617.9961\n",
      "Epoch 10/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 848662.7015 - reconstruction_loss: 802118.2500 - kl_loss: 20310.9668\n",
      "Epoch 11/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 846373.2294 - reconstruction_loss: 801852.0625 - kl_loss: 18419.7031\n",
      "Epoch 12/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 844474.4071 - reconstruction_loss: 801593.5000 - kl_loss: 16864.3145\n",
      "Epoch 13/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 842592.6464 - reconstruction_loss: 801144.6250 - kl_loss: 15551.9619\n",
      "Epoch 14/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 840487.0074 - reconstruction_loss: 799339.3750 - kl_loss: 14816.0996\n",
      "Epoch 15/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 819775.3865 - reconstruction_loss: 733123.2500 - kl_loss: 28164.1191\n",
      "Epoch 16/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 607584.6998 - reconstruction_loss: 487428.3750 - kl_loss: 40468.2070\n",
      "Epoch 17/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 421855.0942 - reconstruction_loss: 335970.7188 - kl_loss: 36591.0312\n",
      "Epoch 18/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 344726.8002 - reconstruction_loss: 276976.4688 - kl_loss: 32795.5781\n",
      "Epoch 19/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 317841.3454 - reconstruction_loss: 257975.9688 - kl_loss: 29081.2773\n",
      "Epoch 20/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 306167.2969 - reconstruction_loss: 250392.6094 - kl_loss: 26071.8457\n",
      "Epoch 21/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 299502.2303 - reconstruction_loss: 246408.7500 - kl_loss: 23727.4844\n",
      "Epoch 22/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 294968.6036 - reconstruction_loss: 243766.7500 - kl_loss: 21844.1836\n",
      "Epoch 23/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 291260.6077 - reconstruction_loss: 241461.6719 - kl_loss: 20308.2852\n",
      "Epoch 24/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 287787.3370 - reconstruction_loss: 239013.8750 - kl_loss: 19066.7441\n",
      "Epoch 25/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 284277.5944 - reconstruction_loss: 236183.1562 - kl_loss: 18069.1992\n",
      "Epoch 26/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 280280.6815 - reconstruction_loss: 232532.7344 - kl_loss: 17302.8086\n",
      "Epoch 27/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 275623.0592 - reconstruction_loss: 227847.8906 - kl_loss: 16722.4082\n",
      "Epoch 28/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 269931.1548 - reconstruction_loss: 221875.1875 - kl_loss: 16325.9736\n",
      "Epoch 29/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 263349.2204 - reconstruction_loss: 214693.2344 - kl_loss: 16105.0938\n",
      "Epoch 30/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 255949.1254 - reconstruction_loss: 206511.1406 - kl_loss: 16031.7764\n",
      "Epoch 31/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 248222.1456 - reconstruction_loss: 197975.3281 - kl_loss: 16051.8047\n",
      "Epoch 32/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 240561.3446 - reconstruction_loss: 189571.5938 - kl_loss: 16129.7002\n",
      "Epoch 33/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 233410.5929 - reconstruction_loss: 181838.8281 - kl_loss: 16181.0303\n",
      "Epoch 34/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 227037.6100 - reconstruction_loss: 175103.0781 - kl_loss: 16152.6299\n",
      "Epoch 35/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 221916.6057 - reconstruction_loss: 169818.9531 - kl_loss: 16002.8203\n",
      "Epoch 36/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 217948.9994 - reconstruction_loss: 165834.0938 - kl_loss: 15734.8916\n",
      "Epoch 37/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 214731.5572 - reconstruction_loss: 162801.4688 - kl_loss: 15379.9316\n",
      "Epoch 38/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 212224.1493 - reconstruction_loss: 160585.4219 - kl_loss: 14950.3984\n",
      "Epoch 39/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 210257.2525 - reconstruction_loss: 158937.9375 - kl_loss: 14477.2217\n",
      "Epoch 40/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 208601.0282 - reconstruction_loss: 157662.7031 - kl_loss: 13982.8984\n",
      "Epoch 41/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 207219.1106 - reconstruction_loss: 156696.3906 - kl_loss: 13473.8916\n",
      "Epoch 42/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 205970.4634 - reconstruction_loss: 155833.7188 - kl_loss: 12972.1650\n",
      "Epoch 43/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 204870.2802 - reconstruction_loss: 155153.0938 - kl_loss: 12487.9414\n",
      "Epoch 44/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 203906.3824 - reconstruction_loss: 154587.7969 - kl_loss: 12023.6631\n",
      "Epoch 45/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 203034.7455 - reconstruction_loss: 154127.7344 - kl_loss: 11574.3447\n",
      "Epoch 46/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 202236.9630 - reconstruction_loss: 153721.2812 - kl_loss: 11147.9248\n",
      "Epoch 47/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 201530.4367 - reconstruction_loss: 153370.1094 - kl_loss: 10745.6719\n",
      "Epoch 48/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 200828.0475 - reconstruction_loss: 153041.1875 - kl_loss: 10364.1553\n",
      "Epoch 49/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 200191.6797 - reconstruction_loss: 152749.5625 - kl_loss: 10002.0088\n",
      "Epoch 50/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 199596.3139 - reconstruction_loss: 152452.9062 - kl_loss: 9661.2861\n",
      "Epoch 51/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 199014.2373 - reconstruction_loss: 152177.2344 - kl_loss: 9339.2354\n",
      "Epoch 52/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 198431.6622 - reconstruction_loss: 151910.1250 - kl_loss: 9034.4004\n",
      "Epoch 53/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 197892.2052 - reconstruction_loss: 151657.1094 - kl_loss: 8748.7002\n",
      "Epoch 54/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 197401.9350 - reconstruction_loss: 151423.0938 - kl_loss: 8479.8838\n",
      "Epoch 55/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 196873.3464 - reconstruction_loss: 151155.7969 - kl_loss: 8225.9385\n",
      "Epoch 56/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 196326.9289 - reconstruction_loss: 150862.8281 - kl_loss: 7986.2793\n",
      "Epoch 57/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 195824.8051 - reconstruction_loss: 150614.6406 - kl_loss: 7758.1357\n",
      "Epoch 58/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 195528.7336 - reconstruction_loss: 150464.8438 - kl_loss: 7555.8018\n",
      "Epoch 59/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 194880.7058 - reconstruction_loss: 150120.1719 - kl_loss: 7334.5024\n",
      "Epoch 60/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 194405.8234 - reconstruction_loss: 149840.3125 - kl_loss: 7143.7993\n",
      "Epoch 61/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 193935.4258 - reconstruction_loss: 149601.0781 - kl_loss: 6960.6064\n",
      "Epoch 62/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 193454.5775 - reconstruction_loss: 149320.6250 - kl_loss: 6788.3359\n",
      "Epoch 63/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 192992.3121 - reconstruction_loss: 149067.2188 - kl_loss: 6623.5942\n",
      "Epoch 64/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 192479.8853 - reconstruction_loss: 148708.0312 - kl_loss: 6468.0288\n",
      "Epoch 65/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 191935.9940 - reconstruction_loss: 148397.2188 - kl_loss: 6323.4736\n",
      "Epoch 66/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 191731.9574 - reconstruction_loss: 148468.0312 - kl_loss: 6182.5264\n",
      "Epoch 67/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 191125.0021 - reconstruction_loss: 147995.1406 - kl_loss: 6055.9878\n",
      "Epoch 68/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 190452.3783 - reconstruction_loss: 147682.8125 - kl_loss: 5943.5674\n",
      "Epoch 69/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 189951.3497 - reconstruction_loss: 147549.5781 - kl_loss: 5832.5220\n",
      "Epoch 70/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 189598.1412 - reconstruction_loss: 146875.1719 - kl_loss: 5728.7827\n",
      "Epoch 71/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 188777.2510 - reconstruction_loss: 146548.3750 - kl_loss: 5635.7871\n",
      "Epoch 72/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 188028.7165 - reconstruction_loss: 145957.2344 - kl_loss: 5542.4185\n",
      "Epoch 73/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 187466.6390 - reconstruction_loss: 145358.6719 - kl_loss: 5464.2607\n",
      "Epoch 74/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 186481.6176 - reconstruction_loss: 144669.6562 - kl_loss: 5395.1152\n",
      "Epoch 75/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 185537.1600 - reconstruction_loss: 144082.3438 - kl_loss: 5314.0137\n",
      "Epoch 76/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 184822.7305 - reconstruction_loss: 143653.5312 - kl_loss: 5234.9937\n",
      "Epoch 77/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 184284.5940 - reconstruction_loss: 143295.6250 - kl_loss: 5159.5469\n",
      "Epoch 78/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 183769.7270 - reconstruction_loss: 142963.3281 - kl_loss: 5082.3291\n",
      "Epoch 79/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 183281.7880 - reconstruction_loss: 142660.6406 - kl_loss: 5015.6016\n",
      "Epoch 80/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 182716.7630 - reconstruction_loss: 142265.6250 - kl_loss: 4956.6392\n",
      "Epoch 81/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 182173.2354 - reconstruction_loss: 141867.4844 - kl_loss: 4896.6562\n",
      "Epoch 82/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 181627.6236 - reconstruction_loss: 141497.3438 - kl_loss: 4834.2021\n",
      "Epoch 83/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 181123.7235 - reconstruction_loss: 141148.4375 - kl_loss: 4784.5298\n",
      "Epoch 84/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 180560.9204 - reconstruction_loss: 140739.4375 - kl_loss: 4729.5073\n",
      "Epoch 85/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 180200.3265 - reconstruction_loss: 140476.5469 - kl_loss: 4676.7783\n",
      "Epoch 86/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 179416.4922 - reconstruction_loss: 140044.2188 - kl_loss: 4627.2344\n",
      "Epoch 87/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 178744.3181 - reconstruction_loss: 139607.6875 - kl_loss: 4578.7754\n",
      "Epoch 88/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 178254.0549 - reconstruction_loss: 139361.0469 - kl_loss: 4533.0269\n",
      "Epoch 89/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 178079.3923 - reconstruction_loss: 139407.0156 - kl_loss: 4490.8218\n",
      "Epoch 90/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 179029.8684 - reconstruction_loss: 140144.7500 - kl_loss: 4449.4346\n",
      "Epoch 91/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 177429.4979 - reconstruction_loss: 139020.7969 - kl_loss: 4406.2969\n",
      "Epoch 92/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 179329.9075 - reconstruction_loss: 139830.8125 - kl_loss: 4373.7090\n",
      "Epoch 93/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 177726.9359 - reconstruction_loss: 139050.8594 - kl_loss: 4345.4541\n",
      "Epoch 94/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 176658.9796 - reconstruction_loss: 138472.9844 - kl_loss: 4315.0845\n",
      "Epoch 95/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 176182.9009 - reconstruction_loss: 138194.6719 - kl_loss: 4282.3311\n",
      "Epoch 96/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 175779.4095 - reconstruction_loss: 137893.7188 - kl_loss: 4247.6748\n",
      "Epoch 97/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 175462.9069 - reconstruction_loss: 137719.9844 - kl_loss: 4211.4741\n",
      "Epoch 98/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 175230.4918 - reconstruction_loss: 137563.0625 - kl_loss: 4179.8916\n",
      "Epoch 99/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 174810.3820 - reconstruction_loss: 137264.8125 - kl_loss: 4147.3345\n",
      "Epoch 100/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 174830.0265 - reconstruction_loss: 137279.9375 - kl_loss: 4117.4683\n",
      "Epoch 101/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 174901.6266 - reconstruction_loss: 137433.1094 - kl_loss: 4094.9268\n",
      "Epoch 102/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 175654.2527 - reconstruction_loss: 137411.6406 - kl_loss: 4063.6086\n",
      "Epoch 103/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 174947.8360 - reconstruction_loss: 136936.3906 - kl_loss: 4032.0896\n",
      "Epoch 104/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 174716.0851 - reconstruction_loss: 137056.0000 - kl_loss: 4009.1357\n",
      "Epoch 105/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 173554.2599 - reconstruction_loss: 136416.5625 - kl_loss: 3990.5022\n",
      "Epoch 106/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 173309.0769 - reconstruction_loss: 136257.6250 - kl_loss: 3970.0518\n",
      "Epoch 107/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 172854.1581 - reconstruction_loss: 135955.5781 - kl_loss: 3943.0688\n",
      "Epoch 108/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 173541.5021 - reconstruction_loss: 136357.5312 - kl_loss: 3923.0325\n",
      "Epoch 109/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 173443.6318 - reconstruction_loss: 136422.2031 - kl_loss: 3905.4346\n",
      "Epoch 110/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 173464.1486 - reconstruction_loss: 136151.3438 - kl_loss: 3881.4583\n",
      "Epoch 111/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 172391.8252 - reconstruction_loss: 135714.1406 - kl_loss: 3862.6255\n",
      "Epoch 112/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 172665.8453 - reconstruction_loss: 135847.7656 - kl_loss: 3847.0779\n",
      "Epoch 113/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 172748.3829 - reconstruction_loss: 135954.6719 - kl_loss: 3830.0830\n",
      "Epoch 114/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 172547.5595 - reconstruction_loss: 135588.0469 - kl_loss: 3805.0288\n",
      "Epoch 115/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 172967.2712 - reconstruction_loss: 135871.0156 - kl_loss: 3793.2729\n",
      "Epoch 116/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 172051.2329 - reconstruction_loss: 135490.9531 - kl_loss: 3780.9729\n",
      "Epoch 117/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 171810.5368 - reconstruction_loss: 135136.2969 - kl_loss: 3762.5771\n",
      "Epoch 118/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 172499.8668 - reconstruction_loss: 135527.5781 - kl_loss: 3749.9624\n",
      "Epoch 119/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 171098.1657 - reconstruction_loss: 134798.0625 - kl_loss: 3737.1904\n",
      "Epoch 120/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 170876.3004 - reconstruction_loss: 134631.2812 - kl_loss: 3717.3232\n",
      "Epoch 121/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 172267.2602 - reconstruction_loss: 135319.4375 - kl_loss: 3708.1345\n",
      "Epoch 122/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 170249.1404 - reconstruction_loss: 134195.4844 - kl_loss: 3691.9387\n",
      "Epoch 123/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 171188.8309 - reconstruction_loss: 134573.5156 - kl_loss: 3694.2275\n",
      "Epoch 124/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 170176.7117 - reconstruction_loss: 134031.8438 - kl_loss: 3714.2476\n",
      "Epoch 125/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 169877.9648 - reconstruction_loss: 133542.4062 - kl_loss: 3719.1438\n",
      "Epoch 126/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 171074.7562 - reconstruction_loss: 134168.6094 - kl_loss: 3730.2100\n",
      "Epoch 127/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 169126.8945 - reconstruction_loss: 133088.2500 - kl_loss: 3736.9233\n",
      "Epoch 128/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 168567.2652 - reconstruction_loss: 132649.9531 - kl_loss: 3735.2737\n",
      "Epoch 129/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 170527.1881 - reconstruction_loss: 133591.5469 - kl_loss: 3744.0803\n",
      "Epoch 130/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 168102.4174 - reconstruction_loss: 132384.0938 - kl_loss: 3753.6426\n",
      "Epoch 131/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 167705.9235 - reconstruction_loss: 131981.7344 - kl_loss: 3752.4509\n",
      "Epoch 132/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 169545.3464 - reconstruction_loss: 132815.4375 - kl_loss: 3760.1797\n",
      "Epoch 133/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 166772.8779 - reconstruction_loss: 131329.8906 - kl_loss: 3771.7861\n",
      "Epoch 134/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 167136.6208 - reconstruction_loss: 131370.6875 - kl_loss: 3779.7688\n",
      "Epoch 135/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 166224.4987 - reconstruction_loss: 130808.9609 - kl_loss: 3803.1799\n",
      "Epoch 136/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 165551.4789 - reconstruction_loss: 129818.1016 - kl_loss: 3805.6858\n",
      "Epoch 137/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 165328.9408 - reconstruction_loss: 129595.5469 - kl_loss: 3817.7808\n",
      "Epoch 138/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 162197.8941 - reconstruction_loss: 127678.0078 - kl_loss: 3857.6621\n",
      "Epoch 139/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 160599.1819 - reconstruction_loss: 125957.3984 - kl_loss: 3882.1396\n",
      "Epoch 140/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 160784.6822 - reconstruction_loss: 125445.3281 - kl_loss: 3917.8313\n",
      "Epoch 141/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 157918.9161 - reconstruction_loss: 123514.4922 - kl_loss: 3952.6104\n",
      "Epoch 142/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 155508.3419 - reconstruction_loss: 121601.2344 - kl_loss: 3975.5459\n",
      "Epoch 143/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 153213.3490 - reconstruction_loss: 119688.4375 - kl_loss: 4001.7146\n",
      "Epoch 144/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 151048.5132 - reconstruction_loss: 118047.8984 - kl_loss: 4019.2988\n",
      "Epoch 145/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 148569.9620 - reconstruction_loss: 116457.3594 - kl_loss: 4043.7612\n",
      "Epoch 146/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 146645.9861 - reconstruction_loss: 114826.2812 - kl_loss: 4066.9204\n",
      "Epoch 147/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 143386.6313 - reconstruction_loss: 112836.7109 - kl_loss: 4100.8359\n",
      "Epoch 148/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 141670.2439 - reconstruction_loss: 111560.2109 - kl_loss: 4157.9692\n",
      "Epoch 149/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 138171.9832 - reconstruction_loss: 109517.6250 - kl_loss: 4220.6069\n",
      "Epoch 150/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 135008.9848 - reconstruction_loss: 107581.6016 - kl_loss: 4298.6489\n",
      "Epoch 151/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 131737.9193 - reconstruction_loss: 105445.1953 - kl_loss: 4403.8862\n",
      "Epoch 152/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 127985.3864 - reconstruction_loss: 103087.7969 - kl_loss: 4511.7544\n",
      "Epoch 153/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 124527.7359 - reconstruction_loss: 100953.6484 - kl_loss: 4616.5415\n",
      "Epoch 154/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 121212.9139 - reconstruction_loss: 99013.3047 - kl_loss: 4731.9258\n",
      "Epoch 155/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 119348.4027 - reconstruction_loss: 97923.9219 - kl_loss: 4810.7466\n",
      "Epoch 156/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 115503.4371 - reconstruction_loss: 95621.8281 - kl_loss: 4899.9634\n",
      "Epoch 157/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 112478.3588 - reconstruction_loss: 93832.1641 - kl_loss: 4982.8213\n",
      "Epoch 158/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 109863.2420 - reconstruction_loss: 92383.5938 - kl_loss: 5048.6211\n",
      "Epoch 159/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 107829.7911 - reconstruction_loss: 91234.8906 - kl_loss: 5086.8052\n",
      "Epoch 160/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 105864.3339 - reconstruction_loss: 90054.8203 - kl_loss: 5106.8970\n",
      "Epoch 161/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 103630.1945 - reconstruction_loss: 88717.9219 - kl_loss: 5118.9976\n",
      "Epoch 162/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 101909.4334 - reconstruction_loss: 87631.5312 - kl_loss: 5131.8628\n",
      "Epoch 163/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 100059.0965 - reconstruction_loss: 86448.9766 - kl_loss: 5143.6821\n",
      "Epoch 164/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 98401.9036 - reconstruction_loss: 85337.6406 - kl_loss: 5146.4634\n",
      "Epoch 165/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 96903.3295 - reconstruction_loss: 84350.4609 - kl_loss: 5137.2646\n",
      "Epoch 166/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 95485.0449 - reconstruction_loss: 83407.6094 - kl_loss: 5124.4956\n",
      "Epoch 167/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 94251.5793 - reconstruction_loss: 82576.3359 - kl_loss: 5102.4966\n",
      "Epoch 168/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 93081.6146 - reconstruction_loss: 81791.3516 - kl_loss: 5078.4897\n",
      "Epoch 169/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 92057.6900 - reconstruction_loss: 81130.3828 - kl_loss: 5053.0005\n",
      "Epoch 170/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 91066.0845 - reconstruction_loss: 80434.4297 - kl_loss: 5019.4297\n",
      "Epoch 171/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 90080.4743 - reconstruction_loss: 79839.0625 - kl_loss: 4980.8076\n",
      "Epoch 172/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 89263.3560 - reconstruction_loss: 79279.5625 - kl_loss: 4940.5366\n",
      "Epoch 173/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 88425.0556 - reconstruction_loss: 78747.1641 - kl_loss: 4903.6489\n",
      "Epoch 174/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 87744.9252 - reconstruction_loss: 78316.6953 - kl_loss: 4862.9258\n",
      "Epoch 175/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 87154.6317 - reconstruction_loss: 77888.6016 - kl_loss: 4820.7681\n",
      "Epoch 176/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 86329.0465 - reconstruction_loss: 77360.0000 - kl_loss: 4773.7847\n",
      "Epoch 177/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 86872.6166 - reconstruction_loss: 78135.9297 - kl_loss: 4822.3359\n",
      "Epoch 178/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 85938.3295 - reconstruction_loss: 76937.2500 - kl_loss: 4726.8799\n",
      "Epoch 179/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 85108.8067 - reconstruction_loss: 76678.6250 - kl_loss: 4654.8052\n",
      "Epoch 180/5000\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 84423.2191 - reconstruction_loss: 76269.8906 - kl_loss: 4599.7251\n",
      "Epoch 181/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 83440.1087 - reconstruction_loss: 75602.6719 - kl_loss: 4555.4312\n",
      "Epoch 182/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 82805.9539 - reconstruction_loss: 75181.3281 - kl_loss: 4512.6455\n",
      "Epoch 183/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 82204.6410 - reconstruction_loss: 74810.4141 - kl_loss: 4470.2134\n",
      "Epoch 184/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 81707.7017 - reconstruction_loss: 74498.8047 - kl_loss: 4428.3423\n",
      "Epoch 185/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 81142.5114 - reconstruction_loss: 74114.6562 - kl_loss: 4389.0054\n",
      "Epoch 186/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 80588.7721 - reconstruction_loss: 73759.0859 - kl_loss: 4346.7847\n",
      "Epoch 187/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 80076.0586 - reconstruction_loss: 73396.4609 - kl_loss: 4307.2500\n",
      "Epoch 188/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 79537.2973 - reconstruction_loss: 72994.3828 - kl_loss: 4277.2319\n",
      "Epoch 189/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 78878.4365 - reconstruction_loss: 72506.5234 - kl_loss: 4253.2271\n",
      "Epoch 190/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 78514.3492 - reconstruction_loss: 72131.7031 - kl_loss: 4298.0269\n",
      "Epoch 191/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 77711.5414 - reconstruction_loss: 71636.2266 - kl_loss: 4215.8169\n",
      "Epoch 192/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 77440.3435 - reconstruction_loss: 71416.2812 - kl_loss: 4191.3184\n",
      "Epoch 193/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 77431.5278 - reconstruction_loss: 71714.6016 - kl_loss: 4171.7598\n",
      "Epoch 194/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 77366.5939 - reconstruction_loss: 71444.8047 - kl_loss: 4157.6011\n",
      "Epoch 195/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 75294.6039 - reconstruction_loss: 69792.0078 - kl_loss: 4155.7998\n",
      "Epoch 196/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 74571.3671 - reconstruction_loss: 69243.7266 - kl_loss: 4143.5801\n",
      "Epoch 197/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 191218.1982 - reconstruction_loss: 96600.1562 - kl_loss: 10308.5469\n",
      "Epoch 198/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 76768.2663 - reconstruction_loss: 69898.5859 - kl_loss: 4348.5552\n",
      "Epoch 199/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 74826.0703 - reconstruction_loss: 68858.7344 - kl_loss: 4267.4082\n",
      "Epoch 200/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 74037.1294 - reconstruction_loss: 68378.7734 - kl_loss: 4206.7749\n",
      "Epoch 201/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 73427.4979 - reconstruction_loss: 67979.3359 - kl_loss: 4154.4966\n",
      "Epoch 202/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 72974.4033 - reconstruction_loss: 67692.1250 - kl_loss: 4111.2573\n",
      "Epoch 203/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 72509.0715 - reconstruction_loss: 67395.1094 - kl_loss: 4069.3787\n",
      "Epoch 204/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 72085.0833 - reconstruction_loss: 67105.3984 - kl_loss: 4029.7380\n",
      "Epoch 205/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 71710.0891 - reconstruction_loss: 66849.9375 - kl_loss: 3993.0837\n",
      "Epoch 206/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 71346.0734 - reconstruction_loss: 66592.1250 - kl_loss: 3958.4836\n",
      "Epoch 207/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 71015.8702 - reconstruction_loss: 66389.5469 - kl_loss: 3925.0022\n",
      "Epoch 208/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 70672.3686 - reconstruction_loss: 66141.9609 - kl_loss: 3891.7363\n",
      "Epoch 209/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 70354.7264 - reconstruction_loss: 65911.0938 - kl_loss: 3861.5671\n",
      "Epoch 210/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 70714.7546 - reconstruction_loss: 66120.6172 - kl_loss: 3872.7087\n",
      "Epoch 211/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 70109.7857 - reconstruction_loss: 65591.8203 - kl_loss: 3812.0967\n",
      "Epoch 212/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 69575.4028 - reconstruction_loss: 65325.3320 - kl_loss: 3777.2236\n",
      "Epoch 213/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 69266.7110 - reconstruction_loss: 65087.0156 - kl_loss: 3745.7942\n",
      "Epoch 214/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 68997.2163 - reconstruction_loss: 64878.8516 - kl_loss: 3714.2637\n",
      "Epoch 215/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 68768.1797 - reconstruction_loss: 64712.9961 - kl_loss: 3681.9922\n",
      "Epoch 216/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 68429.3185 - reconstruction_loss: 64454.4609 - kl_loss: 3653.9546\n",
      "Epoch 217/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 68208.0960 - reconstruction_loss: 64258.3359 - kl_loss: 3629.0249\n",
      "Epoch 218/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 67919.0359 - reconstruction_loss: 64041.6836 - kl_loss: 3599.3513\n",
      "Epoch 219/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 67689.6175 - reconstruction_loss: 63878.2383 - kl_loss: 3566.7192\n",
      "Epoch 220/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 67421.7501 - reconstruction_loss: 63650.9258 - kl_loss: 3542.5276\n",
      "Epoch 221/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 67169.9830 - reconstruction_loss: 63454.7969 - kl_loss: 3511.4216\n",
      "Epoch 222/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 66881.9494 - reconstruction_loss: 63225.0078 - kl_loss: 3487.5859\n",
      "Epoch 223/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 66628.2260 - reconstruction_loss: 63024.4531 - kl_loss: 3462.4861\n",
      "Epoch 224/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 66431.8674 - reconstruction_loss: 62848.0195 - kl_loss: 3437.5667\n",
      "Epoch 225/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 66132.1395 - reconstruction_loss: 62645.3320 - kl_loss: 3409.2522\n",
      "Epoch 226/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 65965.9283 - reconstruction_loss: 62480.3789 - kl_loss: 3382.7314\n",
      "Epoch 227/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 65674.5459 - reconstruction_loss: 62258.4180 - kl_loss: 3353.9753\n",
      "Epoch 228/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 65461.3519 - reconstruction_loss: 62085.7148 - kl_loss: 3327.6067\n",
      "Epoch 229/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 65199.0246 - reconstruction_loss: 61865.4961 - kl_loss: 3304.0356\n",
      "Epoch 230/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 64983.7977 - reconstruction_loss: 61707.7227 - kl_loss: 3278.2139\n",
      "Epoch 231/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 64818.1916 - reconstruction_loss: 61562.4336 - kl_loss: 3257.4570\n",
      "Epoch 232/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 64542.5966 - reconstruction_loss: 61331.6367 - kl_loss: 3229.7139\n",
      "Epoch 233/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 64333.9129 - reconstruction_loss: 61190.3242 - kl_loss: 3206.0920\n",
      "Epoch 234/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 64109.6198 - reconstruction_loss: 60996.0898 - kl_loss: 3184.0745\n",
      "Epoch 235/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 63995.8288 - reconstruction_loss: 61000.3711 - kl_loss: 3158.3765\n",
      "Epoch 236/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 63697.8982 - reconstruction_loss: 60653.7617 - kl_loss: 3138.3723\n",
      "Epoch 237/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 63570.9940 - reconstruction_loss: 60583.0547 - kl_loss: 3114.1995\n",
      "Epoch 238/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 63354.6295 - reconstruction_loss: 60431.4453 - kl_loss: 3092.7771\n",
      "Epoch 239/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 63084.1077 - reconstruction_loss: 60145.9961 - kl_loss: 3071.8040\n",
      "Epoch 240/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 62885.7605 - reconstruction_loss: 59978.2344 - kl_loss: 3050.1157\n",
      "Epoch 241/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 62818.5059 - reconstruction_loss: 59896.1992 - kl_loss: 3033.2588\n",
      "Epoch 242/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 62674.0170 - reconstruction_loss: 59768.1875 - kl_loss: 3011.3926\n",
      "Epoch 243/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 62538.5678 - reconstruction_loss: 59652.6641 - kl_loss: 2995.3174\n",
      "Epoch 244/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 62383.7879 - reconstruction_loss: 59499.1562 - kl_loss: 2982.0491\n",
      "Epoch 245/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 62335.7541 - reconstruction_loss: 59400.5547 - kl_loss: 2963.8755\n",
      "Epoch 246/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 62212.9513 - reconstruction_loss: 59282.6680 - kl_loss: 2949.8677\n",
      "Epoch 247/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 61822.4226 - reconstruction_loss: 58870.5039 - kl_loss: 2932.0156\n",
      "Epoch 248/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 61226.8818 - reconstruction_loss: 58418.1836 - kl_loss: 2918.1355\n",
      "Epoch 249/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 61015.0039 - reconstruction_loss: 58269.7656 - kl_loss: 2905.7620\n",
      "Epoch 250/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 60727.7043 - reconstruction_loss: 57950.0898 - kl_loss: 2889.4739\n",
      "Epoch 251/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 60142.8818 - reconstruction_loss: 57474.2539 - kl_loss: 2873.3560\n",
      "Epoch 252/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 59856.0180 - reconstruction_loss: 57175.7305 - kl_loss: 2859.7180\n",
      "Epoch 253/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 59495.1615 - reconstruction_loss: 56864.5664 - kl_loss: 2845.2756\n",
      "Epoch 254/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 59139.2048 - reconstruction_loss: 56517.7617 - kl_loss: 2828.9595\n",
      "Epoch 255/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 58852.2994 - reconstruction_loss: 56262.5312 - kl_loss: 2806.0425\n",
      "Epoch 256/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 58560.9428 - reconstruction_loss: 56000.0039 - kl_loss: 2789.9324\n",
      "Epoch 257/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 58442.0965 - reconstruction_loss: 55929.5742 - kl_loss: 2768.3616\n",
      "Epoch 258/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 58407.9626 - reconstruction_loss: 55877.2812 - kl_loss: 2746.1030\n",
      "Epoch 259/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 58659.0492 - reconstruction_loss: 56031.8789 - kl_loss: 2731.2351\n",
      "Epoch 260/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 58425.7798 - reconstruction_loss: 56173.9531 - kl_loss: 2711.7510\n",
      "Epoch 261/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 58366.8102 - reconstruction_loss: 55835.0664 - kl_loss: 2686.8389\n",
      "Epoch 262/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 57887.1284 - reconstruction_loss: 55403.3750 - kl_loss: 2669.9351\n",
      "Epoch 263/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 57335.2837 - reconstruction_loss: 54934.3281 - kl_loss: 2653.4746\n",
      "Epoch 264/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 57005.1124 - reconstruction_loss: 54632.5117 - kl_loss: 2632.5713\n",
      "Epoch 265/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 56798.7950 - reconstruction_loss: 54443.3984 - kl_loss: 2615.0576\n",
      "Epoch 266/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 56650.0323 - reconstruction_loss: 54290.6836 - kl_loss: 2596.3115\n",
      "Epoch 267/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 56439.7278 - reconstruction_loss: 54085.5547 - kl_loss: 2579.7266\n",
      "Epoch 268/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 56282.4122 - reconstruction_loss: 53948.6172 - kl_loss: 2564.7266\n",
      "Epoch 269/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 56107.6620 - reconstruction_loss: 53773.0508 - kl_loss: 2549.0662\n",
      "Epoch 270/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 55959.4842 - reconstruction_loss: 53635.5117 - kl_loss: 2529.1467\n",
      "Epoch 271/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 55768.0973 - reconstruction_loss: 53460.1641 - kl_loss: 2513.1812\n",
      "Epoch 272/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 55634.8953 - reconstruction_loss: 53328.7812 - kl_loss: 2493.8896\n",
      "Epoch 273/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 55471.8130 - reconstruction_loss: 53188.5938 - kl_loss: 2473.3577\n",
      "Epoch 274/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 55348.7457 - reconstruction_loss: 53041.6719 - kl_loss: 2458.4087\n",
      "Epoch 275/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 55151.1576 - reconstruction_loss: 52863.7812 - kl_loss: 2439.2930\n",
      "Epoch 276/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 54970.2036 - reconstruction_loss: 52709.4062 - kl_loss: 2424.3774\n",
      "Epoch 277/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 54810.0676 - reconstruction_loss: 52545.6055 - kl_loss: 2408.2969\n",
      "Epoch 278/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 54633.6820 - reconstruction_loss: 52394.0156 - kl_loss: 2394.4312\n",
      "Epoch 279/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 54473.8043 - reconstruction_loss: 52261.3047 - kl_loss: 2378.5854\n",
      "Epoch 280/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 54328.4524 - reconstruction_loss: 52117.3828 - kl_loss: 2361.5886\n",
      "Epoch 281/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 54200.3884 - reconstruction_loss: 51981.3398 - kl_loss: 2346.4185\n",
      "Epoch 282/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 53995.7644 - reconstruction_loss: 51791.9844 - kl_loss: 2331.5508\n",
      "Epoch 283/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 53883.8850 - reconstruction_loss: 51692.5703 - kl_loss: 2318.5273\n",
      "Epoch 284/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 53722.8328 - reconstruction_loss: 51539.7031 - kl_loss: 2303.2554\n",
      "Epoch 285/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 53583.1178 - reconstruction_loss: 51417.7305 - kl_loss: 2288.0466\n",
      "Epoch 286/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 53380.5311 - reconstruction_loss: 51228.6602 - kl_loss: 2273.1116\n",
      "Epoch 287/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 53340.5099 - reconstruction_loss: 51157.7227 - kl_loss: 2260.6709\n",
      "Epoch 288/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 53191.7429 - reconstruction_loss: 51045.7148 - kl_loss: 2247.4421\n",
      "Epoch 289/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 53046.9453 - reconstruction_loss: 50957.7930 - kl_loss: 2233.5269\n",
      "Epoch 290/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 53084.7718 - reconstruction_loss: 51059.6719 - kl_loss: 2219.8628\n",
      "Epoch 291/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 53186.5116 - reconstruction_loss: 51038.8086 - kl_loss: 2210.0334\n",
      "Epoch 292/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 52839.3928 - reconstruction_loss: 50622.5273 - kl_loss: 2200.3586\n",
      "Epoch 293/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 53954.0973 - reconstruction_loss: 51415.5781 - kl_loss: 2205.5955\n",
      "Epoch 294/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 52854.1435 - reconstruction_loss: 50437.7461 - kl_loss: 2175.0461\n",
      "Epoch 295/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 52194.7868 - reconstruction_loss: 50083.3047 - kl_loss: 2168.7009\n",
      "Epoch 296/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 52045.2826 - reconstruction_loss: 49963.3750 - kl_loss: 2157.8572\n",
      "Epoch 297/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 51843.3600 - reconstruction_loss: 49807.6172 - kl_loss: 2148.3943\n",
      "Epoch 298/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 51700.8030 - reconstruction_loss: 49658.3086 - kl_loss: 2141.2542\n",
      "Epoch 299/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 51569.9861 - reconstruction_loss: 49544.2812 - kl_loss: 2127.3411\n",
      "Epoch 300/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 51469.4271 - reconstruction_loss: 49419.5703 - kl_loss: 2119.2034\n",
      "Epoch 301/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 51348.2615 - reconstruction_loss: 49266.0000 - kl_loss: 2108.6182\n",
      "Epoch 302/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 51204.9665 - reconstruction_loss: 49136.7852 - kl_loss: 2103.9504\n",
      "Epoch 303/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 51040.9260 - reconstruction_loss: 48988.2578 - kl_loss: 2095.6584\n",
      "Epoch 304/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 50895.8850 - reconstruction_loss: 48890.3008 - kl_loss: 2089.2283\n",
      "Epoch 305/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 50837.3074 - reconstruction_loss: 48764.6133 - kl_loss: 2077.8433\n",
      "Epoch 306/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 53111.6074 - reconstruction_loss: 49925.9141 - kl_loss: 2077.0408\n",
      "Epoch 307/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 81798.6306 - reconstruction_loss: 61387.9102 - kl_loss: 2158.5437\n",
      "Epoch 308/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 57097.9124 - reconstruction_loss: 51481.7617 - kl_loss: 2158.1174\n",
      "Epoch 309/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 54784.7023 - reconstruction_loss: 50442.8906 - kl_loss: 2088.8728\n",
      "Epoch 310/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 51988.9870 - reconstruction_loss: 49343.4805 - kl_loss: 2076.0737\n",
      "Epoch 311/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 51091.0501 - reconstruction_loss: 48920.6406 - kl_loss: 2062.8999\n",
      "Epoch 312/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 50706.4971 - reconstruction_loss: 48718.5547 - kl_loss: 2056.0522\n",
      "Epoch 313/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 50427.8155 - reconstruction_loss: 48523.3203 - kl_loss: 2043.9698\n",
      "Epoch 314/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 50266.9077 - reconstruction_loss: 48396.6133 - kl_loss: 2034.7623\n",
      "Epoch 315/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 50132.7094 - reconstruction_loss: 48266.9531 - kl_loss: 2027.9669\n",
      "Epoch 316/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 49947.0240 - reconstruction_loss: 48137.5469 - kl_loss: 2024.1238\n",
      "Epoch 317/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 49846.0125 - reconstruction_loss: 48013.0820 - kl_loss: 2015.0437\n",
      "Epoch 318/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 49704.9810 - reconstruction_loss: 47887.9648 - kl_loss: 2011.1442\n",
      "Epoch 319/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 49553.3484 - reconstruction_loss: 47738.1172 - kl_loss: 2006.2219\n",
      "Epoch 320/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 49413.4057 - reconstruction_loss: 47611.5781 - kl_loss: 2001.5398\n",
      "Epoch 321/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 49251.0102 - reconstruction_loss: 47471.2695 - kl_loss: 2000.5542\n",
      "Epoch 322/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 49114.5690 - reconstruction_loss: 47325.0586 - kl_loss: 1995.4756\n",
      "Epoch 323/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 48930.2186 - reconstruction_loss: 47179.5430 - kl_loss: 1993.4579\n",
      "Epoch 324/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 48799.3547 - reconstruction_loss: 47023.0898 - kl_loss: 1988.1775\n",
      "Epoch 325/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 48670.9585 - reconstruction_loss: 46888.3008 - kl_loss: 1985.2883\n",
      "Epoch 326/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 48494.0159 - reconstruction_loss: 46728.1836 - kl_loss: 1985.3895\n",
      "Epoch 327/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 48308.2967 - reconstruction_loss: 46552.7773 - kl_loss: 1981.6871\n",
      "Epoch 328/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 48105.1100 - reconstruction_loss: 46362.9297 - kl_loss: 1982.0138\n",
      "Epoch 329/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 47975.9081 - reconstruction_loss: 46205.5664 - kl_loss: 1982.5394\n",
      "Epoch 330/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 47792.8665 - reconstruction_loss: 46011.5938 - kl_loss: 1979.3998\n",
      "Epoch 331/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 47594.1054 - reconstruction_loss: 45824.3008 - kl_loss: 1976.9186\n",
      "Epoch 332/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 47381.9221 - reconstruction_loss: 45630.7773 - kl_loss: 1976.6489\n",
      "Epoch 333/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 47187.5282 - reconstruction_loss: 45427.4180 - kl_loss: 1976.2206\n",
      "Epoch 334/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 47002.5765 - reconstruction_loss: 45249.7773 - kl_loss: 1975.6073\n",
      "Epoch 335/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 46819.8059 - reconstruction_loss: 45045.5508 - kl_loss: 1976.8879\n",
      "Epoch 336/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 46574.8422 - reconstruction_loss: 44833.3477 - kl_loss: 1977.1985\n",
      "Epoch 337/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 46396.7795 - reconstruction_loss: 44650.6914 - kl_loss: 1979.0389\n",
      "Epoch 338/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 46167.5501 - reconstruction_loss: 44426.3984 - kl_loss: 1979.3773\n",
      "Epoch 339/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 45981.6970 - reconstruction_loss: 44235.1953 - kl_loss: 1977.6118\n",
      "Epoch 340/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 45813.1299 - reconstruction_loss: 44050.3438 - kl_loss: 1978.5699\n",
      "Epoch 341/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 45564.2983 - reconstruction_loss: 43839.4219 - kl_loss: 1977.0961\n",
      "Epoch 342/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 45348.0227 - reconstruction_loss: 43641.1484 - kl_loss: 1973.4407\n",
      "Epoch 343/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 45189.8184 - reconstruction_loss: 43471.8906 - kl_loss: 1975.5592\n",
      "Epoch 344/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 45044.2136 - reconstruction_loss: 43285.7891 - kl_loss: 1972.3228\n",
      "Epoch 345/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 44837.0268 - reconstruction_loss: 43100.8164 - kl_loss: 1968.6410\n",
      "Epoch 346/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 44747.4039 - reconstruction_loss: 42987.2383 - kl_loss: 1963.1248\n",
      "Epoch 347/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 44528.2488 - reconstruction_loss: 42804.6250 - kl_loss: 1960.1423\n",
      "Epoch 348/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 44350.0711 - reconstruction_loss: 42644.0664 - kl_loss: 1958.2931\n",
      "Epoch 349/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 44248.2837 - reconstruction_loss: 42513.2344 - kl_loss: 1956.6267\n",
      "Epoch 350/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 44112.8388 - reconstruction_loss: 42401.5898 - kl_loss: 1950.1829\n",
      "Epoch 351/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 43974.1178 - reconstruction_loss: 42267.9258 - kl_loss: 1949.0870\n",
      "Epoch 352/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 43876.5624 - reconstruction_loss: 42153.9141 - kl_loss: 1942.9711\n",
      "Epoch 353/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 43779.2893 - reconstruction_loss: 42014.2148 - kl_loss: 1939.8833\n",
      "Epoch 354/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 43627.7740 - reconstruction_loss: 41869.8750 - kl_loss: 1937.9427\n",
      "Epoch 355/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 43432.0557 - reconstruction_loss: 41708.8906 - kl_loss: 1934.1410\n",
      "Epoch 356/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 43449.5393 - reconstruction_loss: 41670.9297 - kl_loss: 1928.2111\n",
      "Epoch 357/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 43293.6376 - reconstruction_loss: 41580.3555 - kl_loss: 1926.9236\n",
      "Epoch 358/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 43367.1387 - reconstruction_loss: 41634.7109 - kl_loss: 1922.4852\n",
      "Epoch 359/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 43302.3177 - reconstruction_loss: 41386.9805 - kl_loss: 1919.3962\n",
      "Epoch 360/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 43114.5945 - reconstruction_loss: 41299.0938 - kl_loss: 1910.6271\n",
      "Epoch 361/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 43002.6409 - reconstruction_loss: 41233.8477 - kl_loss: 1909.4030\n",
      "Epoch 362/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 42959.8211 - reconstruction_loss: 41136.4961 - kl_loss: 1908.8354\n",
      "Epoch 363/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 42983.6614 - reconstruction_loss: 41301.9648 - kl_loss: 1904.8875\n",
      "Epoch 364/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 42849.0882 - reconstruction_loss: 41137.7266 - kl_loss: 1904.2119\n",
      "Epoch 365/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 42959.6268 - reconstruction_loss: 41164.2852 - kl_loss: 1897.4496\n",
      "Epoch 366/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 42749.7529 - reconstruction_loss: 40907.6289 - kl_loss: 1893.2592\n",
      "Epoch 367/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 42451.1382 - reconstruction_loss: 40686.3164 - kl_loss: 1891.1948\n",
      "Epoch 368/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 42456.8666 - reconstruction_loss: 40666.7617 - kl_loss: 1886.8013\n",
      "Epoch 369/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 42313.4545 - reconstruction_loss: 40564.4805 - kl_loss: 1885.6825\n",
      "Epoch 370/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 42246.7139 - reconstruction_loss: 40523.1328 - kl_loss: 1882.1421\n",
      "Epoch 371/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 42255.5932 - reconstruction_loss: 40515.8359 - kl_loss: 1882.1948\n",
      "Epoch 372/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 42248.2150 - reconstruction_loss: 40575.0664 - kl_loss: 1878.6029\n",
      "Epoch 373/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 42766.4001 - reconstruction_loss: 40918.2227 - kl_loss: 1873.3267\n",
      "Epoch 374/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 42173.0301 - reconstruction_loss: 40563.5273 - kl_loss: 1869.8534\n",
      "Epoch 375/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 42128.2968 - reconstruction_loss: 40585.7461 - kl_loss: 1869.2842\n",
      "Epoch 376/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 42291.0086 - reconstruction_loss: 40598.0273 - kl_loss: 1866.3248\n",
      "Epoch 377/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 43049.1319 - reconstruction_loss: 40888.0547 - kl_loss: 1858.9159\n",
      "Epoch 378/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 44759.9755 - reconstruction_loss: 41451.9570 - kl_loss: 1857.8918\n",
      "Epoch 379/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 42977.1801 - reconstruction_loss: 40685.8555 - kl_loss: 1860.4927\n",
      "Epoch 380/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 42550.2520 - reconstruction_loss: 40591.1758 - kl_loss: 1857.1851\n",
      "Epoch 381/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 42516.0108 - reconstruction_loss: 40550.1328 - kl_loss: 1856.7220\n",
      "Epoch 382/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 42454.1134 - reconstruction_loss: 40467.1953 - kl_loss: 1854.0088\n",
      "Epoch 383/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 42225.8061 - reconstruction_loss: 40186.5508 - kl_loss: 1851.1851\n",
      "Epoch 384/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 42034.3631 - reconstruction_loss: 39861.6484 - kl_loss: 1850.2930\n",
      "Epoch 385/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 41733.2157 - reconstruction_loss: 39623.5352 - kl_loss: 1851.3821\n",
      "Epoch 386/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 41566.0243 - reconstruction_loss: 39450.6562 - kl_loss: 1848.6152\n",
      "Epoch 387/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 41275.3623 - reconstruction_loss: 39224.2461 - kl_loss: 1844.1500\n",
      "Epoch 388/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 41134.7818 - reconstruction_loss: 39088.7188 - kl_loss: 1843.0660\n",
      "Epoch 389/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 40963.9702 - reconstruction_loss: 38939.2812 - kl_loss: 1841.0938\n",
      "Epoch 390/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 40793.9158 - reconstruction_loss: 38792.3945 - kl_loss: 1840.4529\n",
      "Epoch 391/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 40632.6002 - reconstruction_loss: 38655.5859 - kl_loss: 1836.2795\n",
      "Epoch 392/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 40436.6749 - reconstruction_loss: 38514.6094 - kl_loss: 1832.7277\n",
      "Epoch 393/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 40313.7134 - reconstruction_loss: 38370.5391 - kl_loss: 1831.3187\n",
      "Epoch 394/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 40195.0767 - reconstruction_loss: 38260.3008 - kl_loss: 1828.0573\n",
      "Epoch 395/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 40051.0663 - reconstruction_loss: 38137.2148 - kl_loss: 1823.0233\n",
      "Epoch 396/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 39940.7461 - reconstruction_loss: 38034.8281 - kl_loss: 1819.7865\n",
      "Epoch 397/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 39834.7924 - reconstruction_loss: 37930.2109 - kl_loss: 1817.7773\n",
      "Epoch 398/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 39762.7496 - reconstruction_loss: 37832.6367 - kl_loss: 1813.1971\n",
      "Epoch 399/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 39621.9163 - reconstruction_loss: 37737.2266 - kl_loss: 1811.3564\n",
      "Epoch 400/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 39594.9344 - reconstruction_loss: 37708.6992 - kl_loss: 1805.3627\n",
      "Epoch 401/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 39543.3726 - reconstruction_loss: 37639.9883 - kl_loss: 1805.7175\n",
      "Epoch 402/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 39674.7694 - reconstruction_loss: 37702.4062 - kl_loss: 1798.4166\n",
      "Epoch 403/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 41186.4537 - reconstruction_loss: 38769.6953 - kl_loss: 1792.9996\n",
      "Epoch 404/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 40810.7733 - reconstruction_loss: 38000.2305 - kl_loss: 1769.2866\n",
      "Epoch 405/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 39387.1507 - reconstruction_loss: 37379.7656 - kl_loss: 1775.5302\n",
      "Epoch 406/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 39846.7083 - reconstruction_loss: 37571.3984 - kl_loss: 1778.1282\n",
      "Epoch 407/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 39045.7013 - reconstruction_loss: 37168.8320 - kl_loss: 1773.3198\n",
      "Epoch 408/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 38891.5985 - reconstruction_loss: 37033.8281 - kl_loss: 1767.9761\n",
      "Epoch 409/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 38743.5133 - reconstruction_loss: 36920.9688 - kl_loss: 1764.1536\n",
      "Epoch 410/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 38677.7920 - reconstruction_loss: 36842.9648 - kl_loss: 1758.9186\n",
      "Epoch 411/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 38533.4362 - reconstruction_loss: 36726.7383 - kl_loss: 1758.0829\n",
      "Epoch 412/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 38433.6622 - reconstruction_loss: 36652.7344 - kl_loss: 1753.9449\n",
      "Epoch 413/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 38365.5032 - reconstruction_loss: 36569.3711 - kl_loss: 1750.7618\n",
      "Epoch 414/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 38259.0258 - reconstruction_loss: 36473.0938 - kl_loss: 1747.0068\n",
      "Epoch 415/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 38180.7560 - reconstruction_loss: 36404.8047 - kl_loss: 1745.7101\n",
      "Epoch 416/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 38074.6091 - reconstruction_loss: 36310.3281 - kl_loss: 1738.4644\n",
      "Epoch 417/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 38014.6477 - reconstruction_loss: 36255.4062 - kl_loss: 1736.5243\n",
      "Epoch 418/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 37909.8029 - reconstruction_loss: 36181.8320 - kl_loss: 1732.0001\n",
      "Epoch 419/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 37880.5336 - reconstruction_loss: 36130.9453 - kl_loss: 1730.7816\n",
      "Epoch 420/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 37757.6267 - reconstruction_loss: 36027.0430 - kl_loss: 1726.6448\n",
      "Epoch 421/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 37689.5307 - reconstruction_loss: 35964.4180 - kl_loss: 1723.5808\n",
      "Epoch 422/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 37623.9892 - reconstruction_loss: 35907.8438 - kl_loss: 1718.9674\n",
      "Epoch 423/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 37567.4340 - reconstruction_loss: 35848.8672 - kl_loss: 1715.3453\n",
      "Epoch 424/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 37494.5856 - reconstruction_loss: 35776.5469 - kl_loss: 1710.6144\n",
      "Epoch 425/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 37426.4938 - reconstruction_loss: 35710.7305 - kl_loss: 1705.6998\n",
      "Epoch 426/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 37357.3722 - reconstruction_loss: 35638.0898 - kl_loss: 1701.8530\n",
      "Epoch 427/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 37318.8703 - reconstruction_loss: 35645.7773 - kl_loss: 1698.5676\n",
      "Epoch 428/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 37259.0385 - reconstruction_loss: 35559.8438 - kl_loss: 1698.0616\n",
      "Epoch 429/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 37266.5720 - reconstruction_loss: 35538.5117 - kl_loss: 1689.9646\n",
      "Epoch 430/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 37174.1346 - reconstruction_loss: 35550.8477 - kl_loss: 1686.4801\n",
      "Epoch 431/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 37266.7604 - reconstruction_loss: 35575.2891 - kl_loss: 1686.3849\n",
      "Epoch 432/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 37142.6593 - reconstruction_loss: 35411.7188 - kl_loss: 1678.2675\n",
      "Epoch 433/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 37189.8485 - reconstruction_loss: 35528.7891 - kl_loss: 1671.8398\n",
      "Epoch 434/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 37315.2854 - reconstruction_loss: 35727.5117 - kl_loss: 1675.7090\n",
      "Epoch 435/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 37465.2169 - reconstruction_loss: 35634.9453 - kl_loss: 1675.1036\n",
      "Epoch 436/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 37257.1772 - reconstruction_loss: 35444.2031 - kl_loss: 1669.2106\n",
      "Epoch 437/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 37134.4773 - reconstruction_loss: 35311.5820 - kl_loss: 1665.6431\n",
      "Epoch 438/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 36907.0850 - reconstruction_loss: 35167.0234 - kl_loss: 1664.7915\n",
      "Epoch 439/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 36740.9727 - reconstruction_loss: 35047.6758 - kl_loss: 1663.1913\n",
      "Epoch 440/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 36679.0762 - reconstruction_loss: 35004.7305 - kl_loss: 1655.1058\n",
      "Epoch 441/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 36631.0093 - reconstruction_loss: 35050.2422 - kl_loss: 1650.0969\n",
      "Epoch 442/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36630.2705 - reconstruction_loss: 35056.0625 - kl_loss: 1649.3724\n",
      "Epoch 443/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 36482.4080 - reconstruction_loss: 34889.3594 - kl_loss: 1641.8141\n",
      "Epoch 444/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36347.8175 - reconstruction_loss: 34753.3164 - kl_loss: 1640.3534\n",
      "Epoch 445/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36299.6139 - reconstruction_loss: 34689.9648 - kl_loss: 1634.8589\n",
      "Epoch 446/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 36284.1047 - reconstruction_loss: 34670.6367 - kl_loss: 1631.2759\n",
      "Epoch 447/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 36217.9826 - reconstruction_loss: 34635.2812 - kl_loss: 1628.7466\n",
      "Epoch 448/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 36276.6156 - reconstruction_loss: 34633.0664 - kl_loss: 1624.6639\n",
      "Epoch 449/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 36194.5714 - reconstruction_loss: 34528.1719 - kl_loss: 1620.3839\n",
      "Epoch 450/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 36100.8763 - reconstruction_loss: 34459.3672 - kl_loss: 1615.0504\n",
      "Epoch 451/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35965.7541 - reconstruction_loss: 34408.4492 - kl_loss: 1613.6084\n",
      "Epoch 452/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 36044.9236 - reconstruction_loss: 34451.2461 - kl_loss: 1611.4304\n",
      "Epoch 453/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36090.2389 - reconstruction_loss: 34405.0195 - kl_loss: 1606.5850\n",
      "Epoch 454/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 36049.4921 - reconstruction_loss: 34441.8398 - kl_loss: 1603.1403\n",
      "Epoch 455/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 36395.9264 - reconstruction_loss: 34558.7422 - kl_loss: 1600.5385\n",
      "Epoch 456/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 36285.3595 - reconstruction_loss: 34660.4531 - kl_loss: 1599.3818\n",
      "Epoch 457/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 37342.8928 - reconstruction_loss: 35154.7188 - kl_loss: 1596.6581\n",
      "Epoch 458/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 37355.3569 - reconstruction_loss: 35353.7734 - kl_loss: 1593.4777\n",
      "Epoch 459/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36792.3564 - reconstruction_loss: 34794.6562 - kl_loss: 1598.9237\n",
      "Epoch 460/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 36461.9696 - reconstruction_loss: 34540.4492 - kl_loss: 1594.1033\n",
      "Epoch 461/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36364.4835 - reconstruction_loss: 34478.9297 - kl_loss: 1591.0446\n",
      "Epoch 462/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 36246.9374 - reconstruction_loss: 34538.0703 - kl_loss: 1587.5795\n",
      "Epoch 463/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 36059.8468 - reconstruction_loss: 34425.2578 - kl_loss: 1582.0806\n",
      "Epoch 464/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 35814.5625 - reconstruction_loss: 34204.7227 - kl_loss: 1581.8149\n",
      "Epoch 465/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 35791.1939 - reconstruction_loss: 34154.9453 - kl_loss: 1582.0780\n",
      "Epoch 466/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35786.8262 - reconstruction_loss: 34094.2344 - kl_loss: 1578.8365\n",
      "Epoch 467/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 35635.7877 - reconstruction_loss: 34018.2461 - kl_loss: 1575.7140\n",
      "Epoch 468/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35597.3940 - reconstruction_loss: 33962.5977 - kl_loss: 1574.0355\n",
      "Epoch 469/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 35605.0803 - reconstruction_loss: 33969.8164 - kl_loss: 1573.9598\n",
      "Epoch 470/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 35663.6408 - reconstruction_loss: 33974.2734 - kl_loss: 1569.6353\n",
      "Epoch 471/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 35482.8986 - reconstruction_loss: 33844.0156 - kl_loss: 1566.3986\n",
      "Epoch 472/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35594.8586 - reconstruction_loss: 33946.4336 - kl_loss: 1563.6322\n",
      "Epoch 473/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 35578.6550 - reconstruction_loss: 33831.8594 - kl_loss: 1565.6256\n",
      "Epoch 474/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35562.0132 - reconstruction_loss: 33878.4023 - kl_loss: 1564.2517\n",
      "Epoch 475/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 35644.7110 - reconstruction_loss: 33887.2969 - kl_loss: 1562.0465\n",
      "Epoch 476/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35436.9214 - reconstruction_loss: 33750.6445 - kl_loss: 1558.2583\n",
      "Epoch 477/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 35540.9341 - reconstruction_loss: 33853.2109 - kl_loss: 1554.4799\n",
      "Epoch 478/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35575.0954 - reconstruction_loss: 33836.7891 - kl_loss: 1553.6871\n",
      "Epoch 479/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 35732.5113 - reconstruction_loss: 34078.9883 - kl_loss: 1550.9659\n",
      "Epoch 480/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35969.3948 - reconstruction_loss: 34065.9805 - kl_loss: 1551.4857\n",
      "Epoch 481/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 35949.0385 - reconstruction_loss: 34444.1484 - kl_loss: 1546.0884\n",
      "Epoch 482/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36108.1412 - reconstruction_loss: 34251.0898 - kl_loss: 1538.9214\n",
      "Epoch 483/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 40643.9013 - reconstruction_loss: 40523.1797 - kl_loss: 1581.8566\n",
      "Epoch 484/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 37278.6430 - reconstruction_loss: 35040.1992 - kl_loss: 1559.4187\n",
      "Epoch 485/5000\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 36516.5432 - reconstruction_loss: 34384.7148 - kl_loss: 1544.2952\n",
      "Epoch 486/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 35856.7058 - reconstruction_loss: 33894.5156 - kl_loss: 1538.1831\n",
      "Epoch 487/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 35487.2597 - reconstruction_loss: 33612.6016 - kl_loss: 1534.5748\n",
      "Epoch 488/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 35257.5561 - reconstruction_loss: 33406.2383 - kl_loss: 1533.8285\n",
      "Epoch 489/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 34992.2438 - reconstruction_loss: 33210.5312 - kl_loss: 1530.7679\n",
      "Epoch 490/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 34838.5592 - reconstruction_loss: 33047.2773 - kl_loss: 1531.4720\n",
      "Epoch 491/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 34649.8211 - reconstruction_loss: 32887.3555 - kl_loss: 1526.8185\n",
      "Epoch 492/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 34481.4222 - reconstruction_loss: 32748.6211 - kl_loss: 1525.6223\n",
      "Epoch 493/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 34319.0970 - reconstruction_loss: 32606.9062 - kl_loss: 1522.6455\n",
      "Epoch 494/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 34188.7351 - reconstruction_loss: 32489.0117 - kl_loss: 1521.6848\n",
      "Epoch 495/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 34078.3418 - reconstruction_loss: 32375.2949 - kl_loss: 1518.3317\n",
      "Epoch 496/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 33905.4784 - reconstruction_loss: 32230.9727 - kl_loss: 1516.6371\n",
      "Epoch 497/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 33771.4428 - reconstruction_loss: 32118.1406 - kl_loss: 1514.1998\n",
      "Epoch 498/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 33629.5701 - reconstruction_loss: 31979.1992 - kl_loss: 1512.6466\n",
      "Epoch 499/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 33494.3710 - reconstruction_loss: 31868.9355 - kl_loss: 1509.3242\n",
      "Epoch 500/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 33327.8861 - reconstruction_loss: 31713.9375 - kl_loss: 1506.7310\n",
      "Epoch 501/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 33161.6847 - reconstruction_loss: 31625.1387 - kl_loss: 1503.5796\n",
      "Epoch 502/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 33131.0152 - reconstruction_loss: 31501.8262 - kl_loss: 1503.0956\n",
      "Epoch 503/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 32945.1156 - reconstruction_loss: 31357.0859 - kl_loss: 1506.4869\n",
      "Epoch 504/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 34376.7059 - reconstruction_loss: 32188.1035 - kl_loss: 1508.4449\n",
      "Epoch 505/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 33336.8460 - reconstruction_loss: 31459.5625 - kl_loss: 1494.3583\n",
      "Epoch 506/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 32747.2604 - reconstruction_loss: 31131.9043 - kl_loss: 1490.3906\n",
      "Epoch 507/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 32429.5412 - reconstruction_loss: 30903.8945 - kl_loss: 1489.5795\n",
      "Epoch 508/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 32274.4670 - reconstruction_loss: 30794.2637 - kl_loss: 1488.4008\n",
      "Epoch 509/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 32135.3277 - reconstruction_loss: 30691.4160 - kl_loss: 1487.1161\n",
      "Epoch 510/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 32062.4053 - reconstruction_loss: 30609.1641 - kl_loss: 1484.8104\n",
      "Epoch 511/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 31943.4803 - reconstruction_loss: 30514.2031 - kl_loss: 1481.8303\n",
      "Epoch 512/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 31850.6484 - reconstruction_loss: 30436.2871 - kl_loss: 1479.4509\n",
      "Epoch 513/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 31764.2400 - reconstruction_loss: 30349.2754 - kl_loss: 1476.5538\n",
      "Epoch 514/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 31703.3992 - reconstruction_loss: 30285.1836 - kl_loss: 1473.1288\n",
      "Epoch 515/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 31612.2574 - reconstruction_loss: 30205.7324 - kl_loss: 1470.3228\n",
      "Epoch 516/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 31530.5637 - reconstruction_loss: 30144.2559 - kl_loss: 1467.7740\n",
      "Epoch 517/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 31475.3205 - reconstruction_loss: 30085.8887 - kl_loss: 1465.3752\n",
      "Epoch 518/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 31414.1619 - reconstruction_loss: 30030.5625 - kl_loss: 1461.0210\n",
      "Epoch 519/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 31347.3400 - reconstruction_loss: 29980.8164 - kl_loss: 1458.9393\n",
      "Epoch 520/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 31288.7852 - reconstruction_loss: 29923.8555 - kl_loss: 1452.3447\n",
      "Epoch 521/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 31234.1470 - reconstruction_loss: 29869.8574 - kl_loss: 1451.4342\n",
      "Epoch 522/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 31148.2559 - reconstruction_loss: 29809.5469 - kl_loss: 1447.1218\n",
      "Epoch 523/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 31108.2000 - reconstruction_loss: 29759.2598 - kl_loss: 1443.4152\n",
      "Epoch 524/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 31045.0315 - reconstruction_loss: 29697.5508 - kl_loss: 1440.0862\n",
      "Epoch 525/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 30965.1352 - reconstruction_loss: 29645.2109 - kl_loss: 1435.3037\n",
      "Epoch 526/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 30916.2560 - reconstruction_loss: 29599.7539 - kl_loss: 1430.1451\n",
      "Epoch 527/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 30875.9611 - reconstruction_loss: 29546.1992 - kl_loss: 1429.5963\n",
      "Epoch 528/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 30839.1957 - reconstruction_loss: 29514.6270 - kl_loss: 1422.7748\n",
      "Epoch 529/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 30723.9188 - reconstruction_loss: 29429.9297 - kl_loss: 1419.7133\n",
      "Epoch 530/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 30770.8996 - reconstruction_loss: 29468.7266 - kl_loss: 1414.2535\n",
      "Epoch 531/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 30711.7721 - reconstruction_loss: 29410.7988 - kl_loss: 1409.8112\n",
      "Epoch 532/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 30702.8430 - reconstruction_loss: 29462.4668 - kl_loss: 1407.7380\n",
      "Epoch 533/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 30715.9904 - reconstruction_loss: 29361.1973 - kl_loss: 1405.2842\n",
      "Epoch 534/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 30558.1478 - reconstruction_loss: 29290.8750 - kl_loss: 1401.6942\n",
      "Epoch 535/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 30572.1413 - reconstruction_loss: 29217.9219 - kl_loss: 1397.8076\n",
      "Epoch 536/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 30476.5364 - reconstruction_loss: 29214.5566 - kl_loss: 1393.1144\n",
      "Epoch 537/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 30433.9524 - reconstruction_loss: 29117.6035 - kl_loss: 1389.6743\n",
      "Epoch 538/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 30361.3394 - reconstruction_loss: 29132.6289 - kl_loss: 1385.7421\n",
      "Epoch 539/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 30317.5169 - reconstruction_loss: 29069.2012 - kl_loss: 1381.8015\n",
      "Epoch 540/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 30242.7756 - reconstruction_loss: 29046.0137 - kl_loss: 1379.2222\n",
      "Epoch 541/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 30369.1948 - reconstruction_loss: 29073.9355 - kl_loss: 1374.7367\n",
      "Epoch 542/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 30213.9707 - reconstruction_loss: 28999.3457 - kl_loss: 1373.6467\n",
      "Epoch 543/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 30625.3988 - reconstruction_loss: 29212.6191 - kl_loss: 1368.6227\n",
      "Epoch 544/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 30255.6307 - reconstruction_loss: 29067.8535 - kl_loss: 1365.5659\n",
      "Epoch 545/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 30208.3351 - reconstruction_loss: 28962.4863 - kl_loss: 1360.9425\n",
      "Epoch 546/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29955.7033 - reconstruction_loss: 28785.7051 - kl_loss: 1361.0076\n",
      "Epoch 547/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 29964.7514 - reconstruction_loss: 28748.0566 - kl_loss: 1355.7045\n",
      "Epoch 548/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29909.4038 - reconstruction_loss: 28726.3906 - kl_loss: 1352.6427\n",
      "Epoch 549/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 29864.8106 - reconstruction_loss: 28687.4375 - kl_loss: 1350.1066\n",
      "Epoch 550/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29812.9881 - reconstruction_loss: 28622.3984 - kl_loss: 1347.3845\n",
      "Epoch 551/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 29856.8469 - reconstruction_loss: 28657.0098 - kl_loss: 1345.7280\n",
      "Epoch 552/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 29848.4193 - reconstruction_loss: 28594.8535 - kl_loss: 1340.0795\n",
      "Epoch 553/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 29673.3985 - reconstruction_loss: 28524.4062 - kl_loss: 1335.1672\n",
      "Epoch 554/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29820.1986 - reconstruction_loss: 28576.6738 - kl_loss: 1333.3563\n",
      "Epoch 555/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29564.8344 - reconstruction_loss: 28419.3477 - kl_loss: 1331.8855\n",
      "Epoch 556/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 29568.6618 - reconstruction_loss: 28406.5684 - kl_loss: 1327.7343\n",
      "Epoch 557/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29514.8681 - reconstruction_loss: 28356.4883 - kl_loss: 1322.9659\n",
      "Epoch 558/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29496.3089 - reconstruction_loss: 28323.3691 - kl_loss: 1321.6522\n",
      "Epoch 559/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29423.5488 - reconstruction_loss: 28321.6699 - kl_loss: 1318.8744\n",
      "Epoch 560/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29380.4897 - reconstruction_loss: 28266.2891 - kl_loss: 1316.0057\n",
      "Epoch 561/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29336.0918 - reconstruction_loss: 28199.3301 - kl_loss: 1311.2020\n",
      "Epoch 562/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29262.5271 - reconstruction_loss: 28151.1289 - kl_loss: 1307.8518\n",
      "Epoch 563/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 29254.6595 - reconstruction_loss: 28128.3672 - kl_loss: 1305.0145\n",
      "Epoch 564/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29243.0168 - reconstruction_loss: 28108.0000 - kl_loss: 1299.8624\n",
      "Epoch 565/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29229.9200 - reconstruction_loss: 28101.0312 - kl_loss: 1297.8673\n",
      "Epoch 566/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 29184.5087 - reconstruction_loss: 28069.9180 - kl_loss: 1296.8462\n",
      "Epoch 567/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29159.3431 - reconstruction_loss: 28069.0684 - kl_loss: 1294.6683\n",
      "Epoch 568/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 29139.2853 - reconstruction_loss: 28056.1035 - kl_loss: 1290.0179\n",
      "Epoch 569/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 29176.2294 - reconstruction_loss: 28043.3906 - kl_loss: 1286.5131\n",
      "Epoch 570/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 29262.0496 - reconstruction_loss: 28194.9551 - kl_loss: 1283.9838\n",
      "Epoch 571/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 29346.2606 - reconstruction_loss: 28205.1602 - kl_loss: 1281.1501\n",
      "Epoch 572/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29223.0044 - reconstruction_loss: 28176.4785 - kl_loss: 1278.4362\n",
      "Epoch 573/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 29333.0415 - reconstruction_loss: 28417.2480 - kl_loss: 1277.4272\n",
      "Epoch 574/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29981.8878 - reconstruction_loss: 29023.6914 - kl_loss: 1277.0493\n",
      "Epoch 575/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 30199.3532 - reconstruction_loss: 28512.9824 - kl_loss: 1275.0980\n",
      "Epoch 576/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 30014.7954 - reconstruction_loss: 28657.3652 - kl_loss: 1277.2380\n",
      "Epoch 577/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29838.4630 - reconstruction_loss: 28488.8926 - kl_loss: 1271.0465\n",
      "Epoch 578/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29387.9326 - reconstruction_loss: 28161.6777 - kl_loss: 1267.4080\n",
      "Epoch 579/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 29131.2516 - reconstruction_loss: 27895.8574 - kl_loss: 1265.1815\n",
      "Epoch 580/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 29145.7848 - reconstruction_loss: 27932.6465 - kl_loss: 1264.7129\n",
      "Epoch 581/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29064.7389 - reconstruction_loss: 27880.4648 - kl_loss: 1263.6277\n",
      "Epoch 582/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 28982.0352 - reconstruction_loss: 27790.9355 - kl_loss: 1261.1661\n",
      "Epoch 583/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 28931.3285 - reconstruction_loss: 27753.1660 - kl_loss: 1259.1592\n",
      "Epoch 584/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 28824.1214 - reconstruction_loss: 27689.1113 - kl_loss: 1258.3540\n",
      "Epoch 585/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28810.1951 - reconstruction_loss: 27634.7383 - kl_loss: 1258.4027\n",
      "Epoch 586/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 28855.6684 - reconstruction_loss: 27605.6035 - kl_loss: 1253.5181\n",
      "Epoch 587/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28817.3658 - reconstruction_loss: 27544.2500 - kl_loss: 1251.2448\n",
      "Epoch 588/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 28724.8772 - reconstruction_loss: 27490.3555 - kl_loss: 1251.6522\n",
      "Epoch 589/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28644.4331 - reconstruction_loss: 27449.0000 - kl_loss: 1251.1646\n",
      "Epoch 590/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 28638.0029 - reconstruction_loss: 27408.9512 - kl_loss: 1247.7596\n",
      "Epoch 591/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28490.9243 - reconstruction_loss: 27317.9434 - kl_loss: 1244.8273\n",
      "Epoch 592/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 28397.3106 - reconstruction_loss: 27265.9121 - kl_loss: 1242.8182\n",
      "Epoch 593/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28419.8777 - reconstruction_loss: 27266.4062 - kl_loss: 1240.6394\n",
      "Epoch 594/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 28360.4528 - reconstruction_loss: 27238.4766 - kl_loss: 1237.8787\n",
      "Epoch 595/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28300.1573 - reconstruction_loss: 27169.9570 - kl_loss: 1237.7166\n",
      "Epoch 596/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 28174.6677 - reconstruction_loss: 27104.2461 - kl_loss: 1231.9941\n",
      "Epoch 597/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28179.9587 - reconstruction_loss: 27064.7598 - kl_loss: 1232.6661\n",
      "Epoch 598/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 28066.6234 - reconstruction_loss: 27018.1309 - kl_loss: 1227.6996\n",
      "Epoch 599/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 28087.8942 - reconstruction_loss: 27009.7266 - kl_loss: 1226.9570\n",
      "Epoch 600/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27990.9190 - reconstruction_loss: 26927.7402 - kl_loss: 1223.8782\n",
      "Epoch 601/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27995.9354 - reconstruction_loss: 26950.4277 - kl_loss: 1220.4320\n",
      "Epoch 602/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27947.4664 - reconstruction_loss: 26910.9844 - kl_loss: 1220.6836\n",
      "Epoch 603/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27968.9490 - reconstruction_loss: 26915.2168 - kl_loss: 1217.4393\n",
      "Epoch 604/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27966.3784 - reconstruction_loss: 26903.3945 - kl_loss: 1213.1848\n",
      "Epoch 605/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27786.5424 - reconstruction_loss: 26793.2207 - kl_loss: 1213.5223\n",
      "Epoch 606/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27855.9064 - reconstruction_loss: 26788.8496 - kl_loss: 1212.4747\n",
      "Epoch 607/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27686.9877 - reconstruction_loss: 26714.6836 - kl_loss: 1210.1631\n",
      "Epoch 608/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27851.0407 - reconstruction_loss: 26783.2891 - kl_loss: 1204.0017\n",
      "Epoch 609/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27615.8915 - reconstruction_loss: 26675.8867 - kl_loss: 1201.1353\n",
      "Epoch 610/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27672.5642 - reconstruction_loss: 26636.4004 - kl_loss: 1201.3048\n",
      "Epoch 611/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27535.6792 - reconstruction_loss: 26568.3164 - kl_loss: 1197.4932\n",
      "Epoch 612/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27599.4362 - reconstruction_loss: 26579.4297 - kl_loss: 1195.2650\n",
      "Epoch 613/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27485.3997 - reconstruction_loss: 26551.9180 - kl_loss: 1193.4369\n",
      "Epoch 614/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27520.4248 - reconstruction_loss: 26536.4141 - kl_loss: 1191.4530\n",
      "Epoch 615/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27460.4250 - reconstruction_loss: 26502.5273 - kl_loss: 1185.7986\n",
      "Epoch 616/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27474.7576 - reconstruction_loss: 26492.7324 - kl_loss: 1184.0045\n",
      "Epoch 617/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27472.6016 - reconstruction_loss: 26603.4004 - kl_loss: 1181.7222\n",
      "Epoch 618/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27571.8740 - reconstruction_loss: 26580.7383 - kl_loss: 1181.8960\n",
      "Epoch 619/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27513.1563 - reconstruction_loss: 26497.1895 - kl_loss: 1176.5804\n",
      "Epoch 620/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27408.5736 - reconstruction_loss: 26457.2266 - kl_loss: 1172.5996\n",
      "Epoch 621/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27558.4595 - reconstruction_loss: 26513.2539 - kl_loss: 1173.2581\n",
      "Epoch 622/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27309.2024 - reconstruction_loss: 26373.8691 - kl_loss: 1168.0608\n",
      "Epoch 623/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27393.2671 - reconstruction_loss: 26413.0293 - kl_loss: 1167.8693\n",
      "Epoch 624/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27251.5328 - reconstruction_loss: 26306.4746 - kl_loss: 1165.0055\n",
      "Epoch 625/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27371.1846 - reconstruction_loss: 26361.0508 - kl_loss: 1163.5304\n",
      "Epoch 626/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27272.5736 - reconstruction_loss: 26293.6445 - kl_loss: 1157.8521\n",
      "Epoch 627/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27252.5019 - reconstruction_loss: 26329.2695 - kl_loss: 1154.2894\n",
      "Epoch 628/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27336.5191 - reconstruction_loss: 26336.7734 - kl_loss: 1155.6968\n",
      "Epoch 629/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27251.8307 - reconstruction_loss: 26428.7363 - kl_loss: 1152.5566\n",
      "Epoch 630/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27530.9745 - reconstruction_loss: 26442.3359 - kl_loss: 1150.4728\n",
      "Epoch 631/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27228.7064 - reconstruction_loss: 26283.1934 - kl_loss: 1148.3170\n",
      "Epoch 632/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27206.6223 - reconstruction_loss: 26285.6113 - kl_loss: 1145.2086\n",
      "Epoch 633/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27173.8252 - reconstruction_loss: 26235.0176 - kl_loss: 1143.9524\n",
      "Epoch 634/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27230.5574 - reconstruction_loss: 26321.0020 - kl_loss: 1139.5074\n",
      "Epoch 635/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27195.8111 - reconstruction_loss: 26312.4199 - kl_loss: 1139.1161\n",
      "Epoch 636/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27216.0965 - reconstruction_loss: 26248.5430 - kl_loss: 1137.3458\n",
      "Epoch 637/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27121.6490 - reconstruction_loss: 26195.1855 - kl_loss: 1133.3026\n",
      "Epoch 638/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27133.1935 - reconstruction_loss: 26160.1191 - kl_loss: 1130.5717\n",
      "Epoch 639/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27207.7496 - reconstruction_loss: 26329.5801 - kl_loss: 1128.5746\n",
      "Epoch 640/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27615.7718 - reconstruction_loss: 26554.8438 - kl_loss: 1128.8682\n",
      "Epoch 641/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 28289.9419 - reconstruction_loss: 27107.6543 - kl_loss: 1127.4719\n",
      "Epoch 642/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27921.8608 - reconstruction_loss: 26537.6094 - kl_loss: 1130.1633\n",
      "Epoch 643/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27235.2247 - reconstruction_loss: 26180.5000 - kl_loss: 1125.4380\n",
      "Epoch 644/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27440.2803 - reconstruction_loss: 26232.9082 - kl_loss: 1123.2465\n",
      "Epoch 645/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27220.0306 - reconstruction_loss: 26120.1895 - kl_loss: 1123.5869\n",
      "Epoch 646/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27257.2282 - reconstruction_loss: 26147.4297 - kl_loss: 1121.2351\n",
      "Epoch 647/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27269.2204 - reconstruction_loss: 26138.7793 - kl_loss: 1117.4115\n",
      "Epoch 648/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27156.2785 - reconstruction_loss: 26137.1543 - kl_loss: 1115.9884\n",
      "Epoch 649/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27165.6136 - reconstruction_loss: 26104.8711 - kl_loss: 1115.4551\n",
      "Epoch 650/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27148.7024 - reconstruction_loss: 26120.9160 - kl_loss: 1116.8140\n",
      "Epoch 651/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27144.3549 - reconstruction_loss: 26106.9492 - kl_loss: 1113.3073\n",
      "Epoch 652/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26983.4177 - reconstruction_loss: 26022.9258 - kl_loss: 1108.8124\n",
      "Epoch 653/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27036.1914 - reconstruction_loss: 26032.5156 - kl_loss: 1108.1083\n",
      "Epoch 654/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26977.4540 - reconstruction_loss: 25986.5430 - kl_loss: 1107.7054\n",
      "Epoch 655/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27072.2424 - reconstruction_loss: 26040.4160 - kl_loss: 1105.7909\n",
      "Epoch 656/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26991.6613 - reconstruction_loss: 25993.2871 - kl_loss: 1103.2556\n",
      "Epoch 657/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26997.4373 - reconstruction_loss: 26019.0781 - kl_loss: 1103.0852\n",
      "Epoch 658/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26907.3791 - reconstruction_loss: 25970.5840 - kl_loss: 1104.3618\n",
      "Epoch 659/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26887.9715 - reconstruction_loss: 25921.2070 - kl_loss: 1100.7251\n",
      "Epoch 660/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26918.7672 - reconstruction_loss: 25915.7695 - kl_loss: 1098.1930\n",
      "Epoch 661/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 26897.8420 - reconstruction_loss: 25912.7715 - kl_loss: 1096.1066\n",
      "Epoch 662/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26920.0340 - reconstruction_loss: 25890.5195 - kl_loss: 1094.8292\n",
      "Epoch 663/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26890.3624 - reconstruction_loss: 25889.2578 - kl_loss: 1094.0530\n",
      "Epoch 664/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26920.0444 - reconstruction_loss: 25919.9805 - kl_loss: 1091.6730\n",
      "Epoch 665/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26918.2786 - reconstruction_loss: 25894.2070 - kl_loss: 1089.9171\n",
      "Epoch 666/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26910.2804 - reconstruction_loss: 25932.1309 - kl_loss: 1088.8206\n",
      "Epoch 667/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26979.7616 - reconstruction_loss: 26010.7500 - kl_loss: 1088.2172\n",
      "Epoch 668/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27071.3803 - reconstruction_loss: 26172.0117 - kl_loss: 1087.7495\n",
      "Epoch 669/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26968.8012 - reconstruction_loss: 25957.9062 - kl_loss: 1085.9678\n",
      "Epoch 670/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27071.0943 - reconstruction_loss: 26023.0332 - kl_loss: 1085.4104\n",
      "Epoch 671/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 28030.9893 - reconstruction_loss: 26665.4180 - kl_loss: 1085.3480\n",
      "Epoch 672/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27638.9449 - reconstruction_loss: 26390.7266 - kl_loss: 1085.6055\n",
      "Epoch 673/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27800.8593 - reconstruction_loss: 26383.2832 - kl_loss: 1085.2805\n",
      "Epoch 674/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27504.3299 - reconstruction_loss: 26259.7656 - kl_loss: 1083.5984\n",
      "Epoch 675/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27357.6161 - reconstruction_loss: 26199.1055 - kl_loss: 1083.3683\n",
      "Epoch 676/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27244.5642 - reconstruction_loss: 26127.4883 - kl_loss: 1082.4684\n",
      "Epoch 677/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27152.6381 - reconstruction_loss: 26072.5410 - kl_loss: 1080.0027\n",
      "Epoch 678/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26986.0230 - reconstruction_loss: 25993.4395 - kl_loss: 1077.1653\n",
      "Epoch 679/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26878.2958 - reconstruction_loss: 25914.5410 - kl_loss: 1076.8824\n",
      "Epoch 680/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26835.4208 - reconstruction_loss: 25858.2891 - kl_loss: 1078.8739\n",
      "Epoch 681/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26779.2298 - reconstruction_loss: 25812.8164 - kl_loss: 1077.2522\n",
      "Epoch 682/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26768.0280 - reconstruction_loss: 25821.9395 - kl_loss: 1074.9393\n",
      "Epoch 683/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26787.4240 - reconstruction_loss: 25772.8203 - kl_loss: 1076.6056\n",
      "Epoch 684/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 26803.3799 - reconstruction_loss: 25793.7598 - kl_loss: 1074.9050\n",
      "Epoch 685/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26896.5868 - reconstruction_loss: 25847.4707 - kl_loss: 1073.3737\n",
      "Epoch 686/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 26933.2943 - reconstruction_loss: 25870.6953 - kl_loss: 1071.9150\n",
      "Epoch 687/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 26981.3155 - reconstruction_loss: 25928.6855 - kl_loss: 1072.2133\n",
      "Epoch 688/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27167.8764 - reconstruction_loss: 26080.6973 - kl_loss: 1068.7832\n",
      "Epoch 689/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27290.5749 - reconstruction_loss: 26167.4238 - kl_loss: 1071.1564\n",
      "Epoch 690/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27566.6535 - reconstruction_loss: 26371.2285 - kl_loss: 1066.4613\n",
      "Epoch 691/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27799.5504 - reconstruction_loss: 26498.5059 - kl_loss: 1065.9442\n",
      "Epoch 692/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27717.2982 - reconstruction_loss: 26419.3145 - kl_loss: 1065.1252\n",
      "Epoch 693/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27504.5034 - reconstruction_loss: 26264.2168 - kl_loss: 1069.0803\n",
      "Epoch 694/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 27278.9262 - reconstruction_loss: 26162.9414 - kl_loss: 1066.1672\n",
      "Epoch 695/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27172.5605 - reconstruction_loss: 26087.8867 - kl_loss: 1066.8043\n",
      "Epoch 696/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 27309.8571 - reconstruction_loss: 26075.4180 - kl_loss: 1063.8540\n",
      "Epoch 697/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27104.0308 - reconstruction_loss: 25977.7305 - kl_loss: 1063.5107\n",
      "Epoch 698/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 27200.1164 - reconstruction_loss: 25952.1289 - kl_loss: 1065.2504\n",
      "Epoch 699/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26999.5084 - reconstruction_loss: 25790.8496 - kl_loss: 1063.8551\n",
      "Epoch 700/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 26848.0742 - reconstruction_loss: 25696.6914 - kl_loss: 1064.6140\n",
      "Epoch 701/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26893.6325 - reconstruction_loss: 25683.8164 - kl_loss: 1064.7217\n",
      "Epoch 702/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26649.8629 - reconstruction_loss: 25539.2148 - kl_loss: 1063.1929\n",
      "Epoch 703/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26659.6271 - reconstruction_loss: 25507.2949 - kl_loss: 1063.3793\n",
      "Epoch 704/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26516.7358 - reconstruction_loss: 25408.1621 - kl_loss: 1061.2023\n",
      "Epoch 705/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 26514.4855 - reconstruction_loss: 25380.5684 - kl_loss: 1058.3593\n",
      "Epoch 706/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26446.3309 - reconstruction_loss: 25339.1309 - kl_loss: 1059.0688\n",
      "Epoch 707/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26372.6523 - reconstruction_loss: 25276.2539 - kl_loss: 1058.1410\n",
      "Epoch 708/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26337.7563 - reconstruction_loss: 25246.7480 - kl_loss: 1055.9474\n",
      "Epoch 709/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26263.2032 - reconstruction_loss: 25184.9316 - kl_loss: 1054.8062\n",
      "Epoch 710/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26233.9124 - reconstruction_loss: 25157.8398 - kl_loss: 1054.6971\n",
      "Epoch 711/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26206.7744 - reconstruction_loss: 25104.5547 - kl_loss: 1056.7533\n",
      "Epoch 712/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 26109.5907 - reconstruction_loss: 25054.0508 - kl_loss: 1053.0494\n",
      "Epoch 713/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26092.7171 - reconstruction_loss: 25040.5293 - kl_loss: 1051.7720\n",
      "Epoch 714/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 26088.3717 - reconstruction_loss: 24999.0312 - kl_loss: 1050.4009\n",
      "Epoch 715/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 25945.9066 - reconstruction_loss: 24923.9883 - kl_loss: 1048.9242\n",
      "Epoch 716/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 26082.9904 - reconstruction_loss: 24968.1621 - kl_loss: 1047.3217\n",
      "Epoch 717/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 25933.3037 - reconstruction_loss: 24857.4258 - kl_loss: 1048.0553\n",
      "Epoch 718/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 25920.9571 - reconstruction_loss: 24860.9160 - kl_loss: 1047.0941\n",
      "Epoch 719/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 25870.6213 - reconstruction_loss: 24797.4902 - kl_loss: 1046.4769\n",
      "Epoch 720/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 25705.4121 - reconstruction_loss: 24710.5801 - kl_loss: 1043.8777\n",
      "Epoch 721/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 25797.8969 - reconstruction_loss: 24727.2891 - kl_loss: 1041.5070\n",
      "Epoch 722/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 25639.6265 - reconstruction_loss: 24643.8203 - kl_loss: 1041.5883\n",
      "Epoch 723/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 25615.7899 - reconstruction_loss: 24624.8652 - kl_loss: 1039.6685\n",
      "Epoch 724/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 25567.4822 - reconstruction_loss: 24575.5703 - kl_loss: 1038.2632\n",
      "Epoch 725/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 25474.6347 - reconstruction_loss: 24532.2109 - kl_loss: 1035.6388\n",
      "Epoch 726/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 25524.7662 - reconstruction_loss: 24524.8301 - kl_loss: 1035.6611\n",
      "Epoch 727/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 25432.3517 - reconstruction_loss: 24457.5840 - kl_loss: 1033.4446\n",
      "Epoch 728/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 25391.5555 - reconstruction_loss: 24421.1348 - kl_loss: 1034.0275\n",
      "Epoch 729/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 25317.1953 - reconstruction_loss: 24354.3730 - kl_loss: 1030.7471\n",
      "Epoch 730/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 25264.5515 - reconstruction_loss: 24322.9805 - kl_loss: 1028.2716\n",
      "Epoch 731/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 25261.8163 - reconstruction_loss: 24318.1484 - kl_loss: 1027.7703\n",
      "Epoch 732/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 25222.6702 - reconstruction_loss: 24271.3086 - kl_loss: 1027.8846\n",
      "Epoch 733/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 25161.1806 - reconstruction_loss: 24273.6172 - kl_loss: 1025.3033\n",
      "Epoch 734/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 25204.7873 - reconstruction_loss: 24253.8457 - kl_loss: 1024.6550\n",
      "Epoch 735/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 25128.2392 - reconstruction_loss: 24240.6406 - kl_loss: 1021.3233\n",
      "Epoch 736/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 25126.1037 - reconstruction_loss: 24245.3105 - kl_loss: 1018.8265\n",
      "Epoch 737/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 25196.9047 - reconstruction_loss: 24192.7051 - kl_loss: 1021.0613\n",
      "Epoch 738/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 25040.0761 - reconstruction_loss: 24132.9043 - kl_loss: 1015.7211\n",
      "Epoch 739/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 25031.4691 - reconstruction_loss: 24094.7363 - kl_loss: 1015.6409\n",
      "Epoch 740/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24902.8355 - reconstruction_loss: 24024.1484 - kl_loss: 1012.1225\n",
      "Epoch 741/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24999.1221 - reconstruction_loss: 24118.2598 - kl_loss: 1009.9817\n",
      "Epoch 742/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24960.9057 - reconstruction_loss: 24016.9316 - kl_loss: 1010.1082\n",
      "Epoch 743/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24850.4594 - reconstruction_loss: 23988.5176 - kl_loss: 1007.8426\n",
      "Epoch 744/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24983.9298 - reconstruction_loss: 24038.4355 - kl_loss: 1007.6241\n",
      "Epoch 745/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24867.9712 - reconstruction_loss: 23972.4336 - kl_loss: 1004.2859\n",
      "Epoch 746/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24785.4457 - reconstruction_loss: 23942.1738 - kl_loss: 1004.0732\n",
      "Epoch 747/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24903.5593 - reconstruction_loss: 23954.1621 - kl_loss: 1002.0532\n",
      "Epoch 748/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24719.3559 - reconstruction_loss: 23835.6191 - kl_loss: 999.8349\n",
      "Epoch 749/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24716.0597 - reconstruction_loss: 23829.5059 - kl_loss: 997.4750\n",
      "Epoch 750/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24675.8613 - reconstruction_loss: 23795.0781 - kl_loss: 994.7547\n",
      "Epoch 751/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24631.1123 - reconstruction_loss: 23804.4297 - kl_loss: 994.3896\n",
      "Epoch 752/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24668.1068 - reconstruction_loss: 23793.6211 - kl_loss: 992.6151\n",
      "Epoch 753/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 24558.2281 - reconstruction_loss: 23706.0098 - kl_loss: 989.8671\n",
      "Epoch 754/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 24513.1008 - reconstruction_loss: 23676.6699 - kl_loss: 986.4026\n",
      "Epoch 755/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 24617.9590 - reconstruction_loss: 23725.0352 - kl_loss: 986.1390\n",
      "Epoch 756/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24506.2854 - reconstruction_loss: 23647.0293 - kl_loss: 983.7590\n",
      "Epoch 757/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24466.9077 - reconstruction_loss: 23644.2188 - kl_loss: 980.9995\n",
      "Epoch 758/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24596.6844 - reconstruction_loss: 23720.0195 - kl_loss: 981.6318\n",
      "Epoch 759/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 24438.1237 - reconstruction_loss: 23592.9043 - kl_loss: 978.9198\n",
      "Epoch 760/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 24473.4179 - reconstruction_loss: 23593.8301 - kl_loss: 977.1885\n",
      "Epoch 761/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24433.5524 - reconstruction_loss: 23554.2637 - kl_loss: 972.9471\n",
      "Epoch 762/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 24318.8813 - reconstruction_loss: 23523.8398 - kl_loss: 972.4161\n",
      "Epoch 763/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24615.4558 - reconstruction_loss: 23741.4199 - kl_loss: 971.9883\n",
      "Epoch 764/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24503.6221 - reconstruction_loss: 23634.1270 - kl_loss: 975.7274\n",
      "Epoch 765/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24423.7839 - reconstruction_loss: 23540.3613 - kl_loss: 967.5565\n",
      "Epoch 766/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24417.5183 - reconstruction_loss: 23520.0762 - kl_loss: 963.6620\n",
      "Epoch 767/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24214.0676 - reconstruction_loss: 23360.0430 - kl_loss: 963.8209\n",
      "Epoch 768/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24201.0584 - reconstruction_loss: 23380.2812 - kl_loss: 958.5709\n",
      "Epoch 769/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24141.3953 - reconstruction_loss: 23317.1523 - kl_loss: 957.4454\n",
      "Epoch 770/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24127.7774 - reconstruction_loss: 23320.0742 - kl_loss: 955.6353\n",
      "Epoch 771/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24098.4757 - reconstruction_loss: 23305.3262 - kl_loss: 956.3068\n",
      "Epoch 772/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 24061.0816 - reconstruction_loss: 23256.1758 - kl_loss: 952.8591\n",
      "Epoch 773/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24002.5611 - reconstruction_loss: 23208.2559 - kl_loss: 950.5615\n",
      "Epoch 774/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24047.2332 - reconstruction_loss: 23231.9395 - kl_loss: 948.7099\n",
      "Epoch 775/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 24045.0354 - reconstruction_loss: 23197.4453 - kl_loss: 947.0246\n",
      "Epoch 776/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23993.9275 - reconstruction_loss: 23227.4453 - kl_loss: 943.3328\n",
      "Epoch 777/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24166.1846 - reconstruction_loss: 23265.7969 - kl_loss: 941.7725\n",
      "Epoch 778/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23889.6923 - reconstruction_loss: 23114.0703 - kl_loss: 941.9896\n",
      "Epoch 779/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 24030.0922 - reconstruction_loss: 23196.1562 - kl_loss: 938.1057\n",
      "Epoch 780/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 24062.7046 - reconstruction_loss: 23165.8457 - kl_loss: 936.1677\n",
      "Epoch 781/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23855.7236 - reconstruction_loss: 23080.8926 - kl_loss: 933.6711\n",
      "Epoch 782/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 24162.0136 - reconstruction_loss: 23263.0859 - kl_loss: 934.8436\n",
      "Epoch 783/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 23852.9995 - reconstruction_loss: 23076.5840 - kl_loss: 932.5243\n",
      "Epoch 784/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23922.1001 - reconstruction_loss: 23156.1211 - kl_loss: 931.6177\n",
      "Epoch 785/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 24140.3901 - reconstruction_loss: 23210.5039 - kl_loss: 928.9633\n",
      "Epoch 786/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23847.8654 - reconstruction_loss: 23035.5625 - kl_loss: 928.8645\n",
      "Epoch 787/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23834.1528 - reconstruction_loss: 23016.6328 - kl_loss: 927.5209\n",
      "Epoch 788/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23814.9475 - reconstruction_loss: 22993.8574 - kl_loss: 926.3905\n",
      "Epoch 789/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23938.3953 - reconstruction_loss: 23085.3945 - kl_loss: 922.6002\n",
      "Epoch 790/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23935.8236 - reconstruction_loss: 23182.8340 - kl_loss: 925.1352\n",
      "Epoch 791/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23959.3023 - reconstruction_loss: 23059.6738 - kl_loss: 920.9223\n",
      "Epoch 792/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23871.7579 - reconstruction_loss: 23050.0742 - kl_loss: 920.1859\n",
      "Epoch 793/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23825.7164 - reconstruction_loss: 23034.0957 - kl_loss: 918.4136\n",
      "Epoch 794/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23758.0792 - reconstruction_loss: 23004.8008 - kl_loss: 916.9387\n",
      "Epoch 795/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23825.5033 - reconstruction_loss: 23003.9395 - kl_loss: 916.9070\n",
      "Epoch 796/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 23681.6601 - reconstruction_loss: 22919.3340 - kl_loss: 913.3122\n",
      "Epoch 797/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 23612.1162 - reconstruction_loss: 22837.7852 - kl_loss: 914.8134\n",
      "Epoch 798/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23555.4873 - reconstruction_loss: 22780.0859 - kl_loss: 912.6312\n",
      "Epoch 799/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23498.2392 - reconstruction_loss: 22722.0586 - kl_loss: 911.2294\n",
      "Epoch 800/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 23442.4687 - reconstruction_loss: 22679.7520 - kl_loss: 909.1555\n",
      "Epoch 801/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23435.7416 - reconstruction_loss: 22643.2617 - kl_loss: 907.8743\n",
      "Epoch 802/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23419.5387 - reconstruction_loss: 22634.6621 - kl_loss: 906.2326\n",
      "Epoch 803/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 23475.5049 - reconstruction_loss: 22660.7910 - kl_loss: 904.3128\n",
      "Epoch 804/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23420.5854 - reconstruction_loss: 22651.6367 - kl_loss: 903.5773\n",
      "Epoch 805/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23376.5124 - reconstruction_loss: 22601.6641 - kl_loss: 903.2500\n",
      "Epoch 806/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 23407.7146 - reconstruction_loss: 22589.6504 - kl_loss: 903.9201\n",
      "Epoch 807/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23316.8731 - reconstruction_loss: 22538.2695 - kl_loss: 898.5326\n",
      "Epoch 808/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23298.6283 - reconstruction_loss: 22543.8242 - kl_loss: 898.5569\n",
      "Epoch 809/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 23405.4121 - reconstruction_loss: 22597.4316 - kl_loss: 898.5299\n",
      "Epoch 810/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23272.3895 - reconstruction_loss: 22511.1934 - kl_loss: 898.0929\n",
      "Epoch 811/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23297.5830 - reconstruction_loss: 22586.1289 - kl_loss: 897.1228\n",
      "Epoch 812/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23528.5279 - reconstruction_loss: 22612.0234 - kl_loss: 897.5477\n",
      "Epoch 813/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 23300.5367 - reconstruction_loss: 22471.9648 - kl_loss: 893.3084\n",
      "Epoch 814/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23260.1451 - reconstruction_loss: 22550.7715 - kl_loss: 891.7236\n",
      "Epoch 815/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23574.2020 - reconstruction_loss: 22611.4902 - kl_loss: 893.0327\n",
      "Epoch 816/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 23197.9119 - reconstruction_loss: 22460.0957 - kl_loss: 889.4565\n",
      "Epoch 817/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23257.8420 - reconstruction_loss: 22462.6875 - kl_loss: 889.0291\n",
      "Epoch 818/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 23117.8143 - reconstruction_loss: 22369.8379 - kl_loss: 886.2478\n",
      "Epoch 819/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 23109.9940 - reconstruction_loss: 22392.9707 - kl_loss: 886.8215\n",
      "Epoch 820/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 23065.5405 - reconstruction_loss: 22335.6230 - kl_loss: 884.5334\n",
      "Epoch 821/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 23018.2794 - reconstruction_loss: 22330.8828 - kl_loss: 883.0344\n",
      "Epoch 822/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23008.5807 - reconstruction_loss: 22276.5098 - kl_loss: 882.7446\n",
      "Epoch 823/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22984.4076 - reconstruction_loss: 22259.8301 - kl_loss: 883.8517\n",
      "Epoch 824/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22963.7957 - reconstruction_loss: 22247.5176 - kl_loss: 880.8817\n",
      "Epoch 825/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 22952.0372 - reconstruction_loss: 22237.6953 - kl_loss: 880.8173\n",
      "Epoch 826/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22940.8898 - reconstruction_loss: 22237.2656 - kl_loss: 878.4474\n",
      "Epoch 827/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22939.1116 - reconstruction_loss: 22215.6484 - kl_loss: 877.7706\n",
      "Epoch 828/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22915.5066 - reconstruction_loss: 22176.2930 - kl_loss: 876.2753\n",
      "Epoch 829/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22851.5046 - reconstruction_loss: 22150.9590 - kl_loss: 875.5700\n",
      "Epoch 830/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22961.7813 - reconstruction_loss: 22265.8340 - kl_loss: 872.2942\n",
      "Epoch 831/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22940.1637 - reconstruction_loss: 22230.7227 - kl_loss: 875.3178\n",
      "Epoch 832/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22909.6278 - reconstruction_loss: 22173.1660 - kl_loss: 874.4595\n",
      "Epoch 833/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22987.3642 - reconstruction_loss: 22235.2305 - kl_loss: 872.3803\n",
      "Epoch 834/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23237.6831 - reconstruction_loss: 22389.5254 - kl_loss: 870.8785\n",
      "Epoch 835/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23006.7849 - reconstruction_loss: 22302.8281 - kl_loss: 869.9318\n",
      "Epoch 836/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23276.6815 - reconstruction_loss: 22480.4062 - kl_loss: 870.2775\n",
      "Epoch 837/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23532.3571 - reconstruction_loss: 22704.6133 - kl_loss: 869.6711\n",
      "Epoch 838/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23246.5343 - reconstruction_loss: 22488.6543 - kl_loss: 868.3232\n",
      "Epoch 839/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 23264.6787 - reconstruction_loss: 22442.8711 - kl_loss: 867.4227\n",
      "Epoch 840/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23150.2144 - reconstruction_loss: 22375.1074 - kl_loss: 868.6055\n",
      "Epoch 841/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22957.6015 - reconstruction_loss: 22229.0273 - kl_loss: 868.4969\n",
      "Epoch 842/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22967.7231 - reconstruction_loss: 22228.2598 - kl_loss: 865.2305\n",
      "Epoch 843/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22907.9350 - reconstruction_loss: 22174.5469 - kl_loss: 864.7313\n",
      "Epoch 844/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22803.6648 - reconstruction_loss: 22103.4824 - kl_loss: 862.8580\n",
      "Epoch 845/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 22802.1800 - reconstruction_loss: 22096.8242 - kl_loss: 862.8869\n",
      "Epoch 846/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22774.4122 - reconstruction_loss: 22068.4707 - kl_loss: 862.7028\n",
      "Epoch 847/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22691.0915 - reconstruction_loss: 22005.5117 - kl_loss: 861.5336\n",
      "Epoch 848/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 22672.7330 - reconstruction_loss: 21968.2480 - kl_loss: 861.1852\n",
      "Epoch 849/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22679.1881 - reconstruction_loss: 21974.5078 - kl_loss: 860.1821\n",
      "Epoch 850/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22632.5595 - reconstruction_loss: 21947.5723 - kl_loss: 859.5715\n",
      "Epoch 851/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22624.5150 - reconstruction_loss: 21908.2910 - kl_loss: 860.0453\n",
      "Epoch 852/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22594.7049 - reconstruction_loss: 21897.4727 - kl_loss: 857.4121\n",
      "Epoch 853/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22566.2402 - reconstruction_loss: 21871.8828 - kl_loss: 856.5950\n",
      "Epoch 854/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22522.9589 - reconstruction_loss: 21837.5977 - kl_loss: 854.2175\n",
      "Epoch 855/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22565.6678 - reconstruction_loss: 21841.7578 - kl_loss: 853.7124\n",
      "Epoch 856/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22486.1984 - reconstruction_loss: 21793.7656 - kl_loss: 853.8915\n",
      "Epoch 857/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22510.6503 - reconstruction_loss: 21797.7402 - kl_loss: 850.9539\n",
      "Epoch 858/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 22568.1177 - reconstruction_loss: 21804.7773 - kl_loss: 851.6330\n",
      "Epoch 859/5000\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 22428.9277 - reconstruction_loss: 21724.9746 - kl_loss: 850.7556\n",
      "Epoch 860/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 22591.1679 - reconstruction_loss: 21930.0977 - kl_loss: 850.0638\n",
      "Epoch 861/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22556.3448 - reconstruction_loss: 21787.8438 - kl_loss: 849.0566\n",
      "Epoch 862/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22439.0255 - reconstruction_loss: 21719.5137 - kl_loss: 847.6727\n",
      "Epoch 863/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22411.6480 - reconstruction_loss: 21691.4512 - kl_loss: 847.3711\n",
      "Epoch 864/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22434.1705 - reconstruction_loss: 21682.2246 - kl_loss: 848.5060\n",
      "Epoch 865/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22502.8775 - reconstruction_loss: 21816.9062 - kl_loss: 846.9161\n",
      "Epoch 866/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22449.8654 - reconstruction_loss: 21703.3633 - kl_loss: 847.8389\n",
      "Epoch 867/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22299.4079 - reconstruction_loss: 21614.9453 - kl_loss: 844.7941\n",
      "Epoch 868/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22297.4944 - reconstruction_loss: 21584.4492 - kl_loss: 845.2616\n",
      "Epoch 869/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22250.1540 - reconstruction_loss: 21554.3301 - kl_loss: 842.3513\n",
      "Epoch 870/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22187.3426 - reconstruction_loss: 21520.0078 - kl_loss: 841.7341\n",
      "Epoch 871/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22236.5154 - reconstruction_loss: 21550.6621 - kl_loss: 841.0164\n",
      "Epoch 872/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22156.0690 - reconstruction_loss: 21485.8906 - kl_loss: 839.7408\n",
      "Epoch 873/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 22123.1180 - reconstruction_loss: 21462.9062 - kl_loss: 838.7087\n",
      "Epoch 874/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 22199.1285 - reconstruction_loss: 21473.3398 - kl_loss: 838.2306\n",
      "Epoch 875/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22102.2773 - reconstruction_loss: 21421.4727 - kl_loss: 837.1072\n",
      "Epoch 876/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22133.2825 - reconstruction_loss: 21490.0957 - kl_loss: 836.2392\n",
      "Epoch 877/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 22256.9398 - reconstruction_loss: 21504.9668 - kl_loss: 836.9838\n",
      "Epoch 878/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22085.3996 - reconstruction_loss: 21421.8535 - kl_loss: 833.2252\n",
      "Epoch 879/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 22121.5891 - reconstruction_loss: 21418.1543 - kl_loss: 836.2195\n",
      "Epoch 880/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22141.4682 - reconstruction_loss: 21424.0605 - kl_loss: 834.5718\n",
      "Epoch 881/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22065.9666 - reconstruction_loss: 21351.1074 - kl_loss: 832.8087\n",
      "Epoch 882/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22057.3620 - reconstruction_loss: 21431.0195 - kl_loss: 828.7554\n",
      "Epoch 883/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22297.7301 - reconstruction_loss: 21488.7246 - kl_loss: 831.1165\n",
      "Epoch 884/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22030.2624 - reconstruction_loss: 21312.1562 - kl_loss: 830.1420\n",
      "Epoch 885/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22023.4096 - reconstruction_loss: 21348.1348 - kl_loss: 828.8443\n",
      "Epoch 886/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22002.7583 - reconstruction_loss: 21290.6953 - kl_loss: 828.6525\n",
      "Epoch 887/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21876.7199 - reconstruction_loss: 21213.7773 - kl_loss: 827.7217\n",
      "Epoch 888/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21945.8588 - reconstruction_loss: 21252.9453 - kl_loss: 826.7495\n",
      "Epoch 889/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 21984.2737 - reconstruction_loss: 21243.4961 - kl_loss: 823.5264\n",
      "Epoch 890/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 21938.1661 - reconstruction_loss: 21284.8047 - kl_loss: 825.2037\n",
      "Epoch 891/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21870.1481 - reconstruction_loss: 21197.9570 - kl_loss: 824.5322\n",
      "Epoch 892/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21831.0674 - reconstruction_loss: 21168.0449 - kl_loss: 823.2404\n",
      "Epoch 893/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21869.5334 - reconstruction_loss: 21182.7715 - kl_loss: 821.7113\n",
      "Epoch 894/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21979.6268 - reconstruction_loss: 21282.5957 - kl_loss: 821.9276\n",
      "Epoch 895/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21988.3526 - reconstruction_loss: 21414.0625 - kl_loss: 822.5316\n",
      "Epoch 896/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22331.1317 - reconstruction_loss: 21714.1113 - kl_loss: 824.3582\n",
      "Epoch 897/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22564.6923 - reconstruction_loss: 21810.6270 - kl_loss: 824.6483\n",
      "Epoch 898/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 22531.5368 - reconstruction_loss: 21815.1016 - kl_loss: 820.8847\n",
      "Epoch 899/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 22379.4259 - reconstruction_loss: 21639.3906 - kl_loss: 822.5991\n",
      "Epoch 900/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22218.3868 - reconstruction_loss: 21577.5781 - kl_loss: 820.5144\n",
      "Epoch 901/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22122.3661 - reconstruction_loss: 21447.9805 - kl_loss: 819.4658\n",
      "Epoch 902/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22073.4539 - reconstruction_loss: 21422.1172 - kl_loss: 818.8773\n",
      "Epoch 903/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21951.0444 - reconstruction_loss: 21311.2598 - kl_loss: 820.0524\n",
      "Epoch 904/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21878.7694 - reconstruction_loss: 21264.8555 - kl_loss: 819.0786\n",
      "Epoch 905/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21825.7722 - reconstruction_loss: 21226.0840 - kl_loss: 819.1110\n",
      "Epoch 906/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21814.8513 - reconstruction_loss: 21222.8320 - kl_loss: 819.4337\n",
      "Epoch 907/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21781.0728 - reconstruction_loss: 21153.7266 - kl_loss: 820.5239\n",
      "Epoch 908/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21733.5545 - reconstruction_loss: 21134.7617 - kl_loss: 817.2704\n",
      "Epoch 909/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21774.7385 - reconstruction_loss: 21124.5586 - kl_loss: 817.9881\n",
      "Epoch 910/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21822.3394 - reconstruction_loss: 21144.7695 - kl_loss: 817.8584\n",
      "Epoch 911/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21751.7040 - reconstruction_loss: 21181.8105 - kl_loss: 817.7436\n",
      "Epoch 912/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22053.8224 - reconstruction_loss: 21329.6699 - kl_loss: 817.3370\n",
      "Epoch 913/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21835.3000 - reconstruction_loss: 21127.9258 - kl_loss: 818.2640\n",
      "Epoch 914/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21764.8725 - reconstruction_loss: 21136.0078 - kl_loss: 815.3816\n",
      "Epoch 915/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21822.4201 - reconstruction_loss: 21162.9316 - kl_loss: 815.7408\n",
      "Epoch 916/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21745.1136 - reconstruction_loss: 21136.9473 - kl_loss: 815.7960\n",
      "Epoch 917/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 21849.3940 - reconstruction_loss: 21204.9062 - kl_loss: 814.4733\n",
      "Epoch 918/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 21897.8850 - reconstruction_loss: 21211.7676 - kl_loss: 818.2001\n",
      "Epoch 919/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21849.3190 - reconstruction_loss: 21257.6621 - kl_loss: 813.7008\n",
      "Epoch 920/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 22022.2710 - reconstruction_loss: 21400.8926 - kl_loss: 814.9146\n",
      "Epoch 921/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22161.1778 - reconstruction_loss: 21608.6621 - kl_loss: 818.1503\n",
      "Epoch 922/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 22497.3693 - reconstruction_loss: 21873.2617 - kl_loss: 816.7953\n",
      "Epoch 923/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 22023.9617 - reconstruction_loss: 21491.0430 - kl_loss: 819.4830\n",
      "Epoch 924/5000\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 21929.5959 - reconstruction_loss: 21334.0371 - kl_loss: 816.8178\n",
      "Epoch 925/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 21915.5963 - reconstruction_loss: 21258.6641 - kl_loss: 816.3723\n",
      "Epoch 926/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 21775.6620 - reconstruction_loss: 21139.1504 - kl_loss: 816.4651\n",
      "Epoch 927/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 21783.1058 - reconstruction_loss: 21122.9473 - kl_loss: 814.9161\n",
      "Epoch 928/5000\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 21792.4656 - reconstruction_loss: 21110.7246 - kl_loss: 815.7137\n",
      "Epoch 929/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 21769.4548 - reconstruction_loss: 21062.0312 - kl_loss: 815.7604\n",
      "Epoch 930/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 21798.3931 - reconstruction_loss: 21098.0156 - kl_loss: 813.7451\n",
      "Epoch 931/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21740.1515 - reconstruction_loss: 21037.9004 - kl_loss: 814.7079\n",
      "Epoch 932/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 21782.3412 - reconstruction_loss: 21065.8125 - kl_loss: 813.1613\n",
      "Epoch 933/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 21863.6901 - reconstruction_loss: 21111.4473 - kl_loss: 813.2643\n",
      "Epoch 934/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 21791.1669 - reconstruction_loss: 21122.1641 - kl_loss: 814.9830\n",
      "Epoch 935/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 21906.9216 - reconstruction_loss: 21220.4805 - kl_loss: 814.3251\n",
      "Epoch 936/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 22023.4737 - reconstruction_loss: 21364.5332 - kl_loss: 815.4606\n",
      "Epoch 937/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 22238.9251 - reconstruction_loss: 21597.2891 - kl_loss: 815.3934\n",
      "Epoch 938/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 22619.0918 - reconstruction_loss: 22001.6094 - kl_loss: 815.4395\n",
      "Epoch 939/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 23283.2388 - reconstruction_loss: 22548.0488 - kl_loss: 811.4229\n",
      "Epoch 940/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 23202.6777 - reconstruction_loss: 22306.4746 - kl_loss: 814.6394\n",
      "Epoch 941/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 22650.2111 - reconstruction_loss: 21797.5293 - kl_loss: 815.9936\n",
      "Epoch 942/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 22153.4748 - reconstruction_loss: 21325.5410 - kl_loss: 817.7897\n",
      "Epoch 943/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 21994.4488 - reconstruction_loss: 21166.6738 - kl_loss: 816.6255\n",
      "Epoch 944/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21762.1630 - reconstruction_loss: 20995.0605 - kl_loss: 815.3152\n",
      "Epoch 945/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21692.4107 - reconstruction_loss: 20940.1816 - kl_loss: 816.0565\n",
      "Epoch 946/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21588.8734 - reconstruction_loss: 20853.6992 - kl_loss: 814.6694\n",
      "Epoch 947/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21587.4503 - reconstruction_loss: 20841.6348 - kl_loss: 814.7745\n",
      "Epoch 948/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 21528.5073 - reconstruction_loss: 20804.2344 - kl_loss: 813.2892\n",
      "Epoch 949/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21493.3562 - reconstruction_loss: 20761.6270 - kl_loss: 813.6592\n",
      "Epoch 950/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 21433.3471 - reconstruction_loss: 20701.3379 - kl_loss: 814.3507\n",
      "Epoch 951/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21422.1073 - reconstruction_loss: 20707.5195 - kl_loss: 813.3368\n",
      "Epoch 952/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 21415.8082 - reconstruction_loss: 20656.8848 - kl_loss: 812.5284\n",
      "Epoch 953/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21348.3720 - reconstruction_loss: 20643.0176 - kl_loss: 811.6863\n",
      "Epoch 954/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21313.4291 - reconstruction_loss: 20588.3379 - kl_loss: 811.3463\n",
      "Epoch 955/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21329.0179 - reconstruction_loss: 20617.3320 - kl_loss: 810.7811\n",
      "Epoch 956/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 21287.3801 - reconstruction_loss: 20547.9141 - kl_loss: 811.1475\n",
      "Epoch 957/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 21182.1746 - reconstruction_loss: 20499.1016 - kl_loss: 808.9207\n",
      "Epoch 958/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 21296.1274 - reconstruction_loss: 20556.6426 - kl_loss: 809.5252\n",
      "Epoch 959/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21286.7224 - reconstruction_loss: 20498.2129 - kl_loss: 812.2142\n",
      "Epoch 960/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21137.2150 - reconstruction_loss: 20419.5742 - kl_loss: 809.7884\n",
      "Epoch 961/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21158.4497 - reconstruction_loss: 20435.9434 - kl_loss: 809.0372\n",
      "Epoch 962/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 21169.3481 - reconstruction_loss: 20421.0117 - kl_loss: 810.6987\n",
      "Epoch 963/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21116.8316 - reconstruction_loss: 20384.4160 - kl_loss: 810.2768\n",
      "Epoch 964/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 21195.9422 - reconstruction_loss: 20384.9297 - kl_loss: 809.7097\n",
      "Epoch 965/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21005.6126 - reconstruction_loss: 20298.2383 - kl_loss: 806.7108\n",
      "Epoch 966/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 20979.9438 - reconstruction_loss: 20285.1113 - kl_loss: 803.8713\n",
      "Epoch 967/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20983.4830 - reconstruction_loss: 20262.2461 - kl_loss: 805.8361\n",
      "Epoch 968/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20925.5659 - reconstruction_loss: 20223.4824 - kl_loss: 804.5945\n",
      "Epoch 969/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20942.0061 - reconstruction_loss: 20207.2305 - kl_loss: 804.9204\n",
      "Epoch 970/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20813.7616 - reconstruction_loss: 20137.3340 - kl_loss: 803.3848\n",
      "Epoch 971/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 20835.9300 - reconstruction_loss: 20129.3164 - kl_loss: 802.7438\n",
      "Epoch 972/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20785.1054 - reconstruction_loss: 20095.0156 - kl_loss: 802.2606\n",
      "Epoch 973/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20770.0489 - reconstruction_loss: 20079.1152 - kl_loss: 801.7116\n",
      "Epoch 974/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20746.5625 - reconstruction_loss: 20039.9434 - kl_loss: 800.3236\n",
      "Epoch 975/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 20697.2446 - reconstruction_loss: 20015.3906 - kl_loss: 801.2154\n",
      "Epoch 976/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 20734.1147 - reconstruction_loss: 20023.9883 - kl_loss: 799.6617\n",
      "Epoch 977/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20631.1798 - reconstruction_loss: 19955.6113 - kl_loss: 799.5703\n",
      "Epoch 978/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20664.8744 - reconstruction_loss: 19961.9473 - kl_loss: 799.3483\n",
      "Epoch 979/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20635.8732 - reconstruction_loss: 19924.5488 - kl_loss: 799.3486\n",
      "Epoch 980/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 20572.1140 - reconstruction_loss: 19901.3340 - kl_loss: 796.9590\n",
      "Epoch 981/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20730.8894 - reconstruction_loss: 19999.7461 - kl_loss: 801.2142\n",
      "Epoch 982/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 21144.8723 - reconstruction_loss: 20102.7715 - kl_loss: 796.8901\n",
      "Epoch 983/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20766.9597 - reconstruction_loss: 20001.5605 - kl_loss: 796.0123\n",
      "Epoch 984/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 20517.0278 - reconstruction_loss: 19818.2461 - kl_loss: 794.2104\n",
      "Epoch 985/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 20456.5158 - reconstruction_loss: 19790.2871 - kl_loss: 793.8373\n",
      "Epoch 986/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20458.9325 - reconstruction_loss: 19774.6387 - kl_loss: 792.3710\n",
      "Epoch 987/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 20387.5335 - reconstruction_loss: 19752.7188 - kl_loss: 792.3147\n",
      "Epoch 988/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20366.5913 - reconstruction_loss: 19709.3066 - kl_loss: 792.7196\n",
      "Epoch 989/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20324.0963 - reconstruction_loss: 19675.9336 - kl_loss: 790.4963\n",
      "Epoch 990/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 20369.9183 - reconstruction_loss: 19707.2129 - kl_loss: 789.7303\n",
      "Epoch 991/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20305.1760 - reconstruction_loss: 19650.0762 - kl_loss: 788.9680\n",
      "Epoch 992/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 20419.8669 - reconstruction_loss: 19719.6699 - kl_loss: 787.4232\n",
      "Epoch 993/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 20317.7508 - reconstruction_loss: 19653.0684 - kl_loss: 787.3308\n",
      "Epoch 994/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20304.5844 - reconstruction_loss: 19622.1309 - kl_loss: 787.0079\n",
      "Epoch 995/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 20251.4731 - reconstruction_loss: 19603.2656 - kl_loss: 786.0506\n",
      "Epoch 996/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20283.7340 - reconstruction_loss: 19596.7676 - kl_loss: 785.0411\n",
      "Epoch 997/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 20253.6528 - reconstruction_loss: 19596.0000 - kl_loss: 784.3504\n",
      "Epoch 998/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20255.9954 - reconstruction_loss: 19599.8340 - kl_loss: 783.6916\n",
      "Epoch 999/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20413.1715 - reconstruction_loss: 19685.5449 - kl_loss: 782.1553\n",
      "Epoch 1000/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20290.5049 - reconstruction_loss: 19583.2520 - kl_loss: 781.4957\n",
      "Epoch 1001/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 20210.7609 - reconstruction_loss: 19560.6133 - kl_loss: 780.5059\n",
      "Epoch 1002/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 20301.6370 - reconstruction_loss: 19584.2051 - kl_loss: 778.2965\n",
      "Epoch 1003/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 20161.9080 - reconstruction_loss: 19497.1250 - kl_loss: 781.3498\n",
      "Epoch 1004/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 20092.1070 - reconstruction_loss: 19436.9531 - kl_loss: 779.1365\n",
      "Epoch 1005/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 20157.2908 - reconstruction_loss: 19468.8496 - kl_loss: 777.9359\n",
      "Epoch 1006/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20091.8797 - reconstruction_loss: 19424.1035 - kl_loss: 776.2722\n",
      "Epoch 1007/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20026.8806 - reconstruction_loss: 19401.7930 - kl_loss: 775.7179\n",
      "Epoch 1008/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20040.0354 - reconstruction_loss: 19385.5801 - kl_loss: 774.8365\n",
      "Epoch 1009/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19971.6267 - reconstruction_loss: 19350.1328 - kl_loss: 773.5344\n",
      "Epoch 1010/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 19967.3673 - reconstruction_loss: 19343.8281 - kl_loss: 772.4285\n",
      "Epoch 1011/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20031.9377 - reconstruction_loss: 19382.0762 - kl_loss: 769.1311\n",
      "Epoch 1012/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19951.8085 - reconstruction_loss: 19307.0195 - kl_loss: 770.6894\n",
      "Epoch 1013/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19958.4909 - reconstruction_loss: 19336.3652 - kl_loss: 769.9988\n",
      "Epoch 1014/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19990.8019 - reconstruction_loss: 19301.1895 - kl_loss: 768.8291\n",
      "Epoch 1015/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19891.4831 - reconstruction_loss: 19265.7539 - kl_loss: 768.3356\n",
      "Epoch 1016/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 19997.3591 - reconstruction_loss: 19346.3789 - kl_loss: 767.6541\n",
      "Epoch 1017/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 20048.9836 - reconstruction_loss: 19330.8301 - kl_loss: 766.0358\n",
      "Epoch 1018/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19888.1899 - reconstruction_loss: 19243.4180 - kl_loss: 765.8041\n",
      "Epoch 1019/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19923.5803 - reconstruction_loss: 19266.8867 - kl_loss: 763.5659\n",
      "Epoch 1020/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 19887.0060 - reconstruction_loss: 19228.4785 - kl_loss: 761.8436\n",
      "Epoch 1021/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19811.8165 - reconstruction_loss: 19197.5137 - kl_loss: 761.6849\n",
      "Epoch 1022/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19922.0728 - reconstruction_loss: 19256.0430 - kl_loss: 761.5209\n",
      "Epoch 1023/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19845.0325 - reconstruction_loss: 19185.3203 - kl_loss: 760.3701\n",
      "Epoch 1024/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19747.7907 - reconstruction_loss: 19146.2090 - kl_loss: 758.9779\n",
      "Epoch 1025/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19891.5369 - reconstruction_loss: 19181.5391 - kl_loss: 759.8058\n",
      "Epoch 1026/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19786.5469 - reconstruction_loss: 19185.4473 - kl_loss: 757.9543\n",
      "Epoch 1027/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19826.5064 - reconstruction_loss: 19235.9199 - kl_loss: 757.7679\n",
      "Epoch 1028/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19908.6115 - reconstruction_loss: 19240.4746 - kl_loss: 758.1335\n",
      "Epoch 1029/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 19934.3383 - reconstruction_loss: 19230.2051 - kl_loss: 756.5415\n",
      "Epoch 1030/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19765.0264 - reconstruction_loss: 19167.3125 - kl_loss: 754.4719\n",
      "Epoch 1031/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19692.8194 - reconstruction_loss: 19085.1992 - kl_loss: 752.3586\n",
      "Epoch 1032/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19680.7434 - reconstruction_loss: 19089.0684 - kl_loss: 752.9892\n",
      "Epoch 1033/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19693.8079 - reconstruction_loss: 19092.4570 - kl_loss: 752.0986\n",
      "Epoch 1034/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19631.1660 - reconstruction_loss: 19041.8750 - kl_loss: 751.8483\n",
      "Epoch 1035/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 19620.3065 - reconstruction_loss: 19013.6309 - kl_loss: 751.5909\n",
      "Epoch 1036/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 19724.1390 - reconstruction_loss: 19070.5371 - kl_loss: 751.2881\n",
      "Epoch 1037/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19579.1899 - reconstruction_loss: 18994.8809 - kl_loss: 750.2438\n",
      "Epoch 1038/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19575.4065 - reconstruction_loss: 19027.8867 - kl_loss: 747.0200\n",
      "Epoch 1039/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19618.2192 - reconstruction_loss: 19022.7539 - kl_loss: 747.4980\n",
      "Epoch 1040/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19664.6933 - reconstruction_loss: 19057.1465 - kl_loss: 746.7601\n",
      "Epoch 1041/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19593.6080 - reconstruction_loss: 19036.7266 - kl_loss: 746.8777\n",
      "Epoch 1042/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19696.7332 - reconstruction_loss: 19079.7871 - kl_loss: 745.3044\n",
      "Epoch 1043/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19753.4230 - reconstruction_loss: 19204.6309 - kl_loss: 746.0359\n",
      "Epoch 1044/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19917.5693 - reconstruction_loss: 19451.3340 - kl_loss: 745.6906\n",
      "Epoch 1045/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19901.7510 - reconstruction_loss: 19324.3066 - kl_loss: 745.5012\n",
      "Epoch 1046/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19778.8251 - reconstruction_loss: 19235.6387 - kl_loss: 745.9490\n",
      "Epoch 1047/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19727.6428 - reconstruction_loss: 19175.0469 - kl_loss: 746.1672\n",
      "Epoch 1048/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19797.4341 - reconstruction_loss: 19176.3926 - kl_loss: 746.7556\n",
      "Epoch 1049/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19871.4706 - reconstruction_loss: 19154.8477 - kl_loss: 745.8782\n",
      "Epoch 1050/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 19681.3157 - reconstruction_loss: 19077.8848 - kl_loss: 743.9683\n",
      "Epoch 1051/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19671.5882 - reconstruction_loss: 19038.8262 - kl_loss: 743.7136\n",
      "Epoch 1052/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19563.3343 - reconstruction_loss: 18961.0000 - kl_loss: 742.0652\n",
      "Epoch 1053/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19493.6853 - reconstruction_loss: 18904.1445 - kl_loss: 740.7889\n",
      "Epoch 1054/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19465.4932 - reconstruction_loss: 18881.9492 - kl_loss: 740.8824\n",
      "Epoch 1055/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19567.3027 - reconstruction_loss: 18974.5566 - kl_loss: 739.8023\n",
      "Epoch 1056/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19526.0348 - reconstruction_loss: 18938.6348 - kl_loss: 738.7961\n",
      "Epoch 1057/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19522.4796 - reconstruction_loss: 18898.7402 - kl_loss: 738.5730\n",
      "Epoch 1058/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19484.7209 - reconstruction_loss: 18887.5254 - kl_loss: 738.3486\n",
      "Epoch 1059/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19513.1382 - reconstruction_loss: 18884.2832 - kl_loss: 739.4598\n",
      "Epoch 1060/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19407.8868 - reconstruction_loss: 18808.9941 - kl_loss: 737.2949\n",
      "Epoch 1061/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19410.2385 - reconstruction_loss: 18829.7129 - kl_loss: 737.6113\n",
      "Epoch 1062/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19419.0966 - reconstruction_loss: 18785.3535 - kl_loss: 735.6249\n",
      "Epoch 1063/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19417.2691 - reconstruction_loss: 18950.4961 - kl_loss: 732.4672\n",
      "Epoch 1064/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19394.8425 - reconstruction_loss: 18481.4688 - kl_loss: 734.3203\n",
      "Epoch 1065/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19254.5985 - reconstruction_loss: 18337.2539 - kl_loss: 735.9356\n",
      "Epoch 1066/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19165.1405 - reconstruction_loss: 18246.5977 - kl_loss: 735.9279\n",
      "Epoch 1067/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19090.1844 - reconstruction_loss: 18189.9297 - kl_loss: 734.1192\n",
      "Epoch 1068/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19149.7053 - reconstruction_loss: 18193.6816 - kl_loss: 734.3293\n",
      "Epoch 1069/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19021.1938 - reconstruction_loss: 18109.9668 - kl_loss: 733.0314\n",
      "Epoch 1070/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19025.2237 - reconstruction_loss: 18103.8398 - kl_loss: 733.8726\n",
      "Epoch 1071/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18951.4454 - reconstruction_loss: 18056.5156 - kl_loss: 731.2148\n",
      "Epoch 1072/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18934.3721 - reconstruction_loss: 18058.7676 - kl_loss: 732.2953\n",
      "Epoch 1073/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18938.8545 - reconstruction_loss: 18044.7695 - kl_loss: 732.6915\n",
      "Epoch 1074/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18871.3234 - reconstruction_loss: 17994.9492 - kl_loss: 730.7620\n",
      "Epoch 1075/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18879.9283 - reconstruction_loss: 18008.2324 - kl_loss: 729.6512\n",
      "Epoch 1076/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18887.3573 - reconstruction_loss: 18006.9219 - kl_loss: 729.7027\n",
      "Epoch 1077/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18889.3800 - reconstruction_loss: 18027.4395 - kl_loss: 728.5436\n",
      "Epoch 1078/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18900.5741 - reconstruction_loss: 18020.7734 - kl_loss: 728.0580\n",
      "Epoch 1079/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18846.5227 - reconstruction_loss: 17974.7773 - kl_loss: 728.0901\n",
      "Epoch 1080/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18878.8240 - reconstruction_loss: 18013.4082 - kl_loss: 726.9100\n",
      "Epoch 1081/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18922.8055 - reconstruction_loss: 17987.2734 - kl_loss: 728.7864\n",
      "Epoch 1082/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18806.1337 - reconstruction_loss: 17911.2344 - kl_loss: 727.3195\n",
      "Epoch 1083/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18817.8603 - reconstruction_loss: 17946.9746 - kl_loss: 727.8329\n",
      "Epoch 1084/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18850.5363 - reconstruction_loss: 17941.9414 - kl_loss: 727.6341\n",
      "Epoch 1085/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18865.9762 - reconstruction_loss: 17940.5918 - kl_loss: 727.8416\n",
      "Epoch 1086/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18806.8742 - reconstruction_loss: 17904.4336 - kl_loss: 726.9269\n",
      "Epoch 1087/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 18936.6361 - reconstruction_loss: 17999.1387 - kl_loss: 725.2722\n",
      "Epoch 1088/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18798.3179 - reconstruction_loss: 17926.4785 - kl_loss: 727.0094\n",
      "Epoch 1089/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18900.3108 - reconstruction_loss: 17987.5723 - kl_loss: 725.0906\n",
      "Epoch 1090/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18845.0433 - reconstruction_loss: 17994.0449 - kl_loss: 724.6966\n",
      "Epoch 1091/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18960.1997 - reconstruction_loss: 18094.4414 - kl_loss: 724.0480\n",
      "Epoch 1092/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19452.3480 - reconstruction_loss: 18520.1191 - kl_loss: 723.7132\n",
      "Epoch 1093/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19884.2471 - reconstruction_loss: 18885.2383 - kl_loss: 726.8887\n",
      "Epoch 1094/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19446.6452 - reconstruction_loss: 18537.4160 - kl_loss: 725.5394\n",
      "Epoch 1095/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19307.9722 - reconstruction_loss: 18501.6152 - kl_loss: 722.8879\n",
      "Epoch 1096/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19285.5794 - reconstruction_loss: 18408.7324 - kl_loss: 722.8676\n",
      "Epoch 1097/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19317.0409 - reconstruction_loss: 18309.9648 - kl_loss: 721.0306\n",
      "Epoch 1098/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19269.1361 - reconstruction_loss: 18262.5879 - kl_loss: 723.0066\n",
      "Epoch 1099/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19248.0741 - reconstruction_loss: 18224.3340 - kl_loss: 722.6633\n",
      "Epoch 1100/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19169.7625 - reconstruction_loss: 18143.2441 - kl_loss: 724.6003\n",
      "Epoch 1101/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19163.9648 - reconstruction_loss: 18139.9512 - kl_loss: 722.6356\n",
      "Epoch 1102/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19133.4304 - reconstruction_loss: 18147.0527 - kl_loss: 722.5122\n",
      "Epoch 1103/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19129.9245 - reconstruction_loss: 18132.5020 - kl_loss: 721.5300\n",
      "Epoch 1104/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19152.4719 - reconstruction_loss: 18151.8691 - kl_loss: 720.9105\n",
      "Epoch 1105/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19147.7983 - reconstruction_loss: 18111.8750 - kl_loss: 722.3770\n",
      "Epoch 1106/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19137.8681 - reconstruction_loss: 18106.0059 - kl_loss: 719.6877\n",
      "Epoch 1107/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19093.2631 - reconstruction_loss: 18070.0137 - kl_loss: 719.8640\n",
      "Epoch 1108/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19112.7134 - reconstruction_loss: 18084.1855 - kl_loss: 719.8611\n",
      "Epoch 1109/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19100.0197 - reconstruction_loss: 18050.9766 - kl_loss: 719.4839\n",
      "Epoch 1110/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19021.8557 - reconstruction_loss: 18031.4727 - kl_loss: 720.4583\n",
      "Epoch 1111/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19110.8146 - reconstruction_loss: 18058.6855 - kl_loss: 719.2485\n",
      "Epoch 1112/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19060.5459 - reconstruction_loss: 18039.2441 - kl_loss: 718.8116\n",
      "Epoch 1113/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19045.2892 - reconstruction_loss: 18067.0488 - kl_loss: 721.3480\n",
      "Epoch 1114/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19111.4451 - reconstruction_loss: 18119.4844 - kl_loss: 720.8198\n",
      "Epoch 1115/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19150.0912 - reconstruction_loss: 18203.5742 - kl_loss: 719.6021\n",
      "Epoch 1116/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19240.5945 - reconstruction_loss: 18342.5137 - kl_loss: 718.8834\n",
      "Epoch 1117/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19348.8910 - reconstruction_loss: 18564.6797 - kl_loss: 718.7981\n",
      "Epoch 1118/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19671.1668 - reconstruction_loss: 19068.5195 - kl_loss: 719.6842\n",
      "Epoch 1119/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 21111.5312 - reconstruction_loss: 20044.5176 - kl_loss: 722.5243\n",
      "Epoch 1120/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 20742.2018 - reconstruction_loss: 19205.5352 - kl_loss: 720.6016\n",
      "Epoch 1121/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19612.2308 - reconstruction_loss: 18433.8887 - kl_loss: 720.6931\n",
      "Epoch 1122/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19538.3008 - reconstruction_loss: 18363.3047 - kl_loss: 719.4701\n",
      "Epoch 1123/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19477.3890 - reconstruction_loss: 18291.1113 - kl_loss: 719.8869\n",
      "Epoch 1124/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 19271.7444 - reconstruction_loss: 18158.7363 - kl_loss: 719.9761\n",
      "Epoch 1125/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19255.3344 - reconstruction_loss: 18138.2891 - kl_loss: 720.2310\n",
      "Epoch 1126/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19204.8081 - reconstruction_loss: 18090.4863 - kl_loss: 718.3647\n",
      "Epoch 1127/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19127.6236 - reconstruction_loss: 18045.8262 - kl_loss: 717.9924\n",
      "Epoch 1128/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 19151.9090 - reconstruction_loss: 18050.0176 - kl_loss: 718.1405\n",
      "Epoch 1129/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19063.3845 - reconstruction_loss: 17982.5312 - kl_loss: 717.3916\n",
      "Epoch 1130/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18955.3486 - reconstruction_loss: 17922.5508 - kl_loss: 716.5612\n",
      "Epoch 1131/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18983.7676 - reconstruction_loss: 17934.8438 - kl_loss: 718.0619\n",
      "Epoch 1132/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18994.9412 - reconstruction_loss: 17939.4180 - kl_loss: 716.1706\n",
      "Epoch 1133/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18936.7424 - reconstruction_loss: 17907.8555 - kl_loss: 715.5666\n",
      "Epoch 1134/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18912.7073 - reconstruction_loss: 17876.8926 - kl_loss: 715.2011\n",
      "Epoch 1135/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18876.9940 - reconstruction_loss: 17843.3457 - kl_loss: 716.4465\n",
      "Epoch 1136/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18822.5026 - reconstruction_loss: 17818.0332 - kl_loss: 715.5117\n",
      "Epoch 1137/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18848.0288 - reconstruction_loss: 17826.5645 - kl_loss: 716.8808\n",
      "Epoch 1138/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18808.1405 - reconstruction_loss: 17798.5977 - kl_loss: 716.2794\n",
      "Epoch 1139/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18692.1850 - reconstruction_loss: 17723.3594 - kl_loss: 715.0829\n",
      "Epoch 1140/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18753.0446 - reconstruction_loss: 17758.7188 - kl_loss: 716.0356\n",
      "Epoch 1141/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18746.5191 - reconstruction_loss: 17734.6934 - kl_loss: 714.8956\n",
      "Epoch 1142/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18633.5087 - reconstruction_loss: 17681.4844 - kl_loss: 714.7048\n",
      "Epoch 1143/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18610.7636 - reconstruction_loss: 17666.4297 - kl_loss: 714.4364\n",
      "Epoch 1144/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 18610.6784 - reconstruction_loss: 17656.5039 - kl_loss: 712.9888\n",
      "Epoch 1145/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18537.4653 - reconstruction_loss: 17611.2695 - kl_loss: 713.3344\n",
      "Epoch 1146/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18519.4859 - reconstruction_loss: 17593.1641 - kl_loss: 712.7533\n",
      "Epoch 1147/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18521.9371 - reconstruction_loss: 17573.3379 - kl_loss: 714.0059\n",
      "Epoch 1148/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18484.3020 - reconstruction_loss: 17554.9551 - kl_loss: 712.9553\n",
      "Epoch 1149/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18459.9363 - reconstruction_loss: 17530.5312 - kl_loss: 712.3610\n",
      "Epoch 1150/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18431.6101 - reconstruction_loss: 17498.9766 - kl_loss: 711.2583\n",
      "Epoch 1151/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18374.9693 - reconstruction_loss: 17473.8203 - kl_loss: 712.3741\n",
      "Epoch 1152/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 18399.1300 - reconstruction_loss: 17481.1758 - kl_loss: 712.7786\n",
      "Epoch 1153/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18366.7082 - reconstruction_loss: 17443.2266 - kl_loss: 711.6649\n",
      "Epoch 1154/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18318.4663 - reconstruction_loss: 17419.9043 - kl_loss: 713.2395\n",
      "Epoch 1155/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18339.6907 - reconstruction_loss: 17423.2617 - kl_loss: 711.5146\n",
      "Epoch 1156/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18333.0853 - reconstruction_loss: 17400.1641 - kl_loss: 711.5551\n",
      "Epoch 1157/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18287.0280 - reconstruction_loss: 17391.5781 - kl_loss: 709.5735\n",
      "Epoch 1158/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18267.5718 - reconstruction_loss: 17373.9922 - kl_loss: 708.8900\n",
      "Epoch 1159/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18218.7235 - reconstruction_loss: 17329.3164 - kl_loss: 708.5406\n",
      "Epoch 1160/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18194.5729 - reconstruction_loss: 17313.4062 - kl_loss: 708.1713\n",
      "Epoch 1161/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18241.4820 - reconstruction_loss: 17337.0371 - kl_loss: 708.2859\n",
      "Epoch 1162/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18184.8679 - reconstruction_loss: 17297.1113 - kl_loss: 708.3326\n",
      "Epoch 1163/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18181.7695 - reconstruction_loss: 17319.5762 - kl_loss: 706.8537\n",
      "Epoch 1164/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18182.1287 - reconstruction_loss: 17290.4043 - kl_loss: 705.6597\n",
      "Epoch 1165/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18135.3710 - reconstruction_loss: 17261.0645 - kl_loss: 706.9807\n",
      "Epoch 1166/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18124.9582 - reconstruction_loss: 17250.9004 - kl_loss: 706.0950\n",
      "Epoch 1167/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 18141.9243 - reconstruction_loss: 17259.6641 - kl_loss: 704.6276\n",
      "Epoch 1168/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18110.5406 - reconstruction_loss: 17240.7539 - kl_loss: 703.7939\n",
      "Epoch 1169/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18119.4829 - reconstruction_loss: 17261.6309 - kl_loss: 703.6611\n",
      "Epoch 1170/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18090.6967 - reconstruction_loss: 17209.6758 - kl_loss: 704.8005\n",
      "Epoch 1171/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18081.2937 - reconstruction_loss: 17221.6758 - kl_loss: 705.0507\n",
      "Epoch 1172/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18171.7340 - reconstruction_loss: 17251.1582 - kl_loss: 703.3747\n",
      "Epoch 1173/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18033.8666 - reconstruction_loss: 17175.8027 - kl_loss: 701.8721\n",
      "Epoch 1174/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18083.8109 - reconstruction_loss: 17215.7266 - kl_loss: 700.3099\n",
      "Epoch 1175/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18075.7200 - reconstruction_loss: 17191.8848 - kl_loss: 701.2096\n",
      "Epoch 1176/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17992.0858 - reconstruction_loss: 17135.8730 - kl_loss: 701.1060\n",
      "Epoch 1177/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18053.3333 - reconstruction_loss: 17177.6328 - kl_loss: 701.6145\n",
      "Epoch 1178/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18094.3271 - reconstruction_loss: 17172.4727 - kl_loss: 698.7555\n",
      "Epoch 1179/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17978.2255 - reconstruction_loss: 17125.7246 - kl_loss: 698.4070\n",
      "Epoch 1180/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18059.1736 - reconstruction_loss: 17180.3066 - kl_loss: 698.5805\n",
      "Epoch 1181/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18051.9107 - reconstruction_loss: 17152.5254 - kl_loss: 697.3237\n",
      "Epoch 1182/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17974.1977 - reconstruction_loss: 17126.7441 - kl_loss: 697.2870\n",
      "Epoch 1183/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18049.1084 - reconstruction_loss: 17156.9629 - kl_loss: 697.8431\n",
      "Epoch 1184/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18071.9736 - reconstruction_loss: 17153.5195 - kl_loss: 696.3846\n",
      "Epoch 1185/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17960.3851 - reconstruction_loss: 17103.1426 - kl_loss: 694.9722\n",
      "Epoch 1186/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18002.3485 - reconstruction_loss: 17115.2148 - kl_loss: 695.1328\n",
      "Epoch 1187/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17958.2470 - reconstruction_loss: 17077.4980 - kl_loss: 694.2796\n",
      "Epoch 1188/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17971.8172 - reconstruction_loss: 17103.6035 - kl_loss: 693.5492\n",
      "Epoch 1189/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17935.5857 - reconstruction_loss: 17073.1387 - kl_loss: 693.9918\n",
      "Epoch 1190/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17924.5461 - reconstruction_loss: 17050.5625 - kl_loss: 692.6833\n",
      "Epoch 1191/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17942.0456 - reconstruction_loss: 17076.6660 - kl_loss: 690.3019\n",
      "Epoch 1192/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17890.9702 - reconstruction_loss: 17030.5879 - kl_loss: 691.0685\n",
      "Epoch 1193/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17857.5426 - reconstruction_loss: 17021.6289 - kl_loss: 690.0772\n",
      "Epoch 1194/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17942.0625 - reconstruction_loss: 17080.3066 - kl_loss: 691.9918\n",
      "Epoch 1195/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17885.9498 - reconstruction_loss: 17038.2695 - kl_loss: 690.4905\n",
      "Epoch 1196/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17840.3001 - reconstruction_loss: 17000.5527 - kl_loss: 689.4889\n",
      "Epoch 1197/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17847.1090 - reconstruction_loss: 16995.0371 - kl_loss: 688.0568\n",
      "Epoch 1198/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17831.1727 - reconstruction_loss: 16958.4062 - kl_loss: 687.1273\n",
      "Epoch 1199/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17808.4634 - reconstruction_loss: 16998.6641 - kl_loss: 686.0911\n",
      "Epoch 1200/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17930.2860 - reconstruction_loss: 17051.4980 - kl_loss: 686.9910\n",
      "Epoch 1201/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17868.4193 - reconstruction_loss: 16972.7539 - kl_loss: 686.3331\n",
      "Epoch 1202/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17792.8341 - reconstruction_loss: 16969.4531 - kl_loss: 685.3263\n",
      "Epoch 1203/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18054.8124 - reconstruction_loss: 17185.9902 - kl_loss: 686.3936\n",
      "Epoch 1204/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17972.5060 - reconstruction_loss: 17060.7969 - kl_loss: 684.0947\n",
      "Epoch 1205/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18190.4917 - reconstruction_loss: 17324.6660 - kl_loss: 687.3289\n",
      "Epoch 1206/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18062.3947 - reconstruction_loss: 17123.6973 - kl_loss: 685.2211\n",
      "Epoch 1207/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17916.3425 - reconstruction_loss: 17098.3477 - kl_loss: 684.6786\n",
      "Epoch 1208/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18010.7078 - reconstruction_loss: 17197.5000 - kl_loss: 683.9290\n",
      "Epoch 1209/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17998.1097 - reconstruction_loss: 17204.2754 - kl_loss: 682.1414\n",
      "Epoch 1210/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17993.1534 - reconstruction_loss: 17148.3867 - kl_loss: 683.6843\n",
      "Epoch 1211/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17863.3887 - reconstruction_loss: 17073.8027 - kl_loss: 681.7863\n",
      "Epoch 1212/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17873.4848 - reconstruction_loss: 17052.2910 - kl_loss: 683.1268\n",
      "Epoch 1213/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17805.0230 - reconstruction_loss: 17013.1875 - kl_loss: 681.5674\n",
      "Epoch 1214/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17799.1208 - reconstruction_loss: 16993.0957 - kl_loss: 680.9135\n",
      "Epoch 1215/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17811.8256 - reconstruction_loss: 16997.0918 - kl_loss: 679.5252\n",
      "Epoch 1216/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17790.1251 - reconstruction_loss: 16952.8105 - kl_loss: 680.1660\n",
      "Epoch 1217/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17742.7970 - reconstruction_loss: 16933.2852 - kl_loss: 679.6275\n",
      "Epoch 1218/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17732.1287 - reconstruction_loss: 16930.9434 - kl_loss: 678.7729\n",
      "Epoch 1219/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17764.4406 - reconstruction_loss: 16924.5957 - kl_loss: 677.9920\n",
      "Epoch 1220/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17722.3993 - reconstruction_loss: 16922.7129 - kl_loss: 678.5356\n",
      "Epoch 1221/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17746.5570 - reconstruction_loss: 16921.5508 - kl_loss: 676.8375\n",
      "Epoch 1222/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17745.8355 - reconstruction_loss: 16921.0488 - kl_loss: 676.6614\n",
      "Epoch 1223/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17730.2600 - reconstruction_loss: 16921.6152 - kl_loss: 677.9396\n",
      "Epoch 1224/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17849.3324 - reconstruction_loss: 17009.9668 - kl_loss: 674.7772\n",
      "Epoch 1225/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17790.3366 - reconstruction_loss: 16961.1738 - kl_loss: 675.9420\n",
      "Epoch 1226/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17786.1410 - reconstruction_loss: 16948.1797 - kl_loss: 675.2302\n",
      "Epoch 1227/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17777.3553 - reconstruction_loss: 16912.6426 - kl_loss: 676.0500\n",
      "Epoch 1228/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17735.0305 - reconstruction_loss: 16900.0000 - kl_loss: 677.3022\n",
      "Epoch 1229/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17758.7322 - reconstruction_loss: 16929.0176 - kl_loss: 675.3342\n",
      "Epoch 1230/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17819.1005 - reconstruction_loss: 16994.2832 - kl_loss: 675.9427\n",
      "Epoch 1231/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17787.5585 - reconstruction_loss: 16968.7637 - kl_loss: 675.1833\n",
      "Epoch 1232/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 17819.3936 - reconstruction_loss: 17051.2988 - kl_loss: 673.2580\n",
      "Epoch 1233/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 18013.0548 - reconstruction_loss: 17257.7832 - kl_loss: 673.8945\n",
      "Epoch 1234/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18164.7469 - reconstruction_loss: 17519.5566 - kl_loss: 677.5709\n",
      "Epoch 1235/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18446.2831 - reconstruction_loss: 17612.2168 - kl_loss: 675.8884\n",
      "Epoch 1236/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 18006.2796 - reconstruction_loss: 17307.6992 - kl_loss: 674.1605\n",
      "Epoch 1237/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17993.6365 - reconstruction_loss: 17208.0215 - kl_loss: 674.1363\n",
      "Epoch 1238/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17941.6159 - reconstruction_loss: 17128.8848 - kl_loss: 672.4459\n",
      "Epoch 1239/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17878.1780 - reconstruction_loss: 17083.3867 - kl_loss: 673.0944\n",
      "Epoch 1240/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17933.2668 - reconstruction_loss: 17109.1191 - kl_loss: 673.7275\n",
      "Epoch 1241/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17917.0380 - reconstruction_loss: 17078.6504 - kl_loss: 673.2200\n",
      "Epoch 1242/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17932.5223 - reconstruction_loss: 17078.2422 - kl_loss: 673.4637\n",
      "Epoch 1243/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17951.2335 - reconstruction_loss: 17090.7266 - kl_loss: 672.0461\n",
      "Epoch 1244/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17964.3878 - reconstruction_loss: 17083.9062 - kl_loss: 671.4746\n",
      "Epoch 1245/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17933.3611 - reconstruction_loss: 17068.4043 - kl_loss: 670.4491\n",
      "Epoch 1246/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17926.2854 - reconstruction_loss: 17067.7422 - kl_loss: 670.9546\n",
      "Epoch 1247/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17941.6880 - reconstruction_loss: 17061.4316 - kl_loss: 672.3117\n",
      "Epoch 1248/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17950.0789 - reconstruction_loss: 17083.9297 - kl_loss: 672.2942\n",
      "Epoch 1249/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17991.7222 - reconstruction_loss: 17096.2676 - kl_loss: 670.3190\n",
      "Epoch 1250/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18046.9930 - reconstruction_loss: 17166.5605 - kl_loss: 671.7747\n",
      "Epoch 1251/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18215.4082 - reconstruction_loss: 17275.8711 - kl_loss: 671.9175\n",
      "Epoch 1252/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 18302.0026 - reconstruction_loss: 17365.1895 - kl_loss: 671.6305\n",
      "Epoch 1253/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18379.1889 - reconstruction_loss: 17425.1777 - kl_loss: 670.7520\n",
      "Epoch 1254/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 18381.6129 - reconstruction_loss: 17477.9902 - kl_loss: 669.7117\n",
      "Epoch 1255/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18371.9350 - reconstruction_loss: 17530.9082 - kl_loss: 670.6421\n",
      "Epoch 1256/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18715.4057 - reconstruction_loss: 17837.3770 - kl_loss: 669.5535\n",
      "Epoch 1257/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 19231.9673 - reconstruction_loss: 18127.8477 - kl_loss: 671.1274\n",
      "Epoch 1258/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19092.3408 - reconstruction_loss: 17999.7637 - kl_loss: 670.4117\n",
      "Epoch 1259/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19091.4928 - reconstruction_loss: 17915.4824 - kl_loss: 671.8990\n",
      "Epoch 1260/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 19001.5129 - reconstruction_loss: 17895.9531 - kl_loss: 670.5299\n",
      "Epoch 1261/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18528.0150 - reconstruction_loss: 17556.8828 - kl_loss: 671.0445\n",
      "Epoch 1262/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18404.4072 - reconstruction_loss: 17444.4883 - kl_loss: 672.4595\n",
      "Epoch 1263/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18155.9677 - reconstruction_loss: 17257.6211 - kl_loss: 672.5681\n",
      "Epoch 1264/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18088.1320 - reconstruction_loss: 17196.1504 - kl_loss: 671.8981\n",
      "Epoch 1265/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 18093.2586 - reconstruction_loss: 17147.5684 - kl_loss: 671.3852\n",
      "Epoch 1266/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17992.1743 - reconstruction_loss: 17090.9785 - kl_loss: 669.3750\n",
      "Epoch 1267/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17996.8210 - reconstruction_loss: 17103.5898 - kl_loss: 670.1418\n",
      "Epoch 1268/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18046.1588 - reconstruction_loss: 17090.9082 - kl_loss: 671.0497\n",
      "Epoch 1269/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17954.9760 - reconstruction_loss: 17023.7168 - kl_loss: 670.7618\n",
      "Epoch 1270/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17845.9104 - reconstruction_loss: 16950.7266 - kl_loss: 671.1393\n",
      "Epoch 1271/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17844.4454 - reconstruction_loss: 16925.9648 - kl_loss: 671.0114\n",
      "Epoch 1272/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17775.6906 - reconstruction_loss: 16882.3809 - kl_loss: 670.4987\n",
      "Epoch 1273/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17771.8969 - reconstruction_loss: 16875.2695 - kl_loss: 670.9486\n",
      "Epoch 1274/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 17731.6151 - reconstruction_loss: 16842.1484 - kl_loss: 670.5530\n",
      "Epoch 1275/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17685.9535 - reconstruction_loss: 16804.2402 - kl_loss: 669.9407\n",
      "Epoch 1276/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17659.8999 - reconstruction_loss: 16773.8047 - kl_loss: 669.4343\n",
      "Epoch 1277/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17577.5208 - reconstruction_loss: 16713.1855 - kl_loss: 668.3785\n",
      "Epoch 1278/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17594.2635 - reconstruction_loss: 16736.5527 - kl_loss: 665.6083\n",
      "Epoch 1279/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17577.2837 - reconstruction_loss: 16687.1895 - kl_loss: 667.4216\n",
      "Epoch 1280/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17530.0236 - reconstruction_loss: 16653.0703 - kl_loss: 667.3613\n",
      "Epoch 1281/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17536.2631 - reconstruction_loss: 16648.0215 - kl_loss: 667.3883\n",
      "Epoch 1282/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17481.2324 - reconstruction_loss: 16621.5781 - kl_loss: 666.5428\n",
      "Epoch 1283/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17469.4659 - reconstruction_loss: 16622.6523 - kl_loss: 665.5308\n",
      "Epoch 1284/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17449.4911 - reconstruction_loss: 16577.0488 - kl_loss: 668.4122\n",
      "Epoch 1285/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17440.9865 - reconstruction_loss: 16563.6484 - kl_loss: 666.6146\n",
      "Epoch 1286/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17398.3107 - reconstruction_loss: 16539.7168 - kl_loss: 666.0147\n",
      "Epoch 1287/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17440.8176 - reconstruction_loss: 16561.9609 - kl_loss: 667.0552\n",
      "Epoch 1288/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17378.1428 - reconstruction_loss: 16501.1855 - kl_loss: 665.6698\n",
      "Epoch 1289/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17348.8994 - reconstruction_loss: 16519.2734 - kl_loss: 664.7554\n",
      "Epoch 1290/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17337.0800 - reconstruction_loss: 16473.3789 - kl_loss: 665.9849\n",
      "Epoch 1291/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17255.9613 - reconstruction_loss: 16425.1250 - kl_loss: 665.5843\n",
      "Epoch 1292/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 17273.0228 - reconstruction_loss: 16425.9707 - kl_loss: 665.4274\n",
      "Epoch 1293/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17302.9348 - reconstruction_loss: 16432.1230 - kl_loss: 665.2730\n",
      "Epoch 1294/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17204.8905 - reconstruction_loss: 16390.1172 - kl_loss: 664.6185\n",
      "Epoch 1295/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17239.2427 - reconstruction_loss: 16396.6914 - kl_loss: 662.8765\n",
      "Epoch 1296/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17204.9372 - reconstruction_loss: 16371.8994 - kl_loss: 662.1561\n",
      "Epoch 1297/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17160.3235 - reconstruction_loss: 16334.4805 - kl_loss: 662.7946\n",
      "Epoch 1298/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17204.2285 - reconstruction_loss: 16350.6270 - kl_loss: 662.1943\n",
      "Epoch 1299/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17183.6171 - reconstruction_loss: 16333.9102 - kl_loss: 661.2781\n",
      "Epoch 1300/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17147.9863 - reconstruction_loss: 16341.6025 - kl_loss: 661.8815\n",
      "Epoch 1301/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17176.6428 - reconstruction_loss: 16314.2363 - kl_loss: 662.8046\n",
      "Epoch 1302/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17106.3532 - reconstruction_loss: 16278.7900 - kl_loss: 662.3712\n",
      "Epoch 1303/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17070.1647 - reconstruction_loss: 16255.5254 - kl_loss: 661.4474\n",
      "Epoch 1304/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17100.6995 - reconstruction_loss: 16249.9668 - kl_loss: 660.5419\n",
      "Epoch 1305/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17061.2936 - reconstruction_loss: 16243.2334 - kl_loss: 660.0905\n",
      "Epoch 1306/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17057.1617 - reconstruction_loss: 16230.8984 - kl_loss: 659.8615\n",
      "Epoch 1307/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17055.8928 - reconstruction_loss: 16233.4355 - kl_loss: 658.9945\n",
      "Epoch 1308/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16970.2310 - reconstruction_loss: 16171.9756 - kl_loss: 659.2270\n",
      "Epoch 1309/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16998.0517 - reconstruction_loss: 16174.7686 - kl_loss: 658.6667\n",
      "Epoch 1310/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17013.5378 - reconstruction_loss: 16194.8008 - kl_loss: 658.0223\n",
      "Epoch 1311/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16989.7141 - reconstruction_loss: 16186.2695 - kl_loss: 658.1750\n",
      "Epoch 1312/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16958.9055 - reconstruction_loss: 16159.8535 - kl_loss: 657.3022\n",
      "Epoch 1313/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16943.7134 - reconstruction_loss: 16154.6836 - kl_loss: 657.3074\n",
      "Epoch 1314/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16934.1603 - reconstruction_loss: 16136.4258 - kl_loss: 657.7253\n",
      "Epoch 1315/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16922.8157 - reconstruction_loss: 16122.0791 - kl_loss: 655.7564\n",
      "Epoch 1316/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16880.4424 - reconstruction_loss: 16098.7441 - kl_loss: 653.7587\n",
      "Epoch 1317/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16943.9436 - reconstruction_loss: 16141.9883 - kl_loss: 653.0850\n",
      "Epoch 1318/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16944.7657 - reconstruction_loss: 16140.9141 - kl_loss: 654.1636\n",
      "Epoch 1319/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16892.7782 - reconstruction_loss: 16104.1680 - kl_loss: 654.4222\n",
      "Epoch 1320/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17047.7714 - reconstruction_loss: 16195.8691 - kl_loss: 654.0396\n",
      "Epoch 1321/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17171.7039 - reconstruction_loss: 16264.9287 - kl_loss: 652.6996\n",
      "Epoch 1322/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17008.4466 - reconstruction_loss: 16192.1865 - kl_loss: 653.5376\n",
      "Epoch 1323/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 17129.8952 - reconstruction_loss: 16246.6240 - kl_loss: 650.8625\n",
      "Epoch 1324/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17084.2160 - reconstruction_loss: 16185.4707 - kl_loss: 653.9048\n",
      "Epoch 1325/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16820.4494 - reconstruction_loss: 16046.5293 - kl_loss: 651.6863\n",
      "Epoch 1326/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16824.3912 - reconstruction_loss: 16039.6143 - kl_loss: 649.7014\n",
      "Epoch 1327/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16843.3482 - reconstruction_loss: 16039.1572 - kl_loss: 650.0283\n",
      "Epoch 1328/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16768.9481 - reconstruction_loss: 16011.8271 - kl_loss: 648.2803\n",
      "Epoch 1329/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16793.5621 - reconstruction_loss: 16025.3359 - kl_loss: 650.7336\n",
      "Epoch 1330/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16776.0226 - reconstruction_loss: 15989.7490 - kl_loss: 649.5637\n",
      "Epoch 1331/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16757.1645 - reconstruction_loss: 16008.4580 - kl_loss: 648.2189\n",
      "Epoch 1332/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16820.6656 - reconstruction_loss: 16024.3750 - kl_loss: 648.1124\n",
      "Epoch 1333/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16759.0470 - reconstruction_loss: 15982.1514 - kl_loss: 646.7496\n",
      "Epoch 1334/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16713.0204 - reconstruction_loss: 15953.4756 - kl_loss: 645.6470\n",
      "Epoch 1335/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16738.4011 - reconstruction_loss: 15966.6807 - kl_loss: 645.5005\n",
      "Epoch 1336/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16712.3391 - reconstruction_loss: 15948.4766 - kl_loss: 644.9939\n",
      "Epoch 1337/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16732.3579 - reconstruction_loss: 15961.1172 - kl_loss: 643.7294\n",
      "Epoch 1338/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16802.3907 - reconstruction_loss: 15991.8506 - kl_loss: 645.8017\n",
      "Epoch 1339/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16706.5927 - reconstruction_loss: 15946.1504 - kl_loss: 645.3453\n",
      "Epoch 1340/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16713.1028 - reconstruction_loss: 15952.3789 - kl_loss: 643.1884\n",
      "Epoch 1341/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16749.9947 - reconstruction_loss: 15958.6914 - kl_loss: 643.7744\n",
      "Epoch 1342/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16667.6595 - reconstruction_loss: 15925.1748 - kl_loss: 643.1502\n",
      "Epoch 1343/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16750.8630 - reconstruction_loss: 15960.8896 - kl_loss: 643.5433\n",
      "Epoch 1344/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16840.2445 - reconstruction_loss: 16018.3604 - kl_loss: 640.8113\n",
      "Epoch 1345/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16688.9868 - reconstruction_loss: 15930.6953 - kl_loss: 642.0697\n",
      "Epoch 1346/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16719.2591 - reconstruction_loss: 15947.5615 - kl_loss: 641.7901\n",
      "Epoch 1347/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16656.5859 - reconstruction_loss: 15898.9229 - kl_loss: 639.0020\n",
      "Epoch 1348/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16653.4303 - reconstruction_loss: 15907.0449 - kl_loss: 639.5995\n",
      "Epoch 1349/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16687.0054 - reconstruction_loss: 15899.3359 - kl_loss: 637.8064\n",
      "Epoch 1350/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 16668.2508 - reconstruction_loss: 15895.4326 - kl_loss: 637.3979\n",
      "Epoch 1351/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16712.6571 - reconstruction_loss: 15937.9805 - kl_loss: 636.4008\n",
      "Epoch 1352/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16719.5214 - reconstruction_loss: 15918.8760 - kl_loss: 638.5201\n",
      "Epoch 1353/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16641.1762 - reconstruction_loss: 15877.6865 - kl_loss: 636.2109\n",
      "Epoch 1354/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16706.1561 - reconstruction_loss: 15926.7949 - kl_loss: 636.6608\n",
      "Epoch 1355/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16715.9319 - reconstruction_loss: 15903.2852 - kl_loss: 638.2197\n",
      "Epoch 1356/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16602.0390 - reconstruction_loss: 15854.4941 - kl_loss: 636.2006\n",
      "Epoch 1357/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16647.7903 - reconstruction_loss: 15893.3252 - kl_loss: 635.9086\n",
      "Epoch 1358/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16609.5336 - reconstruction_loss: 15848.7500 - kl_loss: 634.9929\n",
      "Epoch 1359/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16624.4972 - reconstruction_loss: 15861.7725 - kl_loss: 635.2134\n",
      "Epoch 1360/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16742.6504 - reconstruction_loss: 15939.5986 - kl_loss: 634.1084\n",
      "Epoch 1361/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16705.2782 - reconstruction_loss: 15932.9834 - kl_loss: 634.2974\n",
      "Epoch 1362/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16701.5812 - reconstruction_loss: 15979.1699 - kl_loss: 633.5325\n",
      "Epoch 1363/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16973.5574 - reconstruction_loss: 16118.2754 - kl_loss: 634.8922\n",
      "Epoch 1364/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16979.7506 - reconstruction_loss: 16122.2998 - kl_loss: 635.0652\n",
      "Epoch 1365/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16871.6857 - reconstruction_loss: 16074.9375 - kl_loss: 633.1632\n",
      "Epoch 1366/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16781.7517 - reconstruction_loss: 15970.5537 - kl_loss: 632.7661\n",
      "Epoch 1367/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16738.7883 - reconstruction_loss: 15994.8936 - kl_loss: 631.7310\n",
      "Epoch 1368/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16745.5599 - reconstruction_loss: 15981.7207 - kl_loss: 632.4479\n",
      "Epoch 1369/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16703.3630 - reconstruction_loss: 15954.3994 - kl_loss: 632.3191\n",
      "Epoch 1370/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16723.6883 - reconstruction_loss: 16014.2539 - kl_loss: 632.8574\n",
      "Epoch 1371/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16739.3202 - reconstruction_loss: 16041.3262 - kl_loss: 630.8987\n",
      "Epoch 1372/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16758.4759 - reconstruction_loss: 16007.2227 - kl_loss: 632.5673\n",
      "Epoch 1373/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16916.3414 - reconstruction_loss: 16111.7480 - kl_loss: 630.8146\n",
      "Epoch 1374/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16851.9529 - reconstruction_loss: 16083.3916 - kl_loss: 630.2429\n",
      "Epoch 1375/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16798.5671 - reconstruction_loss: 16073.0498 - kl_loss: 629.9980\n",
      "Epoch 1376/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 17100.5430 - reconstruction_loss: 16275.3799 - kl_loss: 631.8976\n",
      "Epoch 1377/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16989.7018 - reconstruction_loss: 16267.9854 - kl_loss: 629.5566\n",
      "Epoch 1378/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16986.9191 - reconstruction_loss: 16268.0332 - kl_loss: 630.8529\n",
      "Epoch 1379/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16942.5480 - reconstruction_loss: 16165.5820 - kl_loss: 629.3630\n",
      "Epoch 1380/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16872.7485 - reconstruction_loss: 16093.0342 - kl_loss: 630.2288\n",
      "Epoch 1381/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16859.7665 - reconstruction_loss: 16067.2471 - kl_loss: 629.2226\n",
      "Epoch 1382/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16874.1785 - reconstruction_loss: 16052.8467 - kl_loss: 631.3231\n",
      "Epoch 1383/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16843.7804 - reconstruction_loss: 16051.2236 - kl_loss: 628.8969\n",
      "Epoch 1384/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16913.8347 - reconstruction_loss: 16099.8613 - kl_loss: 628.4725\n",
      "Epoch 1385/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16839.2748 - reconstruction_loss: 16039.9238 - kl_loss: 629.1495\n",
      "Epoch 1386/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16873.2479 - reconstruction_loss: 16057.3691 - kl_loss: 629.4207\n",
      "Epoch 1387/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16784.0675 - reconstruction_loss: 15988.3613 - kl_loss: 628.5230\n",
      "Epoch 1388/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16784.5320 - reconstruction_loss: 15994.1689 - kl_loss: 627.5625\n",
      "Epoch 1389/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16857.9145 - reconstruction_loss: 16010.3926 - kl_loss: 629.9719\n",
      "Epoch 1390/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16789.7790 - reconstruction_loss: 15971.9316 - kl_loss: 628.8470\n",
      "Epoch 1391/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16708.1413 - reconstruction_loss: 15928.0420 - kl_loss: 627.9151\n",
      "Epoch 1392/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16787.0362 - reconstruction_loss: 15962.8096 - kl_loss: 628.6738\n",
      "Epoch 1393/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16674.3195 - reconstruction_loss: 15910.1729 - kl_loss: 627.1945\n",
      "Epoch 1394/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16722.6132 - reconstruction_loss: 15926.2217 - kl_loss: 627.5757\n",
      "Epoch 1395/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16709.7679 - reconstruction_loss: 15904.4795 - kl_loss: 627.9531\n",
      "Epoch 1396/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16669.1852 - reconstruction_loss: 15878.2197 - kl_loss: 626.8545\n",
      "Epoch 1397/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16645.2029 - reconstruction_loss: 15878.7832 - kl_loss: 627.3844\n",
      "Epoch 1398/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16617.8763 - reconstruction_loss: 15818.9746 - kl_loss: 628.2764\n",
      "Epoch 1399/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16527.0665 - reconstruction_loss: 15767.8789 - kl_loss: 625.3496\n",
      "Epoch 1400/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16593.0363 - reconstruction_loss: 15800.9707 - kl_loss: 625.8430\n",
      "Epoch 1401/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16540.0801 - reconstruction_loss: 15760.4512 - kl_loss: 626.4475\n",
      "Epoch 1402/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16534.6259 - reconstruction_loss: 15749.7236 - kl_loss: 624.6870\n",
      "Epoch 1403/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16535.6284 - reconstruction_loss: 15739.6260 - kl_loss: 626.5007\n",
      "Epoch 1404/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16464.4484 - reconstruction_loss: 15696.7939 - kl_loss: 624.7214\n",
      "Epoch 1405/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 16473.9068 - reconstruction_loss: 15697.0703 - kl_loss: 624.3198\n",
      "Epoch 1406/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 16446.7940 - reconstruction_loss: 15677.0879 - kl_loss: 623.1839\n",
      "Epoch 1407/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16440.1862 - reconstruction_loss: 15681.6240 - kl_loss: 624.4513\n",
      "Epoch 1408/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 16439.1036 - reconstruction_loss: 15669.0791 - kl_loss: 624.7459\n",
      "Epoch 1409/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 16429.2252 - reconstruction_loss: 15646.2012 - kl_loss: 624.3273\n",
      "Epoch 1410/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16383.1192 - reconstruction_loss: 15626.3184 - kl_loss: 623.2855\n",
      "Epoch 1411/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16344.5301 - reconstruction_loss: 15590.9922 - kl_loss: 624.0930\n",
      "Epoch 1412/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16324.9528 - reconstruction_loss: 15582.5312 - kl_loss: 622.4395\n",
      "Epoch 1413/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16338.4239 - reconstruction_loss: 15588.6807 - kl_loss: 622.8254\n",
      "Epoch 1414/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16376.5864 - reconstruction_loss: 15599.5049 - kl_loss: 621.0074\n",
      "Epoch 1415/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16314.7169 - reconstruction_loss: 15576.2188 - kl_loss: 622.4064\n",
      "Epoch 1416/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16329.4902 - reconstruction_loss: 15564.5830 - kl_loss: 621.1757\n",
      "Epoch 1417/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16271.4115 - reconstruction_loss: 15521.7764 - kl_loss: 622.0958\n",
      "Epoch 1418/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16278.1215 - reconstruction_loss: 15549.3652 - kl_loss: 622.2606\n",
      "Epoch 1419/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16455.0253 - reconstruction_loss: 15626.4326 - kl_loss: 621.8863\n",
      "Epoch 1420/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16295.1963 - reconstruction_loss: 15542.0146 - kl_loss: 619.7906\n",
      "Epoch 1421/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16298.9060 - reconstruction_loss: 15562.6855 - kl_loss: 619.3721\n",
      "Epoch 1422/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16312.5318 - reconstruction_loss: 15528.9336 - kl_loss: 619.2343\n",
      "Epoch 1423/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16223.7736 - reconstruction_loss: 15517.9033 - kl_loss: 619.1029\n",
      "Epoch 1424/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16401.7782 - reconstruction_loss: 15600.6006 - kl_loss: 618.8377\n",
      "Epoch 1425/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16284.8389 - reconstruction_loss: 15518.0684 - kl_loss: 619.4994\n",
      "Epoch 1426/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16238.3059 - reconstruction_loss: 15494.5781 - kl_loss: 618.4158\n",
      "Epoch 1427/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16262.2838 - reconstruction_loss: 15500.0039 - kl_loss: 619.9260\n",
      "Epoch 1428/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16222.0211 - reconstruction_loss: 15458.5117 - kl_loss: 617.2103\n",
      "Epoch 1429/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16284.9338 - reconstruction_loss: 15514.8496 - kl_loss: 617.0039\n",
      "Epoch 1430/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16270.9811 - reconstruction_loss: 15498.5957 - kl_loss: 617.9182\n",
      "Epoch 1431/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16151.2968 - reconstruction_loss: 15438.6123 - kl_loss: 616.4370\n",
      "Epoch 1432/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16196.8037 - reconstruction_loss: 15453.2461 - kl_loss: 617.2012\n",
      "Epoch 1433/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16171.4403 - reconstruction_loss: 15436.0059 - kl_loss: 617.6054\n",
      "Epoch 1434/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16179.9774 - reconstruction_loss: 15441.5391 - kl_loss: 615.4147\n",
      "Epoch 1435/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16236.4190 - reconstruction_loss: 15479.7236 - kl_loss: 617.0717\n",
      "Epoch 1436/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16155.0108 - reconstruction_loss: 15427.5332 - kl_loss: 616.8098\n",
      "Epoch 1437/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16183.5625 - reconstruction_loss: 15427.6523 - kl_loss: 614.8976\n",
      "Epoch 1438/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16142.3357 - reconstruction_loss: 15408.0000 - kl_loss: 614.3361\n",
      "Epoch 1439/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16109.8129 - reconstruction_loss: 15387.1143 - kl_loss: 614.5579\n",
      "Epoch 1440/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16188.5771 - reconstruction_loss: 15445.3623 - kl_loss: 613.2838\n",
      "Epoch 1441/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 16187.7186 - reconstruction_loss: 15436.9502 - kl_loss: 612.3795\n",
      "Epoch 1442/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16144.0422 - reconstruction_loss: 15436.9834 - kl_loss: 612.5959\n",
      "Epoch 1443/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16164.3855 - reconstruction_loss: 15423.3711 - kl_loss: 613.6910\n",
      "Epoch 1444/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16098.7317 - reconstruction_loss: 15373.2207 - kl_loss: 611.0016\n",
      "Epoch 1445/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16236.5477 - reconstruction_loss: 15478.6191 - kl_loss: 611.3753\n",
      "Epoch 1446/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16156.3841 - reconstruction_loss: 15393.4316 - kl_loss: 613.1530\n",
      "Epoch 1447/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16133.2597 - reconstruction_loss: 15395.0703 - kl_loss: 612.1874\n",
      "Epoch 1448/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16159.3599 - reconstruction_loss: 15427.0635 - kl_loss: 610.4068\n",
      "Epoch 1449/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16106.9176 - reconstruction_loss: 15384.7148 - kl_loss: 610.1486\n",
      "Epoch 1450/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16096.0155 - reconstruction_loss: 15365.8633 - kl_loss: 610.4209\n",
      "Epoch 1451/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 16153.7052 - reconstruction_loss: 15414.6523 - kl_loss: 609.3894\n",
      "Epoch 1452/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 16148.5495 - reconstruction_loss: 15423.1572 - kl_loss: 611.6085\n",
      "Epoch 1453/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 16087.7064 - reconstruction_loss: 15368.0859 - kl_loss: 609.1208\n",
      "Epoch 1454/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 16076.8191 - reconstruction_loss: 15384.3252 - kl_loss: 608.6518\n",
      "Epoch 1455/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 16175.6478 - reconstruction_loss: 15426.3066 - kl_loss: 607.1297\n",
      "Epoch 1456/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16127.6721 - reconstruction_loss: 15407.6025 - kl_loss: 607.3943\n",
      "Epoch 1457/5000\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 16174.4322 - reconstruction_loss: 15469.8906 - kl_loss: 607.8830\n",
      "Epoch 1458/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 16200.5628 - reconstruction_loss: 15475.5781 - kl_loss: 607.5377\n",
      "Epoch 1459/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16200.7038 - reconstruction_loss: 15485.4727 - kl_loss: 609.0561\n",
      "Epoch 1460/5000\n",
      "75/75 [==============================] - 2s 32ms/step - loss: 16301.3518 - reconstruction_loss: 15570.5771 - kl_loss: 608.4641\n",
      "Epoch 1461/5000\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 16331.3394 - reconstruction_loss: 15536.7285 - kl_loss: 606.0754\n",
      "Epoch 1462/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16212.0757 - reconstruction_loss: 15509.6543 - kl_loss: 607.4789\n",
      "Epoch 1463/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16206.4533 - reconstruction_loss: 15466.0459 - kl_loss: 607.1282\n",
      "Epoch 1464/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16158.8972 - reconstruction_loss: 15443.5449 - kl_loss: 606.7045\n",
      "Epoch 1465/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16105.9697 - reconstruction_loss: 15378.0293 - kl_loss: 604.8613\n",
      "Epoch 1466/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16112.8543 - reconstruction_loss: 15379.8945 - kl_loss: 604.2670\n",
      "Epoch 1467/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16095.3336 - reconstruction_loss: 15349.5117 - kl_loss: 605.4636\n",
      "Epoch 1468/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16052.2889 - reconstruction_loss: 15349.4229 - kl_loss: 605.4594\n",
      "Epoch 1469/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16111.5374 - reconstruction_loss: 15379.1104 - kl_loss: 604.1218\n",
      "Epoch 1470/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16022.6701 - reconstruction_loss: 15324.1992 - kl_loss: 603.7298\n",
      "Epoch 1471/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 16026.8074 - reconstruction_loss: 15319.8027 - kl_loss: 604.0712\n",
      "Epoch 1472/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 16056.2917 - reconstruction_loss: 15316.1016 - kl_loss: 603.0825\n",
      "Epoch 1473/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16051.6228 - reconstruction_loss: 15334.5361 - kl_loss: 602.8934\n",
      "Epoch 1474/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16049.7746 - reconstruction_loss: 15302.6123 - kl_loss: 603.3676\n",
      "Epoch 1475/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15996.4921 - reconstruction_loss: 15283.8760 - kl_loss: 602.3093\n",
      "Epoch 1476/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16000.8437 - reconstruction_loss: 15283.1699 - kl_loss: 602.4592\n",
      "Epoch 1477/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15989.7671 - reconstruction_loss: 15283.1514 - kl_loss: 601.1484\n",
      "Epoch 1478/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15963.5802 - reconstruction_loss: 15262.8154 - kl_loss: 602.3276\n",
      "Epoch 1479/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 16084.7943 - reconstruction_loss: 15327.6016 - kl_loss: 600.7601\n",
      "Epoch 1480/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 16077.1369 - reconstruction_loss: 15310.4287 - kl_loss: 601.1860\n",
      "Epoch 1481/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15984.7626 - reconstruction_loss: 15300.2920 - kl_loss: 600.9857\n",
      "Epoch 1482/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16141.6751 - reconstruction_loss: 15358.7598 - kl_loss: 601.6093\n",
      "Epoch 1483/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16006.0089 - reconstruction_loss: 15294.2148 - kl_loss: 600.2994\n",
      "Epoch 1484/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16041.4049 - reconstruction_loss: 15325.4727 - kl_loss: 600.3703\n",
      "Epoch 1485/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16184.8987 - reconstruction_loss: 15366.3867 - kl_loss: 601.5831\n",
      "Epoch 1486/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16082.0113 - reconstruction_loss: 15340.1406 - kl_loss: 598.7995\n",
      "Epoch 1487/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16067.7827 - reconstruction_loss: 15328.6660 - kl_loss: 599.3358\n",
      "Epoch 1488/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16021.5756 - reconstruction_loss: 15289.3057 - kl_loss: 599.4690\n",
      "Epoch 1489/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16020.2161 - reconstruction_loss: 15317.2656 - kl_loss: 600.1583\n",
      "Epoch 1490/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16174.6566 - reconstruction_loss: 15414.8760 - kl_loss: 600.1088\n",
      "Epoch 1491/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16150.6251 - reconstruction_loss: 15431.0830 - kl_loss: 598.7336\n",
      "Epoch 1492/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16162.3587 - reconstruction_loss: 15438.0361 - kl_loss: 598.1274\n",
      "Epoch 1493/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16185.1640 - reconstruction_loss: 15435.7988 - kl_loss: 599.2102\n",
      "Epoch 1494/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16147.0318 - reconstruction_loss: 15443.5469 - kl_loss: 597.9169\n",
      "Epoch 1495/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16219.9688 - reconstruction_loss: 15459.5146 - kl_loss: 598.5954\n",
      "Epoch 1496/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16414.5770 - reconstruction_loss: 15620.9199 - kl_loss: 597.5364\n",
      "Epoch 1497/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16412.8218 - reconstruction_loss: 15656.4893 - kl_loss: 597.6986\n",
      "Epoch 1498/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16380.7336 - reconstruction_loss: 15669.7305 - kl_loss: 597.0533\n",
      "Epoch 1499/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16398.4824 - reconstruction_loss: 15644.7109 - kl_loss: 597.9864\n",
      "Epoch 1500/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16381.4482 - reconstruction_loss: 15589.8311 - kl_loss: 598.4585\n",
      "Epoch 1501/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16257.7764 - reconstruction_loss: 15551.4443 - kl_loss: 597.3752\n",
      "Epoch 1502/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16290.6877 - reconstruction_loss: 15577.9111 - kl_loss: 595.2985\n",
      "Epoch 1503/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16371.9638 - reconstruction_loss: 15656.0791 - kl_loss: 596.6880\n",
      "Epoch 1504/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16348.4268 - reconstruction_loss: 15649.8291 - kl_loss: 597.0060\n",
      "Epoch 1505/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16341.2674 - reconstruction_loss: 15601.9834 - kl_loss: 596.9398\n",
      "Epoch 1506/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16298.1532 - reconstruction_loss: 15544.0469 - kl_loss: 597.0682\n",
      "Epoch 1507/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16273.5185 - reconstruction_loss: 15525.5029 - kl_loss: 598.0749\n",
      "Epoch 1508/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16268.0471 - reconstruction_loss: 15525.6787 - kl_loss: 597.4011\n",
      "Epoch 1509/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16285.9155 - reconstruction_loss: 15556.0156 - kl_loss: 595.5292\n",
      "Epoch 1510/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16254.3169 - reconstruction_loss: 15540.8691 - kl_loss: 595.9739\n",
      "Epoch 1511/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16306.9430 - reconstruction_loss: 15583.1641 - kl_loss: 596.9614\n",
      "Epoch 1512/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16320.2665 - reconstruction_loss: 15651.8105 - kl_loss: 595.9224\n",
      "Epoch 1513/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16479.8560 - reconstruction_loss: 15801.9814 - kl_loss: 595.4119\n",
      "Epoch 1514/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16558.1513 - reconstruction_loss: 15902.0488 - kl_loss: 594.9039\n",
      "Epoch 1515/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16670.3520 - reconstruction_loss: 15951.9326 - kl_loss: 596.4124\n",
      "Epoch 1516/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16743.5057 - reconstruction_loss: 15989.7744 - kl_loss: 595.5826\n",
      "Epoch 1517/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 17179.9557 - reconstruction_loss: 16392.7949 - kl_loss: 594.2571\n",
      "Epoch 1518/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18342.9529 - reconstruction_loss: 17573.0195 - kl_loss: 594.9022\n",
      "Epoch 1519/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 18413.1708 - reconstruction_loss: 17725.8594 - kl_loss: 595.9726\n",
      "Epoch 1520/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17180.8845 - reconstruction_loss: 16680.4062 - kl_loss: 596.9062\n",
      "Epoch 1521/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16879.1238 - reconstruction_loss: 16283.2471 - kl_loss: 596.7046\n",
      "Epoch 1522/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 16775.6495 - reconstruction_loss: 16151.7949 - kl_loss: 595.3902\n",
      "Epoch 1523/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 16727.9185 - reconstruction_loss: 16028.4160 - kl_loss: 596.9490\n",
      "Epoch 1524/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16625.9111 - reconstruction_loss: 15914.1807 - kl_loss: 597.8325\n",
      "Epoch 1525/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16579.0527 - reconstruction_loss: 15859.0254 - kl_loss: 596.7786\n",
      "Epoch 1526/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16560.3930 - reconstruction_loss: 15830.3428 - kl_loss: 596.1138\n",
      "Epoch 1527/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16558.2777 - reconstruction_loss: 15801.6104 - kl_loss: 596.8702\n",
      "Epoch 1528/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 16463.6569 - reconstruction_loss: 15748.7178 - kl_loss: 595.8376\n",
      "Epoch 1529/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16457.7934 - reconstruction_loss: 15711.6201 - kl_loss: 595.6716\n",
      "Epoch 1530/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 16382.9829 - reconstruction_loss: 15674.8281 - kl_loss: 597.4495\n",
      "Epoch 1531/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 16433.8578 - reconstruction_loss: 15685.3535 - kl_loss: 598.2504\n",
      "Epoch 1532/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16402.4918 - reconstruction_loss: 15644.6201 - kl_loss: 597.4681\n",
      "Epoch 1533/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16316.0619 - reconstruction_loss: 15595.8682 - kl_loss: 596.4202\n",
      "Epoch 1534/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16313.1038 - reconstruction_loss: 15576.3145 - kl_loss: 597.0416\n",
      "Epoch 1535/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16289.7625 - reconstruction_loss: 15564.4404 - kl_loss: 598.0522\n",
      "Epoch 1536/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16260.2772 - reconstruction_loss: 15524.0244 - kl_loss: 597.5369\n",
      "Epoch 1537/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 16234.6035 - reconstruction_loss: 15527.2158 - kl_loss: 597.7847\n",
      "Epoch 1538/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 16239.3149 - reconstruction_loss: 15495.2871 - kl_loss: 597.8820\n",
      "Epoch 1539/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16179.3516 - reconstruction_loss: 15472.5977 - kl_loss: 597.9284\n",
      "Epoch 1540/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16218.6678 - reconstruction_loss: 15478.0352 - kl_loss: 598.2306\n",
      "Epoch 1541/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16147.9697 - reconstruction_loss: 15432.4951 - kl_loss: 597.7476\n",
      "Epoch 1542/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16159.8262 - reconstruction_loss: 15434.0303 - kl_loss: 595.4946\n",
      "Epoch 1543/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16090.9444 - reconstruction_loss: 15390.0166 - kl_loss: 596.0371\n",
      "Epoch 1544/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 16138.7912 - reconstruction_loss: 15417.6387 - kl_loss: 596.4934\n",
      "Epoch 1545/5000\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 16100.1900 - reconstruction_loss: 15376.0957 - kl_loss: 596.2461\n",
      "Epoch 1546/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16117.6271 - reconstruction_loss: 15375.9258 - kl_loss: 596.6459\n",
      "Epoch 1547/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16053.6888 - reconstruction_loss: 15329.3477 - kl_loss: 595.8129\n",
      "Epoch 1548/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 16065.7591 - reconstruction_loss: 15343.3574 - kl_loss: 595.6024\n",
      "Epoch 1549/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16029.6716 - reconstruction_loss: 15302.0791 - kl_loss: 595.2771\n",
      "Epoch 1550/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 16042.5534 - reconstruction_loss: 15333.8447 - kl_loss: 593.3201\n",
      "Epoch 1551/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 16114.6229 - reconstruction_loss: 15334.6826 - kl_loss: 595.3083\n",
      "Epoch 1552/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15998.6569 - reconstruction_loss: 15262.9346 - kl_loss: 594.6852\n",
      "Epoch 1553/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16007.8449 - reconstruction_loss: 15266.1436 - kl_loss: 595.2797\n",
      "Epoch 1554/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15935.0857 - reconstruction_loss: 15208.9990 - kl_loss: 595.7783\n",
      "Epoch 1555/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15937.8880 - reconstruction_loss: 15212.1064 - kl_loss: 595.2385\n",
      "Epoch 1556/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15920.1722 - reconstruction_loss: 15186.1719 - kl_loss: 595.1347\n",
      "Epoch 1557/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15925.5717 - reconstruction_loss: 15181.4580 - kl_loss: 593.6275\n",
      "Epoch 1558/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 15873.7040 - reconstruction_loss: 15158.5615 - kl_loss: 594.2064\n",
      "Epoch 1559/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 15892.3285 - reconstruction_loss: 15147.7598 - kl_loss: 594.8884\n",
      "Epoch 1560/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15855.4285 - reconstruction_loss: 15121.5010 - kl_loss: 593.4099\n",
      "Epoch 1561/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15874.5060 - reconstruction_loss: 15127.7510 - kl_loss: 593.4284\n",
      "Epoch 1562/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 15812.1254 - reconstruction_loss: 15081.0264 - kl_loss: 593.3391\n",
      "Epoch 1563/5000\n",
      "75/75 [==============================] - 2s 33ms/step - loss: 15859.3770 - reconstruction_loss: 15094.6104 - kl_loss: 593.5026\n",
      "Epoch 1564/5000\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 15748.8437 - reconstruction_loss: 15035.6943 - kl_loss: 593.5157\n",
      "Epoch 1565/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15751.5919 - reconstruction_loss: 15028.9414 - kl_loss: 593.3380\n",
      "Epoch 1566/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15764.8592 - reconstruction_loss: 15018.3047 - kl_loss: 594.0772\n",
      "Epoch 1567/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15748.2996 - reconstruction_loss: 15003.7246 - kl_loss: 592.9868\n",
      "Epoch 1568/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15709.8603 - reconstruction_loss: 14987.2607 - kl_loss: 593.3943\n",
      "Epoch 1569/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15746.9393 - reconstruction_loss: 14988.4941 - kl_loss: 593.2796\n",
      "Epoch 1570/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 15670.6342 - reconstruction_loss: 14950.7754 - kl_loss: 591.3746\n",
      "Epoch 1571/5000\n",
      "75/75 [==============================] - 3s 35ms/step - loss: 15675.5678 - reconstruction_loss: 14946.9912 - kl_loss: 591.6777\n",
      "Epoch 1572/5000\n",
      "75/75 [==============================] - 2s 31ms/step - loss: 15663.2624 - reconstruction_loss: 14935.4014 - kl_loss: 591.5159\n",
      "Epoch 1573/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15647.4946 - reconstruction_loss: 14924.1611 - kl_loss: 591.4874\n",
      "Epoch 1574/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15658.9104 - reconstruction_loss: 14916.3486 - kl_loss: 591.5980\n",
      "Epoch 1575/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15601.9987 - reconstruction_loss: 14876.4805 - kl_loss: 591.3516\n",
      "Epoch 1576/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15681.2260 - reconstruction_loss: 14928.7686 - kl_loss: 591.3771\n",
      "Epoch 1577/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15689.6904 - reconstruction_loss: 14895.3174 - kl_loss: 592.4515\n",
      "Epoch 1578/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15608.5149 - reconstruction_loss: 14869.7256 - kl_loss: 590.7480\n",
      "Epoch 1579/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15613.6550 - reconstruction_loss: 14883.2471 - kl_loss: 591.4234\n",
      "Epoch 1580/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15536.9965 - reconstruction_loss: 14818.7910 - kl_loss: 590.7381\n",
      "Epoch 1581/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15540.9227 - reconstruction_loss: 14818.0430 - kl_loss: 590.2023\n",
      "Epoch 1582/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15598.2875 - reconstruction_loss: 14830.5986 - kl_loss: 589.5378\n",
      "Epoch 1583/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15497.3357 - reconstruction_loss: 14774.8057 - kl_loss: 590.2009\n",
      "Epoch 1584/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15532.9927 - reconstruction_loss: 14793.9395 - kl_loss: 590.1744\n",
      "Epoch 1585/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15506.1765 - reconstruction_loss: 14775.9541 - kl_loss: 589.1312\n",
      "Epoch 1586/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15471.0002 - reconstruction_loss: 14758.1221 - kl_loss: 588.0148\n",
      "Epoch 1587/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15505.7511 - reconstruction_loss: 14751.1182 - kl_loss: 589.3963\n",
      "Epoch 1588/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15450.8812 - reconstruction_loss: 14732.6650 - kl_loss: 588.7286\n",
      "Epoch 1589/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15512.3175 - reconstruction_loss: 14759.0410 - kl_loss: 587.7420\n",
      "Epoch 1590/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15437.5749 - reconstruction_loss: 14720.4629 - kl_loss: 588.5812\n",
      "Epoch 1591/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15398.7074 - reconstruction_loss: 14692.6416 - kl_loss: 587.6388\n",
      "Epoch 1592/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15444.4327 - reconstruction_loss: 14709.1992 - kl_loss: 587.7889\n",
      "Epoch 1593/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15355.2356 - reconstruction_loss: 14657.7275 - kl_loss: 587.8773\n",
      "Epoch 1594/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15420.7508 - reconstruction_loss: 14682.1182 - kl_loss: 587.3993\n",
      "Epoch 1595/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15423.7750 - reconstruction_loss: 14690.5605 - kl_loss: 587.6416\n",
      "Epoch 1596/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15404.9669 - reconstruction_loss: 14693.5439 - kl_loss: 586.1243\n",
      "Epoch 1597/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15435.4467 - reconstruction_loss: 14669.7910 - kl_loss: 585.6179\n",
      "Epoch 1598/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15348.2342 - reconstruction_loss: 14629.0186 - kl_loss: 585.2431\n",
      "Epoch 1599/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15415.7135 - reconstruction_loss: 14664.4355 - kl_loss: 585.4072\n",
      "Epoch 1600/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15375.8800 - reconstruction_loss: 14637.7490 - kl_loss: 585.3373\n",
      "Epoch 1601/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15335.4558 - reconstruction_loss: 14634.2949 - kl_loss: 586.1813\n",
      "Epoch 1602/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15361.3051 - reconstruction_loss: 14608.9521 - kl_loss: 585.6085\n",
      "Epoch 1603/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15296.9045 - reconstruction_loss: 14605.7148 - kl_loss: 583.1582\n",
      "Epoch 1604/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15304.8769 - reconstruction_loss: 14598.2705 - kl_loss: 584.3761\n",
      "Epoch 1605/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 15271.9216 - reconstruction_loss: 14575.6924 - kl_loss: 584.2977\n",
      "Epoch 1606/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15300.2736 - reconstruction_loss: 14576.3564 - kl_loss: 585.0044\n",
      "Epoch 1607/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15285.3220 - reconstruction_loss: 14579.0977 - kl_loss: 584.1956\n",
      "Epoch 1608/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15275.1034 - reconstruction_loss: 14552.6279 - kl_loss: 584.6417\n",
      "Epoch 1609/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15245.9226 - reconstruction_loss: 14547.1865 - kl_loss: 583.5116\n",
      "Epoch 1610/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15236.3520 - reconstruction_loss: 14537.4404 - kl_loss: 583.3300\n",
      "Epoch 1611/5000\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 15212.1393 - reconstruction_loss: 14517.7373 - kl_loss: 582.1214\n",
      "Epoch 1612/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 15198.9644 - reconstruction_loss: 14495.4365 - kl_loss: 582.6556\n",
      "Epoch 1613/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15214.0237 - reconstruction_loss: 14494.6777 - kl_loss: 582.8198\n",
      "Epoch 1614/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15207.0233 - reconstruction_loss: 14502.0166 - kl_loss: 581.5663\n",
      "Epoch 1615/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15206.1158 - reconstruction_loss: 14509.1885 - kl_loss: 582.0895\n",
      "Epoch 1616/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15234.6607 - reconstruction_loss: 14503.3086 - kl_loss: 580.7591\n",
      "Epoch 1617/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15164.9776 - reconstruction_loss: 14474.0322 - kl_loss: 579.9829\n",
      "Epoch 1618/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15347.4984 - reconstruction_loss: 14564.1973 - kl_loss: 580.2527\n",
      "Epoch 1619/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15239.5046 - reconstruction_loss: 14502.8965 - kl_loss: 579.6742\n",
      "Epoch 1620/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15205.2734 - reconstruction_loss: 14503.2480 - kl_loss: 579.1140\n",
      "Epoch 1621/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15259.0552 - reconstruction_loss: 14521.5205 - kl_loss: 579.7916\n",
      "Epoch 1622/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15207.1603 - reconstruction_loss: 14485.4023 - kl_loss: 581.6569\n",
      "Epoch 1623/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15136.3563 - reconstruction_loss: 14452.1123 - kl_loss: 578.4055\n",
      "Epoch 1624/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15230.1249 - reconstruction_loss: 14488.2070 - kl_loss: 578.4396\n",
      "Epoch 1625/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15131.1836 - reconstruction_loss: 14467.1982 - kl_loss: 578.6431\n",
      "Epoch 1626/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15142.3665 - reconstruction_loss: 14445.9189 - kl_loss: 576.9337\n",
      "Epoch 1627/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15157.6919 - reconstruction_loss: 14456.1279 - kl_loss: 578.3504\n",
      "Epoch 1628/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15113.9889 - reconstruction_loss: 14426.3809 - kl_loss: 576.4802\n",
      "Epoch 1629/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15105.5926 - reconstruction_loss: 14420.5010 - kl_loss: 577.3474\n",
      "Epoch 1630/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15120.0811 - reconstruction_loss: 14418.7695 - kl_loss: 577.4849\n",
      "Epoch 1631/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15107.6723 - reconstruction_loss: 14429.6914 - kl_loss: 578.1003\n",
      "Epoch 1632/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15091.7441 - reconstruction_loss: 14404.9785 - kl_loss: 577.3295\n",
      "Epoch 1633/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15043.7129 - reconstruction_loss: 14382.3105 - kl_loss: 577.3389\n",
      "Epoch 1634/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15134.2050 - reconstruction_loss: 14447.0381 - kl_loss: 578.2769\n",
      "Epoch 1635/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15101.2232 - reconstruction_loss: 14433.5596 - kl_loss: 576.2556\n",
      "Epoch 1636/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15189.0197 - reconstruction_loss: 14539.3008 - kl_loss: 574.3023\n",
      "Epoch 1637/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15216.9960 - reconstruction_loss: 14580.6133 - kl_loss: 574.8646\n",
      "Epoch 1638/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15269.3722 - reconstruction_loss: 14692.2148 - kl_loss: 578.1215\n",
      "Epoch 1639/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15371.0039 - reconstruction_loss: 14636.9736 - kl_loss: 579.2258\n",
      "Epoch 1640/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15230.8810 - reconstruction_loss: 14532.8975 - kl_loss: 576.3549\n",
      "Epoch 1641/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15250.8710 - reconstruction_loss: 14575.0195 - kl_loss: 576.0979\n",
      "Epoch 1642/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15348.5550 - reconstruction_loss: 14598.6035 - kl_loss: 575.1532\n",
      "Epoch 1643/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15217.8735 - reconstruction_loss: 14533.7451 - kl_loss: 574.2101\n",
      "Epoch 1644/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15304.6125 - reconstruction_loss: 14573.5508 - kl_loss: 575.3222\n",
      "Epoch 1645/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15227.5585 - reconstruction_loss: 14490.0732 - kl_loss: 574.8596\n",
      "Epoch 1646/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 15192.0135 - reconstruction_loss: 14503.3154 - kl_loss: 573.7639\n",
      "Epoch 1647/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15231.8352 - reconstruction_loss: 14497.0449 - kl_loss: 574.9756\n",
      "Epoch 1648/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15198.3774 - reconstruction_loss: 14467.1963 - kl_loss: 575.0326\n",
      "Epoch 1649/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15202.0529 - reconstruction_loss: 14481.0469 - kl_loss: 573.3606\n",
      "Epoch 1650/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15215.3697 - reconstruction_loss: 14483.3770 - kl_loss: 573.5616\n",
      "Epoch 1651/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15183.1694 - reconstruction_loss: 14468.7344 - kl_loss: 572.3896\n",
      "Epoch 1652/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15155.7528 - reconstruction_loss: 14458.5391 - kl_loss: 574.1131\n",
      "Epoch 1653/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15210.5152 - reconstruction_loss: 14479.7598 - kl_loss: 574.4671\n",
      "Epoch 1654/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15236.6184 - reconstruction_loss: 14552.6523 - kl_loss: 571.4242\n",
      "Epoch 1655/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15282.2669 - reconstruction_loss: 14581.4209 - kl_loss: 573.3951\n",
      "Epoch 1656/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15348.6024 - reconstruction_loss: 14637.3936 - kl_loss: 572.8649\n",
      "Epoch 1657/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15420.4122 - reconstruction_loss: 14680.1514 - kl_loss: 571.2880\n",
      "Epoch 1658/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15328.4255 - reconstruction_loss: 14598.1455 - kl_loss: 572.8072\n",
      "Epoch 1659/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15269.6266 - reconstruction_loss: 14564.4180 - kl_loss: 571.9833\n",
      "Epoch 1660/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15183.0630 - reconstruction_loss: 14492.6641 - kl_loss: 572.3594\n",
      "Epoch 1661/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15198.8322 - reconstruction_loss: 14509.3252 - kl_loss: 572.4758\n",
      "Epoch 1662/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15149.0446 - reconstruction_loss: 14468.0547 - kl_loss: 572.5054\n",
      "Epoch 1663/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15158.1147 - reconstruction_loss: 14462.8594 - kl_loss: 571.2686\n",
      "Epoch 1664/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15156.2036 - reconstruction_loss: 14465.2959 - kl_loss: 571.8854\n",
      "Epoch 1665/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15243.4744 - reconstruction_loss: 14520.6826 - kl_loss: 572.3312\n",
      "Epoch 1666/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15202.7898 - reconstruction_loss: 14501.2344 - kl_loss: 571.7397\n",
      "Epoch 1667/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15297.6882 - reconstruction_loss: 14584.5889 - kl_loss: 573.1473\n",
      "Epoch 1668/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15321.9413 - reconstruction_loss: 14608.2334 - kl_loss: 572.7028\n",
      "Epoch 1669/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15338.6495 - reconstruction_loss: 14645.1162 - kl_loss: 571.1197\n",
      "Epoch 1670/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15333.0109 - reconstruction_loss: 14649.5361 - kl_loss: 571.8851\n",
      "Epoch 1671/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 15375.5297 - reconstruction_loss: 14649.2080 - kl_loss: 571.6352\n",
      "Epoch 1672/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 15258.6228 - reconstruction_loss: 14636.2080 - kl_loss: 572.3358\n",
      "Epoch 1673/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15272.7060 - reconstruction_loss: 14606.6387 - kl_loss: 572.2101\n",
      "Epoch 1674/5000\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 15243.1185 - reconstruction_loss: 14627.7012 - kl_loss: 572.3188\n",
      "Epoch 1675/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15337.1771 - reconstruction_loss: 14693.7676 - kl_loss: 572.6998\n",
      "Epoch 1676/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 15353.3905 - reconstruction_loss: 14766.4775 - kl_loss: 573.3382\n",
      "Epoch 1677/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 15589.8963 - reconstruction_loss: 14984.6426 - kl_loss: 571.2985\n",
      "Epoch 1678/5000\n",
      "75/75 [==============================] - 2s 26ms/step - loss: 15821.9171 - reconstruction_loss: 15269.5449 - kl_loss: 572.0891\n",
      "Epoch 1679/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16174.6881 - reconstruction_loss: 15574.3291 - kl_loss: 573.1664\n",
      "Epoch 1680/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 16354.2612 - reconstruction_loss: 15897.6895 - kl_loss: 571.6447\n",
      "Epoch 1681/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 16524.8314 - reconstruction_loss: 15746.0967 - kl_loss: 571.7339\n",
      "Epoch 1682/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15692.9695 - reconstruction_loss: 15066.2295 - kl_loss: 573.1905\n",
      "Epoch 1683/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15507.6928 - reconstruction_loss: 14928.3066 - kl_loss: 572.8110\n",
      "Epoch 1684/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15456.6974 - reconstruction_loss: 14876.5928 - kl_loss: 571.9373\n",
      "Epoch 1685/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15446.5363 - reconstruction_loss: 14853.6260 - kl_loss: 572.5297\n",
      "Epoch 1686/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 15383.5475 - reconstruction_loss: 14776.9844 - kl_loss: 572.9360\n",
      "Epoch 1687/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15422.1446 - reconstruction_loss: 14792.3730 - kl_loss: 572.5394\n",
      "Epoch 1688/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15361.9572 - reconstruction_loss: 14733.8418 - kl_loss: 572.1791\n",
      "Epoch 1689/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15376.3996 - reconstruction_loss: 14732.8486 - kl_loss: 572.4910\n",
      "Epoch 1690/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 15306.7637 - reconstruction_loss: 14656.9609 - kl_loss: 573.4121\n",
      "Epoch 1691/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15305.2634 - reconstruction_loss: 14640.9404 - kl_loss: 573.2397\n",
      "Epoch 1692/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15326.4722 - reconstruction_loss: 14657.0049 - kl_loss: 573.0720\n",
      "Epoch 1693/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15247.9105 - reconstruction_loss: 14578.8564 - kl_loss: 572.8550\n",
      "Epoch 1694/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 15270.8807 - reconstruction_loss: 14582.1094 - kl_loss: 571.0224\n",
      "Epoch 1695/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15244.4681 - reconstruction_loss: 14583.8955 - kl_loss: 572.1432\n",
      "Epoch 1696/5000\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 15236.4501 - reconstruction_loss: 14559.5645 - kl_loss: 572.1851\n",
      "Epoch 1697/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 15233.8819 - reconstruction_loss: 14566.3008 - kl_loss: 571.8741\n",
      "Epoch 1698/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 15202.3556 - reconstruction_loss: 14510.6104 - kl_loss: 573.9684\n",
      "Epoch 1699/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 15130.1168 - reconstruction_loss: 14459.1582 - kl_loss: 572.8224\n",
      "Epoch 1700/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15171.3235 - reconstruction_loss: 14477.1377 - kl_loss: 572.8070\n",
      "Epoch 1701/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15114.4842 - reconstruction_loss: 14445.9170 - kl_loss: 570.7946\n",
      "Epoch 1702/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 15109.4905 - reconstruction_loss: 14443.4863 - kl_loss: 570.3680\n",
      "Epoch 1703/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 15083.4220 - reconstruction_loss: 14386.5576 - kl_loss: 571.6340\n",
      "Epoch 1704/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 15045.0467 - reconstruction_loss: 14358.7520 - kl_loss: 572.3293\n",
      "Epoch 1705/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14980.3426 - reconstruction_loss: 14312.4678 - kl_loss: 571.2530\n",
      "Epoch 1706/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14954.1587 - reconstruction_loss: 14283.6074 - kl_loss: 571.1698\n",
      "Epoch 1707/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 14955.2801 - reconstruction_loss: 14295.0439 - kl_loss: 571.3626\n",
      "Epoch 1708/5000\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 14958.4298 - reconstruction_loss: 14283.7666 - kl_loss: 569.8470\n",
      "Epoch 1709/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 14916.4065 - reconstruction_loss: 14246.3125 - kl_loss: 571.5706\n",
      "Epoch 1710/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14907.1062 - reconstruction_loss: 14229.2412 - kl_loss: 571.9335\n",
      "Epoch 1711/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 14877.2794 - reconstruction_loss: 14208.5566 - kl_loss: 571.4342\n",
      "Epoch 1712/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14842.3372 - reconstruction_loss: 14184.8428 - kl_loss: 569.9526\n",
      "Epoch 1713/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14852.8510 - reconstruction_loss: 14174.0127 - kl_loss: 569.6162\n",
      "Epoch 1714/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14838.5042 - reconstruction_loss: 14163.5244 - kl_loss: 570.7202\n",
      "Epoch 1715/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14771.5666 - reconstruction_loss: 14117.4414 - kl_loss: 570.2914\n",
      "Epoch 1716/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14815.3307 - reconstruction_loss: 14132.3877 - kl_loss: 569.7531\n",
      "Epoch 1717/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14785.8053 - reconstruction_loss: 14131.2441 - kl_loss: 569.8789\n",
      "Epoch 1718/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14791.7358 - reconstruction_loss: 14122.5156 - kl_loss: 570.3478\n",
      "Epoch 1719/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14774.8548 - reconstruction_loss: 14093.4209 - kl_loss: 570.0787\n",
      "Epoch 1720/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14746.4729 - reconstruction_loss: 14065.6367 - kl_loss: 571.3025\n",
      "Epoch 1721/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14721.2839 - reconstruction_loss: 14037.2559 - kl_loss: 570.2947\n",
      "Epoch 1722/5000\n",
      "75/75 [==============================] - 2s 30ms/step - loss: 14710.1199 - reconstruction_loss: 14026.2510 - kl_loss: 568.6653\n",
      "Epoch 1723/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14684.9540 - reconstruction_loss: 14013.1084 - kl_loss: 568.1152\n",
      "Epoch 1724/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 14697.5592 - reconstruction_loss: 13991.8311 - kl_loss: 569.5394\n",
      "Epoch 1725/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14617.6579 - reconstruction_loss: 13950.1553 - kl_loss: 569.3498\n",
      "Epoch 1726/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14680.4761 - reconstruction_loss: 13984.0088 - kl_loss: 568.2447\n",
      "Epoch 1727/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14606.1028 - reconstruction_loss: 13917.8184 - kl_loss: 569.0096\n",
      "Epoch 1728/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14569.5267 - reconstruction_loss: 13914.7227 - kl_loss: 567.3901\n",
      "Epoch 1729/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14611.2759 - reconstruction_loss: 13919.8438 - kl_loss: 567.8286\n",
      "Epoch 1730/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 14547.2967 - reconstruction_loss: 13869.1074 - kl_loss: 568.1611\n",
      "Epoch 1731/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 14531.7124 - reconstruction_loss: 13853.5508 - kl_loss: 568.6489\n",
      "Epoch 1732/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 14522.7230 - reconstruction_loss: 13856.3164 - kl_loss: 566.6625\n",
      "Epoch 1733/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14484.5155 - reconstruction_loss: 13816.2656 - kl_loss: 567.0051\n",
      "Epoch 1734/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14501.8304 - reconstruction_loss: 13820.1611 - kl_loss: 566.9005\n",
      "Epoch 1735/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14474.3052 - reconstruction_loss: 13801.3115 - kl_loss: 566.6433\n",
      "Epoch 1736/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14492.3138 - reconstruction_loss: 13817.1621 - kl_loss: 567.0275\n",
      "Epoch 1737/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14486.0991 - reconstruction_loss: 13795.6182 - kl_loss: 567.7886\n",
      "Epoch 1738/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14443.9578 - reconstruction_loss: 13782.8740 - kl_loss: 565.5215\n",
      "Epoch 1739/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14507.1078 - reconstruction_loss: 13801.1143 - kl_loss: 565.4764\n",
      "Epoch 1740/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14430.2359 - reconstruction_loss: 13751.5869 - kl_loss: 565.3126\n",
      "Epoch 1741/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14510.8677 - reconstruction_loss: 13824.5273 - kl_loss: 565.2738\n",
      "Epoch 1742/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14521.4579 - reconstruction_loss: 13802.1729 - kl_loss: 566.3989\n",
      "Epoch 1743/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14416.7913 - reconstruction_loss: 13752.5225 - kl_loss: 565.0488\n",
      "Epoch 1744/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14580.5468 - reconstruction_loss: 13863.4053 - kl_loss: 563.6611\n",
      "Epoch 1745/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14529.6691 - reconstruction_loss: 13788.8721 - kl_loss: 564.8739\n",
      "Epoch 1746/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14477.8969 - reconstruction_loss: 13786.7119 - kl_loss: 565.8380\n",
      "Epoch 1747/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14564.9677 - reconstruction_loss: 13836.7295 - kl_loss: 564.6094\n",
      "Epoch 1748/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14394.0939 - reconstruction_loss: 13725.8594 - kl_loss: 565.0117\n",
      "Epoch 1749/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14351.4978 - reconstruction_loss: 13683.1807 - kl_loss: 564.0049\n",
      "Epoch 1750/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14853.3356 - reconstruction_loss: 13916.3672 - kl_loss: 569.1034\n",
      "Epoch 1751/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14423.2987 - reconstruction_loss: 13736.1426 - kl_loss: 563.8063\n",
      "Epoch 1752/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14888.3370 - reconstruction_loss: 14008.4365 - kl_loss: 567.3567\n",
      "Epoch 1753/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14415.9774 - reconstruction_loss: 13728.8379 - kl_loss: 563.5712\n",
      "Epoch 1754/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14418.6709 - reconstruction_loss: 13727.6719 - kl_loss: 562.8997\n",
      "Epoch 1755/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14428.3056 - reconstruction_loss: 13714.1992 - kl_loss: 562.8041\n",
      "Epoch 1756/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14297.5684 - reconstruction_loss: 13638.2725 - kl_loss: 561.5875\n",
      "Epoch 1757/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14272.9054 - reconstruction_loss: 13620.3281 - kl_loss: 561.8057\n",
      "Epoch 1758/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14276.6119 - reconstruction_loss: 13625.3291 - kl_loss: 561.2707\n",
      "Epoch 1759/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14248.8878 - reconstruction_loss: 13602.4834 - kl_loss: 561.8239\n",
      "Epoch 1760/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14267.8337 - reconstruction_loss: 13608.2441 - kl_loss: 560.6732\n",
      "Epoch 1761/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14232.7823 - reconstruction_loss: 13583.0576 - kl_loss: 560.2399\n",
      "Epoch 1762/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14238.9256 - reconstruction_loss: 13578.7754 - kl_loss: 560.7343\n",
      "Epoch 1763/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14221.6702 - reconstruction_loss: 13576.2637 - kl_loss: 561.0439\n",
      "Epoch 1764/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14215.0751 - reconstruction_loss: 13563.3213 - kl_loss: 559.5643\n",
      "Epoch 1765/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14204.2011 - reconstruction_loss: 13561.5830 - kl_loss: 558.6443\n",
      "Epoch 1766/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14202.6502 - reconstruction_loss: 13548.1904 - kl_loss: 558.5255\n",
      "Epoch 1767/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14191.9029 - reconstruction_loss: 13541.1660 - kl_loss: 557.7401\n",
      "Epoch 1768/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14185.8454 - reconstruction_loss: 13543.7188 - kl_loss: 558.4675\n",
      "Epoch 1769/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14190.7726 - reconstruction_loss: 13541.1260 - kl_loss: 558.1787\n",
      "Epoch 1770/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14219.0953 - reconstruction_loss: 13555.8232 - kl_loss: 557.5920\n",
      "Epoch 1771/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14197.5552 - reconstruction_loss: 13569.2002 - kl_loss: 556.7374\n",
      "Epoch 1772/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14246.7215 - reconstruction_loss: 13599.1846 - kl_loss: 557.8247\n",
      "Epoch 1773/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14237.3912 - reconstruction_loss: 13596.3623 - kl_loss: 557.6555\n",
      "Epoch 1774/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 14229.2580 - reconstruction_loss: 13563.1182 - kl_loss: 555.9398\n",
      "Epoch 1775/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14205.3262 - reconstruction_loss: 13606.6494 - kl_loss: 555.7221\n",
      "Epoch 1776/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14170.0762 - reconstruction_loss: 13533.8281 - kl_loss: 556.0243\n",
      "Epoch 1777/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14172.4269 - reconstruction_loss: 13525.1934 - kl_loss: 556.6288\n",
      "Epoch 1778/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14142.2540 - reconstruction_loss: 13521.7695 - kl_loss: 556.4135\n",
      "Epoch 1779/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14157.5562 - reconstruction_loss: 13545.8721 - kl_loss: 554.7862\n",
      "Epoch 1780/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14185.1497 - reconstruction_loss: 13574.5479 - kl_loss: 554.0215\n",
      "Epoch 1781/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14277.4829 - reconstruction_loss: 13582.3721 - kl_loss: 554.4734\n",
      "Epoch 1782/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14351.5896 - reconstruction_loss: 13629.5410 - kl_loss: 553.7801\n",
      "Epoch 1783/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14225.1624 - reconstruction_loss: 13525.5820 - kl_loss: 555.0609\n",
      "Epoch 1784/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14186.4290 - reconstruction_loss: 13543.1689 - kl_loss: 554.3432\n",
      "Epoch 1785/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14481.6625 - reconstruction_loss: 13746.6211 - kl_loss: 553.4351\n",
      "Epoch 1786/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14543.1069 - reconstruction_loss: 13758.9326 - kl_loss: 553.7452\n",
      "Epoch 1787/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14386.7305 - reconstruction_loss: 13700.6953 - kl_loss: 554.0674\n",
      "Epoch 1788/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14568.1491 - reconstruction_loss: 13776.9443 - kl_loss: 553.8402\n",
      "Epoch 1789/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14467.6061 - reconstruction_loss: 13695.9785 - kl_loss: 552.6879\n",
      "Epoch 1790/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14425.0839 - reconstruction_loss: 13687.7393 - kl_loss: 552.7419\n",
      "Epoch 1791/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14365.5426 - reconstruction_loss: 13680.3574 - kl_loss: 552.3629\n",
      "Epoch 1792/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14373.1487 - reconstruction_loss: 13685.3926 - kl_loss: 554.1777\n",
      "Epoch 1793/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14374.4864 - reconstruction_loss: 13696.6592 - kl_loss: 552.3492\n",
      "Epoch 1794/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 14352.5992 - reconstruction_loss: 13652.4795 - kl_loss: 552.3156\n",
      "Epoch 1795/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14359.1841 - reconstruction_loss: 13648.4873 - kl_loss: 551.3620\n",
      "Epoch 1796/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14368.9930 - reconstruction_loss: 13663.6758 - kl_loss: 552.8481\n",
      "Epoch 1797/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14349.4251 - reconstruction_loss: 13667.4189 - kl_loss: 552.1037\n",
      "Epoch 1798/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14451.4928 - reconstruction_loss: 13757.9326 - kl_loss: 551.8716\n",
      "Epoch 1799/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14300.4148 - reconstruction_loss: 13653.0234 - kl_loss: 552.6585\n",
      "Epoch 1800/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14316.3551 - reconstruction_loss: 13651.0273 - kl_loss: 551.5319\n",
      "Epoch 1801/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14266.5900 - reconstruction_loss: 13613.0898 - kl_loss: 551.5627\n",
      "Epoch 1802/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14321.1563 - reconstruction_loss: 13648.2422 - kl_loss: 551.6099\n",
      "Epoch 1803/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14300.4634 - reconstruction_loss: 13629.0820 - kl_loss: 549.3787\n",
      "Epoch 1804/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14364.5222 - reconstruction_loss: 13671.6201 - kl_loss: 551.8026\n",
      "Epoch 1805/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14463.3088 - reconstruction_loss: 13744.6465 - kl_loss: 550.5363\n",
      "Epoch 1806/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14491.2617 - reconstruction_loss: 13814.3359 - kl_loss: 551.9255\n",
      "Epoch 1807/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14645.2757 - reconstruction_loss: 13913.8184 - kl_loss: 551.4928\n",
      "Epoch 1808/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14620.0055 - reconstruction_loss: 13929.0615 - kl_loss: 551.1248\n",
      "Epoch 1809/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14617.4890 - reconstruction_loss: 13916.8330 - kl_loss: 551.4264\n",
      "Epoch 1810/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14529.8463 - reconstruction_loss: 13869.8994 - kl_loss: 552.7399\n",
      "Epoch 1811/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14431.3195 - reconstruction_loss: 13777.8672 - kl_loss: 551.9835\n",
      "Epoch 1812/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14356.7637 - reconstruction_loss: 13729.2109 - kl_loss: 551.7507\n",
      "Epoch 1813/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14381.7332 - reconstruction_loss: 13718.8350 - kl_loss: 550.5712\n",
      "Epoch 1814/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14342.7737 - reconstruction_loss: 13691.2451 - kl_loss: 550.4615\n",
      "Epoch 1815/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14363.4505 - reconstruction_loss: 13692.7012 - kl_loss: 549.7548\n",
      "Epoch 1816/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 14371.1736 - reconstruction_loss: 13688.8975 - kl_loss: 550.4257\n",
      "Epoch 1817/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14368.6612 - reconstruction_loss: 13699.6230 - kl_loss: 549.5131\n",
      "Epoch 1818/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14363.5387 - reconstruction_loss: 13681.9502 - kl_loss: 550.0022\n",
      "Epoch 1819/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14308.6831 - reconstruction_loss: 13666.0596 - kl_loss: 550.2930\n",
      "Epoch 1820/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14342.7465 - reconstruction_loss: 13678.5762 - kl_loss: 552.5113\n",
      "Epoch 1821/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14316.9101 - reconstruction_loss: 13652.5098 - kl_loss: 551.0937\n",
      "Epoch 1822/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14292.5765 - reconstruction_loss: 13668.1240 - kl_loss: 551.1664\n",
      "Epoch 1823/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14374.9943 - reconstruction_loss: 13702.7666 - kl_loss: 549.9627\n",
      "Epoch 1824/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 14337.0953 - reconstruction_loss: 13679.0449 - kl_loss: 548.4446\n",
      "Epoch 1825/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14315.0869 - reconstruction_loss: 13682.2793 - kl_loss: 548.4376\n",
      "Epoch 1826/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14378.0027 - reconstruction_loss: 13724.5518 - kl_loss: 549.0635\n",
      "Epoch 1827/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14308.8925 - reconstruction_loss: 13692.2305 - kl_loss: 549.8874\n",
      "Epoch 1828/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14363.9862 - reconstruction_loss: 13724.6895 - kl_loss: 551.1537\n",
      "Epoch 1829/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14378.7623 - reconstruction_loss: 13744.2920 - kl_loss: 550.3906\n",
      "Epoch 1830/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 14389.4195 - reconstruction_loss: 13765.8242 - kl_loss: 548.9217\n",
      "Epoch 1831/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14423.0623 - reconstruction_loss: 13769.2725 - kl_loss: 549.6274\n",
      "Epoch 1832/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14403.2754 - reconstruction_loss: 13727.6699 - kl_loss: 549.9019\n",
      "Epoch 1833/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14360.1605 - reconstruction_loss: 13714.8350 - kl_loss: 549.2691\n",
      "Epoch 1834/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14396.1022 - reconstruction_loss: 13712.3838 - kl_loss: 548.7845\n",
      "Epoch 1835/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14390.0261 - reconstruction_loss: 13717.0811 - kl_loss: 549.2070\n",
      "Epoch 1836/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14405.1706 - reconstruction_loss: 13728.7871 - kl_loss: 550.0305\n",
      "Epoch 1837/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14412.0649 - reconstruction_loss: 13718.5752 - kl_loss: 550.3384\n",
      "Epoch 1838/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14428.0300 - reconstruction_loss: 13745.0918 - kl_loss: 547.7999\n",
      "Epoch 1839/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14479.0818 - reconstruction_loss: 13799.7236 - kl_loss: 549.1885\n",
      "Epoch 1840/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14405.5718 - reconstruction_loss: 13772.7627 - kl_loss: 550.2022\n",
      "Epoch 1841/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14424.4223 - reconstruction_loss: 13840.9717 - kl_loss: 548.1239\n",
      "Epoch 1842/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14538.0392 - reconstruction_loss: 13982.3545 - kl_loss: 547.9623\n",
      "Epoch 1843/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14518.1325 - reconstruction_loss: 14022.3213 - kl_loss: 548.7190\n",
      "Epoch 1844/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14596.2241 - reconstruction_loss: 14168.3984 - kl_loss: 549.2562\n",
      "Epoch 1845/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14672.0626 - reconstruction_loss: 14261.0459 - kl_loss: 548.3422\n",
      "Epoch 1846/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14560.5789 - reconstruction_loss: 14182.9600 - kl_loss: 548.2198\n",
      "Epoch 1847/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14575.8366 - reconstruction_loss: 14126.8242 - kl_loss: 546.5229\n",
      "Epoch 1848/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14509.9120 - reconstruction_loss: 14005.8301 - kl_loss: 547.9003\n",
      "Epoch 1849/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14489.7433 - reconstruction_loss: 13932.3594 - kl_loss: 547.9374\n",
      "Epoch 1850/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14535.0189 - reconstruction_loss: 13946.6982 - kl_loss: 547.3745\n",
      "Epoch 1851/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14520.6362 - reconstruction_loss: 13912.9805 - kl_loss: 546.8740\n",
      "Epoch 1852/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14517.6635 - reconstruction_loss: 13893.1621 - kl_loss: 549.2592\n",
      "Epoch 1853/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14488.5998 - reconstruction_loss: 13883.6670 - kl_loss: 546.8020\n",
      "Epoch 1854/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14465.5486 - reconstruction_loss: 13847.3770 - kl_loss: 547.4004\n",
      "Epoch 1855/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14418.0694 - reconstruction_loss: 13796.8652 - kl_loss: 546.8061\n",
      "Epoch 1856/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14392.7959 - reconstruction_loss: 13756.6709 - kl_loss: 547.4058\n",
      "Epoch 1857/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14373.8457 - reconstruction_loss: 13771.2451 - kl_loss: 547.7335\n",
      "Epoch 1858/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 14349.1184 - reconstruction_loss: 13724.5332 - kl_loss: 549.4657\n",
      "Epoch 1859/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14343.5282 - reconstruction_loss: 13690.2930 - kl_loss: 548.3380\n",
      "Epoch 1860/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14274.7073 - reconstruction_loss: 13659.5420 - kl_loss: 549.7693\n",
      "Epoch 1861/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14255.7494 - reconstruction_loss: 13631.2012 - kl_loss: 548.5666\n",
      "Epoch 1862/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 14218.6623 - reconstruction_loss: 13596.3975 - kl_loss: 547.4171\n",
      "Epoch 1863/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 14197.1638 - reconstruction_loss: 13578.7900 - kl_loss: 546.6384\n",
      "Epoch 1864/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14182.1985 - reconstruction_loss: 13548.8184 - kl_loss: 547.7985\n",
      "Epoch 1865/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 14156.8007 - reconstruction_loss: 13526.7539 - kl_loss: 548.5696\n",
      "Epoch 1866/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14102.8971 - reconstruction_loss: 13484.3896 - kl_loss: 548.8156\n",
      "Epoch 1867/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14119.5809 - reconstruction_loss: 13470.0273 - kl_loss: 546.5833\n",
      "Epoch 1868/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14062.6069 - reconstruction_loss: 13426.1436 - kl_loss: 548.5040\n",
      "Epoch 1869/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14104.4806 - reconstruction_loss: 13465.5156 - kl_loss: 548.4174\n",
      "Epoch 1870/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 14107.8129 - reconstruction_loss: 13435.6689 - kl_loss: 548.0549\n",
      "Epoch 1871/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14029.2836 - reconstruction_loss: 13376.0986 - kl_loss: 547.9663\n",
      "Epoch 1872/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14023.7280 - reconstruction_loss: 13348.9502 - kl_loss: 549.0695\n",
      "Epoch 1873/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13977.7435 - reconstruction_loss: 13311.1279 - kl_loss: 548.1335\n",
      "Epoch 1874/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 13953.2734 - reconstruction_loss: 13312.1982 - kl_loss: 547.9131\n",
      "Epoch 1875/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13922.6392 - reconstruction_loss: 13273.7822 - kl_loss: 548.0926\n",
      "Epoch 1876/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13898.4153 - reconstruction_loss: 13244.9551 - kl_loss: 547.6141\n",
      "Epoch 1877/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13895.2338 - reconstruction_loss: 13236.2041 - kl_loss: 546.6713\n",
      "Epoch 1878/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13844.2515 - reconstruction_loss: 13196.2764 - kl_loss: 547.0389\n",
      "Epoch 1879/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13834.4697 - reconstruction_loss: 13187.2686 - kl_loss: 546.2731\n",
      "Epoch 1880/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13824.9117 - reconstruction_loss: 13175.0605 - kl_loss: 547.1813\n",
      "Epoch 1881/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13782.7511 - reconstruction_loss: 13144.7842 - kl_loss: 546.1514\n",
      "Epoch 1882/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13812.5745 - reconstruction_loss: 13143.6094 - kl_loss: 546.2520\n",
      "Epoch 1883/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13765.1404 - reconstruction_loss: 13114.1641 - kl_loss: 546.1561\n",
      "Epoch 1884/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13776.2784 - reconstruction_loss: 13112.1113 - kl_loss: 547.4421\n",
      "Epoch 1885/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13780.3960 - reconstruction_loss: 13137.0762 - kl_loss: 546.3035\n",
      "Epoch 1886/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13772.7035 - reconstruction_loss: 13091.6514 - kl_loss: 545.7231\n",
      "Epoch 1887/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 13768.7571 - reconstruction_loss: 13096.7344 - kl_loss: 544.8154\n",
      "Epoch 1888/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13705.2966 - reconstruction_loss: 13054.7881 - kl_loss: 545.3764\n",
      "Epoch 1889/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13722.7522 - reconstruction_loss: 13058.1865 - kl_loss: 545.6874\n",
      "Epoch 1890/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13683.8653 - reconstruction_loss: 13032.7539 - kl_loss: 545.3745\n",
      "Epoch 1891/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 13698.8517 - reconstruction_loss: 13073.5361 - kl_loss: 543.0807\n",
      "Epoch 1892/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13744.1932 - reconstruction_loss: 13050.8721 - kl_loss: 544.0684\n",
      "Epoch 1893/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 13660.1248 - reconstruction_loss: 13008.9619 - kl_loss: 543.2873\n",
      "Epoch 1894/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13722.0359 - reconstruction_loss: 13041.7051 - kl_loss: 543.7645\n",
      "Epoch 1895/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13700.4897 - reconstruction_loss: 13013.8604 - kl_loss: 543.1696\n",
      "Epoch 1896/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13662.7819 - reconstruction_loss: 13006.9219 - kl_loss: 543.1594\n",
      "Epoch 1897/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13706.8982 - reconstruction_loss: 12997.7314 - kl_loss: 543.7645\n",
      "Epoch 1898/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13632.6316 - reconstruction_loss: 12962.9795 - kl_loss: 543.4277\n",
      "Epoch 1899/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13695.9290 - reconstruction_loss: 12998.2852 - kl_loss: 542.1568\n",
      "Epoch 1900/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 13850.0144 - reconstruction_loss: 13078.2432 - kl_loss: 545.0486\n",
      "Epoch 1901/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13665.3439 - reconstruction_loss: 12961.5322 - kl_loss: 543.0364\n",
      "Epoch 1902/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13631.1286 - reconstruction_loss: 12943.5293 - kl_loss: 543.1853\n",
      "Epoch 1903/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 13607.7982 - reconstruction_loss: 12929.0166 - kl_loss: 543.4057\n",
      "Epoch 1904/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13614.9000 - reconstruction_loss: 12919.0117 - kl_loss: 541.3830\n",
      "Epoch 1905/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 13591.1992 - reconstruction_loss: 12903.2051 - kl_loss: 541.9908\n",
      "Epoch 1906/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 13564.5195 - reconstruction_loss: 12892.0615 - kl_loss: 541.3336\n",
      "Epoch 1907/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13534.6716 - reconstruction_loss: 12869.5264 - kl_loss: 540.8032\n",
      "Epoch 1908/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13523.3012 - reconstruction_loss: 12866.4932 - kl_loss: 541.0944\n",
      "Epoch 1909/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13510.1850 - reconstruction_loss: 12852.4775 - kl_loss: 540.9399\n",
      "Epoch 1910/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13539.9251 - reconstruction_loss: 12859.5508 - kl_loss: 540.1754\n",
      "Epoch 1911/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13554.3171 - reconstruction_loss: 12883.4795 - kl_loss: 541.0688\n",
      "Epoch 1912/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13568.9000 - reconstruction_loss: 12886.6719 - kl_loss: 540.1646\n",
      "Epoch 1913/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13505.8371 - reconstruction_loss: 12845.0107 - kl_loss: 538.7009\n",
      "Epoch 1914/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13568.4835 - reconstruction_loss: 12877.9941 - kl_loss: 539.5236\n",
      "Epoch 1915/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13501.1173 - reconstruction_loss: 12836.7197 - kl_loss: 538.8105\n",
      "Epoch 1916/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13519.4311 - reconstruction_loss: 12866.3555 - kl_loss: 538.3576\n",
      "Epoch 1917/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13579.6307 - reconstruction_loss: 12870.0449 - kl_loss: 539.5341\n",
      "Epoch 1918/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13492.5541 - reconstruction_loss: 12836.7861 - kl_loss: 538.3391\n",
      "Epoch 1919/5000\n",
      "75/75 [==============================] - 3s 41ms/step - loss: 13655.0243 - reconstruction_loss: 12931.0879 - kl_loss: 538.3255\n",
      "Epoch 1920/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 13563.9438 - reconstruction_loss: 12849.4229 - kl_loss: 540.0790\n",
      "Epoch 1921/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 13524.1295 - reconstruction_loss: 12854.2344 - kl_loss: 540.2773\n",
      "Epoch 1922/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13584.8742 - reconstruction_loss: 12862.5684 - kl_loss: 539.0969\n",
      "Epoch 1923/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13507.0759 - reconstruction_loss: 12838.4883 - kl_loss: 539.1674\n",
      "Epoch 1924/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 13616.3228 - reconstruction_loss: 12896.4404 - kl_loss: 537.3907\n",
      "Epoch 1925/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13541.0221 - reconstruction_loss: 12835.9512 - kl_loss: 537.2989\n",
      "Epoch 1926/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13525.2213 - reconstruction_loss: 12853.6484 - kl_loss: 536.8271\n",
      "Epoch 1927/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13498.5878 - reconstruction_loss: 12808.8916 - kl_loss: 536.4408\n",
      "Epoch 1928/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13457.4909 - reconstruction_loss: 12782.4121 - kl_loss: 536.7494\n",
      "Epoch 1929/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13486.2627 - reconstruction_loss: 12827.8984 - kl_loss: 536.1044\n",
      "Epoch 1930/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 13461.6802 - reconstruction_loss: 12789.5293 - kl_loss: 536.2706\n",
      "Epoch 1931/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13428.5178 - reconstruction_loss: 12768.7900 - kl_loss: 536.7316\n",
      "Epoch 1932/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13432.0805 - reconstruction_loss: 12765.9570 - kl_loss: 535.5297\n",
      "Epoch 1933/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13422.0492 - reconstruction_loss: 12798.6025 - kl_loss: 534.5843\n",
      "Epoch 1934/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13497.8929 - reconstruction_loss: 12789.5479 - kl_loss: 535.3663\n",
      "Epoch 1935/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13484.6215 - reconstruction_loss: 12803.9180 - kl_loss: 535.6985\n",
      "Epoch 1936/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13512.4747 - reconstruction_loss: 12849.9736 - kl_loss: 536.3174\n",
      "Epoch 1937/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13467.5989 - reconstruction_loss: 12806.1016 - kl_loss: 535.8370\n",
      "Epoch 1938/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13453.8889 - reconstruction_loss: 12803.1719 - kl_loss: 534.9732\n",
      "Epoch 1939/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13473.1407 - reconstruction_loss: 12792.6504 - kl_loss: 534.8232\n",
      "Epoch 1940/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13503.6067 - reconstruction_loss: 12806.7832 - kl_loss: 535.1472\n",
      "Epoch 1941/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13523.0825 - reconstruction_loss: 12838.9834 - kl_loss: 534.8091\n",
      "Epoch 1942/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13615.4127 - reconstruction_loss: 12921.7578 - kl_loss: 534.8994\n",
      "Epoch 1943/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13597.6891 - reconstruction_loss: 12961.9668 - kl_loss: 534.2328\n",
      "Epoch 1944/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13557.2489 - reconstruction_loss: 12947.9688 - kl_loss: 534.5039\n",
      "Epoch 1945/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13630.1118 - reconstruction_loss: 12991.6748 - kl_loss: 534.5135\n",
      "Epoch 1946/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13758.4186 - reconstruction_loss: 13076.1758 - kl_loss: 535.2294\n",
      "Epoch 1947/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 14142.7186 - reconstruction_loss: 13201.9336 - kl_loss: 534.7250\n",
      "Epoch 1948/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13870.4004 - reconstruction_loss: 13048.3154 - kl_loss: 533.9271\n",
      "Epoch 1949/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13794.6237 - reconstruction_loss: 13047.0547 - kl_loss: 537.9649\n",
      "Epoch 1950/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13942.9155 - reconstruction_loss: 13037.2861 - kl_loss: 534.6646\n",
      "Epoch 1951/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13597.3414 - reconstruction_loss: 12886.6924 - kl_loss: 534.5647\n",
      "Epoch 1952/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 13667.5377 - reconstruction_loss: 12940.9043 - kl_loss: 534.3741\n",
      "Epoch 1953/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13615.4861 - reconstruction_loss: 12879.7930 - kl_loss: 534.0433\n",
      "Epoch 1954/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13543.7557 - reconstruction_loss: 12844.3584 - kl_loss: 533.2136\n",
      "Epoch 1955/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13522.1861 - reconstruction_loss: 12826.4561 - kl_loss: 533.3233\n",
      "Epoch 1956/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13467.3740 - reconstruction_loss: 12791.6074 - kl_loss: 533.1887\n",
      "Epoch 1957/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13441.2282 - reconstruction_loss: 12773.5537 - kl_loss: 532.6740\n",
      "Epoch 1958/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13424.4305 - reconstruction_loss: 12751.0908 - kl_loss: 531.8952\n",
      "Epoch 1959/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 13410.5851 - reconstruction_loss: 12738.9619 - kl_loss: 532.3922\n",
      "Epoch 1960/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 13379.6029 - reconstruction_loss: 12720.1455 - kl_loss: 529.8856\n",
      "Epoch 1961/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 13362.2122 - reconstruction_loss: 12706.9346 - kl_loss: 532.1631\n",
      "Epoch 1962/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 13329.2712 - reconstruction_loss: 12674.3457 - kl_loss: 533.6182\n",
      "Epoch 1963/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 13322.4751 - reconstruction_loss: 12668.1982 - kl_loss: 532.2385\n",
      "Epoch 1964/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13299.2015 - reconstruction_loss: 12650.5703 - kl_loss: 531.8528\n",
      "Epoch 1965/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13284.5405 - reconstruction_loss: 12625.5947 - kl_loss: 531.3219\n",
      "Epoch 1966/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 13271.3484 - reconstruction_loss: 12616.1211 - kl_loss: 530.7119\n",
      "Epoch 1967/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13260.2059 - reconstruction_loss: 12600.0938 - kl_loss: 530.4937\n",
      "Epoch 1968/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 13269.3735 - reconstruction_loss: 12600.7246 - kl_loss: 529.6807\n",
      "Epoch 1969/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13228.3454 - reconstruction_loss: 12569.8467 - kl_loss: 530.7097\n",
      "Epoch 1970/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13240.9567 - reconstruction_loss: 12582.3115 - kl_loss: 530.8527\n",
      "Epoch 1971/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13214.5472 - reconstruction_loss: 12551.7832 - kl_loss: 531.4590\n",
      "Epoch 1972/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13221.0987 - reconstruction_loss: 12578.1074 - kl_loss: 529.3640\n",
      "Epoch 1973/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13330.3697 - reconstruction_loss: 12639.8057 - kl_loss: 530.9256\n",
      "Epoch 1974/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13281.2215 - reconstruction_loss: 12588.3398 - kl_loss: 530.1982\n",
      "Epoch 1975/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13236.5150 - reconstruction_loss: 12579.8916 - kl_loss: 529.7186\n",
      "Epoch 1976/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13379.6102 - reconstruction_loss: 12641.0752 - kl_loss: 530.8563\n",
      "Epoch 1977/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13271.4706 - reconstruction_loss: 12565.7314 - kl_loss: 529.0897\n",
      "Epoch 1978/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13205.6513 - reconstruction_loss: 12539.8271 - kl_loss: 528.7991\n",
      "Epoch 1979/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13296.1098 - reconstruction_loss: 12571.1758 - kl_loss: 529.6885\n",
      "Epoch 1980/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13174.2874 - reconstruction_loss: 12506.0967 - kl_loss: 529.6433\n",
      "Epoch 1981/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13223.1024 - reconstruction_loss: 12534.7021 - kl_loss: 529.1550\n",
      "Epoch 1982/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13146.3129 - reconstruction_loss: 12484.3350 - kl_loss: 528.5178\n",
      "Epoch 1983/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13146.6742 - reconstruction_loss: 12492.2812 - kl_loss: 528.3351\n",
      "Epoch 1984/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13152.6150 - reconstruction_loss: 12483.0918 - kl_loss: 527.7332\n",
      "Epoch 1985/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13122.5759 - reconstruction_loss: 12474.0957 - kl_loss: 527.9272\n",
      "Epoch 1986/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13142.2499 - reconstruction_loss: 12476.4980 - kl_loss: 527.9010\n",
      "Epoch 1987/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13099.4127 - reconstruction_loss: 12450.7275 - kl_loss: 528.3218\n",
      "Epoch 1988/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13106.2204 - reconstruction_loss: 12443.4785 - kl_loss: 527.0974\n",
      "Epoch 1989/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13096.0367 - reconstruction_loss: 12442.4727 - kl_loss: 527.0946\n",
      "Epoch 1990/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 13110.1338 - reconstruction_loss: 12450.4697 - kl_loss: 526.7175\n",
      "Epoch 1991/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13104.1976 - reconstruction_loss: 12436.2256 - kl_loss: 526.6533\n",
      "Epoch 1992/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13120.8396 - reconstruction_loss: 12468.8184 - kl_loss: 527.1495\n",
      "Epoch 1993/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13141.5126 - reconstruction_loss: 12462.3525 - kl_loss: 527.2402\n",
      "Epoch 1994/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 13074.9790 - reconstruction_loss: 12425.2305 - kl_loss: 526.6240\n",
      "Epoch 1995/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13156.6594 - reconstruction_loss: 12483.4434 - kl_loss: 525.6614\n",
      "Epoch 1996/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13128.6147 - reconstruction_loss: 12441.2559 - kl_loss: 526.1038\n",
      "Epoch 1997/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13106.2411 - reconstruction_loss: 12462.4980 - kl_loss: 525.4196\n",
      "Epoch 1998/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13176.3574 - reconstruction_loss: 12469.1768 - kl_loss: 525.6807\n",
      "Epoch 1999/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13088.9535 - reconstruction_loss: 12427.9990 - kl_loss: 525.7000\n",
      "Epoch 2000/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13139.9958 - reconstruction_loss: 12465.0059 - kl_loss: 526.0416\n",
      "Epoch 2001/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13167.6551 - reconstruction_loss: 12449.7754 - kl_loss: 524.9100\n",
      "Epoch 2002/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13092.5587 - reconstruction_loss: 12470.0117 - kl_loss: 524.9731\n",
      "Epoch 2003/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13142.7837 - reconstruction_loss: 12456.5117 - kl_loss: 526.1834\n",
      "Epoch 2004/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13066.6283 - reconstruction_loss: 12410.4570 - kl_loss: 524.4886\n",
      "Epoch 2005/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13095.1097 - reconstruction_loss: 12428.9072 - kl_loss: 525.4987\n",
      "Epoch 2006/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13081.9019 - reconstruction_loss: 12429.1875 - kl_loss: 524.6177\n",
      "Epoch 2007/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13029.3625 - reconstruction_loss: 12384.7012 - kl_loss: 525.5768\n",
      "Epoch 2008/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13036.3780 - reconstruction_loss: 12377.9492 - kl_loss: 525.5153\n",
      "Epoch 2009/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13031.1478 - reconstruction_loss: 12390.4912 - kl_loss: 523.1158\n",
      "Epoch 2010/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13036.0208 - reconstruction_loss: 12388.2549 - kl_loss: 522.8189\n",
      "Epoch 2011/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13064.8836 - reconstruction_loss: 12410.6123 - kl_loss: 523.1030\n",
      "Epoch 2012/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13036.9635 - reconstruction_loss: 12402.8857 - kl_loss: 522.8322\n",
      "Epoch 2013/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13088.4466 - reconstruction_loss: 12456.5859 - kl_loss: 523.1670\n",
      "Epoch 2014/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13076.1635 - reconstruction_loss: 12443.7197 - kl_loss: 523.0672\n",
      "Epoch 2015/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13064.2170 - reconstruction_loss: 12464.4941 - kl_loss: 522.0479\n",
      "Epoch 2016/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13066.6639 - reconstruction_loss: 12461.3652 - kl_loss: 522.4456\n",
      "Epoch 2017/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13029.3884 - reconstruction_loss: 12439.1680 - kl_loss: 521.3699\n",
      "Epoch 2018/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13062.8279 - reconstruction_loss: 12478.7764 - kl_loss: 521.2346\n",
      "Epoch 2019/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13104.2804 - reconstruction_loss: 12533.4688 - kl_loss: 521.2945\n",
      "Epoch 2020/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13258.6416 - reconstruction_loss: 12604.5918 - kl_loss: 521.2095\n",
      "Epoch 2021/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13336.8091 - reconstruction_loss: 12676.9697 - kl_loss: 521.3000\n",
      "Epoch 2022/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13502.9597 - reconstruction_loss: 12720.3584 - kl_loss: 521.5947\n",
      "Epoch 2023/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13470.4644 - reconstruction_loss: 12765.3408 - kl_loss: 520.5928\n",
      "Epoch 2024/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13317.6327 - reconstruction_loss: 12612.7432 - kl_loss: 520.9884\n",
      "Epoch 2025/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13296.9997 - reconstruction_loss: 12614.3379 - kl_loss: 521.1265\n",
      "Epoch 2026/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13404.3667 - reconstruction_loss: 12649.8662 - kl_loss: 522.4507\n",
      "Epoch 2027/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13186.8147 - reconstruction_loss: 12528.9365 - kl_loss: 521.3023\n",
      "Epoch 2028/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13258.5917 - reconstruction_loss: 12584.0889 - kl_loss: 520.2036\n",
      "Epoch 2029/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13204.6608 - reconstruction_loss: 12501.4795 - kl_loss: 519.5715\n",
      "Epoch 2030/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13118.6413 - reconstruction_loss: 12479.2441 - kl_loss: 521.7001\n",
      "Epoch 2031/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13165.5410 - reconstruction_loss: 12489.6836 - kl_loss: 520.7953\n",
      "Epoch 2032/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13093.8849 - reconstruction_loss: 12443.2168 - kl_loss: 520.7861\n",
      "Epoch 2033/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13078.6736 - reconstruction_loss: 12428.8789 - kl_loss: 520.8705\n",
      "Epoch 2034/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13031.4801 - reconstruction_loss: 12400.1152 - kl_loss: 521.3339\n",
      "Epoch 2035/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13017.0051 - reconstruction_loss: 12383.4297 - kl_loss: 520.8578\n",
      "Epoch 2036/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13019.0136 - reconstruction_loss: 12365.0283 - kl_loss: 522.3707\n",
      "Epoch 2037/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12994.9180 - reconstruction_loss: 12362.5938 - kl_loss: 520.9322\n",
      "Epoch 2038/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12974.2731 - reconstruction_loss: 12347.2822 - kl_loss: 519.3655\n",
      "Epoch 2039/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12972.6951 - reconstruction_loss: 12342.3320 - kl_loss: 520.5504\n",
      "Epoch 2040/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 12943.4605 - reconstruction_loss: 12317.1172 - kl_loss: 519.4786\n",
      "Epoch 2041/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 12953.8809 - reconstruction_loss: 12323.1016 - kl_loss: 519.6355\n",
      "Epoch 2042/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 12931.7723 - reconstruction_loss: 12297.1602 - kl_loss: 518.9573\n",
      "Epoch 2043/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12930.1880 - reconstruction_loss: 12295.7627 - kl_loss: 519.5287\n",
      "Epoch 2044/5000\n",
      "75/75 [==============================] - 3s 35ms/step - loss: 12922.3139 - reconstruction_loss: 12272.2080 - kl_loss: 520.2990\n",
      "Epoch 2045/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 12932.6753 - reconstruction_loss: 12289.7393 - kl_loss: 518.6031\n",
      "Epoch 2046/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13119.0045 - reconstruction_loss: 12453.5684 - kl_loss: 519.8865\n",
      "Epoch 2047/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12949.6288 - reconstruction_loss: 12300.9678 - kl_loss: 520.0334\n",
      "Epoch 2048/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12964.2076 - reconstruction_loss: 12330.9287 - kl_loss: 518.2003\n",
      "Epoch 2049/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13048.5118 - reconstruction_loss: 12347.8750 - kl_loss: 519.3740\n",
      "Epoch 2050/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12996.0366 - reconstruction_loss: 12296.2832 - kl_loss: 518.2047\n",
      "Epoch 2051/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13036.9503 - reconstruction_loss: 12372.2539 - kl_loss: 517.8647\n",
      "Epoch 2052/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 13097.3843 - reconstruction_loss: 12344.7031 - kl_loss: 518.4533\n",
      "Epoch 2053/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 12923.4067 - reconstruction_loss: 12269.9805 - kl_loss: 518.3024\n",
      "Epoch 2054/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12975.2398 - reconstruction_loss: 12269.7900 - kl_loss: 518.4915\n",
      "Epoch 2055/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12859.3857 - reconstruction_loss: 12209.3516 - kl_loss: 517.7846\n",
      "Epoch 2056/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12903.8318 - reconstruction_loss: 12234.7891 - kl_loss: 517.9651\n",
      "Epoch 2057/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12861.1028 - reconstruction_loss: 12207.5430 - kl_loss: 517.3924\n",
      "Epoch 2058/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12873.4492 - reconstruction_loss: 12209.7393 - kl_loss: 517.0272\n",
      "Epoch 2059/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12834.0030 - reconstruction_loss: 12180.3076 - kl_loss: 517.1324\n",
      "Epoch 2060/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12814.8365 - reconstruction_loss: 12174.8633 - kl_loss: 516.3723\n",
      "Epoch 2061/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12800.9532 - reconstruction_loss: 12157.3691 - kl_loss: 516.5867\n",
      "Epoch 2062/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12818.8937 - reconstruction_loss: 12179.0654 - kl_loss: 514.7231\n",
      "Epoch 2063/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12822.2076 - reconstruction_loss: 12170.3887 - kl_loss: 516.1517\n",
      "Epoch 2064/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12774.6637 - reconstruction_loss: 12139.1992 - kl_loss: 516.5740\n",
      "Epoch 2065/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12779.8590 - reconstruction_loss: 12150.0986 - kl_loss: 515.9533\n",
      "Epoch 2066/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12797.7276 - reconstruction_loss: 12149.6279 - kl_loss: 515.8684\n",
      "Epoch 2067/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12791.1618 - reconstruction_loss: 12147.7002 - kl_loss: 515.2247\n",
      "Epoch 2068/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12775.0104 - reconstruction_loss: 12138.2256 - kl_loss: 515.2144\n",
      "Epoch 2069/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12789.8690 - reconstruction_loss: 12152.5029 - kl_loss: 514.9019\n",
      "Epoch 2070/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12831.7743 - reconstruction_loss: 12155.0742 - kl_loss: 515.9951\n",
      "Epoch 2071/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12766.0731 - reconstruction_loss: 12132.5732 - kl_loss: 515.3422\n",
      "Epoch 2072/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12858.5439 - reconstruction_loss: 12224.6621 - kl_loss: 515.5283\n",
      "Epoch 2073/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12851.3423 - reconstruction_loss: 12179.5303 - kl_loss: 516.1183\n",
      "Epoch 2074/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12796.2681 - reconstruction_loss: 12155.2441 - kl_loss: 513.8568\n",
      "Epoch 2075/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12889.2151 - reconstruction_loss: 12187.6875 - kl_loss: 515.3286\n",
      "Epoch 2076/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12764.5029 - reconstruction_loss: 12127.8535 - kl_loss: 514.7452\n",
      "Epoch 2077/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12914.8346 - reconstruction_loss: 12246.4561 - kl_loss: 514.9035\n",
      "Epoch 2078/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13003.7279 - reconstruction_loss: 12272.9316 - kl_loss: 514.5985\n",
      "Epoch 2079/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12831.0895 - reconstruction_loss: 12199.9971 - kl_loss: 514.0157\n",
      "Epoch 2080/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12876.5606 - reconstruction_loss: 12197.9453 - kl_loss: 513.8610\n",
      "Epoch 2081/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12762.9832 - reconstruction_loss: 12119.7588 - kl_loss: 513.4030\n",
      "Epoch 2082/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12796.0249 - reconstruction_loss: 12142.6465 - kl_loss: 513.7828\n",
      "Epoch 2083/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12772.6906 - reconstruction_loss: 12147.2031 - kl_loss: 512.1110\n",
      "Epoch 2084/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12793.0295 - reconstruction_loss: 12170.8525 - kl_loss: 513.9067\n",
      "Epoch 2085/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12790.7451 - reconstruction_loss: 12157.0850 - kl_loss: 513.2563\n",
      "Epoch 2086/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12776.1249 - reconstruction_loss: 12155.4365 - kl_loss: 511.6106\n",
      "Epoch 2087/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12755.0858 - reconstruction_loss: 12134.1270 - kl_loss: 511.6694\n",
      "Epoch 2088/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12742.8755 - reconstruction_loss: 12141.1572 - kl_loss: 512.7332\n",
      "Epoch 2089/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12751.5657 - reconstruction_loss: 12143.0225 - kl_loss: 511.8112\n",
      "Epoch 2090/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12769.4333 - reconstruction_loss: 12133.3613 - kl_loss: 512.3869\n",
      "Epoch 2091/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12764.9260 - reconstruction_loss: 12143.9209 - kl_loss: 511.6578\n",
      "Epoch 2092/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12753.9030 - reconstruction_loss: 12161.2842 - kl_loss: 510.9528\n",
      "Epoch 2093/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12841.0732 - reconstruction_loss: 12229.4541 - kl_loss: 511.4392\n",
      "Epoch 2094/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12857.2677 - reconstruction_loss: 12277.2441 - kl_loss: 511.5276\n",
      "Epoch 2095/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12974.4232 - reconstruction_loss: 12380.6201 - kl_loss: 511.7549\n",
      "Epoch 2096/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13043.1389 - reconstruction_loss: 12531.2900 - kl_loss: 510.2066\n",
      "Epoch 2097/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13339.3964 - reconstruction_loss: 12593.6455 - kl_loss: 511.8358\n",
      "Epoch 2098/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13274.7397 - reconstruction_loss: 12615.0869 - kl_loss: 512.5713\n",
      "Epoch 2099/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13178.9672 - reconstruction_loss: 12477.9521 - kl_loss: 513.0283\n",
      "Epoch 2100/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13316.6125 - reconstruction_loss: 12510.5947 - kl_loss: 511.5879\n",
      "Epoch 2101/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13305.3026 - reconstruction_loss: 12563.6719 - kl_loss: 510.6218\n",
      "Epoch 2102/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13376.6803 - reconstruction_loss: 12635.9756 - kl_loss: 512.5481\n",
      "Epoch 2103/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13371.3693 - reconstruction_loss: 12712.1572 - kl_loss: 511.6615\n",
      "Epoch 2104/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13741.9710 - reconstruction_loss: 13032.5127 - kl_loss: 508.7004\n",
      "Epoch 2105/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14275.1587 - reconstruction_loss: 13318.5098 - kl_loss: 508.4708\n",
      "Epoch 2106/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13776.2073 - reconstruction_loss: 12966.4600 - kl_loss: 512.6146\n",
      "Epoch 2107/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13422.5752 - reconstruction_loss: 12707.5537 - kl_loss: 512.5106\n",
      "Epoch 2108/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13313.1570 - reconstruction_loss: 12634.2559 - kl_loss: 512.0844\n",
      "Epoch 2109/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13262.5150 - reconstruction_loss: 12608.5801 - kl_loss: 510.0556\n",
      "Epoch 2110/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13241.9513 - reconstruction_loss: 12589.4502 - kl_loss: 511.9027\n",
      "Epoch 2111/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13254.7922 - reconstruction_loss: 12557.3154 - kl_loss: 511.0066\n",
      "Epoch 2112/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13153.8923 - reconstruction_loss: 12497.8418 - kl_loss: 510.0539\n",
      "Epoch 2113/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13151.4049 - reconstruction_loss: 12483.4688 - kl_loss: 510.9107\n",
      "Epoch 2114/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13075.3174 - reconstruction_loss: 12441.7441 - kl_loss: 511.7381\n",
      "Epoch 2115/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13089.5709 - reconstruction_loss: 12442.8877 - kl_loss: 510.7597\n",
      "Epoch 2116/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13092.1134 - reconstruction_loss: 12429.4814 - kl_loss: 509.7357\n",
      "Epoch 2117/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13036.7260 - reconstruction_loss: 12386.0547 - kl_loss: 511.3921\n",
      "Epoch 2118/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12995.1138 - reconstruction_loss: 12363.7051 - kl_loss: 513.0425\n",
      "Epoch 2119/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12985.1027 - reconstruction_loss: 12344.3184 - kl_loss: 510.8024\n",
      "Epoch 2120/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12965.5459 - reconstruction_loss: 12335.9229 - kl_loss: 510.0285\n",
      "Epoch 2121/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12989.4783 - reconstruction_loss: 12342.4854 - kl_loss: 510.6493\n",
      "Epoch 2122/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12947.6608 - reconstruction_loss: 12321.8398 - kl_loss: 510.3097\n",
      "Epoch 2123/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12970.8728 - reconstruction_loss: 12331.9150 - kl_loss: 509.7351\n",
      "Epoch 2124/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12953.9692 - reconstruction_loss: 12310.2080 - kl_loss: 510.7446\n",
      "Epoch 2125/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12931.3379 - reconstruction_loss: 12302.5469 - kl_loss: 509.8080\n",
      "Epoch 2126/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12960.2533 - reconstruction_loss: 12298.4844 - kl_loss: 510.6918\n",
      "Epoch 2127/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12886.4529 - reconstruction_loss: 12246.4209 - kl_loss: 511.2414\n",
      "Epoch 2128/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12920.9305 - reconstruction_loss: 12268.4609 - kl_loss: 510.5461\n",
      "Epoch 2129/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12958.2593 - reconstruction_loss: 12261.2012 - kl_loss: 510.2086\n",
      "Epoch 2130/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12865.0609 - reconstruction_loss: 12235.0889 - kl_loss: 509.7597\n",
      "Epoch 2131/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12874.2024 - reconstruction_loss: 12223.0039 - kl_loss: 510.9495\n",
      "Epoch 2132/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12823.7740 - reconstruction_loss: 12186.8281 - kl_loss: 511.0671\n",
      "Epoch 2133/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12827.6127 - reconstruction_loss: 12178.6172 - kl_loss: 510.5725\n",
      "Epoch 2134/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12833.0343 - reconstruction_loss: 12199.0859 - kl_loss: 509.3748\n",
      "Epoch 2135/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12875.6149 - reconstruction_loss: 12243.1387 - kl_loss: 510.8529\n",
      "Epoch 2136/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12809.6082 - reconstruction_loss: 12157.1504 - kl_loss: 510.2749\n",
      "Epoch 2137/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12759.8756 - reconstruction_loss: 12120.3730 - kl_loss: 509.5979\n",
      "Epoch 2138/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12708.9242 - reconstruction_loss: 12089.8193 - kl_loss: 509.5637\n",
      "Epoch 2139/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12712.8619 - reconstruction_loss: 12084.4512 - kl_loss: 509.4418\n",
      "Epoch 2140/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12682.4422 - reconstruction_loss: 12059.3291 - kl_loss: 508.9269\n",
      "Epoch 2141/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12685.1140 - reconstruction_loss: 12054.2070 - kl_loss: 508.9267\n",
      "Epoch 2142/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12650.3885 - reconstruction_loss: 12027.4521 - kl_loss: 509.0619\n",
      "Epoch 2143/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12679.8835 - reconstruction_loss: 12043.0244 - kl_loss: 508.8126\n",
      "Epoch 2144/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12649.0329 - reconstruction_loss: 12030.4512 - kl_loss: 507.6479\n",
      "Epoch 2145/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12666.1261 - reconstruction_loss: 12028.1719 - kl_loss: 509.7585\n",
      "Epoch 2146/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12646.4443 - reconstruction_loss: 12012.9619 - kl_loss: 509.8627\n",
      "Epoch 2147/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12617.2713 - reconstruction_loss: 11984.2090 - kl_loss: 508.4976\n",
      "Epoch 2148/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12669.2228 - reconstruction_loss: 12022.7002 - kl_loss: 507.5531\n",
      "Epoch 2149/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12622.2129 - reconstruction_loss: 11976.8750 - kl_loss: 508.7813\n",
      "Epoch 2150/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12598.9552 - reconstruction_loss: 11982.4912 - kl_loss: 507.9000\n",
      "Epoch 2151/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12639.8511 - reconstruction_loss: 11988.2490 - kl_loss: 507.5074\n",
      "Epoch 2152/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12568.0141 - reconstruction_loss: 11940.8760 - kl_loss: 507.7742\n",
      "Epoch 2153/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12660.6262 - reconstruction_loss: 11999.5029 - kl_loss: 508.8006\n",
      "Epoch 2154/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12602.0314 - reconstruction_loss: 11958.8877 - kl_loss: 508.2650\n",
      "Epoch 2155/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12680.1966 - reconstruction_loss: 12054.6064 - kl_loss: 508.5164\n",
      "Epoch 2156/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12596.4319 - reconstruction_loss: 11942.4971 - kl_loss: 508.4575\n",
      "Epoch 2157/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12530.6642 - reconstruction_loss: 11903.2285 - kl_loss: 507.7243\n",
      "Epoch 2158/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12569.6828 - reconstruction_loss: 11924.1729 - kl_loss: 505.7833\n",
      "Epoch 2159/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12507.2279 - reconstruction_loss: 11883.1074 - kl_loss: 506.4822\n",
      "Epoch 2160/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12498.4495 - reconstruction_loss: 11882.6006 - kl_loss: 507.5883\n",
      "Epoch 2161/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12487.3488 - reconstruction_loss: 11863.4873 - kl_loss: 507.1997\n",
      "Epoch 2162/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12489.0263 - reconstruction_loss: 11877.6396 - kl_loss: 506.9731\n",
      "Epoch 2163/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12505.6151 - reconstruction_loss: 11881.9502 - kl_loss: 507.6111\n",
      "Epoch 2164/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12481.6135 - reconstruction_loss: 11862.9131 - kl_loss: 505.1643\n",
      "Epoch 2165/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12496.9483 - reconstruction_loss: 11869.9883 - kl_loss: 505.9528\n",
      "Epoch 2166/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12486.7689 - reconstruction_loss: 11867.2471 - kl_loss: 505.7200\n",
      "Epoch 2167/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12502.9381 - reconstruction_loss: 11871.7061 - kl_loss: 506.6010\n",
      "Epoch 2168/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12506.6781 - reconstruction_loss: 11860.4365 - kl_loss: 506.2132\n",
      "Epoch 2169/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12481.6395 - reconstruction_loss: 11879.1689 - kl_loss: 506.0826\n",
      "Epoch 2170/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12587.5993 - reconstruction_loss: 11904.6260 - kl_loss: 506.2305\n",
      "Epoch 2171/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12476.8042 - reconstruction_loss: 11842.4453 - kl_loss: 505.5811\n",
      "Epoch 2172/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12521.0610 - reconstruction_loss: 11883.6025 - kl_loss: 506.0109\n",
      "Epoch 2173/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12522.5153 - reconstruction_loss: 11853.3584 - kl_loss: 504.6841\n",
      "Epoch 2174/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12442.9814 - reconstruction_loss: 11844.5791 - kl_loss: 504.0685\n",
      "Epoch 2175/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12469.7543 - reconstruction_loss: 11833.3438 - kl_loss: 504.9134\n",
      "Epoch 2176/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12423.3906 - reconstruction_loss: 11813.9023 - kl_loss: 503.1939\n",
      "Epoch 2177/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12467.3567 - reconstruction_loss: 11832.3320 - kl_loss: 504.3296\n",
      "Epoch 2178/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12464.8268 - reconstruction_loss: 11828.3486 - kl_loss: 503.9563\n",
      "Epoch 2179/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12552.2930 - reconstruction_loss: 11925.8184 - kl_loss: 505.0082\n",
      "Epoch 2180/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12522.8328 - reconstruction_loss: 11865.0303 - kl_loss: 504.6562\n",
      "Epoch 2181/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12410.2766 - reconstruction_loss: 11792.5742 - kl_loss: 504.3944\n",
      "Epoch 2182/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12447.9920 - reconstruction_loss: 11808.2129 - kl_loss: 502.0361\n",
      "Epoch 2183/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12453.0406 - reconstruction_loss: 11825.3457 - kl_loss: 503.1379\n",
      "Epoch 2184/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12415.7432 - reconstruction_loss: 11783.2705 - kl_loss: 502.5125\n",
      "Epoch 2185/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 12445.8489 - reconstruction_loss: 11808.0029 - kl_loss: 502.1868\n",
      "Epoch 2186/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12420.2066 - reconstruction_loss: 11808.4805 - kl_loss: 503.4782\n",
      "Epoch 2187/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12444.6850 - reconstruction_loss: 11822.2637 - kl_loss: 502.6506\n",
      "Epoch 2188/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12480.1242 - reconstruction_loss: 11847.1611 - kl_loss: 502.2193\n",
      "Epoch 2189/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12423.8472 - reconstruction_loss: 11817.7422 - kl_loss: 502.0893\n",
      "Epoch 2190/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12485.8798 - reconstruction_loss: 11831.5869 - kl_loss: 503.0321\n",
      "Epoch 2191/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12406.5092 - reconstruction_loss: 11776.7920 - kl_loss: 502.0013\n",
      "Epoch 2192/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12497.9901 - reconstruction_loss: 11851.8379 - kl_loss: 501.7194\n",
      "Epoch 2193/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12561.8834 - reconstruction_loss: 11867.0137 - kl_loss: 501.5411\n",
      "Epoch 2194/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12440.9579 - reconstruction_loss: 11818.0303 - kl_loss: 500.4560\n",
      "Epoch 2195/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12455.6200 - reconstruction_loss: 11825.1426 - kl_loss: 501.6590\n",
      "Epoch 2196/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12411.5269 - reconstruction_loss: 11786.1924 - kl_loss: 500.6470\n",
      "Epoch 2197/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12463.7801 - reconstruction_loss: 11819.1377 - kl_loss: 500.7047\n",
      "Epoch 2198/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12413.8600 - reconstruction_loss: 11794.3379 - kl_loss: 501.0156\n",
      "Epoch 2199/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12440.3361 - reconstruction_loss: 11806.2803 - kl_loss: 500.1807\n",
      "Epoch 2200/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12399.8863 - reconstruction_loss: 11775.1133 - kl_loss: 499.9901\n",
      "Epoch 2201/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12438.9865 - reconstruction_loss: 11825.3994 - kl_loss: 500.6806\n",
      "Epoch 2202/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12433.2981 - reconstruction_loss: 11789.3789 - kl_loss: 499.7641\n",
      "Epoch 2203/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12416.7954 - reconstruction_loss: 11787.9131 - kl_loss: 499.8708\n",
      "Epoch 2204/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12400.5546 - reconstruction_loss: 11788.7500 - kl_loss: 500.9848\n",
      "Epoch 2205/5000\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 12399.4612 - reconstruction_loss: 11793.6426 - kl_loss: 499.4028\n",
      "Epoch 2206/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 12557.3132 - reconstruction_loss: 11897.8789 - kl_loss: 497.9372\n",
      "Epoch 2207/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12539.2962 - reconstruction_loss: 11902.9473 - kl_loss: 499.5118\n",
      "Epoch 2208/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12477.6180 - reconstruction_loss: 11869.4717 - kl_loss: 499.1199\n",
      "Epoch 2209/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12501.2585 - reconstruction_loss: 11892.0430 - kl_loss: 499.2634\n",
      "Epoch 2210/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12527.5038 - reconstruction_loss: 11941.6475 - kl_loss: 497.7191\n",
      "Epoch 2211/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12776.9782 - reconstruction_loss: 12185.5596 - kl_loss: 499.3392\n",
      "Epoch 2212/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12937.4916 - reconstruction_loss: 12237.7070 - kl_loss: 499.7609\n",
      "Epoch 2213/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12769.8532 - reconstruction_loss: 12174.9150 - kl_loss: 499.2269\n",
      "Epoch 2214/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12624.0356 - reconstruction_loss: 12015.7383 - kl_loss: 500.7707\n",
      "Epoch 2215/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12542.3339 - reconstruction_loss: 11940.8574 - kl_loss: 499.6100\n",
      "Epoch 2216/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12513.2581 - reconstruction_loss: 11915.2373 - kl_loss: 498.2162\n",
      "Epoch 2217/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12489.1714 - reconstruction_loss: 11902.1172 - kl_loss: 498.4414\n",
      "Epoch 2218/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12490.7309 - reconstruction_loss: 11897.1289 - kl_loss: 498.8082\n",
      "Epoch 2219/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12472.4203 - reconstruction_loss: 11881.7314 - kl_loss: 499.1450\n",
      "Epoch 2220/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12436.7528 - reconstruction_loss: 11852.6055 - kl_loss: 498.9318\n",
      "Epoch 2221/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12484.1959 - reconstruction_loss: 11884.7158 - kl_loss: 498.1755\n",
      "Epoch 2222/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12591.7956 - reconstruction_loss: 11983.5332 - kl_loss: 499.5207\n",
      "Epoch 2223/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12473.2189 - reconstruction_loss: 11873.9512 - kl_loss: 498.4749\n",
      "Epoch 2224/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12463.2770 - reconstruction_loss: 11860.0469 - kl_loss: 498.3539\n",
      "Epoch 2225/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12435.3587 - reconstruction_loss: 11836.0820 - kl_loss: 497.1358\n",
      "Epoch 2226/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12445.0624 - reconstruction_loss: 11835.1182 - kl_loss: 497.7473\n",
      "Epoch 2227/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12419.1772 - reconstruction_loss: 11830.1396 - kl_loss: 496.6320\n",
      "Epoch 2228/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12436.4309 - reconstruction_loss: 11834.2793 - kl_loss: 496.8808\n",
      "Epoch 2229/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12412.5979 - reconstruction_loss: 11803.8242 - kl_loss: 497.9934\n",
      "Epoch 2230/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12400.7169 - reconstruction_loss: 11805.3115 - kl_loss: 497.6313\n",
      "Epoch 2231/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12444.5694 - reconstruction_loss: 11827.0439 - kl_loss: 497.7591\n",
      "Epoch 2232/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12469.8326 - reconstruction_loss: 11843.5928 - kl_loss: 497.6403\n",
      "Epoch 2233/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12460.1028 - reconstruction_loss: 11888.0010 - kl_loss: 497.6506\n",
      "Epoch 2234/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12536.6977 - reconstruction_loss: 11897.3779 - kl_loss: 496.5063\n",
      "Epoch 2235/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12657.1835 - reconstruction_loss: 11990.4023 - kl_loss: 497.7443\n",
      "Epoch 2236/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12498.3020 - reconstruction_loss: 11877.3496 - kl_loss: 498.7942\n",
      "Epoch 2237/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12590.7303 - reconstruction_loss: 11908.2578 - kl_loss: 498.0774\n",
      "Epoch 2238/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12460.5627 - reconstruction_loss: 11846.7842 - kl_loss: 497.6845\n",
      "Epoch 2239/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12437.9907 - reconstruction_loss: 11845.5840 - kl_loss: 496.7545\n",
      "Epoch 2240/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12441.8004 - reconstruction_loss: 11845.7812 - kl_loss: 496.6223\n",
      "Epoch 2241/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12469.2354 - reconstruction_loss: 11867.8896 - kl_loss: 497.0009\n",
      "Epoch 2242/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12535.8633 - reconstruction_loss: 11920.7021 - kl_loss: 496.7321\n",
      "Epoch 2243/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12486.7527 - reconstruction_loss: 11882.3213 - kl_loss: 496.5288\n",
      "Epoch 2244/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12512.1641 - reconstruction_loss: 11899.9609 - kl_loss: 496.5756\n",
      "Epoch 2245/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12534.6265 - reconstruction_loss: 11917.6895 - kl_loss: 496.4819\n",
      "Epoch 2246/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12653.6569 - reconstruction_loss: 11963.2754 - kl_loss: 496.1487\n",
      "Epoch 2247/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12758.4329 - reconstruction_loss: 12050.0312 - kl_loss: 495.1120\n",
      "Epoch 2248/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12828.3212 - reconstruction_loss: 12106.1484 - kl_loss: 495.0661\n",
      "Epoch 2249/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13021.5339 - reconstruction_loss: 12231.6445 - kl_loss: 495.0808\n",
      "Epoch 2250/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12998.0202 - reconstruction_loss: 12276.7754 - kl_loss: 494.7417\n",
      "Epoch 2251/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13027.2134 - reconstruction_loss: 12332.6582 - kl_loss: 495.4175\n",
      "Epoch 2252/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13102.9448 - reconstruction_loss: 12401.1426 - kl_loss: 494.9757\n",
      "Epoch 2253/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13320.9599 - reconstruction_loss: 12580.1729 - kl_loss: 494.2477\n",
      "Epoch 2254/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13332.9191 - reconstruction_loss: 12602.6221 - kl_loss: 495.6871\n",
      "Epoch 2255/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13263.0160 - reconstruction_loss: 12587.9316 - kl_loss: 495.3549\n",
      "Epoch 2256/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13274.1680 - reconstruction_loss: 12606.0049 - kl_loss: 495.8354\n",
      "Epoch 2257/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13214.9042 - reconstruction_loss: 12616.4258 - kl_loss: 497.4810\n",
      "Epoch 2258/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13202.1403 - reconstruction_loss: 12595.9160 - kl_loss: 496.0398\n",
      "Epoch 2259/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13187.2599 - reconstruction_loss: 12586.4248 - kl_loss: 495.7614\n",
      "Epoch 2260/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13154.7291 - reconstruction_loss: 12540.9795 - kl_loss: 494.1306\n",
      "Epoch 2261/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13187.0079 - reconstruction_loss: 12560.6338 - kl_loss: 494.8706\n",
      "Epoch 2262/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13154.9493 - reconstruction_loss: 12572.4033 - kl_loss: 493.5271\n",
      "Epoch 2263/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13115.3212 - reconstruction_loss: 12550.3135 - kl_loss: 495.2439\n",
      "Epoch 2264/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13133.9594 - reconstruction_loss: 12538.3701 - kl_loss: 495.1182\n",
      "Epoch 2265/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13162.0069 - reconstruction_loss: 12573.0947 - kl_loss: 495.6512\n",
      "Epoch 2266/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13198.1758 - reconstruction_loss: 12553.6426 - kl_loss: 494.6009\n",
      "Epoch 2267/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13161.9768 - reconstruction_loss: 12563.6797 - kl_loss: 493.9736\n",
      "Epoch 2268/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13176.3281 - reconstruction_loss: 12567.2070 - kl_loss: 495.4766\n",
      "Epoch 2269/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13145.9272 - reconstruction_loss: 12548.2031 - kl_loss: 495.7347\n",
      "Epoch 2270/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 13223.2860 - reconstruction_loss: 12606.3779 - kl_loss: 493.9886\n",
      "Epoch 2271/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 13352.1030 - reconstruction_loss: 12691.4482 - kl_loss: 494.5921\n",
      "Epoch 2272/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13285.2177 - reconstruction_loss: 12646.0850 - kl_loss: 495.4484\n",
      "Epoch 2273/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13173.4713 - reconstruction_loss: 12538.3584 - kl_loss: 496.4953\n",
      "Epoch 2274/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13055.6331 - reconstruction_loss: 12440.8389 - kl_loss: 496.0517\n",
      "Epoch 2275/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 13008.0066 - reconstruction_loss: 12392.6191 - kl_loss: 495.2092\n",
      "Epoch 2276/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12950.0153 - reconstruction_loss: 12349.4229 - kl_loss: 495.0032\n",
      "Epoch 2277/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12907.8606 - reconstruction_loss: 12293.8389 - kl_loss: 494.8791\n",
      "Epoch 2278/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12873.7340 - reconstruction_loss: 12278.4688 - kl_loss: 495.3267\n",
      "Epoch 2279/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12826.3191 - reconstruction_loss: 12215.4434 - kl_loss: 495.5766\n",
      "Epoch 2280/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12825.2587 - reconstruction_loss: 12218.7158 - kl_loss: 495.7822\n",
      "Epoch 2281/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12775.9445 - reconstruction_loss: 12167.5635 - kl_loss: 496.3011\n",
      "Epoch 2282/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12758.4927 - reconstruction_loss: 12164.8877 - kl_loss: 496.8941\n",
      "Epoch 2283/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12700.5774 - reconstruction_loss: 12101.9277 - kl_loss: 497.4028\n",
      "Epoch 2284/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12702.4441 - reconstruction_loss: 12103.1973 - kl_loss: 495.8297\n",
      "Epoch 2285/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12675.4165 - reconstruction_loss: 12066.8691 - kl_loss: 494.9301\n",
      "Epoch 2286/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12624.8154 - reconstruction_loss: 12036.0645 - kl_loss: 495.1299\n",
      "Epoch 2287/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12607.8677 - reconstruction_loss: 12005.0879 - kl_loss: 496.1262\n",
      "Epoch 2288/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12568.3479 - reconstruction_loss: 11976.3877 - kl_loss: 495.2659\n",
      "Epoch 2289/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12568.7718 - reconstruction_loss: 11967.2051 - kl_loss: 494.5274\n",
      "Epoch 2290/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12531.9870 - reconstruction_loss: 11935.8027 - kl_loss: 495.0234\n",
      "Epoch 2291/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 12518.7936 - reconstruction_loss: 11912.3154 - kl_loss: 494.8813\n",
      "Epoch 2292/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12482.8297 - reconstruction_loss: 11893.7695 - kl_loss: 495.8849\n",
      "Epoch 2293/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12504.4891 - reconstruction_loss: 11887.5166 - kl_loss: 495.4405\n",
      "Epoch 2294/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12433.3858 - reconstruction_loss: 11842.0098 - kl_loss: 495.5445\n",
      "Epoch 2295/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12451.0541 - reconstruction_loss: 11838.0752 - kl_loss: 495.2039\n",
      "Epoch 2296/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12424.7769 - reconstruction_loss: 11816.8291 - kl_loss: 494.5476\n",
      "Epoch 2297/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12404.9042 - reconstruction_loss: 11797.3486 - kl_loss: 495.4033\n",
      "Epoch 2298/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12437.9212 - reconstruction_loss: 11800.5791 - kl_loss: 494.1226\n",
      "Epoch 2299/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12367.0077 - reconstruction_loss: 11754.2295 - kl_loss: 495.2088\n",
      "Epoch 2300/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12426.5525 - reconstruction_loss: 11775.2236 - kl_loss: 496.2487\n",
      "Epoch 2301/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12439.5448 - reconstruction_loss: 11764.6162 - kl_loss: 495.7362\n",
      "Epoch 2302/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12321.6411 - reconstruction_loss: 11707.7061 - kl_loss: 495.6895\n",
      "Epoch 2303/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12325.3372 - reconstruction_loss: 11703.3838 - kl_loss: 494.5757\n",
      "Epoch 2304/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12532.0777 - reconstruction_loss: 11806.7178 - kl_loss: 497.5131\n",
      "Epoch 2305/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12301.8720 - reconstruction_loss: 11681.7012 - kl_loss: 496.2902\n",
      "Epoch 2306/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12416.9615 - reconstruction_loss: 11728.2158 - kl_loss: 496.0046\n",
      "Epoch 2307/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12274.9777 - reconstruction_loss: 11641.2373 - kl_loss: 494.7623\n",
      "Epoch 2308/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12237.8274 - reconstruction_loss: 11627.8438 - kl_loss: 494.7010\n",
      "Epoch 2309/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12228.6891 - reconstruction_loss: 11610.6250 - kl_loss: 495.2426\n",
      "Epoch 2310/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12201.7042 - reconstruction_loss: 11596.0654 - kl_loss: 494.5473\n",
      "Epoch 2311/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12230.0872 - reconstruction_loss: 11609.3018 - kl_loss: 495.1473\n",
      "Epoch 2312/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12208.7100 - reconstruction_loss: 11599.5596 - kl_loss: 494.2388\n",
      "Epoch 2313/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12319.7732 - reconstruction_loss: 11681.8652 - kl_loss: 496.9492\n",
      "Epoch 2314/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12198.8247 - reconstruction_loss: 11595.0322 - kl_loss: 494.5701\n",
      "Epoch 2315/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12265.3967 - reconstruction_loss: 11611.1172 - kl_loss: 494.6066\n",
      "Epoch 2316/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 12236.8230 - reconstruction_loss: 11588.1973 - kl_loss: 494.9048\n",
      "Epoch 2317/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12172.3973 - reconstruction_loss: 11540.5430 - kl_loss: 494.2481\n",
      "Epoch 2318/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12148.8081 - reconstruction_loss: 11531.8584 - kl_loss: 492.8147\n",
      "Epoch 2319/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12131.7235 - reconstruction_loss: 11514.6572 - kl_loss: 492.8903\n",
      "Epoch 2320/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12122.2900 - reconstruction_loss: 11512.9316 - kl_loss: 493.0012\n",
      "Epoch 2321/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12179.5333 - reconstruction_loss: 11528.0879 - kl_loss: 492.2632\n",
      "Epoch 2322/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12148.4714 - reconstruction_loss: 11516.6279 - kl_loss: 493.1480\n",
      "Epoch 2323/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 12092.9174 - reconstruction_loss: 11479.4141 - kl_loss: 493.6379\n",
      "Epoch 2324/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12086.1723 - reconstruction_loss: 11473.5752 - kl_loss: 493.1247\n",
      "Epoch 2325/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12073.8385 - reconstruction_loss: 11469.9209 - kl_loss: 492.9700\n",
      "Epoch 2326/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12114.1694 - reconstruction_loss: 11484.1953 - kl_loss: 492.7099\n",
      "Epoch 2327/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12067.2489 - reconstruction_loss: 11460.6553 - kl_loss: 492.4873\n",
      "Epoch 2328/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12102.3159 - reconstruction_loss: 11476.4307 - kl_loss: 492.4468\n",
      "Epoch 2329/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12088.7284 - reconstruction_loss: 11471.7695 - kl_loss: 492.0271\n",
      "Epoch 2330/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12112.6457 - reconstruction_loss: 11484.0879 - kl_loss: 491.9274\n",
      "Epoch 2331/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12099.7688 - reconstruction_loss: 11475.5967 - kl_loss: 491.3625\n",
      "Epoch 2332/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12053.0237 - reconstruction_loss: 11460.4268 - kl_loss: 491.5118\n",
      "Epoch 2333/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12145.6763 - reconstruction_loss: 11524.4297 - kl_loss: 491.1099\n",
      "Epoch 2334/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12086.9160 - reconstruction_loss: 11461.8604 - kl_loss: 491.7954\n",
      "Epoch 2335/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12064.4151 - reconstruction_loss: 11450.5547 - kl_loss: 491.6691\n",
      "Epoch 2336/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12289.9185 - reconstruction_loss: 11591.7012 - kl_loss: 491.3763\n",
      "Epoch 2337/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12288.0003 - reconstruction_loss: 11558.9824 - kl_loss: 491.3541\n",
      "Epoch 2338/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12165.4166 - reconstruction_loss: 11547.5723 - kl_loss: 490.9509\n",
      "Epoch 2339/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12195.3897 - reconstruction_loss: 11520.1758 - kl_loss: 490.9399\n",
      "Epoch 2340/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12092.8915 - reconstruction_loss: 11439.0703 - kl_loss: 491.0730\n",
      "Epoch 2341/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12023.1710 - reconstruction_loss: 11421.5596 - kl_loss: 491.3310\n",
      "Epoch 2342/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12082.9622 - reconstruction_loss: 11448.7510 - kl_loss: 489.9644\n",
      "Epoch 2343/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12185.9741 - reconstruction_loss: 11537.9453 - kl_loss: 491.2818\n",
      "Epoch 2344/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12027.1621 - reconstruction_loss: 11423.0801 - kl_loss: 490.0273\n",
      "Epoch 2345/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12019.0865 - reconstruction_loss: 11401.3965 - kl_loss: 490.0537\n",
      "Epoch 2346/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12019.7669 - reconstruction_loss: 11398.3535 - kl_loss: 490.2030\n",
      "Epoch 2347/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12001.2391 - reconstruction_loss: 11397.1631 - kl_loss: 488.6286\n",
      "Epoch 2348/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11993.1409 - reconstruction_loss: 11386.4678 - kl_loss: 488.2037\n",
      "Epoch 2349/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11995.9593 - reconstruction_loss: 11381.1240 - kl_loss: 488.9007\n",
      "Epoch 2350/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11948.1397 - reconstruction_loss: 11350.2852 - kl_loss: 489.2719\n",
      "Epoch 2351/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11961.0824 - reconstruction_loss: 11357.2061 - kl_loss: 488.6835\n",
      "Epoch 2352/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11964.4920 - reconstruction_loss: 11355.0596 - kl_loss: 488.6551\n",
      "Epoch 2353/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11983.9991 - reconstruction_loss: 11359.3604 - kl_loss: 488.2004\n",
      "Epoch 2354/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11963.2364 - reconstruction_loss: 11365.0352 - kl_loss: 487.5411\n",
      "Epoch 2355/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11983.0418 - reconstruction_loss: 11361.7598 - kl_loss: 488.0334\n",
      "Epoch 2356/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11956.9504 - reconstruction_loss: 11356.1914 - kl_loss: 488.5131\n",
      "Epoch 2357/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12034.5556 - reconstruction_loss: 11403.0322 - kl_loss: 487.7252\n",
      "Epoch 2358/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11965.2689 - reconstruction_loss: 11364.8496 - kl_loss: 486.9392\n",
      "Epoch 2359/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11990.9019 - reconstruction_loss: 11372.3105 - kl_loss: 486.6707\n",
      "Epoch 2360/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11971.2310 - reconstruction_loss: 11360.5322 - kl_loss: 486.7109\n",
      "Epoch 2361/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12014.4314 - reconstruction_loss: 11376.4600 - kl_loss: 487.9550\n",
      "Epoch 2362/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11995.8117 - reconstruction_loss: 11366.9404 - kl_loss: 487.6641\n",
      "Epoch 2363/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11930.8142 - reconstruction_loss: 11321.7295 - kl_loss: 486.8648\n",
      "Epoch 2364/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12007.1510 - reconstruction_loss: 11379.0859 - kl_loss: 487.3303\n",
      "Epoch 2365/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11965.0378 - reconstruction_loss: 11347.2764 - kl_loss: 485.8048\n",
      "Epoch 2366/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 11951.8612 - reconstruction_loss: 11346.4385 - kl_loss: 486.2136\n",
      "Epoch 2367/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12206.7763 - reconstruction_loss: 11456.2041 - kl_loss: 487.4622\n",
      "Epoch 2368/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12039.4265 - reconstruction_loss: 11406.9941 - kl_loss: 485.9278\n",
      "Epoch 2369/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12129.8734 - reconstruction_loss: 11499.0908 - kl_loss: 486.1136\n",
      "Epoch 2370/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12060.1759 - reconstruction_loss: 11406.6191 - kl_loss: 486.2028\n",
      "Epoch 2371/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11994.4580 - reconstruction_loss: 11354.9482 - kl_loss: 486.8059\n",
      "Epoch 2372/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12050.2760 - reconstruction_loss: 11395.5986 - kl_loss: 486.1335\n",
      "Epoch 2373/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12024.2488 - reconstruction_loss: 11364.6240 - kl_loss: 485.1803\n",
      "Epoch 2374/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12006.7071 - reconstruction_loss: 11387.6904 - kl_loss: 484.9610\n",
      "Epoch 2375/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11966.2117 - reconstruction_loss: 11340.5840 - kl_loss: 485.9410\n",
      "Epoch 2376/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11976.2647 - reconstruction_loss: 11371.2627 - kl_loss: 484.0821\n",
      "Epoch 2377/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12016.9930 - reconstruction_loss: 11387.1025 - kl_loss: 484.2018\n",
      "Epoch 2378/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12048.8697 - reconstruction_loss: 11422.3281 - kl_loss: 483.9609\n",
      "Epoch 2379/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12008.3998 - reconstruction_loss: 11418.4609 - kl_loss: 483.7701\n",
      "Epoch 2380/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12092.2787 - reconstruction_loss: 11499.8564 - kl_loss: 483.2271\n",
      "Epoch 2381/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12173.1803 - reconstruction_loss: 11543.6270 - kl_loss: 486.8076\n",
      "Epoch 2382/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12053.4432 - reconstruction_loss: 11451.2471 - kl_loss: 484.8868\n",
      "Epoch 2383/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12046.9541 - reconstruction_loss: 11440.7256 - kl_loss: 483.6896\n",
      "Epoch 2384/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12057.7312 - reconstruction_loss: 11408.9980 - kl_loss: 484.0872\n",
      "Epoch 2385/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12035.9828 - reconstruction_loss: 11421.4893 - kl_loss: 482.9389\n",
      "Epoch 2386/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12054.4737 - reconstruction_loss: 11410.2344 - kl_loss: 484.5442\n",
      "Epoch 2387/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12075.9901 - reconstruction_loss: 11413.6074 - kl_loss: 484.3921\n",
      "Epoch 2388/5000\n",
      "75/75 [==============================] - 2s 31ms/step - loss: 12015.5182 - reconstruction_loss: 11384.1367 - kl_loss: 481.9610\n",
      "Epoch 2389/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12071.6332 - reconstruction_loss: 11415.0088 - kl_loss: 482.6453\n",
      "Epoch 2390/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12056.0268 - reconstruction_loss: 11426.6602 - kl_loss: 483.0930\n",
      "Epoch 2391/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12095.7929 - reconstruction_loss: 11451.7539 - kl_loss: 482.4007\n",
      "Epoch 2392/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12183.0585 - reconstruction_loss: 11546.6514 - kl_loss: 482.0918\n",
      "Epoch 2393/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12174.8554 - reconstruction_loss: 11564.6377 - kl_loss: 482.2172\n",
      "Epoch 2394/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12191.7726 - reconstruction_loss: 11561.4375 - kl_loss: 483.7083\n",
      "Epoch 2395/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12285.5206 - reconstruction_loss: 11644.1055 - kl_loss: 483.1704\n",
      "Epoch 2396/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12286.0146 - reconstruction_loss: 11619.9893 - kl_loss: 482.4258\n",
      "Epoch 2397/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12369.5406 - reconstruction_loss: 11701.7217 - kl_loss: 481.6164\n",
      "Epoch 2398/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12378.5346 - reconstruction_loss: 11739.6611 - kl_loss: 481.5483\n",
      "Epoch 2399/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12500.6731 - reconstruction_loss: 11826.3525 - kl_loss: 481.2922\n",
      "Epoch 2400/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12404.6853 - reconstruction_loss: 11726.8691 - kl_loss: 482.0310\n",
      "Epoch 2401/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12351.7743 - reconstruction_loss: 11685.6201 - kl_loss: 482.3718\n",
      "Epoch 2402/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12505.5420 - reconstruction_loss: 11767.1797 - kl_loss: 482.0648\n",
      "Epoch 2403/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12374.0564 - reconstruction_loss: 11720.4033 - kl_loss: 482.6261\n",
      "Epoch 2404/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12332.2736 - reconstruction_loss: 11694.8848 - kl_loss: 481.7125\n",
      "Epoch 2405/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12339.1277 - reconstruction_loss: 11692.6650 - kl_loss: 481.8589\n",
      "Epoch 2406/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12366.3715 - reconstruction_loss: 11705.7285 - kl_loss: 481.8304\n",
      "Epoch 2407/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12368.0377 - reconstruction_loss: 11700.6777 - kl_loss: 481.4886\n",
      "Epoch 2408/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12393.5885 - reconstruction_loss: 11708.5791 - kl_loss: 482.3625\n",
      "Epoch 2409/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12357.9028 - reconstruction_loss: 11694.6230 - kl_loss: 481.7285\n",
      "Epoch 2410/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12297.9394 - reconstruction_loss: 11665.6914 - kl_loss: 481.8152\n",
      "Epoch 2411/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12311.6136 - reconstruction_loss: 11654.2725 - kl_loss: 481.4910\n",
      "Epoch 2412/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12277.2588 - reconstruction_loss: 11650.4570 - kl_loss: 481.3273\n",
      "Epoch 2413/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12291.6205 - reconstruction_loss: 11675.6045 - kl_loss: 481.2395\n",
      "Epoch 2414/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12300.5654 - reconstruction_loss: 11673.0645 - kl_loss: 480.5234\n",
      "Epoch 2415/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12289.6920 - reconstruction_loss: 11662.8545 - kl_loss: 482.6527\n",
      "Epoch 2416/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12293.1824 - reconstruction_loss: 11647.3486 - kl_loss: 481.0296\n",
      "Epoch 2417/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12301.8771 - reconstruction_loss: 11660.2354 - kl_loss: 481.7303\n",
      "Epoch 2418/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12270.7880 - reconstruction_loss: 11656.6162 - kl_loss: 481.4026\n",
      "Epoch 2419/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 12286.1560 - reconstruction_loss: 11664.6445 - kl_loss: 481.4170\n",
      "Epoch 2420/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12306.0922 - reconstruction_loss: 11674.2725 - kl_loss: 481.2297\n",
      "Epoch 2421/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12293.1055 - reconstruction_loss: 11650.0020 - kl_loss: 481.8808\n",
      "Epoch 2422/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12253.2015 - reconstruction_loss: 11646.1191 - kl_loss: 481.8808\n",
      "Epoch 2423/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12262.7205 - reconstruction_loss: 11640.3369 - kl_loss: 482.1136\n",
      "Epoch 2424/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12236.0923 - reconstruction_loss: 11627.8604 - kl_loss: 481.8125\n",
      "Epoch 2425/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12266.5467 - reconstruction_loss: 11635.6182 - kl_loss: 483.3359\n",
      "Epoch 2426/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12302.1005 - reconstruction_loss: 11663.5352 - kl_loss: 482.0459\n",
      "Epoch 2427/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12301.5661 - reconstruction_loss: 11663.2324 - kl_loss: 481.2336\n",
      "Epoch 2428/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12308.5274 - reconstruction_loss: 11684.7900 - kl_loss: 481.7335\n",
      "Epoch 2429/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12222.8392 - reconstruction_loss: 11628.8516 - kl_loss: 481.3671\n",
      "Epoch 2430/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12290.8167 - reconstruction_loss: 11663.8457 - kl_loss: 480.5437\n",
      "Epoch 2431/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12223.1007 - reconstruction_loss: 11618.7178 - kl_loss: 481.0192\n",
      "Epoch 2432/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12184.4456 - reconstruction_loss: 11598.8457 - kl_loss: 481.5396\n",
      "Epoch 2433/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12186.7256 - reconstruction_loss: 11585.2959 - kl_loss: 480.9033\n",
      "Epoch 2434/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12187.7772 - reconstruction_loss: 11606.5781 - kl_loss: 480.0543\n",
      "Epoch 2435/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12198.5629 - reconstruction_loss: 11594.0645 - kl_loss: 480.5761\n",
      "Epoch 2436/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12174.1424 - reconstruction_loss: 11586.2432 - kl_loss: 481.3013\n",
      "Epoch 2437/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12167.8852 - reconstruction_loss: 11567.5918 - kl_loss: 481.1855\n",
      "Epoch 2438/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12154.0701 - reconstruction_loss: 11576.1914 - kl_loss: 481.1652\n",
      "Epoch 2439/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12177.1366 - reconstruction_loss: 11581.1592 - kl_loss: 479.6034\n",
      "Epoch 2440/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12176.2670 - reconstruction_loss: 11581.1445 - kl_loss: 480.7162\n",
      "Epoch 2441/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12163.0433 - reconstruction_loss: 11566.7100 - kl_loss: 481.5162\n",
      "Epoch 2442/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12162.4677 - reconstruction_loss: 11579.6387 - kl_loss: 481.0257\n",
      "Epoch 2443/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12178.1198 - reconstruction_loss: 11581.9824 - kl_loss: 479.8717\n",
      "Epoch 2444/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12164.9872 - reconstruction_loss: 11568.7686 - kl_loss: 480.7159\n",
      "Epoch 2445/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12181.4068 - reconstruction_loss: 11570.3057 - kl_loss: 481.0652\n",
      "Epoch 2446/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12192.2429 - reconstruction_loss: 11589.5088 - kl_loss: 480.0265\n",
      "Epoch 2447/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12202.8398 - reconstruction_loss: 11607.3330 - kl_loss: 480.0812\n",
      "Epoch 2448/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12270.8210 - reconstruction_loss: 11634.8984 - kl_loss: 481.3895\n",
      "Epoch 2449/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12278.9871 - reconstruction_loss: 11645.8965 - kl_loss: 480.7124\n",
      "Epoch 2450/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12343.6745 - reconstruction_loss: 11722.4033 - kl_loss: 477.8299\n",
      "Epoch 2451/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12433.2660 - reconstruction_loss: 11773.9873 - kl_loss: 480.0089\n",
      "Epoch 2452/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12498.7231 - reconstruction_loss: 11867.7285 - kl_loss: 480.1696\n",
      "Epoch 2453/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12749.8868 - reconstruction_loss: 12013.5049 - kl_loss: 479.6002\n",
      "Epoch 2454/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 12960.4975 - reconstruction_loss: 12162.8154 - kl_loss: 477.8126\n",
      "Epoch 2455/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12843.9038 - reconstruction_loss: 12091.5410 - kl_loss: 478.3424\n",
      "Epoch 2456/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12701.2141 - reconstruction_loss: 12033.3086 - kl_loss: 480.0527\n",
      "Epoch 2457/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12466.8098 - reconstruction_loss: 11924.8369 - kl_loss: 480.3927\n",
      "Epoch 2458/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12530.1087 - reconstruction_loss: 11954.3047 - kl_loss: 478.9449\n",
      "Epoch 2459/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12450.5691 - reconstruction_loss: 11912.6348 - kl_loss: 479.8233\n",
      "Epoch 2460/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12445.5815 - reconstruction_loss: 11904.1123 - kl_loss: 480.1988\n",
      "Epoch 2461/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12372.9737 - reconstruction_loss: 11870.0732 - kl_loss: 479.3398\n",
      "Epoch 2462/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12367.0425 - reconstruction_loss: 11852.9180 - kl_loss: 479.1878\n",
      "Epoch 2463/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12327.4000 - reconstruction_loss: 11844.0908 - kl_loss: 479.7878\n",
      "Epoch 2464/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12311.3700 - reconstruction_loss: 11802.4980 - kl_loss: 480.3168\n",
      "Epoch 2465/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12289.4526 - reconstruction_loss: 11801.6484 - kl_loss: 479.1769\n",
      "Epoch 2466/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 12234.9032 - reconstruction_loss: 11738.1729 - kl_loss: 479.4458\n",
      "Epoch 2467/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 12215.0577 - reconstruction_loss: 11726.7178 - kl_loss: 479.9682\n",
      "Epoch 2468/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 12222.5555 - reconstruction_loss: 11726.6953 - kl_loss: 479.7579\n",
      "Epoch 2469/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12195.2671 - reconstruction_loss: 11686.9092 - kl_loss: 480.1941\n",
      "Epoch 2470/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 12158.8586 - reconstruction_loss: 11653.9473 - kl_loss: 480.5051\n",
      "Epoch 2471/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 12163.2441 - reconstruction_loss: 11652.9883 - kl_loss: 480.4772\n",
      "Epoch 2472/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12138.7824 - reconstruction_loss: 11628.2764 - kl_loss: 480.0294\n",
      "Epoch 2473/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12129.3824 - reconstruction_loss: 11617.9570 - kl_loss: 479.9270\n",
      "Epoch 2474/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12109.5903 - reconstruction_loss: 11584.0723 - kl_loss: 480.0090\n",
      "Epoch 2475/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12086.3249 - reconstruction_loss: 11563.4668 - kl_loss: 481.2686\n",
      "Epoch 2476/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12073.0290 - reconstruction_loss: 11557.9736 - kl_loss: 479.5475\n",
      "Epoch 2477/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12066.1745 - reconstruction_loss: 11527.5479 - kl_loss: 479.5579\n",
      "Epoch 2478/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12041.9520 - reconstruction_loss: 11494.8438 - kl_loss: 480.9657\n",
      "Epoch 2479/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12026.6781 - reconstruction_loss: 11490.6260 - kl_loss: 480.1177\n",
      "Epoch 2480/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11999.2260 - reconstruction_loss: 11465.8643 - kl_loss: 478.8937\n",
      "Epoch 2481/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 12062.1255 - reconstruction_loss: 11500.8477 - kl_loss: 480.6615\n",
      "Epoch 2482/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12007.7046 - reconstruction_loss: 11448.7236 - kl_loss: 480.2454\n",
      "Epoch 2483/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12042.8040 - reconstruction_loss: 11492.8965 - kl_loss: 480.1111\n",
      "Epoch 2484/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12000.8605 - reconstruction_loss: 11413.1396 - kl_loss: 481.1153\n",
      "Epoch 2485/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11934.4624 - reconstruction_loss: 11387.0859 - kl_loss: 481.0546\n",
      "Epoch 2486/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11942.9778 - reconstruction_loss: 11377.1621 - kl_loss: 481.1499\n",
      "Epoch 2487/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11900.3085 - reconstruction_loss: 11326.3760 - kl_loss: 480.0729\n",
      "Epoch 2488/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11885.5122 - reconstruction_loss: 11322.8848 - kl_loss: 479.4989\n",
      "Epoch 2489/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11866.2717 - reconstruction_loss: 11294.4580 - kl_loss: 480.4643\n",
      "Epoch 2490/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11827.7162 - reconstruction_loss: 11271.1709 - kl_loss: 480.1104\n",
      "Epoch 2491/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11825.6877 - reconstruction_loss: 11265.5566 - kl_loss: 479.8352\n",
      "Epoch 2492/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11790.6537 - reconstruction_loss: 11234.0566 - kl_loss: 479.0753\n",
      "Epoch 2493/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11808.0279 - reconstruction_loss: 11242.3809 - kl_loss: 478.3880\n",
      "Epoch 2494/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11772.8543 - reconstruction_loss: 11209.2441 - kl_loss: 479.3336\n",
      "Epoch 2495/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11781.6312 - reconstruction_loss: 11214.3213 - kl_loss: 478.9092\n",
      "Epoch 2496/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11769.5621 - reconstruction_loss: 11191.4150 - kl_loss: 479.3039\n",
      "Epoch 2497/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11802.7119 - reconstruction_loss: 11231.0176 - kl_loss: 479.1750\n",
      "Epoch 2498/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11863.7438 - reconstruction_loss: 11268.3672 - kl_loss: 479.4657\n",
      "Epoch 2499/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11763.4726 - reconstruction_loss: 11190.7129 - kl_loss: 479.7835\n",
      "Epoch 2500/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11784.8658 - reconstruction_loss: 11182.4141 - kl_loss: 479.0097\n",
      "Epoch 2501/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11771.4656 - reconstruction_loss: 11173.6475 - kl_loss: 479.6584\n",
      "Epoch 2502/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11769.1681 - reconstruction_loss: 11196.9287 - kl_loss: 478.6182\n",
      "Epoch 2503/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11871.8622 - reconstruction_loss: 11214.5479 - kl_loss: 478.6904\n",
      "Epoch 2504/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11793.2961 - reconstruction_loss: 11162.6104 - kl_loss: 479.4745\n",
      "Epoch 2505/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11749.0116 - reconstruction_loss: 11168.2783 - kl_loss: 479.2153\n",
      "Epoch 2506/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11830.5969 - reconstruction_loss: 11183.4951 - kl_loss: 477.8712\n",
      "Epoch 2507/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11727.6944 - reconstruction_loss: 11134.6699 - kl_loss: 477.7265\n",
      "Epoch 2508/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11718.4276 - reconstruction_loss: 11125.5430 - kl_loss: 478.9343\n",
      "Epoch 2509/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11733.2278 - reconstruction_loss: 11112.3662 - kl_loss: 477.6654\n",
      "Epoch 2510/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11678.4369 - reconstruction_loss: 11090.7227 - kl_loss: 477.8227\n",
      "Epoch 2511/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11681.7378 - reconstruction_loss: 11081.6836 - kl_loss: 477.0013\n",
      "Epoch 2512/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11647.4656 - reconstruction_loss: 11062.8877 - kl_loss: 477.6686\n",
      "Epoch 2513/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11642.8593 - reconstruction_loss: 11055.6113 - kl_loss: 477.8285\n",
      "Epoch 2514/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11648.7143 - reconstruction_loss: 11059.2061 - kl_loss: 478.0427\n",
      "Epoch 2515/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11633.8934 - reconstruction_loss: 11051.1738 - kl_loss: 477.7146\n",
      "Epoch 2516/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11674.0379 - reconstruction_loss: 11079.1631 - kl_loss: 477.7864\n",
      "Epoch 2517/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11639.8134 - reconstruction_loss: 11050.7646 - kl_loss: 477.5644\n",
      "Epoch 2518/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11667.2193 - reconstruction_loss: 11075.7461 - kl_loss: 476.7692\n",
      "Epoch 2519/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11652.8179 - reconstruction_loss: 11050.6074 - kl_loss: 476.9135\n",
      "Epoch 2520/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11659.4429 - reconstruction_loss: 11074.9648 - kl_loss: 478.9933\n",
      "Epoch 2521/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11690.5836 - reconstruction_loss: 11070.5098 - kl_loss: 477.5125\n",
      "Epoch 2522/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11608.8448 - reconstruction_loss: 11018.2490 - kl_loss: 476.7722\n",
      "Epoch 2523/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11648.0903 - reconstruction_loss: 11050.7510 - kl_loss: 476.3445\n",
      "Epoch 2524/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11735.0736 - reconstruction_loss: 11132.8408 - kl_loss: 478.4130\n",
      "Epoch 2525/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11630.9028 - reconstruction_loss: 11027.8730 - kl_loss: 476.6945\n",
      "Epoch 2526/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11720.1304 - reconstruction_loss: 11087.7354 - kl_loss: 475.2246\n",
      "Epoch 2527/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11671.9083 - reconstruction_loss: 11030.4414 - kl_loss: 475.1740\n",
      "Epoch 2528/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11633.3431 - reconstruction_loss: 11042.6924 - kl_loss: 475.4702\n",
      "Epoch 2529/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11604.2847 - reconstruction_loss: 11005.8672 - kl_loss: 476.1189\n",
      "Epoch 2530/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11556.0599 - reconstruction_loss: 10970.9883 - kl_loss: 476.0614\n",
      "Epoch 2531/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11592.9417 - reconstruction_loss: 11005.2988 - kl_loss: 475.2654\n",
      "Epoch 2532/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11618.9431 - reconstruction_loss: 10997.4902 - kl_loss: 474.4776\n",
      "Epoch 2533/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11659.2839 - reconstruction_loss: 11039.7900 - kl_loss: 474.7045\n",
      "Epoch 2534/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11701.1152 - reconstruction_loss: 11067.4053 - kl_loss: 473.9601\n",
      "Epoch 2535/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14679.6182 - reconstruction_loss: 13798.3916 - kl_loss: 504.6927\n",
      "Epoch 2536/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12933.8894 - reconstruction_loss: 11725.5488 - kl_loss: 488.0435\n",
      "Epoch 2537/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11924.5452 - reconstruction_loss: 11265.4316 - kl_loss: 480.9481\n",
      "Epoch 2538/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11729.7746 - reconstruction_loss: 11115.7480 - kl_loss: 480.1264\n",
      "Epoch 2539/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11675.0567 - reconstruction_loss: 11070.5918 - kl_loss: 477.3133\n",
      "Epoch 2540/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11671.0279 - reconstruction_loss: 11057.0762 - kl_loss: 475.0782\n",
      "Epoch 2541/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11610.5875 - reconstruction_loss: 11017.3838 - kl_loss: 474.3387\n",
      "Epoch 2542/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11594.6356 - reconstruction_loss: 10997.1934 - kl_loss: 474.8642\n",
      "Epoch 2543/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11605.0970 - reconstruction_loss: 11003.7363 - kl_loss: 474.4026\n",
      "Epoch 2544/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11571.0835 - reconstruction_loss: 10981.2461 - kl_loss: 473.7844\n",
      "Epoch 2545/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11548.9228 - reconstruction_loss: 10962.3164 - kl_loss: 473.5224\n",
      "Epoch 2546/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11532.7475 - reconstruction_loss: 10946.9600 - kl_loss: 471.9332\n",
      "Epoch 2547/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11519.0755 - reconstruction_loss: 10937.0312 - kl_loss: 471.5569\n",
      "Epoch 2548/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11524.7826 - reconstruction_loss: 10939.0303 - kl_loss: 473.3124\n",
      "Epoch 2549/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11490.5290 - reconstruction_loss: 10920.6934 - kl_loss: 472.0464\n",
      "Epoch 2550/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11497.9121 - reconstruction_loss: 10917.5869 - kl_loss: 472.4749\n",
      "Epoch 2551/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11496.6203 - reconstruction_loss: 10911.7129 - kl_loss: 472.3669\n",
      "Epoch 2552/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11478.5734 - reconstruction_loss: 10906.0430 - kl_loss: 471.8360\n",
      "Epoch 2553/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11493.2636 - reconstruction_loss: 10905.1377 - kl_loss: 473.1969\n",
      "Epoch 2554/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11481.9498 - reconstruction_loss: 10900.7920 - kl_loss: 472.2227\n",
      "Epoch 2555/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11471.5419 - reconstruction_loss: 10883.6084 - kl_loss: 472.4831\n",
      "Epoch 2556/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11460.5828 - reconstruction_loss: 10879.5586 - kl_loss: 471.9342\n",
      "Epoch 2557/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11454.2598 - reconstruction_loss: 10870.1348 - kl_loss: 472.1989\n",
      "Epoch 2558/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11445.7341 - reconstruction_loss: 10866.0088 - kl_loss: 471.5405\n",
      "Epoch 2559/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11446.1188 - reconstruction_loss: 10867.3027 - kl_loss: 470.6450\n",
      "Epoch 2560/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11448.0142 - reconstruction_loss: 10868.4229 - kl_loss: 470.7656\n",
      "Epoch 2561/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11443.8599 - reconstruction_loss: 10861.4990 - kl_loss: 470.4424\n",
      "Epoch 2562/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11462.5438 - reconstruction_loss: 10871.6816 - kl_loss: 470.9435\n",
      "Epoch 2563/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11425.0599 - reconstruction_loss: 10845.2588 - kl_loss: 471.1063\n",
      "Epoch 2564/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11465.8333 - reconstruction_loss: 10886.6846 - kl_loss: 469.9911\n",
      "Epoch 2565/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11631.2040 - reconstruction_loss: 11022.9268 - kl_loss: 471.0394\n",
      "Epoch 2566/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11466.4229 - reconstruction_loss: 10893.3945 - kl_loss: 471.1952\n",
      "Epoch 2567/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 11475.4806 - reconstruction_loss: 10864.0000 - kl_loss: 470.4405\n",
      "Epoch 2568/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11408.3274 - reconstruction_loss: 10819.9521 - kl_loss: 470.1254\n",
      "Epoch 2569/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11417.8549 - reconstruction_loss: 10835.7070 - kl_loss: 470.4267\n",
      "Epoch 2570/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11400.3479 - reconstruction_loss: 10809.1523 - kl_loss: 470.0396\n",
      "Epoch 2571/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11385.8929 - reconstruction_loss: 10806.1699 - kl_loss: 469.8960\n",
      "Epoch 2572/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11378.6320 - reconstruction_loss: 10800.3184 - kl_loss: 469.8079\n",
      "Epoch 2573/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11374.3229 - reconstruction_loss: 10788.8457 - kl_loss: 469.9507\n",
      "Epoch 2574/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11371.0913 - reconstruction_loss: 10791.5996 - kl_loss: 469.6961\n",
      "Epoch 2575/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11388.3925 - reconstruction_loss: 10797.4492 - kl_loss: 469.6217\n",
      "Epoch 2576/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 11397.5671 - reconstruction_loss: 10800.3105 - kl_loss: 469.7653\n",
      "Epoch 2577/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 11416.0287 - reconstruction_loss: 10817.7734 - kl_loss: 469.1155\n",
      "Epoch 2578/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11414.7382 - reconstruction_loss: 10833.9033 - kl_loss: 468.2483\n",
      "Epoch 2579/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11400.2104 - reconstruction_loss: 10802.9854 - kl_loss: 469.6624\n",
      "Epoch 2580/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11368.2821 - reconstruction_loss: 10785.3096 - kl_loss: 468.5271\n",
      "Epoch 2581/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11345.4768 - reconstruction_loss: 10768.1924 - kl_loss: 468.8131\n",
      "Epoch 2582/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11351.6981 - reconstruction_loss: 10766.5078 - kl_loss: 468.5322\n",
      "Epoch 2583/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11351.5037 - reconstruction_loss: 10770.7578 - kl_loss: 467.5026\n",
      "Epoch 2584/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11372.6164 - reconstruction_loss: 10780.5430 - kl_loss: 467.5802\n",
      "Epoch 2585/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11382.6170 - reconstruction_loss: 10777.6758 - kl_loss: 468.2170\n",
      "Epoch 2586/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 11342.6244 - reconstruction_loss: 10759.5439 - kl_loss: 467.9483\n",
      "Epoch 2587/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11340.5370 - reconstruction_loss: 10769.1006 - kl_loss: 467.2405\n",
      "Epoch 2588/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11323.6866 - reconstruction_loss: 10745.8496 - kl_loss: 467.4637\n",
      "Epoch 2589/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11333.2572 - reconstruction_loss: 10750.6152 - kl_loss: 467.5471\n",
      "Epoch 2590/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11322.2567 - reconstruction_loss: 10757.5586 - kl_loss: 467.2032\n",
      "Epoch 2591/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11420.5236 - reconstruction_loss: 10836.4111 - kl_loss: 467.1840\n",
      "Epoch 2592/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11375.8967 - reconstruction_loss: 10784.4043 - kl_loss: 466.4323\n",
      "Epoch 2593/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11358.2755 - reconstruction_loss: 10775.9990 - kl_loss: 466.7639\n",
      "Epoch 2594/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11464.6212 - reconstruction_loss: 10872.8242 - kl_loss: 467.1727\n",
      "Epoch 2595/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11471.7991 - reconstruction_loss: 10858.6250 - kl_loss: 466.4722\n",
      "Epoch 2596/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11489.0413 - reconstruction_loss: 10901.0371 - kl_loss: 466.2370\n",
      "Epoch 2597/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11484.0289 - reconstruction_loss: 10858.7979 - kl_loss: 465.9437\n",
      "Epoch 2598/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11426.5480 - reconstruction_loss: 10870.7891 - kl_loss: 465.7032\n",
      "Epoch 2599/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11475.4613 - reconstruction_loss: 10892.4932 - kl_loss: 466.4513\n",
      "Epoch 2600/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11474.0474 - reconstruction_loss: 10890.1475 - kl_loss: 466.4591\n",
      "Epoch 2601/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11586.1364 - reconstruction_loss: 10960.6064 - kl_loss: 467.8992\n",
      "Epoch 2602/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11587.2200 - reconstruction_loss: 10974.1768 - kl_loss: 465.8662\n",
      "Epoch 2603/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11534.4484 - reconstruction_loss: 10980.4277 - kl_loss: 464.9358\n",
      "Epoch 2604/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11661.8767 - reconstruction_loss: 11063.7158 - kl_loss: 465.2036\n",
      "Epoch 2605/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11929.1415 - reconstruction_loss: 11196.4795 - kl_loss: 464.6178\n",
      "Epoch 2606/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12121.9460 - reconstruction_loss: 11421.5225 - kl_loss: 467.1795\n",
      "Epoch 2607/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11960.2651 - reconstruction_loss: 11291.2383 - kl_loss: 468.2846\n",
      "Epoch 2608/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11743.1808 - reconstruction_loss: 11157.6064 - kl_loss: 467.3569\n",
      "Epoch 2609/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11736.2894 - reconstruction_loss: 11126.1113 - kl_loss: 466.5492\n",
      "Epoch 2610/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11763.9528 - reconstruction_loss: 11131.1982 - kl_loss: 467.0246\n",
      "Epoch 2611/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11843.0608 - reconstruction_loss: 11152.1572 - kl_loss: 465.6535\n",
      "Epoch 2612/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11885.4913 - reconstruction_loss: 11141.9033 - kl_loss: 465.0095\n",
      "Epoch 2613/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11798.4474 - reconstruction_loss: 11068.9727 - kl_loss: 466.8268\n",
      "Epoch 2614/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11662.7199 - reconstruction_loss: 11006.9004 - kl_loss: 465.2709\n",
      "Epoch 2615/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11636.6460 - reconstruction_loss: 10989.4590 - kl_loss: 465.5005\n",
      "Epoch 2616/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11625.8828 - reconstruction_loss: 10999.1895 - kl_loss: 465.1610\n",
      "Epoch 2617/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11628.6396 - reconstruction_loss: 10986.0420 - kl_loss: 466.9055\n",
      "Epoch 2618/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11575.9401 - reconstruction_loss: 10958.3926 - kl_loss: 466.3846\n",
      "Epoch 2619/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11533.3231 - reconstruction_loss: 10938.6953 - kl_loss: 466.0595\n",
      "Epoch 2620/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11560.1437 - reconstruction_loss: 10935.4707 - kl_loss: 466.1253\n",
      "Epoch 2621/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11529.7541 - reconstruction_loss: 10925.5439 - kl_loss: 465.9620\n",
      "Epoch 2622/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11504.0452 - reconstruction_loss: 10908.5195 - kl_loss: 466.4462\n",
      "Epoch 2623/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11477.4804 - reconstruction_loss: 10886.6650 - kl_loss: 465.0625\n",
      "Epoch 2624/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11455.6053 - reconstruction_loss: 10885.3604 - kl_loss: 465.8213\n",
      "Epoch 2625/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11467.1258 - reconstruction_loss: 10888.7090 - kl_loss: 465.7605\n",
      "Epoch 2626/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11463.1446 - reconstruction_loss: 10865.3564 - kl_loss: 466.2935\n",
      "Epoch 2627/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11424.1053 - reconstruction_loss: 10843.0654 - kl_loss: 465.3414\n",
      "Epoch 2628/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11490.1657 - reconstruction_loss: 10878.1855 - kl_loss: 464.6880\n",
      "Epoch 2629/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11440.8828 - reconstruction_loss: 10845.7559 - kl_loss: 464.5708\n",
      "Epoch 2630/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11407.8429 - reconstruction_loss: 10840.4150 - kl_loss: 465.1390\n",
      "Epoch 2631/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11473.0129 - reconstruction_loss: 10865.9688 - kl_loss: 465.3829\n",
      "Epoch 2632/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11361.3220 - reconstruction_loss: 10796.5596 - kl_loss: 465.8689\n",
      "Epoch 2633/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11367.9934 - reconstruction_loss: 10794.2188 - kl_loss: 464.1270\n",
      "Epoch 2634/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11314.0208 - reconstruction_loss: 10758.0430 - kl_loss: 464.9536\n",
      "Epoch 2635/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11321.7453 - reconstruction_loss: 10771.9277 - kl_loss: 465.5474\n",
      "Epoch 2636/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11285.3657 - reconstruction_loss: 10725.0430 - kl_loss: 465.4565\n",
      "Epoch 2637/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11271.7064 - reconstruction_loss: 10731.1504 - kl_loss: 464.4222\n",
      "Epoch 2638/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11282.9958 - reconstruction_loss: 10708.3076 - kl_loss: 465.2338\n",
      "Epoch 2639/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11238.3399 - reconstruction_loss: 10684.1787 - kl_loss: 464.7507\n",
      "Epoch 2640/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11239.7283 - reconstruction_loss: 10702.9580 - kl_loss: 464.7930\n",
      "Epoch 2641/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11220.3627 - reconstruction_loss: 10679.1064 - kl_loss: 464.2970\n",
      "Epoch 2642/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11238.3239 - reconstruction_loss: 10688.2432 - kl_loss: 464.0753\n",
      "Epoch 2643/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11210.7727 - reconstruction_loss: 10661.2705 - kl_loss: 463.6392\n",
      "Epoch 2644/5000\n",
      "75/75 [==============================] - 2s 29ms/step - loss: 11173.4878 - reconstruction_loss: 10635.0869 - kl_loss: 463.3148\n",
      "Epoch 2645/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 11206.7866 - reconstruction_loss: 10660.0918 - kl_loss: 463.3760\n",
      "Epoch 2646/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11159.6623 - reconstruction_loss: 10619.5674 - kl_loss: 464.3013\n",
      "Epoch 2647/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 11187.8739 - reconstruction_loss: 10652.3467 - kl_loss: 463.8376\n",
      "Epoch 2648/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11195.1233 - reconstruction_loss: 10628.9463 - kl_loss: 463.7693\n",
      "Epoch 2649/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11143.4887 - reconstruction_loss: 10621.5215 - kl_loss: 462.6710\n",
      "Epoch 2650/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11192.9188 - reconstruction_loss: 10635.3340 - kl_loss: 463.9252\n",
      "Epoch 2651/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11138.5814 - reconstruction_loss: 10603.7783 - kl_loss: 462.4194\n",
      "Epoch 2652/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11194.6561 - reconstruction_loss: 10650.9932 - kl_loss: 463.2925\n",
      "Epoch 2653/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11156.2139 - reconstruction_loss: 10604.6025 - kl_loss: 463.1063\n",
      "Epoch 2654/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11148.0500 - reconstruction_loss: 10603.8672 - kl_loss: 463.2764\n",
      "Epoch 2655/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11178.4100 - reconstruction_loss: 10624.1006 - kl_loss: 463.4692\n",
      "Epoch 2656/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11108.4909 - reconstruction_loss: 10592.7139 - kl_loss: 463.5330\n",
      "Epoch 2657/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11185.3406 - reconstruction_loss: 10614.5059 - kl_loss: 464.3795\n",
      "Epoch 2658/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11124.6525 - reconstruction_loss: 10572.5430 - kl_loss: 464.3883\n",
      "Epoch 2659/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11107.7504 - reconstruction_loss: 10582.2158 - kl_loss: 462.8073\n",
      "Epoch 2660/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11413.4918 - reconstruction_loss: 10840.2578 - kl_loss: 464.3371\n",
      "Epoch 2661/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11120.3746 - reconstruction_loss: 10575.2344 - kl_loss: 463.4926\n",
      "Epoch 2662/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11123.0032 - reconstruction_loss: 10571.2441 - kl_loss: 461.7709\n",
      "Epoch 2663/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11062.9989 - reconstruction_loss: 10544.8584 - kl_loss: 462.5251\n",
      "Epoch 2664/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11170.3865 - reconstruction_loss: 10606.7725 - kl_loss: 462.5098\n",
      "Epoch 2665/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11120.4167 - reconstruction_loss: 10563.7031 - kl_loss: 461.5971\n",
      "Epoch 2666/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11113.9700 - reconstruction_loss: 10572.7402 - kl_loss: 461.6943\n",
      "Epoch 2667/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11077.3871 - reconstruction_loss: 10545.7041 - kl_loss: 461.4022\n",
      "Epoch 2668/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11039.6760 - reconstruction_loss: 10522.9580 - kl_loss: 462.3160\n",
      "Epoch 2669/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11110.8464 - reconstruction_loss: 10564.0078 - kl_loss: 462.1247\n",
      "Epoch 2670/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11041.3983 - reconstruction_loss: 10520.4111 - kl_loss: 461.3266\n",
      "Epoch 2671/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11117.3367 - reconstruction_loss: 10582.0127 - kl_loss: 461.2538\n",
      "Epoch 2672/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11076.8701 - reconstruction_loss: 10531.2969 - kl_loss: 462.0073\n",
      "Epoch 2673/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11036.6866 - reconstruction_loss: 10527.0195 - kl_loss: 461.2502\n",
      "Epoch 2674/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11134.0844 - reconstruction_loss: 10563.3223 - kl_loss: 461.0600\n",
      "Epoch 2675/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11063.5279 - reconstruction_loss: 10519.5430 - kl_loss: 461.2151\n",
      "Epoch 2676/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11104.9405 - reconstruction_loss: 10555.0205 - kl_loss: 461.6619\n",
      "Epoch 2677/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11086.8103 - reconstruction_loss: 10534.4736 - kl_loss: 460.5479\n",
      "Epoch 2678/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11024.7096 - reconstruction_loss: 10509.4473 - kl_loss: 461.8047\n",
      "Epoch 2679/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11037.0019 - reconstruction_loss: 10520.7988 - kl_loss: 461.6159\n",
      "Epoch 2680/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11114.5753 - reconstruction_loss: 10542.5771 - kl_loss: 460.9643\n",
      "Epoch 2681/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11086.6437 - reconstruction_loss: 10546.6494 - kl_loss: 459.6985\n",
      "Epoch 2682/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11138.1313 - reconstruction_loss: 10596.1709 - kl_loss: 460.1473\n",
      "Epoch 2683/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11113.3225 - reconstruction_loss: 10552.6006 - kl_loss: 460.9381\n",
      "Epoch 2684/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11062.4360 - reconstruction_loss: 10530.2461 - kl_loss: 460.5490\n",
      "Epoch 2685/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11084.1176 - reconstruction_loss: 10548.1328 - kl_loss: 459.8569\n",
      "Epoch 2686/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11056.6728 - reconstruction_loss: 10519.1475 - kl_loss: 459.9561\n",
      "Epoch 2687/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11014.1333 - reconstruction_loss: 10491.8955 - kl_loss: 459.6507\n",
      "Epoch 2688/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11020.5441 - reconstruction_loss: 10490.7188 - kl_loss: 458.6518\n",
      "Epoch 2689/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11018.8982 - reconstruction_loss: 10492.5312 - kl_loss: 458.9999\n",
      "Epoch 2690/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10997.6332 - reconstruction_loss: 10481.0908 - kl_loss: 459.1472\n",
      "Epoch 2691/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11047.9076 - reconstruction_loss: 10496.9775 - kl_loss: 458.7330\n",
      "Epoch 2692/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10974.5187 - reconstruction_loss: 10463.0811 - kl_loss: 458.6830\n",
      "Epoch 2693/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10995.4901 - reconstruction_loss: 10468.8662 - kl_loss: 458.7449\n",
      "Epoch 2694/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10969.8433 - reconstruction_loss: 10455.2432 - kl_loss: 457.6641\n",
      "Epoch 2695/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11009.5103 - reconstruction_loss: 10493.5908 - kl_loss: 458.3942\n",
      "Epoch 2696/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11124.9541 - reconstruction_loss: 10559.8506 - kl_loss: 458.3367\n",
      "Epoch 2697/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11124.4606 - reconstruction_loss: 10600.6348 - kl_loss: 459.2028\n",
      "Epoch 2698/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11150.0276 - reconstruction_loss: 10636.1328 - kl_loss: 458.4720\n",
      "Epoch 2699/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11067.2637 - reconstruction_loss: 10554.1797 - kl_loss: 457.5542\n",
      "Epoch 2700/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11015.6442 - reconstruction_loss: 10525.5752 - kl_loss: 456.5189\n",
      "Epoch 2701/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11082.5695 - reconstruction_loss: 10563.3818 - kl_loss: 457.0264\n",
      "Epoch 2702/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11175.4286 - reconstruction_loss: 10622.5547 - kl_loss: 458.4572\n",
      "Epoch 2703/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11093.5583 - reconstruction_loss: 10615.0771 - kl_loss: 459.0071\n",
      "Epoch 2704/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11120.8269 - reconstruction_loss: 10591.8730 - kl_loss: 458.5775\n",
      "Epoch 2705/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11082.2287 - reconstruction_loss: 10565.2031 - kl_loss: 458.6342\n",
      "Epoch 2706/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11098.1367 - reconstruction_loss: 10598.0547 - kl_loss: 457.2144\n",
      "Epoch 2707/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11169.8440 - reconstruction_loss: 10617.3574 - kl_loss: 457.2868\n",
      "Epoch 2708/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11172.4569 - reconstruction_loss: 10640.4336 - kl_loss: 456.3640\n",
      "Epoch 2709/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11226.5033 - reconstruction_loss: 10675.0557 - kl_loss: 456.9321\n",
      "Epoch 2710/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11217.0131 - reconstruction_loss: 10651.3213 - kl_loss: 457.2809\n",
      "Epoch 2711/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11208.7705 - reconstruction_loss: 10653.9219 - kl_loss: 457.0661\n",
      "Epoch 2712/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11269.0655 - reconstruction_loss: 10687.5527 - kl_loss: 458.3714\n",
      "Epoch 2713/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11196.9888 - reconstruction_loss: 10641.4238 - kl_loss: 459.0934\n",
      "Epoch 2714/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11161.5555 - reconstruction_loss: 10644.6719 - kl_loss: 456.8819\n",
      "Epoch 2715/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11165.6565 - reconstruction_loss: 10622.4854 - kl_loss: 457.3497\n",
      "Epoch 2716/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11321.8534 - reconstruction_loss: 10773.9590 - kl_loss: 456.0980\n",
      "Epoch 2717/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 11408.9739 - reconstruction_loss: 10812.3379 - kl_loss: 458.5327\n",
      "Epoch 2718/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11315.1751 - reconstruction_loss: 10755.1660 - kl_loss: 458.6663\n",
      "Epoch 2719/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11220.6029 - reconstruction_loss: 10673.8008 - kl_loss: 456.6487\n",
      "Epoch 2720/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11215.2937 - reconstruction_loss: 10665.1816 - kl_loss: 456.2407\n",
      "Epoch 2721/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11228.9443 - reconstruction_loss: 10679.5498 - kl_loss: 457.5602\n",
      "Epoch 2722/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11247.8367 - reconstruction_loss: 10689.1592 - kl_loss: 457.4355\n",
      "Epoch 2723/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11309.7838 - reconstruction_loss: 10706.0908 - kl_loss: 456.4141\n",
      "Epoch 2724/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11385.7366 - reconstruction_loss: 10746.7949 - kl_loss: 456.9665\n",
      "Epoch 2725/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11305.3310 - reconstruction_loss: 10711.8125 - kl_loss: 456.2609\n",
      "Epoch 2726/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11341.8213 - reconstruction_loss: 10732.1367 - kl_loss: 456.7159\n",
      "Epoch 2727/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11322.6767 - reconstruction_loss: 10727.0850 - kl_loss: 458.3124\n",
      "Epoch 2728/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11286.8068 - reconstruction_loss: 10724.0859 - kl_loss: 456.5581\n",
      "Epoch 2729/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11302.8230 - reconstruction_loss: 10754.3164 - kl_loss: 457.9757\n",
      "Epoch 2730/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11287.8406 - reconstruction_loss: 10727.9023 - kl_loss: 458.9057\n",
      "Epoch 2731/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11315.6398 - reconstruction_loss: 10780.9287 - kl_loss: 458.5490\n",
      "Epoch 2732/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11344.9147 - reconstruction_loss: 10779.5400 - kl_loss: 457.8870\n",
      "Epoch 2733/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11302.9996 - reconstruction_loss: 10776.0762 - kl_loss: 456.2104\n",
      "Epoch 2734/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11344.6135 - reconstruction_loss: 10829.9092 - kl_loss: 455.9470\n",
      "Epoch 2735/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11334.6698 - reconstruction_loss: 10809.1289 - kl_loss: 457.9514\n",
      "Epoch 2736/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11274.0021 - reconstruction_loss: 10793.8291 - kl_loss: 457.3374\n",
      "Epoch 2737/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11304.6760 - reconstruction_loss: 10803.7324 - kl_loss: 458.0076\n",
      "Epoch 2738/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11269.7124 - reconstruction_loss: 10806.2412 - kl_loss: 457.1138\n",
      "Epoch 2739/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11329.4053 - reconstruction_loss: 10832.4170 - kl_loss: 457.6865\n",
      "Epoch 2740/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11320.6638 - reconstruction_loss: 10838.0908 - kl_loss: 458.0660\n",
      "Epoch 2741/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11343.2368 - reconstruction_loss: 10864.5723 - kl_loss: 458.2004\n",
      "Epoch 2742/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11291.5210 - reconstruction_loss: 10821.3623 - kl_loss: 457.6888\n",
      "Epoch 2743/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11254.4530 - reconstruction_loss: 10787.6963 - kl_loss: 457.1682\n",
      "Epoch 2744/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11262.0082 - reconstruction_loss: 10813.6191 - kl_loss: 456.0475\n",
      "Epoch 2745/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11253.7836 - reconstruction_loss: 10802.1914 - kl_loss: 455.6161\n",
      "Epoch 2746/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11237.4531 - reconstruction_loss: 10789.6230 - kl_loss: 455.8755\n",
      "Epoch 2747/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11233.9345 - reconstruction_loss: 10798.1123 - kl_loss: 456.1097\n",
      "Epoch 2748/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11244.2521 - reconstruction_loss: 10785.1611 - kl_loss: 457.1674\n",
      "Epoch 2749/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11228.0949 - reconstruction_loss: 10779.5332 - kl_loss: 456.8849\n",
      "Epoch 2750/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11294.6913 - reconstruction_loss: 10838.5928 - kl_loss: 457.0539\n",
      "Epoch 2751/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11357.0633 - reconstruction_loss: 10886.9727 - kl_loss: 456.0506\n",
      "Epoch 2752/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11454.9846 - reconstruction_loss: 10988.3613 - kl_loss: 455.8760\n",
      "Epoch 2753/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11566.3772 - reconstruction_loss: 11103.5762 - kl_loss: 457.8511\n",
      "Epoch 2754/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11470.8433 - reconstruction_loss: 11035.6328 - kl_loss: 458.5013\n",
      "Epoch 2755/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11371.0100 - reconstruction_loss: 10946.5342 - kl_loss: 458.0270\n",
      "Epoch 2756/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11383.7858 - reconstruction_loss: 10907.0352 - kl_loss: 457.0457\n",
      "Epoch 2757/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 11255.5952 - reconstruction_loss: 10836.3330 - kl_loss: 458.0550\n",
      "Epoch 2758/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11248.3127 - reconstruction_loss: 10830.0859 - kl_loss: 457.5446\n",
      "Epoch 2759/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11243.0947 - reconstruction_loss: 10798.0381 - kl_loss: 456.9798\n",
      "Epoch 2760/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11220.8175 - reconstruction_loss: 10784.2578 - kl_loss: 457.8041\n",
      "Epoch 2761/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11205.9624 - reconstruction_loss: 10763.3174 - kl_loss: 458.5028\n",
      "Epoch 2762/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11208.1203 - reconstruction_loss: 10773.1143 - kl_loss: 457.3970\n",
      "Epoch 2763/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11188.3168 - reconstruction_loss: 10761.7520 - kl_loss: 457.4005\n",
      "Epoch 2764/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11198.0621 - reconstruction_loss: 10761.2412 - kl_loss: 457.2911\n",
      "Epoch 2765/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11177.5159 - reconstruction_loss: 10736.5449 - kl_loss: 457.3246\n",
      "Epoch 2766/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11175.4369 - reconstruction_loss: 10733.8359 - kl_loss: 456.9248\n",
      "Epoch 2767/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11135.1648 - reconstruction_loss: 10711.2852 - kl_loss: 457.6630\n",
      "Epoch 2768/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11187.9813 - reconstruction_loss: 10730.5459 - kl_loss: 456.7658\n",
      "Epoch 2769/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11160.3130 - reconstruction_loss: 10713.9023 - kl_loss: 456.1789\n",
      "Epoch 2770/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11178.4317 - reconstruction_loss: 10714.7070 - kl_loss: 456.3420\n",
      "Epoch 2771/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11139.0169 - reconstruction_loss: 10692.3105 - kl_loss: 456.8903\n",
      "Epoch 2772/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11179.6938 - reconstruction_loss: 10715.9463 - kl_loss: 457.7081\n",
      "Epoch 2773/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11165.0728 - reconstruction_loss: 10729.1279 - kl_loss: 457.4194\n",
      "Epoch 2774/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11208.5318 - reconstruction_loss: 10717.7422 - kl_loss: 457.3018\n",
      "Epoch 2775/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11140.9225 - reconstruction_loss: 10686.9951 - kl_loss: 457.0547\n",
      "Epoch 2776/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11144.5129 - reconstruction_loss: 10706.6680 - kl_loss: 456.8753\n",
      "Epoch 2777/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11180.6139 - reconstruction_loss: 10714.9902 - kl_loss: 457.1748\n",
      "Epoch 2778/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11132.2497 - reconstruction_loss: 10698.2988 - kl_loss: 457.9581\n",
      "Epoch 2779/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11175.4249 - reconstruction_loss: 10713.3691 - kl_loss: 456.8356\n",
      "Epoch 2780/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11224.0902 - reconstruction_loss: 10754.8506 - kl_loss: 456.5190\n",
      "Epoch 2781/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11157.2112 - reconstruction_loss: 10689.7939 - kl_loss: 457.9163\n",
      "Epoch 2782/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11169.5831 - reconstruction_loss: 10705.4521 - kl_loss: 458.2798\n",
      "Epoch 2783/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11126.9854 - reconstruction_loss: 10675.7598 - kl_loss: 457.0114\n",
      "Epoch 2784/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11146.5041 - reconstruction_loss: 10689.3848 - kl_loss: 457.0276\n",
      "Epoch 2785/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11181.5617 - reconstruction_loss: 10677.8242 - kl_loss: 458.0129\n",
      "Epoch 2786/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11132.7972 - reconstruction_loss: 10675.4355 - kl_loss: 456.4753\n",
      "Epoch 2787/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11152.0165 - reconstruction_loss: 10673.5938 - kl_loss: 456.2883\n",
      "Epoch 2788/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11105.5879 - reconstruction_loss: 10653.7158 - kl_loss: 456.3648\n",
      "Epoch 2789/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11120.2647 - reconstruction_loss: 10647.7764 - kl_loss: 456.6637\n",
      "Epoch 2790/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11122.2923 - reconstruction_loss: 10632.8809 - kl_loss: 455.4533\n",
      "Epoch 2791/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11090.4006 - reconstruction_loss: 10625.0430 - kl_loss: 455.6845\n",
      "Epoch 2792/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11128.4093 - reconstruction_loss: 10640.5303 - kl_loss: 456.0613\n",
      "Epoch 2793/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11077.6040 - reconstruction_loss: 10624.1377 - kl_loss: 455.2021\n",
      "Epoch 2794/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11105.0790 - reconstruction_loss: 10630.5312 - kl_loss: 455.3373\n",
      "Epoch 2795/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11112.0887 - reconstruction_loss: 10616.9551 - kl_loss: 455.7156\n",
      "Epoch 2796/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 11114.1651 - reconstruction_loss: 10617.9453 - kl_loss: 456.2027\n",
      "Epoch 2797/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11105.1738 - reconstruction_loss: 10613.9355 - kl_loss: 455.6265\n",
      "Epoch 2798/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11079.4074 - reconstruction_loss: 10595.6514 - kl_loss: 456.0569\n",
      "Epoch 2799/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11089.6137 - reconstruction_loss: 10614.3047 - kl_loss: 455.5011\n",
      "Epoch 2800/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11091.1927 - reconstruction_loss: 10593.9316 - kl_loss: 455.9718\n",
      "Epoch 2801/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11079.0546 - reconstruction_loss: 10577.2861 - kl_loss: 456.5867\n",
      "Epoch 2802/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11078.3535 - reconstruction_loss: 10580.7666 - kl_loss: 457.2907\n",
      "Epoch 2803/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11054.2864 - reconstruction_loss: 10579.8125 - kl_loss: 455.9016\n",
      "Epoch 2804/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11100.4964 - reconstruction_loss: 10609.1543 - kl_loss: 456.3738\n",
      "Epoch 2805/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11103.3063 - reconstruction_loss: 10578.6465 - kl_loss: 457.2126\n",
      "Epoch 2806/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11072.9404 - reconstruction_loss: 10582.7012 - kl_loss: 456.1956\n",
      "Epoch 2807/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11125.1998 - reconstruction_loss: 10590.9814 - kl_loss: 456.3179\n",
      "Epoch 2808/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11060.8004 - reconstruction_loss: 10566.2715 - kl_loss: 455.0514\n",
      "Epoch 2809/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11047.1579 - reconstruction_loss: 10566.9453 - kl_loss: 455.6489\n",
      "Epoch 2810/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11062.9241 - reconstruction_loss: 10569.5449 - kl_loss: 455.3323\n",
      "Epoch 2811/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11034.7437 - reconstruction_loss: 10533.4824 - kl_loss: 454.8625\n",
      "Epoch 2812/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11060.5956 - reconstruction_loss: 10578.6982 - kl_loss: 455.5690\n",
      "Epoch 2813/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11047.3756 - reconstruction_loss: 10546.6299 - kl_loss: 455.1218\n",
      "Epoch 2814/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11023.2535 - reconstruction_loss: 10547.1211 - kl_loss: 455.3005\n",
      "Epoch 2815/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 11040.5509 - reconstruction_loss: 10536.3750 - kl_loss: 455.6595\n",
      "Epoch 2816/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 10998.8564 - reconstruction_loss: 10512.2891 - kl_loss: 455.0693\n",
      "Epoch 2817/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11021.7640 - reconstruction_loss: 10511.0146 - kl_loss: 455.5161\n",
      "Epoch 2818/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11014.2015 - reconstruction_loss: 10502.3545 - kl_loss: 454.8755\n",
      "Epoch 2819/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11007.0530 - reconstruction_loss: 10507.9795 - kl_loss: 455.6532\n",
      "Epoch 2820/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11001.1265 - reconstruction_loss: 10497.4736 - kl_loss: 454.4363\n",
      "Epoch 2821/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11001.1108 - reconstruction_loss: 10524.2432 - kl_loss: 454.9411\n",
      "Epoch 2822/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11072.8356 - reconstruction_loss: 10523.7969 - kl_loss: 454.5969\n",
      "Epoch 2823/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11003.7140 - reconstruction_loss: 10502.3242 - kl_loss: 454.6342\n",
      "Epoch 2824/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11040.6797 - reconstruction_loss: 10523.7920 - kl_loss: 454.3408\n",
      "Epoch 2825/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11048.8018 - reconstruction_loss: 10530.7939 - kl_loss: 454.0503\n",
      "Epoch 2826/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11034.5227 - reconstruction_loss: 10506.0107 - kl_loss: 453.2151\n",
      "Epoch 2827/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11036.6072 - reconstruction_loss: 10519.8350 - kl_loss: 453.9765\n",
      "Epoch 2828/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10997.3764 - reconstruction_loss: 10484.6055 - kl_loss: 454.0892\n",
      "Epoch 2829/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11032.3431 - reconstruction_loss: 10515.1592 - kl_loss: 454.7943\n",
      "Epoch 2830/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10963.4305 - reconstruction_loss: 10464.3711 - kl_loss: 454.5799\n",
      "Epoch 2831/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10999.5276 - reconstruction_loss: 10487.6660 - kl_loss: 454.3628\n",
      "Epoch 2832/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10990.6052 - reconstruction_loss: 10476.9668 - kl_loss: 453.9082\n",
      "Epoch 2833/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10966.7963 - reconstruction_loss: 10459.6816 - kl_loss: 453.9957\n",
      "Epoch 2834/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10977.2714 - reconstruction_loss: 10475.5469 - kl_loss: 453.8658\n",
      "Epoch 2835/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10943.1845 - reconstruction_loss: 10453.1699 - kl_loss: 454.7734\n",
      "Epoch 2836/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10970.5344 - reconstruction_loss: 10462.3750 - kl_loss: 454.2032\n",
      "Epoch 2837/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10954.2426 - reconstruction_loss: 10451.1914 - kl_loss: 453.2242\n",
      "Epoch 2838/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10951.3715 - reconstruction_loss: 10451.3115 - kl_loss: 454.0320\n",
      "Epoch 2839/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10947.9914 - reconstruction_loss: 10444.7939 - kl_loss: 454.9227\n",
      "Epoch 2840/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10914.8711 - reconstruction_loss: 10429.4590 - kl_loss: 453.5116\n",
      "Epoch 2841/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10962.1736 - reconstruction_loss: 10463.8008 - kl_loss: 452.7367\n",
      "Epoch 2842/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10933.5256 - reconstruction_loss: 10431.2432 - kl_loss: 453.7556\n",
      "Epoch 2843/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10967.4641 - reconstruction_loss: 10471.9629 - kl_loss: 454.1523\n",
      "Epoch 2844/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10983.8450 - reconstruction_loss: 10463.2637 - kl_loss: 453.1005\n",
      "Epoch 2845/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10935.4724 - reconstruction_loss: 10435.0781 - kl_loss: 453.7526\n",
      "Epoch 2846/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11023.1845 - reconstruction_loss: 10489.0811 - kl_loss: 453.0568\n",
      "Epoch 2847/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10988.4898 - reconstruction_loss: 10480.3467 - kl_loss: 453.1137\n",
      "Epoch 2848/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10958.9145 - reconstruction_loss: 10451.5547 - kl_loss: 454.6307\n",
      "Epoch 2849/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11004.9258 - reconstruction_loss: 10497.3926 - kl_loss: 453.6263\n",
      "Epoch 2850/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11232.4593 - reconstruction_loss: 10706.0146 - kl_loss: 453.5791\n",
      "Epoch 2851/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11048.4173 - reconstruction_loss: 10537.4717 - kl_loss: 455.2842\n",
      "Epoch 2852/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10969.3572 - reconstruction_loss: 10478.5088 - kl_loss: 453.3818\n",
      "Epoch 2853/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11029.1846 - reconstruction_loss: 10508.2441 - kl_loss: 453.7094\n",
      "Epoch 2854/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10973.1744 - reconstruction_loss: 10475.7383 - kl_loss: 453.0422\n",
      "Epoch 2855/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10959.3159 - reconstruction_loss: 10461.2559 - kl_loss: 453.3851\n",
      "Epoch 2856/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11014.0430 - reconstruction_loss: 10519.5293 - kl_loss: 452.9942\n",
      "Epoch 2857/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10973.7460 - reconstruction_loss: 10467.0498 - kl_loss: 453.3198\n",
      "Epoch 2858/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11000.7307 - reconstruction_loss: 10491.5127 - kl_loss: 453.5619\n",
      "Epoch 2859/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10949.8345 - reconstruction_loss: 10452.2744 - kl_loss: 453.3082\n",
      "Epoch 2860/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10991.2064 - reconstruction_loss: 10483.7236 - kl_loss: 452.6541\n",
      "Epoch 2861/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10987.3750 - reconstruction_loss: 10474.6885 - kl_loss: 453.5034\n",
      "Epoch 2862/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11004.3892 - reconstruction_loss: 10510.0928 - kl_loss: 452.0226\n",
      "Epoch 2863/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11033.8510 - reconstruction_loss: 10499.2588 - kl_loss: 452.5123\n",
      "Epoch 2864/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10974.6239 - reconstruction_loss: 10485.1553 - kl_loss: 452.2242\n",
      "Epoch 2865/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11005.9521 - reconstruction_loss: 10520.4912 - kl_loss: 451.9738\n",
      "Epoch 2866/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11047.6183 - reconstruction_loss: 10553.3350 - kl_loss: 452.3025\n",
      "Epoch 2867/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11011.1816 - reconstruction_loss: 10523.1885 - kl_loss: 453.3924\n",
      "Epoch 2868/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11058.0168 - reconstruction_loss: 10586.4443 - kl_loss: 452.9242\n",
      "Epoch 2869/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11052.9868 - reconstruction_loss: 10581.0488 - kl_loss: 452.9502\n",
      "Epoch 2870/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11135.9271 - reconstruction_loss: 10665.3125 - kl_loss: 452.6257\n",
      "Epoch 2871/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11203.7585 - reconstruction_loss: 10751.7900 - kl_loss: 452.3543\n",
      "Epoch 2872/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 11343.0005 - reconstruction_loss: 10893.3291 - kl_loss: 450.7115\n",
      "Epoch 2873/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11460.5489 - reconstruction_loss: 11049.7188 - kl_loss: 450.8093\n",
      "Epoch 2874/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11685.4467 - reconstruction_loss: 11161.4111 - kl_loss: 452.6743\n",
      "Epoch 2875/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11749.9231 - reconstruction_loss: 11159.5840 - kl_loss: 453.1317\n",
      "Epoch 2876/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11707.1735 - reconstruction_loss: 11166.7002 - kl_loss: 452.9669\n",
      "Epoch 2877/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11804.4302 - reconstruction_loss: 11305.7148 - kl_loss: 454.2165\n",
      "Epoch 2878/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11615.5655 - reconstruction_loss: 11192.4277 - kl_loss: 453.1770\n",
      "Epoch 2879/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11654.3115 - reconstruction_loss: 11304.8623 - kl_loss: 451.8385\n",
      "Epoch 2880/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11853.0634 - reconstruction_loss: 11460.6260 - kl_loss: 451.5447\n",
      "Epoch 2881/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12018.0822 - reconstruction_loss: 11362.6211 - kl_loss: 455.4189\n",
      "Epoch 2882/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11853.7288 - reconstruction_loss: 11235.3486 - kl_loss: 454.2641\n",
      "Epoch 2883/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11707.1485 - reconstruction_loss: 11159.9766 - kl_loss: 452.7228\n",
      "Epoch 2884/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11672.5664 - reconstruction_loss: 11141.3398 - kl_loss: 453.5759\n",
      "Epoch 2885/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11659.7768 - reconstruction_loss: 11125.5205 - kl_loss: 454.0637\n",
      "Epoch 2886/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11591.3593 - reconstruction_loss: 11083.6680 - kl_loss: 453.4529\n",
      "Epoch 2887/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11556.5723 - reconstruction_loss: 11033.0352 - kl_loss: 453.1767\n",
      "Epoch 2888/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11564.5238 - reconstruction_loss: 11016.4961 - kl_loss: 453.0060\n",
      "Epoch 2889/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11515.1418 - reconstruction_loss: 11011.4854 - kl_loss: 451.8866\n",
      "Epoch 2890/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11505.8334 - reconstruction_loss: 10978.7930 - kl_loss: 451.9350\n",
      "Epoch 2891/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11470.0155 - reconstruction_loss: 10963.3779 - kl_loss: 452.0655\n",
      "Epoch 2892/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11431.9639 - reconstruction_loss: 10913.4375 - kl_loss: 452.4850\n",
      "Epoch 2893/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11439.4403 - reconstruction_loss: 10920.7627 - kl_loss: 451.8305\n",
      "Epoch 2894/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11399.6922 - reconstruction_loss: 10895.3877 - kl_loss: 452.5513\n",
      "Epoch 2895/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11377.7999 - reconstruction_loss: 10891.5244 - kl_loss: 452.6089\n",
      "Epoch 2896/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11374.2197 - reconstruction_loss: 10864.6104 - kl_loss: 452.6044\n",
      "Epoch 2897/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11374.0628 - reconstruction_loss: 10872.7949 - kl_loss: 453.4561\n",
      "Epoch 2898/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11365.5092 - reconstruction_loss: 10865.1504 - kl_loss: 453.9931\n",
      "Epoch 2899/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11350.1497 - reconstruction_loss: 10850.2930 - kl_loss: 452.5063\n",
      "Epoch 2900/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11360.4193 - reconstruction_loss: 10884.8857 - kl_loss: 451.8406\n",
      "Epoch 2901/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11350.7836 - reconstruction_loss: 10870.2607 - kl_loss: 452.5618\n",
      "Epoch 2902/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11312.8670 - reconstruction_loss: 10829.5166 - kl_loss: 452.8864\n",
      "Epoch 2903/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11337.3817 - reconstruction_loss: 10857.5225 - kl_loss: 452.6492\n",
      "Epoch 2904/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11319.7347 - reconstruction_loss: 10848.7002 - kl_loss: 453.1860\n",
      "Epoch 2905/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11278.5265 - reconstruction_loss: 10825.6055 - kl_loss: 453.2835\n",
      "Epoch 2906/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11322.4522 - reconstruction_loss: 10828.1465 - kl_loss: 451.8107\n",
      "Epoch 2907/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11292.2375 - reconstruction_loss: 10794.7227 - kl_loss: 452.0254\n",
      "Epoch 2908/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 11230.4760 - reconstruction_loss: 10762.7256 - kl_loss: 452.2139\n",
      "Epoch 2909/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11250.8129 - reconstruction_loss: 10770.8799 - kl_loss: 452.2664\n",
      "Epoch 2910/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11200.1265 - reconstruction_loss: 10727.0137 - kl_loss: 452.7224\n",
      "Epoch 2911/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11228.6825 - reconstruction_loss: 10734.5859 - kl_loss: 452.3745\n",
      "Epoch 2912/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11192.2379 - reconstruction_loss: 10695.5781 - kl_loss: 452.6892\n",
      "Epoch 2913/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11141.3869 - reconstruction_loss: 10657.2090 - kl_loss: 453.0814\n",
      "Epoch 2914/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11162.9162 - reconstruction_loss: 10688.8760 - kl_loss: 452.3006\n",
      "Epoch 2915/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11099.6379 - reconstruction_loss: 10619.8574 - kl_loss: 453.3888\n",
      "Epoch 2916/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11125.6159 - reconstruction_loss: 10632.8828 - kl_loss: 453.3306\n",
      "Epoch 2917/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11062.0193 - reconstruction_loss: 10578.3613 - kl_loss: 453.3230\n",
      "Epoch 2918/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11051.5869 - reconstruction_loss: 10572.3428 - kl_loss: 452.3307\n",
      "Epoch 2919/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11047.2743 - reconstruction_loss: 10558.9434 - kl_loss: 452.5836\n",
      "Epoch 2920/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11019.3389 - reconstruction_loss: 10542.7725 - kl_loss: 453.7655\n",
      "Epoch 2921/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11029.1335 - reconstruction_loss: 10530.8359 - kl_loss: 453.8283\n",
      "Epoch 2922/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11005.0461 - reconstruction_loss: 10506.0420 - kl_loss: 452.6446\n",
      "Epoch 2923/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10995.8652 - reconstruction_loss: 10491.8613 - kl_loss: 451.9501\n",
      "Epoch 2924/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10990.0097 - reconstruction_loss: 10488.6211 - kl_loss: 453.3476\n",
      "Epoch 2925/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10952.8459 - reconstruction_loss: 10460.9814 - kl_loss: 453.0376\n",
      "Epoch 2926/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11004.2636 - reconstruction_loss: 10490.3242 - kl_loss: 452.5676\n",
      "Epoch 2927/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10957.4425 - reconstruction_loss: 10437.9541 - kl_loss: 452.7182\n",
      "Epoch 2928/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10950.4997 - reconstruction_loss: 10439.6475 - kl_loss: 452.8781\n",
      "Epoch 2929/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10981.3530 - reconstruction_loss: 10441.3926 - kl_loss: 452.9242\n",
      "Epoch 2930/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10930.3636 - reconstruction_loss: 10413.2490 - kl_loss: 452.8361\n",
      "Epoch 2931/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 10966.6632 - reconstruction_loss: 10431.9004 - kl_loss: 450.9420\n",
      "Epoch 2932/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10947.0270 - reconstruction_loss: 10390.7188 - kl_loss: 453.5053\n",
      "Epoch 2933/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10886.7970 - reconstruction_loss: 10359.5596 - kl_loss: 452.9940\n",
      "Epoch 2934/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10938.7580 - reconstruction_loss: 10395.8623 - kl_loss: 450.8636\n",
      "Epoch 2935/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10879.8687 - reconstruction_loss: 10339.9844 - kl_loss: 453.5286\n",
      "Epoch 2936/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10874.7366 - reconstruction_loss: 10356.9678 - kl_loss: 453.2162\n",
      "Epoch 2937/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10857.9663 - reconstruction_loss: 10323.1768 - kl_loss: 452.5515\n",
      "Epoch 2938/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10825.7415 - reconstruction_loss: 10306.4766 - kl_loss: 452.6897\n",
      "Epoch 2939/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10849.8517 - reconstruction_loss: 10303.9990 - kl_loss: 452.4362\n",
      "Epoch 2940/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10807.4192 - reconstruction_loss: 10273.3369 - kl_loss: 451.2804\n",
      "Epoch 2941/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10817.6694 - reconstruction_loss: 10285.9365 - kl_loss: 450.4102\n",
      "Epoch 2942/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10816.3265 - reconstruction_loss: 10268.1631 - kl_loss: 453.0989\n",
      "Epoch 2943/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10776.7321 - reconstruction_loss: 10252.9316 - kl_loss: 453.0567\n",
      "Epoch 2944/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10812.0846 - reconstruction_loss: 10267.5781 - kl_loss: 452.2914\n",
      "Epoch 2945/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10759.8562 - reconstruction_loss: 10226.4775 - kl_loss: 452.3495\n",
      "Epoch 2946/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10775.8832 - reconstruction_loss: 10240.8271 - kl_loss: 451.8929\n",
      "Epoch 2947/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10760.6110 - reconstruction_loss: 10229.8340 - kl_loss: 451.9520\n",
      "Epoch 2948/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10865.0322 - reconstruction_loss: 10320.1367 - kl_loss: 453.2705\n",
      "Epoch 2949/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10794.8700 - reconstruction_loss: 10241.2490 - kl_loss: 451.3165\n",
      "Epoch 2950/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10765.4640 - reconstruction_loss: 10235.4824 - kl_loss: 452.1761\n",
      "Epoch 2951/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10805.5767 - reconstruction_loss: 10228.4707 - kl_loss: 452.1953\n",
      "Epoch 2952/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10730.6058 - reconstruction_loss: 10189.0225 - kl_loss: 451.1434\n",
      "Epoch 2953/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10750.1838 - reconstruction_loss: 10202.5264 - kl_loss: 452.0579\n",
      "Epoch 2954/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10769.3126 - reconstruction_loss: 10210.6738 - kl_loss: 450.6716\n",
      "Epoch 2955/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10694.8041 - reconstruction_loss: 10170.9131 - kl_loss: 450.7900\n",
      "Epoch 2956/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10819.7114 - reconstruction_loss: 10244.3887 - kl_loss: 452.2202\n",
      "Epoch 2957/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10720.4162 - reconstruction_loss: 10170.8115 - kl_loss: 450.6491\n",
      "Epoch 2958/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10714.1248 - reconstruction_loss: 10187.0605 - kl_loss: 450.9830\n",
      "Epoch 2959/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10755.3424 - reconstruction_loss: 10200.0938 - kl_loss: 450.8684\n",
      "Epoch 2960/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10713.9411 - reconstruction_loss: 10174.3457 - kl_loss: 449.4371\n",
      "Epoch 2961/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10723.7680 - reconstruction_loss: 10178.8643 - kl_loss: 449.7362\n",
      "Epoch 2962/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10690.8124 - reconstruction_loss: 10143.3047 - kl_loss: 450.4757\n",
      "Epoch 2963/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10671.5257 - reconstruction_loss: 10151.4492 - kl_loss: 450.3790\n",
      "Epoch 2964/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10702.7701 - reconstruction_loss: 10141.2373 - kl_loss: 450.8662\n",
      "Epoch 2965/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10645.5941 - reconstruction_loss: 10116.7217 - kl_loss: 450.2196\n",
      "Epoch 2966/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10669.9608 - reconstruction_loss: 10138.7451 - kl_loss: 449.9848\n",
      "Epoch 2967/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10651.9847 - reconstruction_loss: 10118.5527 - kl_loss: 449.1955\n",
      "Epoch 2968/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10645.8263 - reconstruction_loss: 10112.8164 - kl_loss: 449.9486\n",
      "Epoch 2969/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10673.3551 - reconstruction_loss: 10142.9043 - kl_loss: 450.2779\n",
      "Epoch 2970/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10694.1173 - reconstruction_loss: 10141.1055 - kl_loss: 450.8272\n",
      "Epoch 2971/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10617.9868 - reconstruction_loss: 10096.2148 - kl_loss: 449.2061\n",
      "Epoch 2972/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10617.6721 - reconstruction_loss: 10092.7139 - kl_loss: 448.7516\n",
      "Epoch 2973/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10646.5659 - reconstruction_loss: 10106.9668 - kl_loss: 448.9935\n",
      "Epoch 2974/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10652.0001 - reconstruction_loss: 10126.1602 - kl_loss: 447.8618\n",
      "Epoch 2975/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10656.8866 - reconstruction_loss: 10111.4385 - kl_loss: 448.5985\n",
      "Epoch 2976/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10665.3389 - reconstruction_loss: 10172.6562 - kl_loss: 447.9128\n",
      "Epoch 2977/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10793.4274 - reconstruction_loss: 10225.9854 - kl_loss: 449.8772\n",
      "Epoch 2978/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10692.4224 - reconstruction_loss: 10147.0742 - kl_loss: 449.9397\n",
      "Epoch 2979/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10667.1919 - reconstruction_loss: 10121.3477 - kl_loss: 450.2050\n",
      "Epoch 2980/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10645.9892 - reconstruction_loss: 10127.6514 - kl_loss: 448.4856\n",
      "Epoch 2981/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10706.4536 - reconstruction_loss: 10164.1484 - kl_loss: 448.3540\n",
      "Epoch 2982/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10683.5558 - reconstruction_loss: 10122.5537 - kl_loss: 448.4672\n",
      "Epoch 2983/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10631.1805 - reconstruction_loss: 10114.9824 - kl_loss: 448.4576\n",
      "Epoch 2984/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10781.5406 - reconstruction_loss: 10229.1807 - kl_loss: 447.9103\n",
      "Epoch 2985/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10772.2268 - reconstruction_loss: 10172.6035 - kl_loss: 447.6944\n",
      "Epoch 2986/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10707.5460 - reconstruction_loss: 10135.2432 - kl_loss: 447.2742\n",
      "Epoch 2987/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10735.8180 - reconstruction_loss: 10193.2354 - kl_loss: 447.8808\n",
      "Epoch 2988/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10709.8839 - reconstruction_loss: 10126.6221 - kl_loss: 447.1121\n",
      "Epoch 2989/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10651.1135 - reconstruction_loss: 10120.9717 - kl_loss: 446.0194\n",
      "Epoch 2990/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10654.4315 - reconstruction_loss: 10105.8252 - kl_loss: 447.0256\n",
      "Epoch 2991/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10668.5077 - reconstruction_loss: 10109.5322 - kl_loss: 446.7551\n",
      "Epoch 2992/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10639.7758 - reconstruction_loss: 10115.4893 - kl_loss: 447.0613\n",
      "Epoch 2993/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10654.0656 - reconstruction_loss: 10107.0020 - kl_loss: 447.2343\n",
      "Epoch 2994/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10632.4272 - reconstruction_loss: 10101.3477 - kl_loss: 446.2045\n",
      "Epoch 2995/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10612.3662 - reconstruction_loss: 10075.2490 - kl_loss: 447.4106\n",
      "Epoch 2996/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10626.5018 - reconstruction_loss: 10083.8037 - kl_loss: 446.3757\n",
      "Epoch 2997/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10614.1167 - reconstruction_loss: 10090.3486 - kl_loss: 446.8395\n",
      "Epoch 2998/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10605.2874 - reconstruction_loss: 10079.4004 - kl_loss: 446.6602\n",
      "Epoch 2999/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10622.5684 - reconstruction_loss: 10109.8682 - kl_loss: 445.9426\n",
      "Epoch 3000/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10634.7538 - reconstruction_loss: 10105.7012 - kl_loss: 446.4838\n",
      "Epoch 3001/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10646.4036 - reconstruction_loss: 10105.7559 - kl_loss: 446.4763\n",
      "Epoch 3002/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10631.9534 - reconstruction_loss: 10114.0430 - kl_loss: 445.9779\n",
      "Epoch 3003/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10667.9530 - reconstruction_loss: 10143.1348 - kl_loss: 444.6105\n",
      "Epoch 3004/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10752.5367 - reconstruction_loss: 10218.8125 - kl_loss: 448.4161\n",
      "Epoch 3005/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10696.3990 - reconstruction_loss: 10160.4199 - kl_loss: 447.2621\n",
      "Epoch 3006/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10686.7435 - reconstruction_loss: 10124.0674 - kl_loss: 446.3566\n",
      "Epoch 3007/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10673.5244 - reconstruction_loss: 10151.9561 - kl_loss: 445.8037\n",
      "Epoch 3008/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10755.1745 - reconstruction_loss: 10193.5664 - kl_loss: 446.7799\n",
      "Epoch 3009/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10685.0270 - reconstruction_loss: 10144.4092 - kl_loss: 446.4457\n",
      "Epoch 3010/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10732.1421 - reconstruction_loss: 10170.6904 - kl_loss: 446.3444\n",
      "Epoch 3011/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10829.0454 - reconstruction_loss: 10261.6836 - kl_loss: 445.6078\n",
      "Epoch 3012/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10895.4638 - reconstruction_loss: 10301.0898 - kl_loss: 445.5858\n",
      "Epoch 3013/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10818.8091 - reconstruction_loss: 10263.6133 - kl_loss: 445.7562\n",
      "Epoch 3014/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10784.1205 - reconstruction_loss: 10245.0557 - kl_loss: 446.0885\n",
      "Epoch 3015/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10768.7178 - reconstruction_loss: 10242.1211 - kl_loss: 444.5370\n",
      "Epoch 3016/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10780.0967 - reconstruction_loss: 10251.7822 - kl_loss: 444.4433\n",
      "Epoch 3017/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10789.6183 - reconstruction_loss: 10254.0996 - kl_loss: 446.5471\n",
      "Epoch 3018/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10833.5171 - reconstruction_loss: 10299.1035 - kl_loss: 444.2202\n",
      "Epoch 3019/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10835.2150 - reconstruction_loss: 10294.9297 - kl_loss: 444.8272\n",
      "Epoch 3020/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10939.4678 - reconstruction_loss: 10400.2520 - kl_loss: 444.4884\n",
      "Epoch 3021/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10842.5508 - reconstruction_loss: 10347.9268 - kl_loss: 445.1465\n",
      "Epoch 3022/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10883.7713 - reconstruction_loss: 10372.6475 - kl_loss: 444.1196\n",
      "Epoch 3023/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10847.8823 - reconstruction_loss: 10377.9160 - kl_loss: 444.6664\n",
      "Epoch 3024/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10834.4110 - reconstruction_loss: 10414.4922 - kl_loss: 444.4346\n",
      "Epoch 3025/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10892.0057 - reconstruction_loss: 10406.3291 - kl_loss: 443.7478\n",
      "Epoch 3026/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11007.4094 - reconstruction_loss: 10485.7744 - kl_loss: 443.8621\n",
      "Epoch 3027/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11048.8454 - reconstruction_loss: 10504.0684 - kl_loss: 444.2464\n",
      "Epoch 3028/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11147.2631 - reconstruction_loss: 10570.1143 - kl_loss: 445.7985\n",
      "Epoch 3029/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10969.7645 - reconstruction_loss: 10423.1797 - kl_loss: 446.6504\n",
      "Epoch 3030/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10901.4513 - reconstruction_loss: 10354.7656 - kl_loss: 444.4998\n",
      "Epoch 3031/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10808.7079 - reconstruction_loss: 10282.3066 - kl_loss: 444.7618\n",
      "Epoch 3032/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10852.0252 - reconstruction_loss: 10312.0459 - kl_loss: 444.5035\n",
      "Epoch 3033/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10781.7068 - reconstruction_loss: 10249.2568 - kl_loss: 444.6175\n",
      "Epoch 3034/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10766.7047 - reconstruction_loss: 10241.7422 - kl_loss: 446.0743\n",
      "Epoch 3035/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10774.2253 - reconstruction_loss: 10239.4258 - kl_loss: 444.0293\n",
      "Epoch 3036/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10725.7191 - reconstruction_loss: 10210.8926 - kl_loss: 445.1454\n",
      "Epoch 3037/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10805.7090 - reconstruction_loss: 10256.5586 - kl_loss: 443.9847\n",
      "Epoch 3038/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10727.1294 - reconstruction_loss: 10197.9014 - kl_loss: 444.2950\n",
      "Epoch 3039/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10721.3837 - reconstruction_loss: 10200.6582 - kl_loss: 444.5791\n",
      "Epoch 3040/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10691.0625 - reconstruction_loss: 10169.2939 - kl_loss: 444.2871\n",
      "Epoch 3041/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10700.1791 - reconstruction_loss: 10176.8955 - kl_loss: 443.5772\n",
      "Epoch 3042/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10721.9445 - reconstruction_loss: 10180.4160 - kl_loss: 444.7054\n",
      "Epoch 3043/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10675.3392 - reconstruction_loss: 10158.2207 - kl_loss: 444.4868\n",
      "Epoch 3044/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10701.8703 - reconstruction_loss: 10177.8457 - kl_loss: 444.1434\n",
      "Epoch 3045/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10671.7050 - reconstruction_loss: 10145.5264 - kl_loss: 443.7168\n",
      "Epoch 3046/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10637.8927 - reconstruction_loss: 10121.6367 - kl_loss: 444.4953\n",
      "Epoch 3047/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10679.7950 - reconstruction_loss: 10141.4785 - kl_loss: 445.6975\n",
      "Epoch 3048/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10619.7981 - reconstruction_loss: 10102.4854 - kl_loss: 445.1286\n",
      "Epoch 3049/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10635.7931 - reconstruction_loss: 10120.5840 - kl_loss: 444.1799\n",
      "Epoch 3050/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10620.4348 - reconstruction_loss: 10107.8076 - kl_loss: 443.2993\n",
      "Epoch 3051/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10595.3507 - reconstruction_loss: 10088.4619 - kl_loss: 443.5137\n",
      "Epoch 3052/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10618.3478 - reconstruction_loss: 10092.3818 - kl_loss: 443.2446\n",
      "Epoch 3053/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10600.3053 - reconstruction_loss: 10090.0352 - kl_loss: 442.4307\n",
      "Epoch 3054/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10692.9477 - reconstruction_loss: 10164.0010 - kl_loss: 444.7650\n",
      "Epoch 3055/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10580.9353 - reconstruction_loss: 10060.6445 - kl_loss: 443.8450\n",
      "Epoch 3056/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10576.8481 - reconstruction_loss: 10061.5977 - kl_loss: 443.6955\n",
      "Epoch 3057/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10621.5618 - reconstruction_loss: 10091.9736 - kl_loss: 443.6082\n",
      "Epoch 3058/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10572.1163 - reconstruction_loss: 10046.9678 - kl_loss: 443.3306\n",
      "Epoch 3059/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10583.6861 - reconstruction_loss: 10075.1719 - kl_loss: 442.4370\n",
      "Epoch 3060/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10600.7713 - reconstruction_loss: 10069.3623 - kl_loss: 442.8607\n",
      "Epoch 3061/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10559.7037 - reconstruction_loss: 10045.7812 - kl_loss: 443.3323\n",
      "Epoch 3062/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10622.7459 - reconstruction_loss: 10092.9561 - kl_loss: 443.1521\n",
      "Epoch 3063/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10573.2448 - reconstruction_loss: 10043.5889 - kl_loss: 443.0125\n",
      "Epoch 3064/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10573.7549 - reconstruction_loss: 10057.3984 - kl_loss: 442.9252\n",
      "Epoch 3065/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10605.2157 - reconstruction_loss: 10054.1758 - kl_loss: 443.5680\n",
      "Epoch 3066/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10589.2688 - reconstruction_loss: 10053.7256 - kl_loss: 442.1748\n",
      "Epoch 3067/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10590.3385 - reconstruction_loss: 10056.6289 - kl_loss: 442.5556\n",
      "Epoch 3068/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10593.0981 - reconstruction_loss: 10048.8643 - kl_loss: 441.6178\n",
      "Epoch 3069/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10503.9850 - reconstruction_loss: 10002.2871 - kl_loss: 442.0276\n",
      "Epoch 3070/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10549.5642 - reconstruction_loss: 10007.3555 - kl_loss: 442.0826\n",
      "Epoch 3071/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10533.7540 - reconstruction_loss: 10001.4287 - kl_loss: 442.4716\n",
      "Epoch 3072/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10527.2806 - reconstruction_loss: 10010.2793 - kl_loss: 442.0705\n",
      "Epoch 3073/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10538.6230 - reconstruction_loss: 10004.6758 - kl_loss: 441.8795\n",
      "Epoch 3074/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10520.5347 - reconstruction_loss: 10014.0000 - kl_loss: 442.9316\n",
      "Epoch 3075/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10510.9433 - reconstruction_loss: 9989.4473 - kl_loss: 442.1569\n",
      "Epoch 3076/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10473.2532 - reconstruction_loss: 9964.8496 - kl_loss: 441.0649\n",
      "Epoch 3077/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10499.8117 - reconstruction_loss: 9986.8096 - kl_loss: 442.0264\n",
      "Epoch 3078/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10479.2429 - reconstruction_loss: 9965.1279 - kl_loss: 441.0353\n",
      "Epoch 3079/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10474.8567 - reconstruction_loss: 9972.8662 - kl_loss: 441.1464\n",
      "Epoch 3080/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10507.2594 - reconstruction_loss: 9992.1709 - kl_loss: 440.7675\n",
      "Epoch 3081/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10481.9784 - reconstruction_loss: 9961.1133 - kl_loss: 439.9812\n",
      "Epoch 3082/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10486.8610 - reconstruction_loss: 9966.5469 - kl_loss: 442.0370\n",
      "Epoch 3083/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10611.5285 - reconstruction_loss: 10055.4844 - kl_loss: 441.7586\n",
      "Epoch 3084/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10532.3152 - reconstruction_loss: 9987.9668 - kl_loss: 442.6360\n",
      "Epoch 3085/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10551.0600 - reconstruction_loss: 10027.8350 - kl_loss: 442.6854\n",
      "Epoch 3086/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10570.4785 - reconstruction_loss: 10042.1445 - kl_loss: 442.0145\n",
      "Epoch 3087/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10679.3781 - reconstruction_loss: 10115.2637 - kl_loss: 444.0522\n",
      "Epoch 3088/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10537.1246 - reconstruction_loss: 10003.0264 - kl_loss: 443.7382\n",
      "Epoch 3089/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10551.3097 - reconstruction_loss: 10000.4580 - kl_loss: 441.5134\n",
      "Epoch 3090/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10473.0157 - reconstruction_loss: 9942.4795 - kl_loss: 440.9134\n",
      "Epoch 3091/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10496.0367 - reconstruction_loss: 9968.7598 - kl_loss: 440.5526\n",
      "Epoch 3092/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10505.4771 - reconstruction_loss: 9952.3555 - kl_loss: 440.5867\n",
      "Epoch 3093/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10463.4146 - reconstruction_loss: 9945.0244 - kl_loss: 440.4899\n",
      "Epoch 3094/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10492.3548 - reconstruction_loss: 9950.1621 - kl_loss: 440.4937\n",
      "Epoch 3095/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10469.9018 - reconstruction_loss: 9937.5078 - kl_loss: 439.6161\n",
      "Epoch 3096/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10466.4365 - reconstruction_loss: 9940.7158 - kl_loss: 440.2391\n",
      "Epoch 3097/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10453.5150 - reconstruction_loss: 9918.6533 - kl_loss: 441.3316\n",
      "Epoch 3098/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10425.3494 - reconstruction_loss: 9907.7119 - kl_loss: 440.0293\n",
      "Epoch 3099/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10460.8816 - reconstruction_loss: 9928.3008 - kl_loss: 440.4275\n",
      "Epoch 3100/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10444.7066 - reconstruction_loss: 9921.1387 - kl_loss: 439.4553\n",
      "Epoch 3101/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10431.8782 - reconstruction_loss: 9911.5938 - kl_loss: 438.9557\n",
      "Epoch 3102/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10465.8810 - reconstruction_loss: 9928.0098 - kl_loss: 439.6225\n",
      "Epoch 3103/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10417.0696 - reconstruction_loss: 9901.2471 - kl_loss: 438.6582\n",
      "Epoch 3104/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10431.2897 - reconstruction_loss: 9913.2295 - kl_loss: 439.2336\n",
      "Epoch 3105/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10429.1471 - reconstruction_loss: 9896.5371 - kl_loss: 440.4239\n",
      "Epoch 3106/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10435.2255 - reconstruction_loss: 9913.7715 - kl_loss: 440.4500\n",
      "Epoch 3107/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10408.9695 - reconstruction_loss: 9890.4189 - kl_loss: 439.1479\n",
      "Epoch 3108/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10408.8049 - reconstruction_loss: 9900.9922 - kl_loss: 439.4112\n",
      "Epoch 3109/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10458.0058 - reconstruction_loss: 9925.2959 - kl_loss: 438.7073\n",
      "Epoch 3110/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10424.1048 - reconstruction_loss: 9903.7334 - kl_loss: 438.3732\n",
      "Epoch 3111/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10494.7066 - reconstruction_loss: 9959.1406 - kl_loss: 438.7456\n",
      "Epoch 3112/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10462.5401 - reconstruction_loss: 9925.5264 - kl_loss: 438.2148\n",
      "Epoch 3113/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10439.3795 - reconstruction_loss: 9921.2568 - kl_loss: 438.8356\n",
      "Epoch 3114/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10495.3874 - reconstruction_loss: 9933.2393 - kl_loss: 439.3578\n",
      "Epoch 3115/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10414.9748 - reconstruction_loss: 9904.0576 - kl_loss: 438.5682\n",
      "Epoch 3116/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10510.1946 - reconstruction_loss: 9965.2715 - kl_loss: 437.7731\n",
      "Epoch 3117/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10447.2123 - reconstruction_loss: 9905.4316 - kl_loss: 438.0993\n",
      "Epoch 3118/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10416.3506 - reconstruction_loss: 9904.0654 - kl_loss: 437.3083\n",
      "Epoch 3119/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10443.6874 - reconstruction_loss: 9913.3506 - kl_loss: 438.0816\n",
      "Epoch 3120/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10454.8525 - reconstruction_loss: 9921.2432 - kl_loss: 438.0054\n",
      "Epoch 3121/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10470.9823 - reconstruction_loss: 9937.0615 - kl_loss: 437.1723\n",
      "Epoch 3122/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10434.6844 - reconstruction_loss: 9920.0742 - kl_loss: 436.9743\n",
      "Epoch 3123/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10463.4475 - reconstruction_loss: 9937.2168 - kl_loss: 436.5586\n",
      "Epoch 3124/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10440.1168 - reconstruction_loss: 9939.8535 - kl_loss: 436.3197\n",
      "Epoch 3125/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10415.1868 - reconstruction_loss: 9914.7949 - kl_loss: 437.2482\n",
      "Epoch 3126/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10474.5249 - reconstruction_loss: 9980.8105 - kl_loss: 436.7692\n",
      "Epoch 3127/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10472.5502 - reconstruction_loss: 9962.4336 - kl_loss: 438.0338\n",
      "Epoch 3128/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10495.0138 - reconstruction_loss: 10000.3477 - kl_loss: 438.3102\n",
      "Epoch 3129/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10567.3047 - reconstruction_loss: 10035.0137 - kl_loss: 436.5432\n",
      "Epoch 3130/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10513.3725 - reconstruction_loss: 10032.7861 - kl_loss: 436.8880\n",
      "Epoch 3131/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10594.7048 - reconstruction_loss: 10075.5703 - kl_loss: 435.3369\n",
      "Epoch 3132/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10648.7702 - reconstruction_loss: 10100.9229 - kl_loss: 436.7081\n",
      "Epoch 3133/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10580.2223 - reconstruction_loss: 10080.8672 - kl_loss: 436.8298\n",
      "Epoch 3134/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10641.8921 - reconstruction_loss: 10142.9980 - kl_loss: 435.7108\n",
      "Epoch 3135/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10765.0729 - reconstruction_loss: 10249.4893 - kl_loss: 437.2726\n",
      "Epoch 3136/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10688.7880 - reconstruction_loss: 10221.1045 - kl_loss: 438.5290\n",
      "Epoch 3137/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10744.3748 - reconstruction_loss: 10254.0518 - kl_loss: 436.4675\n",
      "Epoch 3138/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10858.2221 - reconstruction_loss: 10335.6553 - kl_loss: 437.4373\n",
      "Epoch 3139/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10875.9942 - reconstruction_loss: 10354.9736 - kl_loss: 436.3386\n",
      "Epoch 3140/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10897.4565 - reconstruction_loss: 10336.2100 - kl_loss: 437.1624\n",
      "Epoch 3141/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10883.9420 - reconstruction_loss: 10338.4863 - kl_loss: 437.0618\n",
      "Epoch 3142/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10875.8760 - reconstruction_loss: 10354.0078 - kl_loss: 436.8242\n",
      "Epoch 3143/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10789.7591 - reconstruction_loss: 10301.1865 - kl_loss: 436.1387\n",
      "Epoch 3144/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10848.1201 - reconstruction_loss: 10332.4658 - kl_loss: 436.5771\n",
      "Epoch 3145/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10809.1902 - reconstruction_loss: 10323.0469 - kl_loss: 436.9924\n",
      "Epoch 3146/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10789.0324 - reconstruction_loss: 10328.9150 - kl_loss: 436.8593\n",
      "Epoch 3147/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10859.3569 - reconstruction_loss: 10387.3174 - kl_loss: 436.2581\n",
      "Epoch 3148/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10978.8800 - reconstruction_loss: 10413.7871 - kl_loss: 436.4273\n",
      "Epoch 3149/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10982.7090 - reconstruction_loss: 10410.6514 - kl_loss: 437.1743\n",
      "Epoch 3150/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11035.5487 - reconstruction_loss: 10436.0654 - kl_loss: 437.1677\n",
      "Epoch 3151/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11056.8758 - reconstruction_loss: 10472.1807 - kl_loss: 436.5021\n",
      "Epoch 3152/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11095.0663 - reconstruction_loss: 10517.1885 - kl_loss: 436.5502\n",
      "Epoch 3153/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11059.8040 - reconstruction_loss: 10531.5811 - kl_loss: 435.8209\n",
      "Epoch 3154/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11071.4849 - reconstruction_loss: 10552.4014 - kl_loss: 435.9515\n",
      "Epoch 3155/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 11069.4248 - reconstruction_loss: 10566.9043 - kl_loss: 436.9344\n",
      "Epoch 3156/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11110.4906 - reconstruction_loss: 10625.3730 - kl_loss: 436.5377\n",
      "Epoch 3157/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11191.7279 - reconstruction_loss: 10697.0410 - kl_loss: 436.9091\n",
      "Epoch 3158/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11179.1955 - reconstruction_loss: 10712.0928 - kl_loss: 436.9018\n",
      "Epoch 3159/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11282.6048 - reconstruction_loss: 10805.0752 - kl_loss: 434.6036\n",
      "Epoch 3160/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11317.0554 - reconstruction_loss: 10859.4902 - kl_loss: 435.6153\n",
      "Epoch 3161/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11394.3607 - reconstruction_loss: 10927.2480 - kl_loss: 437.3221\n",
      "Epoch 3162/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11415.2904 - reconstruction_loss: 10969.7686 - kl_loss: 435.4695\n",
      "Epoch 3163/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11506.5542 - reconstruction_loss: 11009.8818 - kl_loss: 436.7795\n",
      "Epoch 3164/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11329.1147 - reconstruction_loss: 10864.3652 - kl_loss: 436.7445\n",
      "Epoch 3165/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11280.7667 - reconstruction_loss: 10827.8027 - kl_loss: 436.9012\n",
      "Epoch 3166/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11303.4465 - reconstruction_loss: 10836.4590 - kl_loss: 435.7957\n",
      "Epoch 3167/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11372.2391 - reconstruction_loss: 10900.5947 - kl_loss: 435.7006\n",
      "Epoch 3168/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11395.7263 - reconstruction_loss: 10917.4170 - kl_loss: 434.9302\n",
      "Epoch 3169/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11436.9598 - reconstruction_loss: 10939.3896 - kl_loss: 435.7033\n",
      "Epoch 3170/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11461.0694 - reconstruction_loss: 11012.3506 - kl_loss: 435.1104\n",
      "Epoch 3171/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11659.0776 - reconstruction_loss: 11172.7793 - kl_loss: 434.9733\n",
      "Epoch 3172/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11790.5488 - reconstruction_loss: 11309.4775 - kl_loss: 435.1041\n",
      "Epoch 3173/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11942.5523 - reconstruction_loss: 11463.9756 - kl_loss: 434.7105\n",
      "Epoch 3174/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12023.1794 - reconstruction_loss: 11490.9590 - kl_loss: 436.7097\n",
      "Epoch 3175/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11919.7570 - reconstruction_loss: 11378.0547 - kl_loss: 436.0603\n",
      "Epoch 3176/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11820.4186 - reconstruction_loss: 11256.0742 - kl_loss: 437.3309\n",
      "Epoch 3177/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11774.1923 - reconstruction_loss: 11174.2646 - kl_loss: 438.0617\n",
      "Epoch 3178/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11678.1968 - reconstruction_loss: 11100.1855 - kl_loss: 437.1090\n",
      "Epoch 3179/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11596.2723 - reconstruction_loss: 11034.6240 - kl_loss: 438.9435\n",
      "Epoch 3180/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11450.6679 - reconstruction_loss: 10974.3818 - kl_loss: 438.2252\n",
      "Epoch 3181/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11425.0043 - reconstruction_loss: 10946.6250 - kl_loss: 436.3050\n",
      "Epoch 3182/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11431.2126 - reconstruction_loss: 10956.2754 - kl_loss: 437.3642\n",
      "Epoch 3183/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11384.2905 - reconstruction_loss: 10925.7197 - kl_loss: 438.6072\n",
      "Epoch 3184/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11357.1103 - reconstruction_loss: 10898.3643 - kl_loss: 437.3475\n",
      "Epoch 3185/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11202.8439 - reconstruction_loss: 10764.0293 - kl_loss: 438.0536\n",
      "Epoch 3186/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11177.9133 - reconstruction_loss: 10718.7832 - kl_loss: 437.1652\n",
      "Epoch 3187/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11108.1769 - reconstruction_loss: 10675.8213 - kl_loss: 437.8474\n",
      "Epoch 3188/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11133.3930 - reconstruction_loss: 10662.0078 - kl_loss: 438.3975\n",
      "Epoch 3189/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10983.5879 - reconstruction_loss: 10536.5430 - kl_loss: 438.4741\n",
      "Epoch 3190/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10964.4451 - reconstruction_loss: 10494.0410 - kl_loss: 437.1016\n",
      "Epoch 3191/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10894.9997 - reconstruction_loss: 10439.5664 - kl_loss: 438.1089\n",
      "Epoch 3192/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10915.3938 - reconstruction_loss: 10451.6406 - kl_loss: 438.2290\n",
      "Epoch 3193/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10882.5243 - reconstruction_loss: 10414.6514 - kl_loss: 437.6748\n",
      "Epoch 3194/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10844.9084 - reconstruction_loss: 10371.5137 - kl_loss: 437.8889\n",
      "Epoch 3195/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10785.5330 - reconstruction_loss: 10326.3057 - kl_loss: 437.7135\n",
      "Epoch 3196/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10747.4374 - reconstruction_loss: 10283.1377 - kl_loss: 438.8063\n",
      "Epoch 3197/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10741.1672 - reconstruction_loss: 10269.6602 - kl_loss: 438.4200\n",
      "Epoch 3198/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10749.7666 - reconstruction_loss: 10275.8242 - kl_loss: 437.1826\n",
      "Epoch 3199/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10733.0946 - reconstruction_loss: 10255.0576 - kl_loss: 437.5131\n",
      "Epoch 3200/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10687.8410 - reconstruction_loss: 10218.4072 - kl_loss: 436.8022\n",
      "Epoch 3201/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10723.6421 - reconstruction_loss: 10237.8711 - kl_loss: 437.7388\n",
      "Epoch 3202/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10657.3528 - reconstruction_loss: 10197.7871 - kl_loss: 437.1350\n",
      "Epoch 3203/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 10682.3374 - reconstruction_loss: 10196.9619 - kl_loss: 438.7356\n",
      "Epoch 3204/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10713.1261 - reconstruction_loss: 10222.3096 - kl_loss: 437.2684\n",
      "Epoch 3205/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10658.0650 - reconstruction_loss: 10183.7744 - kl_loss: 436.5017\n",
      "Epoch 3206/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10652.3423 - reconstruction_loss: 10173.6592 - kl_loss: 437.3818\n",
      "Epoch 3207/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10657.1987 - reconstruction_loss: 10152.5371 - kl_loss: 438.0168\n",
      "Epoch 3208/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10602.3723 - reconstruction_loss: 10125.5869 - kl_loss: 437.3300\n",
      "Epoch 3209/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10627.4064 - reconstruction_loss: 10127.3477 - kl_loss: 438.0175\n",
      "Epoch 3210/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10606.6967 - reconstruction_loss: 10110.0918 - kl_loss: 436.4530\n",
      "Epoch 3211/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10575.0357 - reconstruction_loss: 10090.2451 - kl_loss: 436.5490\n",
      "Epoch 3212/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10614.9871 - reconstruction_loss: 10112.1914 - kl_loss: 437.7918\n",
      "Epoch 3213/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10564.5192 - reconstruction_loss: 10068.8613 - kl_loss: 437.4914\n",
      "Epoch 3214/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10536.6549 - reconstruction_loss: 10052.7168 - kl_loss: 436.7884\n",
      "Epoch 3215/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10548.8422 - reconstruction_loss: 10047.8877 - kl_loss: 437.0537\n",
      "Epoch 3216/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10556.1166 - reconstruction_loss: 10047.9600 - kl_loss: 436.2461\n",
      "Epoch 3217/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10514.5181 - reconstruction_loss: 10029.1240 - kl_loss: 436.9570\n",
      "Epoch 3218/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10535.5553 - reconstruction_loss: 10029.1240 - kl_loss: 436.5813\n",
      "Epoch 3219/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10494.5272 - reconstruction_loss: 9997.7393 - kl_loss: 437.5146\n",
      "Epoch 3220/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10500.9877 - reconstruction_loss: 10004.3047 - kl_loss: 437.3087\n",
      "Epoch 3221/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10516.2700 - reconstruction_loss: 9996.9473 - kl_loss: 436.8069\n",
      "Epoch 3222/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10470.1437 - reconstruction_loss: 9971.3154 - kl_loss: 437.4842\n",
      "Epoch 3223/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10460.1569 - reconstruction_loss: 9964.3271 - kl_loss: 437.0610\n",
      "Epoch 3224/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10491.3187 - reconstruction_loss: 9967.7070 - kl_loss: 437.5787\n",
      "Epoch 3225/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10452.9958 - reconstruction_loss: 9948.8770 - kl_loss: 436.8930\n",
      "Epoch 3226/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10466.9512 - reconstruction_loss: 9957.3359 - kl_loss: 436.3145\n",
      "Epoch 3227/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10486.4452 - reconstruction_loss: 9955.3926 - kl_loss: 435.5155\n",
      "Epoch 3228/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10434.2470 - reconstruction_loss: 9932.0361 - kl_loss: 435.8140\n",
      "Epoch 3229/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10416.9953 - reconstruction_loss: 9917.7773 - kl_loss: 435.6344\n",
      "Epoch 3230/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10401.5520 - reconstruction_loss: 9899.5840 - kl_loss: 435.8324\n",
      "Epoch 3231/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10406.5601 - reconstruction_loss: 9902.0205 - kl_loss: 435.7401\n",
      "Epoch 3232/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10443.9991 - reconstruction_loss: 9910.4775 - kl_loss: 436.0232\n",
      "Epoch 3233/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10380.5842 - reconstruction_loss: 9880.3223 - kl_loss: 435.4754\n",
      "Epoch 3234/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10405.9130 - reconstruction_loss: 9908.3018 - kl_loss: 435.5023\n",
      "Epoch 3235/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10406.1928 - reconstruction_loss: 9876.9600 - kl_loss: 436.4814\n",
      "Epoch 3236/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10404.9656 - reconstruction_loss: 9897.5000 - kl_loss: 435.4573\n",
      "Epoch 3237/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10421.0654 - reconstruction_loss: 9877.1338 - kl_loss: 435.5383\n",
      "Epoch 3238/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10455.6420 - reconstruction_loss: 9899.9697 - kl_loss: 436.4671\n",
      "Epoch 3239/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10347.6428 - reconstruction_loss: 9843.4414 - kl_loss: 435.5854\n",
      "Epoch 3240/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10427.7158 - reconstruction_loss: 9901.6484 - kl_loss: 436.2253\n",
      "Epoch 3241/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10396.3699 - reconstruction_loss: 9861.7041 - kl_loss: 436.3974\n",
      "Epoch 3242/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10357.7545 - reconstruction_loss: 9851.7891 - kl_loss: 435.8810\n",
      "Epoch 3243/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10379.8224 - reconstruction_loss: 9852.6562 - kl_loss: 435.2664\n",
      "Epoch 3244/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10321.2310 - reconstruction_loss: 9816.7783 - kl_loss: 435.4316\n",
      "Epoch 3245/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10315.9131 - reconstruction_loss: 9817.1318 - kl_loss: 435.0649\n",
      "Epoch 3246/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10313.2060 - reconstruction_loss: 9805.2988 - kl_loss: 434.9292\n",
      "Epoch 3247/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10299.7404 - reconstruction_loss: 9801.3984 - kl_loss: 434.7050\n",
      "Epoch 3248/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10301.6800 - reconstruction_loss: 9794.1279 - kl_loss: 434.2236\n",
      "Epoch 3249/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10312.9758 - reconstruction_loss: 9804.3691 - kl_loss: 434.2531\n",
      "Epoch 3250/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10293.0199 - reconstruction_loss: 9794.1152 - kl_loss: 434.8076\n",
      "Epoch 3251/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10341.4384 - reconstruction_loss: 9821.9004 - kl_loss: 434.2667\n",
      "Epoch 3252/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10529.7111 - reconstruction_loss: 9969.0605 - kl_loss: 435.0588\n",
      "Epoch 3253/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10379.3576 - reconstruction_loss: 9845.1240 - kl_loss: 435.0927\n",
      "Epoch 3254/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10341.6137 - reconstruction_loss: 9808.0391 - kl_loss: 434.5168\n",
      "Epoch 3255/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10301.8457 - reconstruction_loss: 9789.2900 - kl_loss: 434.0542\n",
      "Epoch 3256/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10383.4874 - reconstruction_loss: 9847.1621 - kl_loss: 434.7820\n",
      "Epoch 3257/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10296.8542 - reconstruction_loss: 9781.7939 - kl_loss: 434.5892\n",
      "Epoch 3258/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10283.4393 - reconstruction_loss: 9772.3633 - kl_loss: 433.9423\n",
      "Epoch 3259/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10303.5369 - reconstruction_loss: 9787.6230 - kl_loss: 433.7559\n",
      "Epoch 3260/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10291.0270 - reconstruction_loss: 9760.4727 - kl_loss: 434.1606\n",
      "Epoch 3261/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10248.8408 - reconstruction_loss: 9744.2129 - kl_loss: 434.0014\n",
      "Epoch 3262/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10285.2857 - reconstruction_loss: 9788.5811 - kl_loss: 434.0458\n",
      "Epoch 3263/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10263.0117 - reconstruction_loss: 9747.1631 - kl_loss: 433.8125\n",
      "Epoch 3264/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 10313.9149 - reconstruction_loss: 9785.7051 - kl_loss: 432.9413\n",
      "Epoch 3265/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 10290.3552 - reconstruction_loss: 9789.9297 - kl_loss: 433.6192\n",
      "Epoch 3266/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10323.5665 - reconstruction_loss: 9776.0566 - kl_loss: 432.7074\n",
      "Epoch 3267/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10251.4680 - reconstruction_loss: 9744.0859 - kl_loss: 433.2216\n",
      "Epoch 3268/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10279.1031 - reconstruction_loss: 9768.9922 - kl_loss: 433.5555\n",
      "Epoch 3269/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10272.8983 - reconstruction_loss: 9750.7109 - kl_loss: 433.8341\n",
      "Epoch 3270/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10243.3791 - reconstruction_loss: 9735.6484 - kl_loss: 434.0851\n",
      "Epoch 3271/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10256.0756 - reconstruction_loss: 9738.0332 - kl_loss: 433.2911\n",
      "Epoch 3272/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10238.6194 - reconstruction_loss: 9722.6973 - kl_loss: 433.5039\n",
      "Epoch 3273/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 10240.7772 - reconstruction_loss: 9745.3369 - kl_loss: 435.1652\n",
      "Epoch 3274/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 10307.4676 - reconstruction_loss: 9761.4287 - kl_loss: 433.8049\n",
      "Epoch 3275/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10247.5563 - reconstruction_loss: 9734.0684 - kl_loss: 432.3123\n",
      "Epoch 3276/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10290.1242 - reconstruction_loss: 9777.0430 - kl_loss: 432.3680\n",
      "Epoch 3277/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10314.0395 - reconstruction_loss: 9779.3428 - kl_loss: 433.0238\n",
      "Epoch 3278/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10265.9668 - reconstruction_loss: 9762.2529 - kl_loss: 432.8316\n",
      "Epoch 3279/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10263.2902 - reconstruction_loss: 9758.1016 - kl_loss: 432.7556\n",
      "Epoch 3280/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10303.8962 - reconstruction_loss: 9760.9033 - kl_loss: 432.5316\n",
      "Epoch 3281/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10329.3081 - reconstruction_loss: 9788.1279 - kl_loss: 432.4685\n",
      "Epoch 3282/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10240.4729 - reconstruction_loss: 9734.6514 - kl_loss: 433.1836\n",
      "Epoch 3283/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10266.7154 - reconstruction_loss: 9736.3252 - kl_loss: 431.8329\n",
      "Epoch 3284/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10194.4273 - reconstruction_loss: 9704.3770 - kl_loss: 431.5205\n",
      "Epoch 3285/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10210.6026 - reconstruction_loss: 9716.0225 - kl_loss: 432.4733\n",
      "Epoch 3286/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10219.1822 - reconstruction_loss: 9709.0674 - kl_loss: 432.4732\n",
      "Epoch 3287/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10190.7559 - reconstruction_loss: 9693.3154 - kl_loss: 431.3770\n",
      "Epoch 3288/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10268.0467 - reconstruction_loss: 9736.0518 - kl_loss: 432.2470\n",
      "Epoch 3289/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10226.3260 - reconstruction_loss: 9703.3086 - kl_loss: 431.9420\n",
      "Epoch 3290/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10249.5600 - reconstruction_loss: 9730.6924 - kl_loss: 431.8998\n",
      "Epoch 3291/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10257.4158 - reconstruction_loss: 9751.1094 - kl_loss: 431.3717\n",
      "Epoch 3292/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10240.2168 - reconstruction_loss: 9706.8193 - kl_loss: 431.0312\n",
      "Epoch 3293/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10173.3935 - reconstruction_loss: 9684.3096 - kl_loss: 430.5327\n",
      "Epoch 3294/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10225.9474 - reconstruction_loss: 9704.7939 - kl_loss: 429.8392\n",
      "Epoch 3295/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10197.7524 - reconstruction_loss: 9674.9795 - kl_loss: 431.2369\n",
      "Epoch 3296/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10165.8694 - reconstruction_loss: 9672.8076 - kl_loss: 431.0306\n",
      "Epoch 3297/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10208.4861 - reconstruction_loss: 9700.7305 - kl_loss: 430.8918\n",
      "Epoch 3298/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10203.2734 - reconstruction_loss: 9697.0771 - kl_loss: 430.8580\n",
      "Epoch 3299/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10305.8148 - reconstruction_loss: 9790.4873 - kl_loss: 431.6135\n",
      "Epoch 3300/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10256.2271 - reconstruction_loss: 9725.1807 - kl_loss: 431.1950\n",
      "Epoch 3301/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10184.9617 - reconstruction_loss: 9683.6328 - kl_loss: 430.6031\n",
      "Epoch 3302/5000\n",
      "75/75 [==============================] - 2s 33ms/step - loss: 10212.9979 - reconstruction_loss: 9707.7715 - kl_loss: 431.4454\n",
      "Epoch 3303/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 10268.3325 - reconstruction_loss: 9738.0791 - kl_loss: 430.4739\n",
      "Epoch 3304/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10180.1275 - reconstruction_loss: 9675.5137 - kl_loss: 430.6951\n",
      "Epoch 3305/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10217.1846 - reconstruction_loss: 9712.5430 - kl_loss: 429.6725\n",
      "Epoch 3306/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10217.8808 - reconstruction_loss: 9693.8604 - kl_loss: 429.7946\n",
      "Epoch 3307/5000\n",
      "75/75 [==============================] - 704s 10s/step - loss: 10184.4393 - reconstruction_loss: 9679.1572 - kl_loss: 429.4646\n",
      "Epoch 3308/5000\n",
      "75/75 [==============================] - 3s 39ms/step - loss: 10180.4775 - reconstruction_loss: 9695.0986 - kl_loss: 428.7356\n",
      "Epoch 3309/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 10199.5685 - reconstruction_loss: 9685.7959 - kl_loss: 429.5466\n",
      "Epoch 3310/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 10143.2652 - reconstruction_loss: 9660.0957 - kl_loss: 429.3915\n",
      "Epoch 3311/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 10194.0115 - reconstruction_loss: 9705.3018 - kl_loss: 429.8687\n",
      "Epoch 3312/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 10278.0327 - reconstruction_loss: 9745.8779 - kl_loss: 428.8675\n",
      "Epoch 3313/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10200.8456 - reconstruction_loss: 9710.6602 - kl_loss: 428.6094\n",
      "Epoch 3314/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10217.4824 - reconstruction_loss: 9711.8936 - kl_loss: 429.2510\n",
      "Epoch 3315/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10266.3962 - reconstruction_loss: 9739.6045 - kl_loss: 429.2621\n",
      "Epoch 3316/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10214.8698 - reconstruction_loss: 9733.3057 - kl_loss: 429.4169\n",
      "Epoch 3317/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10260.1923 - reconstruction_loss: 9759.5537 - kl_loss: 429.8427\n",
      "Epoch 3318/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10258.0514 - reconstruction_loss: 9744.9512 - kl_loss: 429.5661\n",
      "Epoch 3319/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10249.8731 - reconstruction_loss: 9748.2402 - kl_loss: 427.9651\n",
      "Epoch 3320/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10291.6785 - reconstruction_loss: 9806.4463 - kl_loss: 428.7976\n",
      "Epoch 3321/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10311.9703 - reconstruction_loss: 9831.7500 - kl_loss: 429.1038\n",
      "Epoch 3322/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10414.8917 - reconstruction_loss: 9858.9014 - kl_loss: 428.4277\n",
      "Epoch 3323/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10466.2247 - reconstruction_loss: 9926.3066 - kl_loss: 429.2253\n",
      "Epoch 3324/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10375.3327 - reconstruction_loss: 9840.5566 - kl_loss: 429.4937\n",
      "Epoch 3325/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10400.8791 - reconstruction_loss: 9855.1182 - kl_loss: 428.7957\n",
      "Epoch 3326/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10472.8733 - reconstruction_loss: 9899.3076 - kl_loss: 429.9991\n",
      "Epoch 3327/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10412.9969 - reconstruction_loss: 9864.8350 - kl_loss: 429.2721\n",
      "Epoch 3328/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10491.7673 - reconstruction_loss: 9934.5137 - kl_loss: 427.9381\n",
      "Epoch 3329/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10470.7772 - reconstruction_loss: 9913.0771 - kl_loss: 427.9161\n",
      "Epoch 3330/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10418.1287 - reconstruction_loss: 9887.0957 - kl_loss: 428.5652\n",
      "Epoch 3331/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10450.2586 - reconstruction_loss: 9932.6689 - kl_loss: 428.4262\n",
      "Epoch 3332/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10444.6050 - reconstruction_loss: 9919.6680 - kl_loss: 428.2315\n",
      "Epoch 3333/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10473.4322 - reconstruction_loss: 9938.1494 - kl_loss: 428.8351\n",
      "Epoch 3334/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10464.4492 - reconstruction_loss: 9952.4404 - kl_loss: 428.7398\n",
      "Epoch 3335/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10477.0709 - reconstruction_loss: 9956.8037 - kl_loss: 427.4055\n",
      "Epoch 3336/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10453.5428 - reconstruction_loss: 9968.7480 - kl_loss: 427.8387\n",
      "Epoch 3337/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10446.5901 - reconstruction_loss: 9973.5156 - kl_loss: 428.3025\n",
      "Epoch 3338/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10475.6134 - reconstruction_loss: 10001.4873 - kl_loss: 428.7950\n",
      "Epoch 3339/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 10449.4849 - reconstruction_loss: 10037.5566 - kl_loss: 427.5135\n",
      "Epoch 3340/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10496.1117 - reconstruction_loss: 10099.1475 - kl_loss: 426.7770\n",
      "Epoch 3341/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10546.7036 - reconstruction_loss: 10093.1152 - kl_loss: 425.2883\n",
      "Epoch 3342/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10640.7069 - reconstruction_loss: 10118.2061 - kl_loss: 427.5714\n",
      "Epoch 3343/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10558.9120 - reconstruction_loss: 10073.6895 - kl_loss: 429.1422\n",
      "Epoch 3344/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10477.8111 - reconstruction_loss: 10067.9062 - kl_loss: 426.6174\n",
      "Epoch 3345/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10499.1528 - reconstruction_loss: 10074.2324 - kl_loss: 427.3568\n",
      "Epoch 3346/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10580.5321 - reconstruction_loss: 10117.4951 - kl_loss: 429.2321\n",
      "Epoch 3347/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10532.1865 - reconstruction_loss: 10097.5635 - kl_loss: 428.8645\n",
      "Epoch 3348/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10549.2200 - reconstruction_loss: 10124.4688 - kl_loss: 428.0589\n",
      "Epoch 3349/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10655.6240 - reconstruction_loss: 10144.9736 - kl_loss: 429.8117\n",
      "Epoch 3350/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10565.3341 - reconstruction_loss: 10097.9248 - kl_loss: 427.6492\n",
      "Epoch 3351/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10663.7252 - reconstruction_loss: 10190.6670 - kl_loss: 427.6500\n",
      "Epoch 3352/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10617.3298 - reconstruction_loss: 10137.6396 - kl_loss: 428.0896\n",
      "Epoch 3353/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10576.2322 - reconstruction_loss: 10121.5479 - kl_loss: 426.9463\n",
      "Epoch 3354/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10562.2802 - reconstruction_loss: 10094.7891 - kl_loss: 428.4770\n",
      "Epoch 3355/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10575.2320 - reconstruction_loss: 10119.9795 - kl_loss: 427.9279\n",
      "Epoch 3356/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10550.1213 - reconstruction_loss: 10123.6582 - kl_loss: 428.3331\n",
      "Epoch 3357/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10655.3614 - reconstruction_loss: 10179.9775 - kl_loss: 428.0825\n",
      "Epoch 3358/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10644.0876 - reconstruction_loss: 10173.3701 - kl_loss: 429.0398\n",
      "Epoch 3359/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10672.9555 - reconstruction_loss: 10212.5918 - kl_loss: 428.9048\n",
      "Epoch 3360/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10669.9958 - reconstruction_loss: 10214.2197 - kl_loss: 427.4099\n",
      "Epoch 3361/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10753.8419 - reconstruction_loss: 10289.4111 - kl_loss: 427.9667\n",
      "Epoch 3362/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10715.2423 - reconstruction_loss: 10255.0322 - kl_loss: 427.4381\n",
      "Epoch 3363/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 10837.3014 - reconstruction_loss: 10350.6143 - kl_loss: 427.3453\n",
      "Epoch 3364/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10856.6200 - reconstruction_loss: 10379.7012 - kl_loss: 427.7515\n",
      "Epoch 3365/5000\n",
      "75/75 [==============================] - 2s 27ms/step - loss: 10849.9457 - reconstruction_loss: 10358.1484 - kl_loss: 428.4919\n",
      "Epoch 3366/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10809.0799 - reconstruction_loss: 10346.3262 - kl_loss: 427.3637\n",
      "Epoch 3367/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10845.3165 - reconstruction_loss: 10367.2705 - kl_loss: 426.3401\n",
      "Epoch 3368/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10824.2489 - reconstruction_loss: 10341.8906 - kl_loss: 427.5836\n",
      "Epoch 3369/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10882.6274 - reconstruction_loss: 10391.8281 - kl_loss: 426.8160\n",
      "Epoch 3370/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10858.2807 - reconstruction_loss: 10382.4316 - kl_loss: 427.4529\n",
      "Epoch 3371/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10807.3224 - reconstruction_loss: 10340.7109 - kl_loss: 429.3588\n",
      "Epoch 3372/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10777.9651 - reconstruction_loss: 10357.1270 - kl_loss: 427.6567\n",
      "Epoch 3373/5000\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 10733.2097 - reconstruction_loss: 10317.7754 - kl_loss: 426.9692\n",
      "Epoch 3374/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10717.9701 - reconstruction_loss: 10307.7578 - kl_loss: 427.9951\n",
      "Epoch 3375/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10699.4696 - reconstruction_loss: 10291.6631 - kl_loss: 426.9547\n",
      "Epoch 3376/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10686.2605 - reconstruction_loss: 10282.4609 - kl_loss: 427.4491\n",
      "Epoch 3377/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10693.5423 - reconstruction_loss: 10283.2305 - kl_loss: 427.0823\n",
      "Epoch 3378/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10671.1225 - reconstruction_loss: 10265.2227 - kl_loss: 427.1418\n",
      "Epoch 3379/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10711.0315 - reconstruction_loss: 10288.0225 - kl_loss: 428.2470\n",
      "Epoch 3380/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10699.1645 - reconstruction_loss: 10301.1943 - kl_loss: 427.4822\n",
      "Epoch 3381/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10824.0067 - reconstruction_loss: 10375.6318 - kl_loss: 428.1248\n",
      "Epoch 3382/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10799.4601 - reconstruction_loss: 10359.0830 - kl_loss: 428.2181\n",
      "Epoch 3383/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10804.3797 - reconstruction_loss: 10372.4355 - kl_loss: 426.8367\n",
      "Epoch 3384/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10813.8786 - reconstruction_loss: 10356.5527 - kl_loss: 428.3892\n",
      "Epoch 3385/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10859.2522 - reconstruction_loss: 10390.4609 - kl_loss: 428.3267\n",
      "Epoch 3386/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10819.5584 - reconstruction_loss: 10358.6074 - kl_loss: 427.7636\n",
      "Epoch 3387/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10838.0726 - reconstruction_loss: 10370.3760 - kl_loss: 427.4804\n",
      "Epoch 3388/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10764.8418 - reconstruction_loss: 10315.8994 - kl_loss: 428.4379\n",
      "Epoch 3389/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10757.5559 - reconstruction_loss: 10320.6582 - kl_loss: 427.7548\n",
      "Epoch 3390/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10723.1557 - reconstruction_loss: 10287.0791 - kl_loss: 427.3532\n",
      "Epoch 3391/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10692.3268 - reconstruction_loss: 10253.4023 - kl_loss: 428.2790\n",
      "Epoch 3392/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10681.6376 - reconstruction_loss: 10261.3320 - kl_loss: 428.3135\n",
      "Epoch 3393/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10668.1946 - reconstruction_loss: 10236.4219 - kl_loss: 428.6984\n",
      "Epoch 3394/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10710.5772 - reconstruction_loss: 10264.6836 - kl_loss: 428.1571\n",
      "Epoch 3395/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10696.5936 - reconstruction_loss: 10258.0547 - kl_loss: 428.3046\n",
      "Epoch 3396/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10683.7548 - reconstruction_loss: 10253.7705 - kl_loss: 429.2720\n",
      "Epoch 3397/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10691.8878 - reconstruction_loss: 10279.5811 - kl_loss: 429.2210\n",
      "Epoch 3398/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10735.2235 - reconstruction_loss: 10296.6484 - kl_loss: 428.1535\n",
      "Epoch 3399/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10737.0609 - reconstruction_loss: 10314.6797 - kl_loss: 427.6585\n",
      "Epoch 3400/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10768.4263 - reconstruction_loss: 10325.5244 - kl_loss: 426.8484\n",
      "Epoch 3401/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10770.8914 - reconstruction_loss: 10319.6328 - kl_loss: 428.5727\n",
      "Epoch 3402/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10776.4531 - reconstruction_loss: 10327.7666 - kl_loss: 427.3369\n",
      "Epoch 3403/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10762.6718 - reconstruction_loss: 10319.5127 - kl_loss: 427.3508\n",
      "Epoch 3404/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10788.2180 - reconstruction_loss: 10348.9014 - kl_loss: 427.7678\n",
      "Epoch 3405/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10899.3811 - reconstruction_loss: 10412.9561 - kl_loss: 426.9661\n",
      "Epoch 3406/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10925.6201 - reconstruction_loss: 10408.7920 - kl_loss: 427.2114\n",
      "Epoch 3407/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10860.4590 - reconstruction_loss: 10379.1533 - kl_loss: 428.2180\n",
      "Epoch 3408/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10961.1138 - reconstruction_loss: 10446.8906 - kl_loss: 428.1742\n",
      "Epoch 3409/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10905.1372 - reconstruction_loss: 10380.1758 - kl_loss: 428.7414\n",
      "Epoch 3410/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10862.9321 - reconstruction_loss: 10372.6211 - kl_loss: 428.3143\n",
      "Epoch 3411/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10884.3348 - reconstruction_loss: 10362.2744 - kl_loss: 427.2340\n",
      "Epoch 3412/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10785.3353 - reconstruction_loss: 10294.8174 - kl_loss: 428.2509\n",
      "Epoch 3413/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10762.0597 - reconstruction_loss: 10293.6904 - kl_loss: 429.1305\n",
      "Epoch 3414/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10764.5471 - reconstruction_loss: 10303.7676 - kl_loss: 427.9995\n",
      "Epoch 3415/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10790.9475 - reconstruction_loss: 10314.5684 - kl_loss: 428.1133\n",
      "Epoch 3416/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10752.8563 - reconstruction_loss: 10296.5010 - kl_loss: 428.1566\n",
      "Epoch 3417/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10777.5293 - reconstruction_loss: 10309.4219 - kl_loss: 429.5036\n",
      "Epoch 3418/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10713.4949 - reconstruction_loss: 10241.5537 - kl_loss: 430.2798\n",
      "Epoch 3419/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10647.9776 - reconstruction_loss: 10185.5615 - kl_loss: 429.0111\n",
      "Epoch 3420/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 10620.8595 - reconstruction_loss: 10145.4658 - kl_loss: 429.2029\n",
      "Epoch 3421/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10558.2238 - reconstruction_loss: 10102.2344 - kl_loss: 429.3185\n",
      "Epoch 3422/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10513.4445 - reconstruction_loss: 10062.9531 - kl_loss: 429.5282\n",
      "Epoch 3423/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10487.3876 - reconstruction_loss: 10034.1299 - kl_loss: 429.6011\n",
      "Epoch 3424/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10433.6558 - reconstruction_loss: 9981.7275 - kl_loss: 429.8609\n",
      "Epoch 3425/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10402.4117 - reconstruction_loss: 9957.4463 - kl_loss: 429.5061\n",
      "Epoch 3426/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10389.5737 - reconstruction_loss: 9928.7646 - kl_loss: 429.1807\n",
      "Epoch 3427/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10366.4442 - reconstruction_loss: 9913.0352 - kl_loss: 430.6031\n",
      "Epoch 3428/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10359.5748 - reconstruction_loss: 9903.7783 - kl_loss: 429.7789\n",
      "Epoch 3429/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10383.8676 - reconstruction_loss: 9916.1699 - kl_loss: 429.4627\n",
      "Epoch 3430/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10373.6856 - reconstruction_loss: 9900.6523 - kl_loss: 430.5239\n",
      "Epoch 3431/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10325.1726 - reconstruction_loss: 9881.3242 - kl_loss: 429.4884\n",
      "Epoch 3432/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10340.7688 - reconstruction_loss: 9863.1309 - kl_loss: 428.6949\n",
      "Epoch 3433/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10346.4546 - reconstruction_loss: 9862.3105 - kl_loss: 429.7788\n",
      "Epoch 3434/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10285.0801 - reconstruction_loss: 9827.1250 - kl_loss: 429.1114\n",
      "Epoch 3435/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10349.8136 - reconstruction_loss: 9861.9941 - kl_loss: 428.6224\n",
      "Epoch 3436/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10353.6211 - reconstruction_loss: 9856.3125 - kl_loss: 428.5485\n",
      "Epoch 3437/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10272.0352 - reconstruction_loss: 9802.3213 - kl_loss: 428.6347\n",
      "Epoch 3438/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10261.5964 - reconstruction_loss: 9800.6768 - kl_loss: 429.3240\n",
      "Epoch 3439/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10242.3159 - reconstruction_loss: 9774.9600 - kl_loss: 429.2869\n",
      "Epoch 3440/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10236.4746 - reconstruction_loss: 9757.5693 - kl_loss: 429.6769\n",
      "Epoch 3441/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10219.1108 - reconstruction_loss: 9761.2969 - kl_loss: 429.5591\n",
      "Epoch 3442/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10215.4418 - reconstruction_loss: 9753.9121 - kl_loss: 428.0290\n",
      "Epoch 3443/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10197.0886 - reconstruction_loss: 9738.4629 - kl_loss: 429.7148\n",
      "Epoch 3444/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10182.6161 - reconstruction_loss: 9727.7617 - kl_loss: 428.8999\n",
      "Epoch 3445/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10183.5185 - reconstruction_loss: 9713.6602 - kl_loss: 429.1300\n",
      "Epoch 3446/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10161.2313 - reconstruction_loss: 9704.7578 - kl_loss: 427.4572\n",
      "Epoch 3447/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10154.0883 - reconstruction_loss: 9696.5586 - kl_loss: 426.6207\n",
      "Epoch 3448/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10167.4928 - reconstruction_loss: 9705.5732 - kl_loss: 427.0475\n",
      "Epoch 3449/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10138.3406 - reconstruction_loss: 9683.8652 - kl_loss: 428.6729\n",
      "Epoch 3450/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10140.1771 - reconstruction_loss: 9679.9688 - kl_loss: 428.2619\n",
      "Epoch 3451/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10124.1195 - reconstruction_loss: 9653.8750 - kl_loss: 427.9596\n",
      "Epoch 3452/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10118.5963 - reconstruction_loss: 9652.9121 - kl_loss: 427.5481\n",
      "Epoch 3453/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10111.3498 - reconstruction_loss: 9649.1953 - kl_loss: 428.2199\n",
      "Epoch 3454/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10110.8413 - reconstruction_loss: 9646.1582 - kl_loss: 428.0342\n",
      "Epoch 3455/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10127.6686 - reconstruction_loss: 9649.3193 - kl_loss: 427.8537\n",
      "Epoch 3456/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10098.7964 - reconstruction_loss: 9608.9082 - kl_loss: 428.7026\n",
      "Epoch 3457/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10063.2149 - reconstruction_loss: 9593.4229 - kl_loss: 426.8860\n",
      "Epoch 3458/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10212.2748 - reconstruction_loss: 9675.1055 - kl_loss: 427.5062\n",
      "Epoch 3459/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10175.3785 - reconstruction_loss: 9634.0225 - kl_loss: 427.7754\n",
      "Epoch 3460/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10086.8840 - reconstruction_loss: 9620.2754 - kl_loss: 426.2883\n",
      "Epoch 3461/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10150.4202 - reconstruction_loss: 9617.8916 - kl_loss: 427.1645\n",
      "Epoch 3462/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10142.3292 - reconstruction_loss: 9618.6104 - kl_loss: 427.3132\n",
      "Epoch 3463/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10230.0243 - reconstruction_loss: 9738.9570 - kl_loss: 429.6579\n",
      "Epoch 3464/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10094.4699 - reconstruction_loss: 9603.0020 - kl_loss: 428.2407\n",
      "Epoch 3465/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10044.4990 - reconstruction_loss: 9561.1289 - kl_loss: 427.4703\n",
      "Epoch 3466/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10017.1246 - reconstruction_loss: 9542.0732 - kl_loss: 425.9562\n",
      "Epoch 3467/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10024.7114 - reconstruction_loss: 9545.1445 - kl_loss: 426.3564\n",
      "Epoch 3468/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10013.1106 - reconstruction_loss: 9529.6387 - kl_loss: 426.8076\n",
      "Epoch 3469/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9988.2034 - reconstruction_loss: 9511.9180 - kl_loss: 426.6637\n",
      "Epoch 3470/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10004.6207 - reconstruction_loss: 9527.4951 - kl_loss: 425.7797\n",
      "Epoch 3471/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9982.5776 - reconstruction_loss: 9513.1289 - kl_loss: 425.8931\n",
      "Epoch 3472/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9971.4457 - reconstruction_loss: 9498.3652 - kl_loss: 426.3130\n",
      "Epoch 3473/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9960.0513 - reconstruction_loss: 9491.4609 - kl_loss: 425.7886\n",
      "Epoch 3474/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9981.0567 - reconstruction_loss: 9495.3525 - kl_loss: 426.1788\n",
      "Epoch 3475/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9963.0368 - reconstruction_loss: 9489.2295 - kl_loss: 426.4339\n",
      "Epoch 3476/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9978.6520 - reconstruction_loss: 9496.8271 - kl_loss: 426.7888\n",
      "Epoch 3477/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9957.6284 - reconstruction_loss: 9483.5908 - kl_loss: 425.8617\n",
      "Epoch 3478/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10027.6030 - reconstruction_loss: 9524.5801 - kl_loss: 425.8399\n",
      "Epoch 3479/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9979.4050 - reconstruction_loss: 9509.1143 - kl_loss: 425.5115\n",
      "Epoch 3480/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9962.6132 - reconstruction_loss: 9489.1738 - kl_loss: 426.0937\n",
      "Epoch 3481/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10017.1147 - reconstruction_loss: 9524.0127 - kl_loss: 425.9167\n",
      "Epoch 3482/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10048.4684 - reconstruction_loss: 9533.8848 - kl_loss: 425.6556\n",
      "Epoch 3483/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10089.8158 - reconstruction_loss: 9612.5645 - kl_loss: 424.7789\n",
      "Epoch 3484/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10159.7812 - reconstruction_loss: 9627.3408 - kl_loss: 426.6480\n",
      "Epoch 3485/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10062.1924 - reconstruction_loss: 9534.8760 - kl_loss: 427.2311\n",
      "Epoch 3486/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10034.8859 - reconstruction_loss: 9556.7012 - kl_loss: 425.4501\n",
      "Epoch 3487/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10216.9172 - reconstruction_loss: 9631.2236 - kl_loss: 424.6218\n",
      "Epoch 3488/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10139.7024 - reconstruction_loss: 9566.4805 - kl_loss: 425.2898\n",
      "Epoch 3489/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10106.3841 - reconstruction_loss: 9606.5908 - kl_loss: 426.7559\n",
      "Epoch 3490/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10029.6900 - reconstruction_loss: 9516.6162 - kl_loss: 424.8633\n",
      "Epoch 3491/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9991.9283 - reconstruction_loss: 9492.2559 - kl_loss: 425.3012\n",
      "Epoch 3492/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9998.2302 - reconstruction_loss: 9503.1074 - kl_loss: 424.5178\n",
      "Epoch 3493/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9990.5289 - reconstruction_loss: 9491.5664 - kl_loss: 423.7685\n",
      "Epoch 3494/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9958.6585 - reconstruction_loss: 9483.2139 - kl_loss: 423.7906\n",
      "Epoch 3495/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9971.5722 - reconstruction_loss: 9502.8604 - kl_loss: 423.9156\n",
      "Epoch 3496/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10039.4207 - reconstruction_loss: 9544.0713 - kl_loss: 425.2584\n",
      "Epoch 3497/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9953.6343 - reconstruction_loss: 9470.5781 - kl_loss: 423.4253\n",
      "Epoch 3498/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9953.9084 - reconstruction_loss: 9464.7061 - kl_loss: 423.7309\n",
      "Epoch 3499/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9943.3333 - reconstruction_loss: 9458.0537 - kl_loss: 423.7005\n",
      "Epoch 3500/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9960.4312 - reconstruction_loss: 9462.5938 - kl_loss: 424.7852\n",
      "Epoch 3501/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9962.5104 - reconstruction_loss: 9475.0898 - kl_loss: 424.5154\n",
      "Epoch 3502/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9966.6678 - reconstruction_loss: 9464.9932 - kl_loss: 423.9988\n",
      "Epoch 3503/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9954.5659 - reconstruction_loss: 9465.4346 - kl_loss: 423.7357\n",
      "Epoch 3504/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9952.0236 - reconstruction_loss: 9457.0088 - kl_loss: 423.1004\n",
      "Epoch 3505/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9998.4594 - reconstruction_loss: 9505.9697 - kl_loss: 422.8126\n",
      "Epoch 3506/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9942.2299 - reconstruction_loss: 9464.4844 - kl_loss: 423.3721\n",
      "Epoch 3507/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9922.8988 - reconstruction_loss: 9456.7822 - kl_loss: 423.5257\n",
      "Epoch 3508/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9967.2090 - reconstruction_loss: 9482.9414 - kl_loss: 423.5685\n",
      "Epoch 3509/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9983.8322 - reconstruction_loss: 9492.8652 - kl_loss: 422.3487\n",
      "Epoch 3510/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10058.0118 - reconstruction_loss: 9617.4072 - kl_loss: 424.0627\n",
      "Epoch 3511/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10173.4505 - reconstruction_loss: 9589.4717 - kl_loss: 424.0313\n",
      "Epoch 3512/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10071.0704 - reconstruction_loss: 9526.8750 - kl_loss: 422.8157\n",
      "Epoch 3513/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9997.9099 - reconstruction_loss: 9516.6465 - kl_loss: 423.6736\n",
      "Epoch 3514/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 10095.9830 - reconstruction_loss: 9556.5439 - kl_loss: 423.0044\n",
      "Epoch 3515/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9972.1446 - reconstruction_loss: 9474.4502 - kl_loss: 422.3210\n",
      "Epoch 3516/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9964.8204 - reconstruction_loss: 9478.7842 - kl_loss: 422.0992\n",
      "Epoch 3517/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9942.4062 - reconstruction_loss: 9458.7842 - kl_loss: 421.8480\n",
      "Epoch 3518/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9919.3875 - reconstruction_loss: 9441.7402 - kl_loss: 422.1547\n",
      "Epoch 3519/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9915.6839 - reconstruction_loss: 9453.7148 - kl_loss: 422.1542\n",
      "Epoch 3520/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9916.6478 - reconstruction_loss: 9443.0371 - kl_loss: 422.5034\n",
      "Epoch 3521/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9915.9760 - reconstruction_loss: 9441.7656 - kl_loss: 422.5548\n",
      "Epoch 3522/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9898.6902 - reconstruction_loss: 9429.0049 - kl_loss: 421.8971\n",
      "Epoch 3523/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9914.0412 - reconstruction_loss: 9441.4482 - kl_loss: 421.4596\n",
      "Epoch 3524/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9920.9888 - reconstruction_loss: 9447.6123 - kl_loss: 421.4093\n",
      "Epoch 3525/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9921.1879 - reconstruction_loss: 9446.8857 - kl_loss: 421.4075\n",
      "Epoch 3526/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9930.7416 - reconstruction_loss: 9446.0742 - kl_loss: 421.4197\n",
      "Epoch 3527/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9896.0966 - reconstruction_loss: 9425.0488 - kl_loss: 421.9399\n",
      "Epoch 3528/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9917.2012 - reconstruction_loss: 9446.9502 - kl_loss: 420.7386\n",
      "Epoch 3529/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9936.1960 - reconstruction_loss: 9453.2344 - kl_loss: 421.4787\n",
      "Epoch 3530/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 9934.1056 - reconstruction_loss: 9460.2520 - kl_loss: 420.8872\n",
      "Epoch 3531/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9923.1692 - reconstruction_loss: 9442.5918 - kl_loss: 420.5807\n",
      "Epoch 3532/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9966.6756 - reconstruction_loss: 9471.4629 - kl_loss: 420.6502\n",
      "Epoch 3533/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9953.0999 - reconstruction_loss: 9461.1904 - kl_loss: 420.8559\n",
      "Epoch 3534/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9951.3068 - reconstruction_loss: 9480.5322 - kl_loss: 420.2556\n",
      "Epoch 3535/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10035.0807 - reconstruction_loss: 9525.6494 - kl_loss: 420.7534\n",
      "Epoch 3536/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10014.6686 - reconstruction_loss: 9507.3301 - kl_loss: 421.1564\n",
      "Epoch 3537/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9961.1474 - reconstruction_loss: 9468.5635 - kl_loss: 420.2736\n",
      "Epoch 3538/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10030.1499 - reconstruction_loss: 9503.8018 - kl_loss: 420.5724\n",
      "Epoch 3539/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10050.8683 - reconstruction_loss: 9532.6768 - kl_loss: 420.1661\n",
      "Epoch 3540/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10307.7273 - reconstruction_loss: 9772.1826 - kl_loss: 423.4232\n",
      "Epoch 3541/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10141.6115 - reconstruction_loss: 9603.7119 - kl_loss: 422.4404\n",
      "Epoch 3542/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10148.5999 - reconstruction_loss: 9623.7695 - kl_loss: 421.0752\n",
      "Epoch 3543/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10080.5003 - reconstruction_loss: 9581.5391 - kl_loss: 420.5150\n",
      "Epoch 3544/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10110.2324 - reconstruction_loss: 9599.2949 - kl_loss: 420.0487\n",
      "Epoch 3545/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10109.0603 - reconstruction_loss: 9596.2764 - kl_loss: 420.4785\n",
      "Epoch 3546/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10163.4208 - reconstruction_loss: 9635.9688 - kl_loss: 419.8435\n",
      "Epoch 3547/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10205.5875 - reconstruction_loss: 9651.8174 - kl_loss: 419.2607\n",
      "Epoch 3548/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10225.9074 - reconstruction_loss: 9684.5752 - kl_loss: 420.4477\n",
      "Epoch 3549/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10151.5029 - reconstruction_loss: 9647.5264 - kl_loss: 420.5436\n",
      "Epoch 3550/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10258.2235 - reconstruction_loss: 9729.1621 - kl_loss: 420.5808\n",
      "Epoch 3551/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10210.8749 - reconstruction_loss: 9715.7080 - kl_loss: 419.9757\n",
      "Epoch 3552/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10284.8680 - reconstruction_loss: 9784.3623 - kl_loss: 420.5524\n",
      "Epoch 3553/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10274.4444 - reconstruction_loss: 9762.5889 - kl_loss: 421.1230\n",
      "Epoch 3554/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10355.2499 - reconstruction_loss: 9803.0186 - kl_loss: 420.2020\n",
      "Epoch 3555/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10304.5803 - reconstruction_loss: 9783.4316 - kl_loss: 421.9153\n",
      "Epoch 3556/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10346.3596 - reconstruction_loss: 9821.6865 - kl_loss: 420.3846\n",
      "Epoch 3557/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10298.6551 - reconstruction_loss: 9785.1074 - kl_loss: 420.1828\n",
      "Epoch 3558/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10304.0712 - reconstruction_loss: 9781.3447 - kl_loss: 419.9632\n",
      "Epoch 3559/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10280.6928 - reconstruction_loss: 9749.8359 - kl_loss: 420.2975\n",
      "Epoch 3560/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10271.0582 - reconstruction_loss: 9725.4307 - kl_loss: 419.2254\n",
      "Epoch 3561/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10248.4131 - reconstruction_loss: 9704.6416 - kl_loss: 419.0574\n",
      "Epoch 3562/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10183.9957 - reconstruction_loss: 9646.2148 - kl_loss: 419.2579\n",
      "Epoch 3563/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10129.9734 - reconstruction_loss: 9622.7705 - kl_loss: 418.9442\n",
      "Epoch 3564/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10109.9097 - reconstruction_loss: 9607.8750 - kl_loss: 419.5221\n",
      "Epoch 3565/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10105.0521 - reconstruction_loss: 9597.4766 - kl_loss: 420.0064\n",
      "Epoch 3566/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10088.1308 - reconstruction_loss: 9570.3604 - kl_loss: 419.8415\n",
      "Epoch 3567/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10031.9978 - reconstruction_loss: 9550.8809 - kl_loss: 420.0407\n",
      "Epoch 3568/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 10106.7305 - reconstruction_loss: 9579.9727 - kl_loss: 419.7364\n",
      "Epoch 3569/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 10033.4712 - reconstruction_loss: 9552.7246 - kl_loss: 419.3996\n",
      "Epoch 3570/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10035.5236 - reconstruction_loss: 9541.8008 - kl_loss: 419.5505\n",
      "Epoch 3571/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10039.4807 - reconstruction_loss: 9541.3164 - kl_loss: 418.6639\n",
      "Epoch 3572/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10035.0697 - reconstruction_loss: 9519.6211 - kl_loss: 419.0270\n",
      "Epoch 3573/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9998.6966 - reconstruction_loss: 9503.1807 - kl_loss: 419.3804\n",
      "Epoch 3574/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9993.1993 - reconstruction_loss: 9487.2500 - kl_loss: 419.8039\n",
      "Epoch 3575/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9972.2375 - reconstruction_loss: 9485.2354 - kl_loss: 420.3244\n",
      "Epoch 3576/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10003.8616 - reconstruction_loss: 9502.7080 - kl_loss: 419.7805\n",
      "Epoch 3577/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9945.9946 - reconstruction_loss: 9471.1240 - kl_loss: 419.1506\n",
      "Epoch 3578/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9963.7637 - reconstruction_loss: 9464.6523 - kl_loss: 419.0892\n",
      "Epoch 3579/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9933.2117 - reconstruction_loss: 9452.7500 - kl_loss: 418.4366\n",
      "Epoch 3580/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9963.7862 - reconstruction_loss: 9452.0098 - kl_loss: 419.0319\n",
      "Epoch 3581/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9952.5862 - reconstruction_loss: 9451.0596 - kl_loss: 419.6118\n",
      "Epoch 3582/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9953.4634 - reconstruction_loss: 9439.0498 - kl_loss: 419.2103\n",
      "Epoch 3583/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9933.4215 - reconstruction_loss: 9444.4756 - kl_loss: 418.1473\n",
      "Epoch 3584/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9962.4425 - reconstruction_loss: 9448.0889 - kl_loss: 418.4205\n",
      "Epoch 3585/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9956.0238 - reconstruction_loss: 9446.1943 - kl_loss: 419.5636\n",
      "Epoch 3586/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9899.1115 - reconstruction_loss: 9413.7666 - kl_loss: 419.4835\n",
      "Epoch 3587/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9881.2875 - reconstruction_loss: 9399.1270 - kl_loss: 419.0174\n",
      "Epoch 3588/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9882.4269 - reconstruction_loss: 9394.6738 - kl_loss: 418.0875\n",
      "Epoch 3589/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9849.8775 - reconstruction_loss: 9370.7871 - kl_loss: 418.1729\n",
      "Epoch 3590/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9857.3333 - reconstruction_loss: 9380.6953 - kl_loss: 418.5373\n",
      "Epoch 3591/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9869.7095 - reconstruction_loss: 9381.4541 - kl_loss: 417.6553\n",
      "Epoch 3592/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9839.6468 - reconstruction_loss: 9359.8604 - kl_loss: 417.8314\n",
      "Epoch 3593/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9844.4048 - reconstruction_loss: 9380.8711 - kl_loss: 418.5245\n",
      "Epoch 3594/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9885.4660 - reconstruction_loss: 9385.4697 - kl_loss: 418.7065\n",
      "Epoch 3595/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9842.2529 - reconstruction_loss: 9354.9473 - kl_loss: 418.6226\n",
      "Epoch 3596/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9856.8929 - reconstruction_loss: 9367.5537 - kl_loss: 417.4743\n",
      "Epoch 3597/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9872.9236 - reconstruction_loss: 9380.1172 - kl_loss: 418.2781\n",
      "Epoch 3598/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9816.8667 - reconstruction_loss: 9344.1211 - kl_loss: 417.1119\n",
      "Epoch 3599/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9885.7212 - reconstruction_loss: 9399.5352 - kl_loss: 417.8765\n",
      "Epoch 3600/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9905.3468 - reconstruction_loss: 9387.2529 - kl_loss: 416.6846\n",
      "Epoch 3601/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9867.0318 - reconstruction_loss: 9381.4512 - kl_loss: 416.8862\n",
      "Epoch 3602/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10026.5064 - reconstruction_loss: 9528.7031 - kl_loss: 417.7614\n",
      "Epoch 3603/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9943.9858 - reconstruction_loss: 9410.9834 - kl_loss: 416.7707\n",
      "Epoch 3604/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9861.3077 - reconstruction_loss: 9362.9395 - kl_loss: 417.2532\n",
      "Epoch 3605/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9877.4259 - reconstruction_loss: 9399.0664 - kl_loss: 417.9850\n",
      "Epoch 3606/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9856.4699 - reconstruction_loss: 9360.5254 - kl_loss: 417.8061\n",
      "Epoch 3607/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9804.7504 - reconstruction_loss: 9320.4492 - kl_loss: 416.7664\n",
      "Epoch 3608/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9822.1541 - reconstruction_loss: 9341.2900 - kl_loss: 416.7475\n",
      "Epoch 3609/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9799.3817 - reconstruction_loss: 9320.6006 - kl_loss: 416.5231\n",
      "Epoch 3610/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9778.1654 - reconstruction_loss: 9304.0898 - kl_loss: 416.2929\n",
      "Epoch 3611/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9803.9339 - reconstruction_loss: 9323.8877 - kl_loss: 416.7589\n",
      "Epoch 3612/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9799.0834 - reconstruction_loss: 9319.5410 - kl_loss: 415.9709\n",
      "Epoch 3613/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9804.0298 - reconstruction_loss: 9324.4121 - kl_loss: 416.3596\n",
      "Epoch 3614/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9827.4776 - reconstruction_loss: 9338.5879 - kl_loss: 416.8985\n",
      "Epoch 3615/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9796.5016 - reconstruction_loss: 9308.8066 - kl_loss: 415.9773\n",
      "Epoch 3616/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9775.3132 - reconstruction_loss: 9297.7881 - kl_loss: 415.7576\n",
      "Epoch 3617/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9805.2076 - reconstruction_loss: 9314.8379 - kl_loss: 415.9754\n",
      "Epoch 3618/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9791.0261 - reconstruction_loss: 9301.1533 - kl_loss: 415.1346\n",
      "Epoch 3619/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9764.1823 - reconstruction_loss: 9296.3789 - kl_loss: 414.8459\n",
      "Epoch 3620/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9880.4114 - reconstruction_loss: 9370.5703 - kl_loss: 415.1874\n",
      "Epoch 3621/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9834.1499 - reconstruction_loss: 9329.4766 - kl_loss: 415.3690\n",
      "Epoch 3622/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9815.1650 - reconstruction_loss: 9339.8330 - kl_loss: 415.2872\n",
      "Epoch 3623/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9918.1624 - reconstruction_loss: 9393.6729 - kl_loss: 414.8117\n",
      "Epoch 3624/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9830.0855 - reconstruction_loss: 9337.3799 - kl_loss: 415.1789\n",
      "Epoch 3625/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9828.2375 - reconstruction_loss: 9328.6650 - kl_loss: 415.9150\n",
      "Epoch 3626/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9867.3376 - reconstruction_loss: 9343.1104 - kl_loss: 416.4208\n",
      "Epoch 3627/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9831.0696 - reconstruction_loss: 9326.2393 - kl_loss: 416.0906\n",
      "Epoch 3628/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9801.3634 - reconstruction_loss: 9309.8271 - kl_loss: 416.7859\n",
      "Epoch 3629/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9850.2097 - reconstruction_loss: 9340.1084 - kl_loss: 415.4725\n",
      "Epoch 3630/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9809.8825 - reconstruction_loss: 9327.3350 - kl_loss: 414.5646\n",
      "Epoch 3631/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10008.0832 - reconstruction_loss: 9508.9375 - kl_loss: 416.9318\n",
      "Epoch 3632/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9873.3207 - reconstruction_loss: 9361.7441 - kl_loss: 414.7451\n",
      "Epoch 3633/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9861.6181 - reconstruction_loss: 9354.6133 - kl_loss: 414.9448\n",
      "Epoch 3634/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9888.0280 - reconstruction_loss: 9402.3164 - kl_loss: 414.4498\n",
      "Epoch 3635/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9855.3254 - reconstruction_loss: 9373.6650 - kl_loss: 415.8596\n",
      "Epoch 3636/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9779.9996 - reconstruction_loss: 9318.1680 - kl_loss: 415.1299\n",
      "Epoch 3637/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9806.8021 - reconstruction_loss: 9333.6543 - kl_loss: 413.5032\n",
      "Epoch 3638/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9784.2348 - reconstruction_loss: 9299.8467 - kl_loss: 414.3696\n",
      "Epoch 3639/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9761.8877 - reconstruction_loss: 9292.2930 - kl_loss: 413.9619\n",
      "Epoch 3640/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9750.4500 - reconstruction_loss: 9286.0723 - kl_loss: 413.9734\n",
      "Epoch 3641/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9757.7165 - reconstruction_loss: 9289.5566 - kl_loss: 413.9347\n",
      "Epoch 3642/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9763.2949 - reconstruction_loss: 9291.3760 - kl_loss: 413.9080\n",
      "Epoch 3643/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9763.1404 - reconstruction_loss: 9289.1982 - kl_loss: 413.4980\n",
      "Epoch 3644/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9792.8676 - reconstruction_loss: 9315.0635 - kl_loss: 413.5209\n",
      "Epoch 3645/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9796.6917 - reconstruction_loss: 9303.3232 - kl_loss: 414.2267\n",
      "Epoch 3646/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9768.8301 - reconstruction_loss: 9296.1309 - kl_loss: 413.8274\n",
      "Epoch 3647/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9772.0706 - reconstruction_loss: 9303.8574 - kl_loss: 413.8017\n",
      "Epoch 3648/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9777.1198 - reconstruction_loss: 9296.0127 - kl_loss: 412.3633\n",
      "Epoch 3649/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9795.5079 - reconstruction_loss: 9324.7373 - kl_loss: 413.1555\n",
      "Epoch 3650/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9867.7078 - reconstruction_loss: 9350.2432 - kl_loss: 412.2283\n",
      "Epoch 3651/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9794.0316 - reconstruction_loss: 9297.6494 - kl_loss: 412.0835\n",
      "Epoch 3652/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9799.2567 - reconstruction_loss: 9313.0771 - kl_loss: 412.7076\n",
      "Epoch 3653/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9922.0108 - reconstruction_loss: 9408.6689 - kl_loss: 412.7492\n",
      "Epoch 3654/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9871.2171 - reconstruction_loss: 9377.3701 - kl_loss: 412.7871\n",
      "Epoch 3655/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9798.5341 - reconstruction_loss: 9334.6494 - kl_loss: 412.5603\n",
      "Epoch 3656/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9912.9525 - reconstruction_loss: 9388.7549 - kl_loss: 411.8735\n",
      "Epoch 3657/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9829.1616 - reconstruction_loss: 9335.0420 - kl_loss: 411.9231\n",
      "Epoch 3658/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9798.7285 - reconstruction_loss: 9322.0723 - kl_loss: 412.3078\n",
      "Epoch 3659/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9791.5820 - reconstruction_loss: 9318.1582 - kl_loss: 413.9126\n",
      "Epoch 3660/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9830.9539 - reconstruction_loss: 9347.5645 - kl_loss: 412.7640\n",
      "Epoch 3661/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9834.7797 - reconstruction_loss: 9349.5625 - kl_loss: 412.4434\n",
      "Epoch 3662/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9806.4226 - reconstruction_loss: 9321.6660 - kl_loss: 412.8240\n",
      "Epoch 3663/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9808.2823 - reconstruction_loss: 9316.8848 - kl_loss: 413.2214\n",
      "Epoch 3664/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9756.0587 - reconstruction_loss: 9290.2949 - kl_loss: 412.6303\n",
      "Epoch 3665/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9770.3867 - reconstruction_loss: 9293.2256 - kl_loss: 411.7915\n",
      "Epoch 3666/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9768.5960 - reconstruction_loss: 9311.1543 - kl_loss: 412.1563\n",
      "Epoch 3667/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9781.4703 - reconstruction_loss: 9293.1064 - kl_loss: 412.3151\n",
      "Epoch 3668/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9773.2572 - reconstruction_loss: 9306.8623 - kl_loss: 411.0504\n",
      "Epoch 3669/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9821.8681 - reconstruction_loss: 9352.9043 - kl_loss: 412.7198\n",
      "Epoch 3670/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9845.9060 - reconstruction_loss: 9338.0312 - kl_loss: 412.4493\n",
      "Epoch 3671/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9820.5773 - reconstruction_loss: 9323.0732 - kl_loss: 411.6887\n",
      "Epoch 3672/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9801.1156 - reconstruction_loss: 9319.4561 - kl_loss: 412.0307\n",
      "Epoch 3673/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9780.8211 - reconstruction_loss: 9308.1133 - kl_loss: 411.7827\n",
      "Epoch 3674/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9811.5304 - reconstruction_loss: 9318.1494 - kl_loss: 411.4504\n",
      "Epoch 3675/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9789.3132 - reconstruction_loss: 9318.4453 - kl_loss: 410.0527\n",
      "Epoch 3676/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9824.8825 - reconstruction_loss: 9347.0938 - kl_loss: 410.6247\n",
      "Epoch 3677/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9961.1423 - reconstruction_loss: 9481.9619 - kl_loss: 411.6501\n",
      "Epoch 3678/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9859.2793 - reconstruction_loss: 9365.0020 - kl_loss: 411.9765\n",
      "Epoch 3679/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9897.1003 - reconstruction_loss: 9401.5869 - kl_loss: 410.4348\n",
      "Epoch 3680/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9858.7759 - reconstruction_loss: 9364.8555 - kl_loss: 410.7111\n",
      "Epoch 3681/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9838.3403 - reconstruction_loss: 9370.4795 - kl_loss: 409.9657\n",
      "Epoch 3682/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9930.0952 - reconstruction_loss: 9408.1582 - kl_loss: 410.0199\n",
      "Epoch 3683/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9912.6421 - reconstruction_loss: 9386.7705 - kl_loss: 410.0551\n",
      "Epoch 3684/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9853.4561 - reconstruction_loss: 9375.3477 - kl_loss: 411.1810\n",
      "Epoch 3685/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9932.9647 - reconstruction_loss: 9439.7041 - kl_loss: 409.5288\n",
      "Epoch 3686/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10434.3261 - reconstruction_loss: 9701.0586 - kl_loss: 416.3462\n",
      "Epoch 3687/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9968.2088 - reconstruction_loss: 9439.3477 - kl_loss: 411.5268\n",
      "Epoch 3688/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9973.4640 - reconstruction_loss: 9467.7363 - kl_loss: 411.3874\n",
      "Epoch 3689/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9987.5543 - reconstruction_loss: 9486.1396 - kl_loss: 411.0041\n",
      "Epoch 3690/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9900.5460 - reconstruction_loss: 9436.6191 - kl_loss: 410.6020\n",
      "Epoch 3691/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9912.5426 - reconstruction_loss: 9451.7969 - kl_loss: 411.2198\n",
      "Epoch 3692/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9898.9735 - reconstruction_loss: 9463.4697 - kl_loss: 410.7065\n",
      "Epoch 3693/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9894.9786 - reconstruction_loss: 9436.6494 - kl_loss: 411.7220\n",
      "Epoch 3694/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9892.3301 - reconstruction_loss: 9443.8945 - kl_loss: 410.0284\n",
      "Epoch 3695/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9906.2289 - reconstruction_loss: 9453.2842 - kl_loss: 409.8135\n",
      "Epoch 3696/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9931.4969 - reconstruction_loss: 9463.7734 - kl_loss: 411.3131\n",
      "Epoch 3697/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9911.8820 - reconstruction_loss: 9441.6348 - kl_loss: 410.8227\n",
      "Epoch 3698/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9920.8093 - reconstruction_loss: 9457.0391 - kl_loss: 410.7361\n",
      "Epoch 3699/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9931.4866 - reconstruction_loss: 9470.4111 - kl_loss: 410.7220\n",
      "Epoch 3700/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9947.5415 - reconstruction_loss: 9475.7207 - kl_loss: 410.0319\n",
      "Epoch 3701/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9976.2296 - reconstruction_loss: 9502.7402 - kl_loss: 408.9481\n",
      "Epoch 3702/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9920.3858 - reconstruction_loss: 9469.6055 - kl_loss: 410.1926\n",
      "Epoch 3703/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9920.2246 - reconstruction_loss: 9481.2588 - kl_loss: 408.7836\n",
      "Epoch 3704/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9949.9105 - reconstruction_loss: 9472.6934 - kl_loss: 409.3387\n",
      "Epoch 3705/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9885.8788 - reconstruction_loss: 9425.4834 - kl_loss: 410.7246\n",
      "Epoch 3706/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9879.0263 - reconstruction_loss: 9422.8691 - kl_loss: 410.2021\n",
      "Epoch 3707/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9899.7513 - reconstruction_loss: 9419.6826 - kl_loss: 409.3153\n",
      "Epoch 3708/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9887.4159 - reconstruction_loss: 9415.7998 - kl_loss: 409.3586\n",
      "Epoch 3709/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9895.6708 - reconstruction_loss: 9430.6191 - kl_loss: 409.3399\n",
      "Epoch 3710/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9903.6260 - reconstruction_loss: 9419.7012 - kl_loss: 408.7125\n",
      "Epoch 3711/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9884.1354 - reconstruction_loss: 9425.8301 - kl_loss: 409.9902\n",
      "Epoch 3712/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9891.3130 - reconstruction_loss: 9432.6182 - kl_loss: 410.3408\n",
      "Epoch 3713/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9901.6767 - reconstruction_loss: 9428.9111 - kl_loss: 410.2169\n",
      "Epoch 3714/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9900.0258 - reconstruction_loss: 9427.9199 - kl_loss: 409.7279\n",
      "Epoch 3715/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9912.2149 - reconstruction_loss: 9436.8496 - kl_loss: 409.9075\n",
      "Epoch 3716/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9930.1563 - reconstruction_loss: 9467.4121 - kl_loss: 409.7202\n",
      "Epoch 3717/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10041.1763 - reconstruction_loss: 9566.1475 - kl_loss: 410.2608\n",
      "Epoch 3718/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9913.0225 - reconstruction_loss: 9449.6484 - kl_loss: 409.8112\n",
      "Epoch 3719/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9884.7182 - reconstruction_loss: 9431.5215 - kl_loss: 408.7346\n",
      "Epoch 3720/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9886.8246 - reconstruction_loss: 9432.6729 - kl_loss: 408.6208\n",
      "Epoch 3721/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9926.0080 - reconstruction_loss: 9456.0713 - kl_loss: 408.8059\n",
      "Epoch 3722/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9914.4572 - reconstruction_loss: 9459.1104 - kl_loss: 409.4278\n",
      "Epoch 3723/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9914.7866 - reconstruction_loss: 9465.6006 - kl_loss: 409.2106\n",
      "Epoch 3724/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9914.4080 - reconstruction_loss: 9472.6387 - kl_loss: 409.1422\n",
      "Epoch 3725/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9916.0890 - reconstruction_loss: 9471.6729 - kl_loss: 409.1529\n",
      "Epoch 3726/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9937.5785 - reconstruction_loss: 9469.6299 - kl_loss: 409.3528\n",
      "Epoch 3727/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9949.6396 - reconstruction_loss: 9494.8682 - kl_loss: 409.6304\n",
      "Epoch 3728/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9949.3288 - reconstruction_loss: 9491.1553 - kl_loss: 408.2469\n",
      "Epoch 3729/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9955.0489 - reconstruction_loss: 9506.9912 - kl_loss: 407.1790\n",
      "Epoch 3730/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9969.8426 - reconstruction_loss: 9512.0654 - kl_loss: 407.3689\n",
      "Epoch 3731/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10003.6012 - reconstruction_loss: 9526.4512 - kl_loss: 407.2595\n",
      "Epoch 3732/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10020.8017 - reconstruction_loss: 9549.3096 - kl_loss: 409.8981\n",
      "Epoch 3733/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10057.6125 - reconstruction_loss: 9558.5156 - kl_loss: 409.4491\n",
      "Epoch 3734/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10032.4271 - reconstruction_loss: 9548.3086 - kl_loss: 408.4817\n",
      "Epoch 3735/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10040.1414 - reconstruction_loss: 9555.0898 - kl_loss: 408.0351\n",
      "Epoch 3736/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10054.2716 - reconstruction_loss: 9560.9365 - kl_loss: 408.5894\n",
      "Epoch 3737/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10000.3929 - reconstruction_loss: 9534.3838 - kl_loss: 408.3029\n",
      "Epoch 3738/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 10022.3022 - reconstruction_loss: 9549.7334 - kl_loss: 409.3068\n",
      "Epoch 3739/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 10012.7073 - reconstruction_loss: 9540.1250 - kl_loss: 408.3215\n",
      "Epoch 3740/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10044.0630 - reconstruction_loss: 9588.2402 - kl_loss: 407.8267\n",
      "Epoch 3741/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10058.9217 - reconstruction_loss: 9593.8291 - kl_loss: 408.3548\n",
      "Epoch 3742/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10112.7468 - reconstruction_loss: 9652.2871 - kl_loss: 408.3227\n",
      "Epoch 3743/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10136.9215 - reconstruction_loss: 9690.9902 - kl_loss: 409.7493\n",
      "Epoch 3744/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10180.4626 - reconstruction_loss: 9734.3984 - kl_loss: 408.5082\n",
      "Epoch 3745/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10195.9033 - reconstruction_loss: 9779.6807 - kl_loss: 408.5458\n",
      "Epoch 3746/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 10205.9879 - reconstruction_loss: 9800.0791 - kl_loss: 408.1310\n",
      "Epoch 3747/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10182.5752 - reconstruction_loss: 9764.8486 - kl_loss: 408.3709\n",
      "Epoch 3748/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10193.0043 - reconstruction_loss: 9793.3340 - kl_loss: 406.3912\n",
      "Epoch 3749/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10208.6999 - reconstruction_loss: 9787.1846 - kl_loss: 407.3940\n",
      "Epoch 3750/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10329.9615 - reconstruction_loss: 9891.3818 - kl_loss: 407.6778\n",
      "Epoch 3751/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10434.0161 - reconstruction_loss: 9945.4307 - kl_loss: 407.3974\n",
      "Epoch 3752/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10290.5954 - reconstruction_loss: 9825.5273 - kl_loss: 408.7538\n",
      "Epoch 3753/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10289.7038 - reconstruction_loss: 9835.6963 - kl_loss: 406.8506\n",
      "Epoch 3754/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10265.6883 - reconstruction_loss: 9801.8564 - kl_loss: 407.1486\n",
      "Epoch 3755/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10245.3475 - reconstruction_loss: 9798.0586 - kl_loss: 408.1541\n",
      "Epoch 3756/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10221.0233 - reconstruction_loss: 9791.2129 - kl_loss: 408.3687\n",
      "Epoch 3757/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10213.7055 - reconstruction_loss: 9786.4854 - kl_loss: 409.3980\n",
      "Epoch 3758/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10179.3833 - reconstruction_loss: 9761.2959 - kl_loss: 408.2116\n",
      "Epoch 3759/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10194.9408 - reconstruction_loss: 9766.5371 - kl_loss: 408.3493\n",
      "Epoch 3760/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10187.2859 - reconstruction_loss: 9756.4365 - kl_loss: 408.7560\n",
      "Epoch 3761/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10190.5263 - reconstruction_loss: 9757.9082 - kl_loss: 408.1862\n",
      "Epoch 3762/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10164.7941 - reconstruction_loss: 9751.6826 - kl_loss: 407.9268\n",
      "Epoch 3763/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10213.1155 - reconstruction_loss: 9763.9990 - kl_loss: 407.8253\n",
      "Epoch 3764/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10179.1977 - reconstruction_loss: 9744.0703 - kl_loss: 407.2043\n",
      "Epoch 3765/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10208.5918 - reconstruction_loss: 9762.6230 - kl_loss: 407.7780\n",
      "Epoch 3766/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10158.0786 - reconstruction_loss: 9724.9414 - kl_loss: 408.8801\n",
      "Epoch 3767/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10208.3268 - reconstruction_loss: 9763.7393 - kl_loss: 408.2718\n",
      "Epoch 3768/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10209.8995 - reconstruction_loss: 9784.8926 - kl_loss: 407.0592\n",
      "Epoch 3769/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10239.1200 - reconstruction_loss: 9775.3438 - kl_loss: 408.3158\n",
      "Epoch 3770/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10247.0250 - reconstruction_loss: 9789.5234 - kl_loss: 409.4809\n",
      "Epoch 3771/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10206.6053 - reconstruction_loss: 9768.3516 - kl_loss: 408.6501\n",
      "Epoch 3772/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10271.8195 - reconstruction_loss: 9809.7100 - kl_loss: 409.1986\n",
      "Epoch 3773/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10295.7687 - reconstruction_loss: 9828.5176 - kl_loss: 408.8838\n",
      "Epoch 3774/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10306.2876 - reconstruction_loss: 9845.3428 - kl_loss: 407.8524\n",
      "Epoch 3775/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10290.8988 - reconstruction_loss: 9845.8369 - kl_loss: 407.9527\n",
      "Epoch 3776/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10305.2727 - reconstruction_loss: 9847.5176 - kl_loss: 407.5149\n",
      "Epoch 3777/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10260.5723 - reconstruction_loss: 9831.2617 - kl_loss: 407.3353\n",
      "Epoch 3778/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10253.3685 - reconstruction_loss: 9809.9570 - kl_loss: 409.3559\n",
      "Epoch 3779/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10255.7700 - reconstruction_loss: 9798.1426 - kl_loss: 408.2155\n",
      "Epoch 3780/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10182.9798 - reconstruction_loss: 9756.1074 - kl_loss: 408.5761\n",
      "Epoch 3781/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10213.5189 - reconstruction_loss: 9778.4072 - kl_loss: 408.2206\n",
      "Epoch 3782/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10171.8800 - reconstruction_loss: 9734.3486 - kl_loss: 407.9460\n",
      "Epoch 3783/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10159.4960 - reconstruction_loss: 9741.0176 - kl_loss: 408.4505\n",
      "Epoch 3784/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10165.6660 - reconstruction_loss: 9740.8066 - kl_loss: 409.2606\n",
      "Epoch 3785/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10154.5822 - reconstruction_loss: 9747.3730 - kl_loss: 408.4819\n",
      "Epoch 3786/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10166.5089 - reconstruction_loss: 9759.8643 - kl_loss: 407.9280\n",
      "Epoch 3787/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10131.1314 - reconstruction_loss: 9713.8633 - kl_loss: 408.3597\n",
      "Epoch 3788/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10106.9044 - reconstruction_loss: 9708.8301 - kl_loss: 408.4458\n",
      "Epoch 3789/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10098.9824 - reconstruction_loss: 9697.2080 - kl_loss: 408.3090\n",
      "Epoch 3790/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10104.7835 - reconstruction_loss: 9683.4971 - kl_loss: 409.4368\n",
      "Epoch 3791/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10064.8792 - reconstruction_loss: 9662.2393 - kl_loss: 409.2636\n",
      "Epoch 3792/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10064.1002 - reconstruction_loss: 9659.4678 - kl_loss: 408.7474\n",
      "Epoch 3793/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 10066.7266 - reconstruction_loss: 9665.8633 - kl_loss: 408.7967\n",
      "Epoch 3794/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10024.4340 - reconstruction_loss: 9620.2266 - kl_loss: 409.4258\n",
      "Epoch 3795/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10046.8445 - reconstruction_loss: 9636.3584 - kl_loss: 409.3676\n",
      "Epoch 3796/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10022.1823 - reconstruction_loss: 9638.9033 - kl_loss: 409.0812\n",
      "Epoch 3797/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10075.0445 - reconstruction_loss: 9664.8340 - kl_loss: 408.3664\n",
      "Epoch 3798/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10043.1788 - reconstruction_loss: 9620.8457 - kl_loss: 409.4370\n",
      "Epoch 3799/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10025.2459 - reconstruction_loss: 9621.4980 - kl_loss: 409.7894\n",
      "Epoch 3800/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10018.3156 - reconstruction_loss: 9591.0137 - kl_loss: 409.0535\n",
      "Epoch 3801/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10014.9489 - reconstruction_loss: 9589.9053 - kl_loss: 408.8231\n",
      "Epoch 3802/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9994.5883 - reconstruction_loss: 9576.0547 - kl_loss: 407.3564\n",
      "Epoch 3803/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9983.0276 - reconstruction_loss: 9547.0234 - kl_loss: 408.4437\n",
      "Epoch 3804/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9943.5255 - reconstruction_loss: 9532.1318 - kl_loss: 408.7705\n",
      "Epoch 3805/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9946.8609 - reconstruction_loss: 9525.4082 - kl_loss: 408.8005\n",
      "Epoch 3806/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9943.7273 - reconstruction_loss: 9509.5312 - kl_loss: 408.2362\n",
      "Epoch 3807/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9890.5021 - reconstruction_loss: 9475.5684 - kl_loss: 408.6508\n",
      "Epoch 3808/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9895.8558 - reconstruction_loss: 9481.8213 - kl_loss: 408.3718\n",
      "Epoch 3809/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9911.8418 - reconstruction_loss: 9477.2529 - kl_loss: 408.2353\n",
      "Epoch 3810/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9887.1353 - reconstruction_loss: 9462.0195 - kl_loss: 408.9709\n",
      "Epoch 3811/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9871.2442 - reconstruction_loss: 9447.0381 - kl_loss: 410.1188\n",
      "Epoch 3812/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9901.5337 - reconstruction_loss: 9460.8525 - kl_loss: 409.1714\n",
      "Epoch 3813/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9869.4843 - reconstruction_loss: 9429.5928 - kl_loss: 408.8165\n",
      "Epoch 3814/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9871.2085 - reconstruction_loss: 9429.0879 - kl_loss: 409.3437\n",
      "Epoch 3815/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9847.3497 - reconstruction_loss: 9407.0322 - kl_loss: 408.2364\n",
      "Epoch 3816/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9849.1961 - reconstruction_loss: 9414.3652 - kl_loss: 408.0462\n",
      "Epoch 3817/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9837.3426 - reconstruction_loss: 9406.1982 - kl_loss: 407.8442\n",
      "Epoch 3818/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9823.0213 - reconstruction_loss: 9393.4395 - kl_loss: 408.3266\n",
      "Epoch 3819/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9812.5931 - reconstruction_loss: 9380.6992 - kl_loss: 407.2110\n",
      "Epoch 3820/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9800.8382 - reconstruction_loss: 9367.2158 - kl_loss: 407.9246\n",
      "Epoch 3821/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9788.4415 - reconstruction_loss: 9349.6494 - kl_loss: 408.7918\n",
      "Epoch 3822/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9812.2885 - reconstruction_loss: 9362.0781 - kl_loss: 407.9975\n",
      "Epoch 3823/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9769.5507 - reconstruction_loss: 9337.8350 - kl_loss: 408.2566\n",
      "Epoch 3824/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9772.2845 - reconstruction_loss: 9342.8525 - kl_loss: 406.5995\n",
      "Epoch 3825/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9777.7422 - reconstruction_loss: 9331.5566 - kl_loss: 406.4552\n",
      "Epoch 3826/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9770.4389 - reconstruction_loss: 9326.3809 - kl_loss: 406.7419\n",
      "Epoch 3827/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9794.6697 - reconstruction_loss: 9344.0811 - kl_loss: 406.8620\n",
      "Epoch 3828/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9794.8247 - reconstruction_loss: 9331.5273 - kl_loss: 406.9146\n",
      "Epoch 3829/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9771.2033 - reconstruction_loss: 9322.6104 - kl_loss: 407.1905\n",
      "Epoch 3830/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9806.1966 - reconstruction_loss: 9336.5264 - kl_loss: 407.8491\n",
      "Epoch 3831/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9763.9048 - reconstruction_loss: 9314.2998 - kl_loss: 407.6649\n",
      "Epoch 3832/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9769.4561 - reconstruction_loss: 9333.2861 - kl_loss: 407.4257\n",
      "Epoch 3833/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9820.8220 - reconstruction_loss: 9337.8682 - kl_loss: 407.9267\n",
      "Epoch 3834/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9755.0397 - reconstruction_loss: 9304.4141 - kl_loss: 408.1748\n",
      "Epoch 3835/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9785.0502 - reconstruction_loss: 9321.0352 - kl_loss: 409.0306\n",
      "Epoch 3836/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9749.7674 - reconstruction_loss: 9293.6045 - kl_loss: 407.7961\n",
      "Epoch 3837/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9741.8785 - reconstruction_loss: 9300.2129 - kl_loss: 407.2929\n",
      "Epoch 3838/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9789.2698 - reconstruction_loss: 9314.4678 - kl_loss: 407.0302\n",
      "Epoch 3839/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9730.6087 - reconstruction_loss: 9286.4736 - kl_loss: 406.0585\n",
      "Epoch 3840/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9752.8553 - reconstruction_loss: 9288.2627 - kl_loss: 407.1237\n",
      "Epoch 3841/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9735.9537 - reconstruction_loss: 9281.0762 - kl_loss: 407.1483\n",
      "Epoch 3842/5000\n",
      "75/75 [==============================] - 3s 36ms/step - loss: 9741.3488 - reconstruction_loss: 9292.8428 - kl_loss: 407.7533\n",
      "Epoch 3843/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9755.7530 - reconstruction_loss: 9281.4053 - kl_loss: 408.1779\n",
      "Epoch 3844/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9724.9734 - reconstruction_loss: 9274.4219 - kl_loss: 406.6208\n",
      "Epoch 3845/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9750.1637 - reconstruction_loss: 9288.6768 - kl_loss: 407.4886\n",
      "Epoch 3846/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9730.3464 - reconstruction_loss: 9277.4980 - kl_loss: 406.3577\n",
      "Epoch 3847/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9739.1518 - reconstruction_loss: 9287.2305 - kl_loss: 406.5402\n",
      "Epoch 3848/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9788.1079 - reconstruction_loss: 9311.4102 - kl_loss: 406.7773\n",
      "Epoch 3849/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9748.6113 - reconstruction_loss: 9291.9844 - kl_loss: 406.6874\n",
      "Epoch 3850/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9811.1593 - reconstruction_loss: 9333.8545 - kl_loss: 406.1569\n",
      "Epoch 3851/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9750.5333 - reconstruction_loss: 9312.6572 - kl_loss: 405.7337\n",
      "Epoch 3852/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9807.7828 - reconstruction_loss: 9335.8154 - kl_loss: 407.4873\n",
      "Epoch 3853/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9805.5949 - reconstruction_loss: 9328.2559 - kl_loss: 407.2425\n",
      "Epoch 3854/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9789.1920 - reconstruction_loss: 9316.3730 - kl_loss: 405.8233\n",
      "Epoch 3855/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9794.0110 - reconstruction_loss: 9324.2725 - kl_loss: 405.4389\n",
      "Epoch 3856/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9824.0084 - reconstruction_loss: 9340.2559 - kl_loss: 406.0576\n",
      "Epoch 3857/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9810.4894 - reconstruction_loss: 9347.5176 - kl_loss: 407.7877\n",
      "Epoch 3858/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9843.5820 - reconstruction_loss: 9353.4834 - kl_loss: 405.3199\n",
      "Epoch 3859/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9827.8246 - reconstruction_loss: 9350.7363 - kl_loss: 405.2527\n",
      "Epoch 3860/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9880.5341 - reconstruction_loss: 9392.1113 - kl_loss: 406.3136\n",
      "Epoch 3861/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9846.8393 - reconstruction_loss: 9373.2959 - kl_loss: 406.5920\n",
      "Epoch 3862/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9883.3946 - reconstruction_loss: 9405.3203 - kl_loss: 405.8738\n",
      "Epoch 3863/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9923.6987 - reconstruction_loss: 9418.8682 - kl_loss: 405.1630\n",
      "Epoch 3864/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9896.7400 - reconstruction_loss: 9428.4404 - kl_loss: 405.9486\n",
      "Epoch 3865/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9907.2712 - reconstruction_loss: 9419.8750 - kl_loss: 406.0294\n",
      "Epoch 3866/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9915.1713 - reconstruction_loss: 9436.6758 - kl_loss: 405.9821\n",
      "Epoch 3867/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9925.3821 - reconstruction_loss: 9445.9268 - kl_loss: 406.2617\n",
      "Epoch 3868/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9957.9881 - reconstruction_loss: 9477.2148 - kl_loss: 407.5880\n",
      "Epoch 3869/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9936.5939 - reconstruction_loss: 9447.4971 - kl_loss: 406.5901\n",
      "Epoch 3870/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9970.8980 - reconstruction_loss: 9479.5059 - kl_loss: 405.3429\n",
      "Epoch 3871/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10008.0790 - reconstruction_loss: 9497.1270 - kl_loss: 406.5811\n",
      "Epoch 3872/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10000.8216 - reconstruction_loss: 9501.6064 - kl_loss: 406.7565\n",
      "Epoch 3873/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10007.8035 - reconstruction_loss: 9500.7373 - kl_loss: 406.0589\n",
      "Epoch 3874/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9991.5410 - reconstruction_loss: 9494.8496 - kl_loss: 405.8624\n",
      "Epoch 3875/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10028.7013 - reconstruction_loss: 9521.8418 - kl_loss: 406.1268\n",
      "Epoch 3876/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10067.0764 - reconstruction_loss: 9568.1250 - kl_loss: 405.5093\n",
      "Epoch 3877/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10081.7203 - reconstruction_loss: 9602.9844 - kl_loss: 405.8041\n",
      "Epoch 3878/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10175.5397 - reconstruction_loss: 9692.2705 - kl_loss: 405.0312\n",
      "Epoch 3879/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10218.5014 - reconstruction_loss: 9733.0449 - kl_loss: 405.5725\n",
      "Epoch 3880/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10288.8084 - reconstruction_loss: 9764.3857 - kl_loss: 406.0597\n",
      "Epoch 3881/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10333.8347 - reconstruction_loss: 9759.5098 - kl_loss: 405.1995\n",
      "Epoch 3882/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10197.4102 - reconstruction_loss: 9688.2178 - kl_loss: 405.4419\n",
      "Epoch 3883/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10263.4894 - reconstruction_loss: 9748.6631 - kl_loss: 405.8308\n",
      "Epoch 3884/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10374.5494 - reconstruction_loss: 9794.7822 - kl_loss: 406.2105\n",
      "Epoch 3885/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10400.2517 - reconstruction_loss: 9803.5781 - kl_loss: 406.2952\n",
      "Epoch 3886/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10284.2294 - reconstruction_loss: 9764.0361 - kl_loss: 405.5212\n",
      "Epoch 3887/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10213.3230 - reconstruction_loss: 9719.7246 - kl_loss: 406.3746\n",
      "Epoch 3888/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10224.8368 - reconstruction_loss: 9707.1689 - kl_loss: 406.1041\n",
      "Epoch 3889/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10172.8083 - reconstruction_loss: 9656.0391 - kl_loss: 407.0596\n",
      "Epoch 3890/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10126.8724 - reconstruction_loss: 9630.4795 - kl_loss: 405.9981\n",
      "Epoch 3891/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10080.6789 - reconstruction_loss: 9599.4619 - kl_loss: 405.4370\n",
      "Epoch 3892/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10056.9322 - reconstruction_loss: 9600.0098 - kl_loss: 405.4469\n",
      "Epoch 3893/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10078.3660 - reconstruction_loss: 9608.8164 - kl_loss: 406.5410\n",
      "Epoch 3894/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10105.7984 - reconstruction_loss: 9634.9092 - kl_loss: 405.3645\n",
      "Epoch 3895/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10136.5112 - reconstruction_loss: 9654.7383 - kl_loss: 405.3907\n",
      "Epoch 3896/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10217.1150 - reconstruction_loss: 9684.9668 - kl_loss: 405.9005\n",
      "Epoch 3897/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10125.1840 - reconstruction_loss: 9596.2607 - kl_loss: 406.2675\n",
      "Epoch 3898/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10170.1037 - reconstruction_loss: 9629.1943 - kl_loss: 405.1345\n",
      "Epoch 3899/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10115.1738 - reconstruction_loss: 9583.2578 - kl_loss: 406.0452\n",
      "Epoch 3900/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10075.1364 - reconstruction_loss: 9567.5000 - kl_loss: 405.9390\n",
      "Epoch 3901/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10061.6596 - reconstruction_loss: 9551.7891 - kl_loss: 405.4403\n",
      "Epoch 3902/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10046.6090 - reconstruction_loss: 9550.2725 - kl_loss: 405.6622\n",
      "Epoch 3903/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10005.4514 - reconstruction_loss: 9525.8154 - kl_loss: 406.0796\n",
      "Epoch 3904/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9981.1301 - reconstruction_loss: 9492.9863 - kl_loss: 406.7842\n",
      "Epoch 3905/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9948.4878 - reconstruction_loss: 9486.8223 - kl_loss: 406.2199\n",
      "Epoch 3906/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10014.7159 - reconstruction_loss: 9522.4268 - kl_loss: 406.5917\n",
      "Epoch 3907/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9993.9536 - reconstruction_loss: 9506.4014 - kl_loss: 406.9553\n",
      "Epoch 3908/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9999.6447 - reconstruction_loss: 9516.9365 - kl_loss: 407.0126\n",
      "Epoch 3909/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10007.5872 - reconstruction_loss: 9511.3027 - kl_loss: 407.2426\n",
      "Epoch 3910/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10021.4643 - reconstruction_loss: 9519.3730 - kl_loss: 406.6308\n",
      "Epoch 3911/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9981.4169 - reconstruction_loss: 9508.9854 - kl_loss: 405.9343\n",
      "Epoch 3912/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10045.9759 - reconstruction_loss: 9550.3564 - kl_loss: 404.5766\n",
      "Epoch 3913/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9990.6018 - reconstruction_loss: 9528.6816 - kl_loss: 404.6113\n",
      "Epoch 3914/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10071.2225 - reconstruction_loss: 9571.6914 - kl_loss: 405.9722\n",
      "Epoch 3915/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10048.8407 - reconstruction_loss: 9569.1865 - kl_loss: 405.0886\n",
      "Epoch 3916/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10092.7015 - reconstruction_loss: 9609.3203 - kl_loss: 405.6018\n",
      "Epoch 3917/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10085.3776 - reconstruction_loss: 9632.3076 - kl_loss: 406.7573\n",
      "Epoch 3918/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10100.2892 - reconstruction_loss: 9636.6953 - kl_loss: 405.7415\n",
      "Epoch 3919/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10112.8168 - reconstruction_loss: 9652.4658 - kl_loss: 405.9489\n",
      "Epoch 3920/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10176.6392 - reconstruction_loss: 9685.3096 - kl_loss: 406.8059\n",
      "Epoch 3921/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10199.1597 - reconstruction_loss: 9672.5205 - kl_loss: 405.6461\n",
      "Epoch 3922/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10182.8086 - reconstruction_loss: 9660.8467 - kl_loss: 405.2866\n",
      "Epoch 3923/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10137.7365 - reconstruction_loss: 9636.4102 - kl_loss: 405.1149\n",
      "Epoch 3924/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10103.0398 - reconstruction_loss: 9623.3369 - kl_loss: 405.8275\n",
      "Epoch 3925/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10045.5315 - reconstruction_loss: 9584.5293 - kl_loss: 406.1049\n",
      "Epoch 3926/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10054.5657 - reconstruction_loss: 9585.0762 - kl_loss: 405.7452\n",
      "Epoch 3927/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10033.9562 - reconstruction_loss: 9573.9512 - kl_loss: 406.3185\n",
      "Epoch 3928/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10042.3951 - reconstruction_loss: 9579.1338 - kl_loss: 405.6897\n",
      "Epoch 3929/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10064.1780 - reconstruction_loss: 9585.2139 - kl_loss: 405.2721\n",
      "Epoch 3930/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10063.5249 - reconstruction_loss: 9587.7354 - kl_loss: 405.8026\n",
      "Epoch 3931/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10078.2740 - reconstruction_loss: 9585.8955 - kl_loss: 406.1498\n",
      "Epoch 3932/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10062.7980 - reconstruction_loss: 9570.9385 - kl_loss: 405.9860\n",
      "Epoch 3933/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10075.5222 - reconstruction_loss: 9571.8604 - kl_loss: 405.7183\n",
      "Epoch 3934/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10112.1568 - reconstruction_loss: 9599.5303 - kl_loss: 407.3177\n",
      "Epoch 3935/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10062.6804 - reconstruction_loss: 9563.4658 - kl_loss: 406.9516\n",
      "Epoch 3936/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10049.9799 - reconstruction_loss: 9560.4023 - kl_loss: 406.6421\n",
      "Epoch 3937/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10028.9153 - reconstruction_loss: 9534.6621 - kl_loss: 407.9066\n",
      "Epoch 3938/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10026.3069 - reconstruction_loss: 9530.1914 - kl_loss: 406.8235\n",
      "Epoch 3939/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9998.3974 - reconstruction_loss: 9528.7715 - kl_loss: 407.8536\n",
      "Epoch 3940/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10058.6862 - reconstruction_loss: 9565.8643 - kl_loss: 405.5725\n",
      "Epoch 3941/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10064.8057 - reconstruction_loss: 9585.1025 - kl_loss: 405.3025\n",
      "Epoch 3942/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10065.4134 - reconstruction_loss: 9585.7920 - kl_loss: 405.8405\n",
      "Epoch 3943/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10137.5735 - reconstruction_loss: 9631.4424 - kl_loss: 405.0887\n",
      "Epoch 3944/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 10122.5118 - reconstruction_loss: 9641.7148 - kl_loss: 404.9797\n",
      "Epoch 3945/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 10144.2304 - reconstruction_loss: 9681.1035 - kl_loss: 404.7544\n",
      "Epoch 3946/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10224.8446 - reconstruction_loss: 9754.3564 - kl_loss: 404.1380\n",
      "Epoch 3947/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10282.5341 - reconstruction_loss: 9812.0908 - kl_loss: 404.9641\n",
      "Epoch 3948/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10409.7696 - reconstruction_loss: 9946.7529 - kl_loss: 404.0595\n",
      "Epoch 3949/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10645.7087 - reconstruction_loss: 10127.8252 - kl_loss: 404.6771\n",
      "Epoch 3950/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10857.7330 - reconstruction_loss: 10334.4414 - kl_loss: 404.9904\n",
      "Epoch 3951/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 11184.3234 - reconstruction_loss: 10643.0791 - kl_loss: 405.1029\n",
      "Epoch 3952/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 11613.6000 - reconstruction_loss: 10962.0098 - kl_loss: 403.6679\n",
      "Epoch 3953/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11863.9174 - reconstruction_loss: 11113.4336 - kl_loss: 404.9000\n",
      "Epoch 3954/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11464.4688 - reconstruction_loss: 10601.5947 - kl_loss: 408.4865\n",
      "Epoch 3955/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11026.2443 - reconstruction_loss: 10304.6807 - kl_loss: 406.6167\n",
      "Epoch 3956/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10836.8406 - reconstruction_loss: 10126.9375 - kl_loss: 406.1273\n",
      "Epoch 3957/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10658.9734 - reconstruction_loss: 10005.0264 - kl_loss: 405.4276\n",
      "Epoch 3958/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 10534.6643 - reconstruction_loss: 9909.7959 - kl_loss: 406.3085\n",
      "Epoch 3959/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10458.2162 - reconstruction_loss: 9856.5713 - kl_loss: 406.4093\n",
      "Epoch 3960/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10371.8649 - reconstruction_loss: 9793.9727 - kl_loss: 406.4478\n",
      "Epoch 3961/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10329.1406 - reconstruction_loss: 9773.5566 - kl_loss: 406.9655\n",
      "Epoch 3962/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10249.1748 - reconstruction_loss: 9727.6875 - kl_loss: 406.8258\n",
      "Epoch 3963/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10236.5439 - reconstruction_loss: 9706.8174 - kl_loss: 407.4693\n",
      "Epoch 3964/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10198.1475 - reconstruction_loss: 9667.8535 - kl_loss: 408.7910\n",
      "Epoch 3965/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10174.8130 - reconstruction_loss: 9660.7920 - kl_loss: 409.2545\n",
      "Epoch 3966/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10153.5588 - reconstruction_loss: 9643.5342 - kl_loss: 407.7692\n",
      "Epoch 3967/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10134.9840 - reconstruction_loss: 9622.3711 - kl_loss: 407.5195\n",
      "Epoch 3968/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10113.6949 - reconstruction_loss: 9630.9941 - kl_loss: 406.9901\n",
      "Epoch 3969/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10099.0141 - reconstruction_loss: 9616.9697 - kl_loss: 406.9398\n",
      "Epoch 3970/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10113.6960 - reconstruction_loss: 9615.5186 - kl_loss: 405.8768\n",
      "Epoch 3971/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10131.7632 - reconstruction_loss: 9614.8682 - kl_loss: 406.7175\n",
      "Epoch 3972/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10080.6076 - reconstruction_loss: 9578.0654 - kl_loss: 407.1265\n",
      "Epoch 3973/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10055.5486 - reconstruction_loss: 9563.3252 - kl_loss: 407.7396\n",
      "Epoch 3974/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10031.6540 - reconstruction_loss: 9534.5098 - kl_loss: 407.1673\n",
      "Epoch 3975/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10021.2704 - reconstruction_loss: 9524.1807 - kl_loss: 407.0481\n",
      "Epoch 3976/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10022.4154 - reconstruction_loss: 9517.0820 - kl_loss: 408.4564\n",
      "Epoch 3977/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9960.2252 - reconstruction_loss: 9473.5977 - kl_loss: 409.1831\n",
      "Epoch 3978/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9941.9894 - reconstruction_loss: 9465.3984 - kl_loss: 408.1309\n",
      "Epoch 3979/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9978.9138 - reconstruction_loss: 9459.8682 - kl_loss: 407.7361\n",
      "Epoch 3980/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9906.0029 - reconstruction_loss: 9425.1748 - kl_loss: 408.3857\n",
      "Epoch 3981/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9916.8773 - reconstruction_loss: 9422.1035 - kl_loss: 407.3742\n",
      "Epoch 3982/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9879.6819 - reconstruction_loss: 9396.4541 - kl_loss: 406.6891\n",
      "Epoch 3983/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9855.6293 - reconstruction_loss: 9376.4951 - kl_loss: 407.5530\n",
      "Epoch 3984/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9816.9127 - reconstruction_loss: 9348.8408 - kl_loss: 409.0661\n",
      "Epoch 3985/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9796.7218 - reconstruction_loss: 9329.8828 - kl_loss: 408.4539\n",
      "Epoch 3986/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9799.0840 - reconstruction_loss: 9334.3711 - kl_loss: 407.3315\n",
      "Epoch 3987/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9801.0528 - reconstruction_loss: 9325.5869 - kl_loss: 407.1349\n",
      "Epoch 3988/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9757.8514 - reconstruction_loss: 9300.8789 - kl_loss: 407.3306\n",
      "Epoch 3989/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9746.7858 - reconstruction_loss: 9293.0137 - kl_loss: 406.6710\n",
      "Epoch 3990/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9728.3408 - reconstruction_loss: 9266.7588 - kl_loss: 407.8793\n",
      "Epoch 3991/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9711.6995 - reconstruction_loss: 9253.0898 - kl_loss: 406.5020\n",
      "Epoch 3992/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9716.6895 - reconstruction_loss: 9254.4229 - kl_loss: 406.0959\n",
      "Epoch 3993/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9708.3354 - reconstruction_loss: 9246.4160 - kl_loss: 406.2172\n",
      "Epoch 3994/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9705.7461 - reconstruction_loss: 9243.1865 - kl_loss: 405.7531\n",
      "Epoch 3995/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9791.8230 - reconstruction_loss: 9310.8809 - kl_loss: 407.6217\n",
      "Epoch 3996/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9711.2051 - reconstruction_loss: 9238.3584 - kl_loss: 407.6037\n",
      "Epoch 3997/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9670.5374 - reconstruction_loss: 9211.4854 - kl_loss: 407.0894\n",
      "Epoch 3998/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9677.8487 - reconstruction_loss: 9199.4092 - kl_loss: 406.6165\n",
      "Epoch 3999/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9653.6751 - reconstruction_loss: 9184.9570 - kl_loss: 406.3861\n",
      "Epoch 4000/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9632.7779 - reconstruction_loss: 9181.5869 - kl_loss: 405.8788\n",
      "Epoch 4001/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9650.3910 - reconstruction_loss: 9175.2178 - kl_loss: 405.8980\n",
      "Epoch 4002/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9623.2242 - reconstruction_loss: 9155.0244 - kl_loss: 406.1938\n",
      "Epoch 4003/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9649.6957 - reconstruction_loss: 9182.0010 - kl_loss: 406.0336\n",
      "Epoch 4004/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9650.4790 - reconstruction_loss: 9173.3350 - kl_loss: 406.0779\n",
      "Epoch 4005/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9626.3052 - reconstruction_loss: 9155.0625 - kl_loss: 406.3929\n",
      "Epoch 4006/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9639.6544 - reconstruction_loss: 9163.7236 - kl_loss: 406.5836\n",
      "Epoch 4007/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9675.9901 - reconstruction_loss: 9175.3662 - kl_loss: 405.8676\n",
      "Epoch 4008/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9597.2799 - reconstruction_loss: 9129.8115 - kl_loss: 406.3747\n",
      "Epoch 4009/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9632.9605 - reconstruction_loss: 9156.5400 - kl_loss: 406.1447\n",
      "Epoch 4010/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9639.5283 - reconstruction_loss: 9145.5439 - kl_loss: 406.2736\n",
      "Epoch 4011/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9595.1783 - reconstruction_loss: 9131.3691 - kl_loss: 406.0826\n",
      "Epoch 4012/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9710.5287 - reconstruction_loss: 9193.2295 - kl_loss: 406.0557\n",
      "Epoch 4013/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9606.1474 - reconstruction_loss: 9137.9307 - kl_loss: 406.2606\n",
      "Epoch 4014/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9602.7042 - reconstruction_loss: 9120.9609 - kl_loss: 406.1111\n",
      "Epoch 4015/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9593.8203 - reconstruction_loss: 9106.8271 - kl_loss: 405.8377\n",
      "Epoch 4016/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9546.4647 - reconstruction_loss: 9086.5645 - kl_loss: 406.1891\n",
      "Epoch 4017/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9552.9372 - reconstruction_loss: 9086.7656 - kl_loss: 405.7785\n",
      "Epoch 4018/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9564.1977 - reconstruction_loss: 9086.3916 - kl_loss: 405.6504\n",
      "Epoch 4019/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9550.7274 - reconstruction_loss: 9078.5107 - kl_loss: 405.1287\n",
      "Epoch 4020/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9543.5816 - reconstruction_loss: 9075.4482 - kl_loss: 404.1182\n",
      "Epoch 4021/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9528.2875 - reconstruction_loss: 9056.8779 - kl_loss: 405.5218\n",
      "Epoch 4022/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9534.5516 - reconstruction_loss: 9069.5664 - kl_loss: 405.2589\n",
      "Epoch 4023/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9535.2342 - reconstruction_loss: 9060.8936 - kl_loss: 404.8071\n",
      "Epoch 4024/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9515.2067 - reconstruction_loss: 9046.9736 - kl_loss: 404.7377\n",
      "Epoch 4025/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9521.7479 - reconstruction_loss: 9070.9551 - kl_loss: 404.8615\n",
      "Epoch 4026/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9568.7145 - reconstruction_loss: 9077.8184 - kl_loss: 404.8696\n",
      "Epoch 4027/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9535.2456 - reconstruction_loss: 9072.9453 - kl_loss: 404.2902\n",
      "Epoch 4028/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9604.3333 - reconstruction_loss: 9121.2529 - kl_loss: 404.5622\n",
      "Epoch 4029/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9572.5066 - reconstruction_loss: 9077.5254 - kl_loss: 404.6465\n",
      "Epoch 4030/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9518.9690 - reconstruction_loss: 9076.0273 - kl_loss: 404.2336\n",
      "Epoch 4031/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9584.1955 - reconstruction_loss: 9090.2402 - kl_loss: 405.1175\n",
      "Epoch 4032/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9580.0026 - reconstruction_loss: 9080.2100 - kl_loss: 404.8678\n",
      "Epoch 4033/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9610.7920 - reconstruction_loss: 9163.2725 - kl_loss: 405.4628\n",
      "Epoch 4034/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9755.0345 - reconstruction_loss: 9171.1631 - kl_loss: 404.2993\n",
      "Epoch 4035/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9536.8619 - reconstruction_loss: 9072.5586 - kl_loss: 403.8547\n",
      "Epoch 4036/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9545.1883 - reconstruction_loss: 9063.1953 - kl_loss: 404.0674\n",
      "Epoch 4037/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9510.3269 - reconstruction_loss: 9036.5156 - kl_loss: 404.8203\n",
      "Epoch 4038/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9486.6380 - reconstruction_loss: 9025.9326 - kl_loss: 404.0579\n",
      "Epoch 4039/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9490.5204 - reconstruction_loss: 9039.0078 - kl_loss: 403.6375\n",
      "Epoch 4040/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9497.0270 - reconstruction_loss: 9027.8779 - kl_loss: 404.2830\n",
      "Epoch 4041/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9478.9322 - reconstruction_loss: 9013.3242 - kl_loss: 404.4837\n",
      "Epoch 4042/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9473.9879 - reconstruction_loss: 9009.7188 - kl_loss: 403.5172\n",
      "Epoch 4043/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9478.4514 - reconstruction_loss: 9014.5527 - kl_loss: 403.1067\n",
      "Epoch 4044/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9472.7323 - reconstruction_loss: 9011.7529 - kl_loss: 404.3474\n",
      "Epoch 4045/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9479.1190 - reconstruction_loss: 9011.2959 - kl_loss: 403.7823\n",
      "Epoch 4046/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9488.3539 - reconstruction_loss: 9012.5938 - kl_loss: 403.5381\n",
      "Epoch 4047/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9508.8495 - reconstruction_loss: 9042.2598 - kl_loss: 404.1854\n",
      "Epoch 4048/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9565.6521 - reconstruction_loss: 9079.9365 - kl_loss: 403.7938\n",
      "Epoch 4049/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9546.5887 - reconstruction_loss: 9067.1318 - kl_loss: 403.2563\n",
      "Epoch 4050/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9614.8583 - reconstruction_loss: 9141.7598 - kl_loss: 403.0571\n",
      "Epoch 4051/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9674.2420 - reconstruction_loss: 9123.4951 - kl_loss: 403.1973\n",
      "Epoch 4052/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9531.7208 - reconstruction_loss: 9035.9453 - kl_loss: 401.9412\n",
      "Epoch 4053/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9662.3690 - reconstruction_loss: 9177.3320 - kl_loss: 403.6711\n",
      "Epoch 4054/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9729.0376 - reconstruction_loss: 9148.2305 - kl_loss: 402.7540\n",
      "Epoch 4055/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9545.3726 - reconstruction_loss: 9073.0723 - kl_loss: 402.1405\n",
      "Epoch 4056/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9885.7268 - reconstruction_loss: 9263.0195 - kl_loss: 405.9905\n",
      "Epoch 4057/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9612.7479 - reconstruction_loss: 9102.4580 - kl_loss: 401.9257\n",
      "Epoch 4058/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9745.6645 - reconstruction_loss: 9192.0518 - kl_loss: 402.6930\n",
      "Epoch 4059/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9622.2512 - reconstruction_loss: 9092.9219 - kl_loss: 403.7526\n",
      "Epoch 4060/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9530.5089 - reconstruction_loss: 9045.5938 - kl_loss: 402.5707\n",
      "Epoch 4061/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9517.9021 - reconstruction_loss: 9032.1768 - kl_loss: 402.6436\n",
      "Epoch 4062/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9497.6562 - reconstruction_loss: 9030.6055 - kl_loss: 401.6899\n",
      "Epoch 4063/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9498.1552 - reconstruction_loss: 9021.1377 - kl_loss: 402.2276\n",
      "Epoch 4064/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9491.1869 - reconstruction_loss: 9011.0342 - kl_loss: 401.6680\n",
      "Epoch 4065/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9486.0369 - reconstruction_loss: 9012.7168 - kl_loss: 401.7093\n",
      "Epoch 4066/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9487.2246 - reconstruction_loss: 9007.8760 - kl_loss: 401.9946\n",
      "Epoch 4067/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9474.0427 - reconstruction_loss: 9002.4336 - kl_loss: 401.7307\n",
      "Epoch 4068/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9472.5698 - reconstruction_loss: 9013.2568 - kl_loss: 401.3972\n",
      "Epoch 4069/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9473.5364 - reconstruction_loss: 9004.9531 - kl_loss: 401.1733\n",
      "Epoch 4070/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9468.0050 - reconstruction_loss: 8999.2070 - kl_loss: 401.2461\n",
      "Epoch 4071/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9483.5529 - reconstruction_loss: 9010.7100 - kl_loss: 401.6153\n",
      "Epoch 4072/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9466.1271 - reconstruction_loss: 9005.2412 - kl_loss: 402.0127\n",
      "Epoch 4073/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9486.8043 - reconstruction_loss: 9020.6709 - kl_loss: 401.2045\n",
      "Epoch 4074/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9477.3375 - reconstruction_loss: 9005.0186 - kl_loss: 401.4797\n",
      "Epoch 4075/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9530.7120 - reconstruction_loss: 9067.2910 - kl_loss: 400.5388\n",
      "Epoch 4076/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9693.2798 - reconstruction_loss: 9186.1035 - kl_loss: 401.4390\n",
      "Epoch 4077/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9553.0307 - reconstruction_loss: 9074.6309 - kl_loss: 401.8124\n",
      "Epoch 4078/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9617.2947 - reconstruction_loss: 9126.0723 - kl_loss: 401.2605\n",
      "Epoch 4079/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9544.7648 - reconstruction_loss: 9052.7305 - kl_loss: 402.1055\n",
      "Epoch 4080/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9548.0146 - reconstruction_loss: 9075.2100 - kl_loss: 401.7567\n",
      "Epoch 4081/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9558.4918 - reconstruction_loss: 9071.4307 - kl_loss: 401.0126\n",
      "Epoch 4082/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9506.1922 - reconstruction_loss: 9037.2314 - kl_loss: 400.7316\n",
      "Epoch 4083/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9522.0600 - reconstruction_loss: 9059.4258 - kl_loss: 400.0234\n",
      "Epoch 4084/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9577.1750 - reconstruction_loss: 9076.4258 - kl_loss: 400.3448\n",
      "Epoch 4085/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9515.5454 - reconstruction_loss: 9042.3018 - kl_loss: 400.1340\n",
      "Epoch 4086/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9568.4532 - reconstruction_loss: 9103.8027 - kl_loss: 400.2728\n",
      "Epoch 4087/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9561.6266 - reconstruction_loss: 9075.7705 - kl_loss: 400.8366\n",
      "Epoch 4088/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9506.0666 - reconstruction_loss: 9046.9814 - kl_loss: 400.7225\n",
      "Epoch 4089/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9551.7529 - reconstruction_loss: 9071.3633 - kl_loss: 400.4028\n",
      "Epoch 4090/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9516.1616 - reconstruction_loss: 9048.6045 - kl_loss: 399.7577\n",
      "Epoch 4091/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9532.8990 - reconstruction_loss: 9080.6846 - kl_loss: 399.9531\n",
      "Epoch 4092/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9566.0600 - reconstruction_loss: 9099.2979 - kl_loss: 399.7805\n",
      "Epoch 4093/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9521.7913 - reconstruction_loss: 9075.0869 - kl_loss: 399.2352\n",
      "Epoch 4094/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9522.3930 - reconstruction_loss: 9087.0264 - kl_loss: 398.9021\n",
      "Epoch 4095/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9525.2980 - reconstruction_loss: 9065.6885 - kl_loss: 399.4907\n",
      "Epoch 4096/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9513.8782 - reconstruction_loss: 9063.6025 - kl_loss: 399.2123\n",
      "Epoch 4097/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9545.1301 - reconstruction_loss: 9084.3857 - kl_loss: 400.4677\n",
      "Epoch 4098/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9534.9069 - reconstruction_loss: 9077.9727 - kl_loss: 400.3391\n",
      "Epoch 4099/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9546.8515 - reconstruction_loss: 9089.9482 - kl_loss: 399.6667\n",
      "Epoch 4100/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9539.5578 - reconstruction_loss: 9070.3965 - kl_loss: 399.0439\n",
      "Epoch 4101/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9545.4425 - reconstruction_loss: 9104.6836 - kl_loss: 398.9108\n",
      "Epoch 4102/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9573.7346 - reconstruction_loss: 9099.8535 - kl_loss: 399.1223\n",
      "Epoch 4103/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9559.2041 - reconstruction_loss: 9112.5166 - kl_loss: 399.5122\n",
      "Epoch 4104/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9620.8546 - reconstruction_loss: 9140.8955 - kl_loss: 399.0838\n",
      "Epoch 4105/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9583.0295 - reconstruction_loss: 9134.6123 - kl_loss: 399.0079\n",
      "Epoch 4106/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9632.8532 - reconstruction_loss: 9208.1523 - kl_loss: 398.7388\n",
      "Epoch 4107/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9768.3121 - reconstruction_loss: 9265.2969 - kl_loss: 398.8513\n",
      "Epoch 4108/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9680.3997 - reconstruction_loss: 9178.1172 - kl_loss: 399.5057\n",
      "Epoch 4109/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9588.4500 - reconstruction_loss: 9127.6748 - kl_loss: 400.4778\n",
      "Epoch 4110/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9551.2783 - reconstruction_loss: 9100.5967 - kl_loss: 399.3169\n",
      "Epoch 4111/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9563.8242 - reconstruction_loss: 9124.7031 - kl_loss: 399.6919\n",
      "Epoch 4112/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9583.3412 - reconstruction_loss: 9132.6377 - kl_loss: 398.7968\n",
      "Epoch 4113/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9577.7932 - reconstruction_loss: 9121.4209 - kl_loss: 399.4003\n",
      "Epoch 4114/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9630.5702 - reconstruction_loss: 9173.5391 - kl_loss: 399.6104\n",
      "Epoch 4115/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9589.6447 - reconstruction_loss: 9128.9912 - kl_loss: 399.5905\n",
      "Epoch 4116/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9538.4115 - reconstruction_loss: 9106.0029 - kl_loss: 400.5542\n",
      "Epoch 4117/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9543.2874 - reconstruction_loss: 9092.5869 - kl_loss: 400.7083\n",
      "Epoch 4118/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9584.8310 - reconstruction_loss: 9117.8516 - kl_loss: 399.8035\n",
      "Epoch 4119/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9511.4132 - reconstruction_loss: 9078.4609 - kl_loss: 398.5171\n",
      "Epoch 4120/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9522.9981 - reconstruction_loss: 9083.0615 - kl_loss: 398.8525\n",
      "Epoch 4121/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9506.8585 - reconstruction_loss: 9062.6758 - kl_loss: 398.4766\n",
      "Epoch 4122/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9556.9504 - reconstruction_loss: 9101.1357 - kl_loss: 399.3484\n",
      "Epoch 4123/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9577.1750 - reconstruction_loss: 9101.4873 - kl_loss: 399.3744\n",
      "Epoch 4124/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9518.2242 - reconstruction_loss: 9084.5703 - kl_loss: 399.3137\n",
      "Epoch 4125/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9539.8221 - reconstruction_loss: 9084.9629 - kl_loss: 398.6242\n",
      "Epoch 4126/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9497.6411 - reconstruction_loss: 9047.0215 - kl_loss: 399.3706\n",
      "Epoch 4127/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9518.4693 - reconstruction_loss: 9070.4912 - kl_loss: 399.8354\n",
      "Epoch 4128/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9562.9139 - reconstruction_loss: 9077.7871 - kl_loss: 399.2982\n",
      "Epoch 4129/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9540.9413 - reconstruction_loss: 9069.2852 - kl_loss: 398.0387\n",
      "Epoch 4130/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9546.8852 - reconstruction_loss: 9102.3467 - kl_loss: 397.4989\n",
      "Epoch 4131/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9534.7641 - reconstruction_loss: 9074.5479 - kl_loss: 398.2746\n",
      "Epoch 4132/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9565.2281 - reconstruction_loss: 9103.4951 - kl_loss: 398.1301\n",
      "Epoch 4133/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9647.5897 - reconstruction_loss: 9161.0088 - kl_loss: 398.9991\n",
      "Epoch 4134/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9550.9138 - reconstruction_loss: 9100.4033 - kl_loss: 398.5195\n",
      "Epoch 4135/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9604.1649 - reconstruction_loss: 9108.1211 - kl_loss: 398.4359\n",
      "Epoch 4136/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9556.0373 - reconstruction_loss: 9109.1475 - kl_loss: 398.0042\n",
      "Epoch 4137/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9621.1855 - reconstruction_loss: 9149.2529 - kl_loss: 398.4296\n",
      "Epoch 4138/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9685.6375 - reconstruction_loss: 9184.9199 - kl_loss: 398.0912\n",
      "Epoch 4139/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9707.1135 - reconstruction_loss: 9240.7783 - kl_loss: 397.9526\n",
      "Epoch 4140/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9830.3881 - reconstruction_loss: 9319.3389 - kl_loss: 397.4937\n",
      "Epoch 4141/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9773.2614 - reconstruction_loss: 9300.2764 - kl_loss: 398.4373\n",
      "Epoch 4142/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9759.1356 - reconstruction_loss: 9274.2188 - kl_loss: 399.2914\n",
      "Epoch 4143/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9744.6134 - reconstruction_loss: 9263.3535 - kl_loss: 397.9557\n",
      "Epoch 4144/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9720.4725 - reconstruction_loss: 9256.8076 - kl_loss: 398.4008\n",
      "Epoch 4145/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9771.9643 - reconstruction_loss: 9279.2188 - kl_loss: 398.6380\n",
      "Epoch 4146/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9695.7125 - reconstruction_loss: 9218.3887 - kl_loss: 398.7305\n",
      "Epoch 4147/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9644.3943 - reconstruction_loss: 9178.9492 - kl_loss: 398.4617\n",
      "Epoch 4148/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9626.6612 - reconstruction_loss: 9144.9629 - kl_loss: 398.2620\n",
      "Epoch 4149/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9577.4649 - reconstruction_loss: 9108.5000 - kl_loss: 397.8501\n",
      "Epoch 4150/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9603.0956 - reconstruction_loss: 9132.1484 - kl_loss: 398.2131\n",
      "Epoch 4151/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9579.9215 - reconstruction_loss: 9101.3145 - kl_loss: 398.1519\n",
      "Epoch 4152/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9536.2068 - reconstruction_loss: 9075.6201 - kl_loss: 397.7996\n",
      "Epoch 4153/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9562.8395 - reconstruction_loss: 9089.7471 - kl_loss: 397.5191\n",
      "Epoch 4154/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9519.7356 - reconstruction_loss: 9050.4834 - kl_loss: 397.6349\n",
      "Epoch 4155/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9530.4056 - reconstruction_loss: 9068.7217 - kl_loss: 397.5387\n",
      "Epoch 4156/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9547.2763 - reconstruction_loss: 9075.1992 - kl_loss: 397.4074\n",
      "Epoch 4157/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9491.1344 - reconstruction_loss: 9040.4697 - kl_loss: 398.3574\n",
      "Epoch 4158/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9510.8184 - reconstruction_loss: 9042.2812 - kl_loss: 398.2199\n",
      "Epoch 4159/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9503.9697 - reconstruction_loss: 9025.8906 - kl_loss: 398.1267\n",
      "Epoch 4160/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9477.4069 - reconstruction_loss: 9011.4199 - kl_loss: 397.8875\n",
      "Epoch 4161/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9497.9179 - reconstruction_loss: 9018.6162 - kl_loss: 397.2602\n",
      "Epoch 4162/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9446.1124 - reconstruction_loss: 8988.7676 - kl_loss: 397.1349\n",
      "Epoch 4163/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9475.8945 - reconstruction_loss: 9009.3379 - kl_loss: 396.6940\n",
      "Epoch 4164/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9445.5738 - reconstruction_loss: 8989.5029 - kl_loss: 397.1216\n",
      "Epoch 4165/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9431.7964 - reconstruction_loss: 8977.8984 - kl_loss: 397.0278\n",
      "Epoch 4166/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9464.9109 - reconstruction_loss: 8988.9180 - kl_loss: 397.1192\n",
      "Epoch 4167/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9438.2350 - reconstruction_loss: 8966.8906 - kl_loss: 397.3809\n",
      "Epoch 4168/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9463.6315 - reconstruction_loss: 9022.0342 - kl_loss: 397.6686\n",
      "Epoch 4169/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9523.9427 - reconstruction_loss: 9015.4268 - kl_loss: 397.1314\n",
      "Epoch 4170/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9444.6069 - reconstruction_loss: 8967.5791 - kl_loss: 397.2315\n",
      "Epoch 4171/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9451.9747 - reconstruction_loss: 8989.5020 - kl_loss: 397.3794\n",
      "Epoch 4172/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9443.1455 - reconstruction_loss: 8968.8857 - kl_loss: 396.9828\n",
      "Epoch 4173/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9398.4579 - reconstruction_loss: 8941.4736 - kl_loss: 397.1053\n",
      "Epoch 4174/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9449.8775 - reconstruction_loss: 8976.7529 - kl_loss: 397.7458\n",
      "Epoch 4175/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9416.6476 - reconstruction_loss: 8946.5947 - kl_loss: 397.8920\n",
      "Epoch 4176/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9398.1331 - reconstruction_loss: 8944.9805 - kl_loss: 397.4804\n",
      "Epoch 4177/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9387.8570 - reconstruction_loss: 8926.8545 - kl_loss: 395.9182\n",
      "Epoch 4178/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9378.5520 - reconstruction_loss: 8920.8760 - kl_loss: 396.5768\n",
      "Epoch 4179/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9421.2759 - reconstruction_loss: 8967.6602 - kl_loss: 395.9662\n",
      "Epoch 4180/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9393.3473 - reconstruction_loss: 8932.4199 - kl_loss: 395.2147\n",
      "Epoch 4181/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9401.0590 - reconstruction_loss: 8937.4219 - kl_loss: 395.2465\n",
      "Epoch 4182/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9408.4594 - reconstruction_loss: 8940.8652 - kl_loss: 395.9541\n",
      "Epoch 4183/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9376.6178 - reconstruction_loss: 8923.2578 - kl_loss: 396.2361\n",
      "Epoch 4184/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9412.9884 - reconstruction_loss: 8944.1514 - kl_loss: 395.9891\n",
      "Epoch 4185/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9391.3582 - reconstruction_loss: 8915.9053 - kl_loss: 396.0823\n",
      "Epoch 4186/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9397.2281 - reconstruction_loss: 8945.9424 - kl_loss: 396.3218\n",
      "Epoch 4187/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9425.2509 - reconstruction_loss: 8942.5049 - kl_loss: 396.3495\n",
      "Epoch 4188/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9359.0994 - reconstruction_loss: 8910.5000 - kl_loss: 396.7737\n",
      "Epoch 4189/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9413.2795 - reconstruction_loss: 8942.2705 - kl_loss: 397.8401\n",
      "Epoch 4190/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9437.4386 - reconstruction_loss: 8942.1494 - kl_loss: 396.4233\n",
      "Epoch 4191/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9380.1801 - reconstruction_loss: 8933.1406 - kl_loss: 395.4955\n",
      "Epoch 4192/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9463.9214 - reconstruction_loss: 8974.4385 - kl_loss: 395.7495\n",
      "Epoch 4193/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9359.5503 - reconstruction_loss: 8898.9512 - kl_loss: 395.7652\n",
      "Epoch 4194/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9404.7215 - reconstruction_loss: 8943.1611 - kl_loss: 395.2417\n",
      "Epoch 4195/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9392.2891 - reconstruction_loss: 8916.4883 - kl_loss: 395.1046\n",
      "Epoch 4196/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9387.3242 - reconstruction_loss: 8933.7510 - kl_loss: 395.1316\n",
      "Epoch 4197/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9411.5114 - reconstruction_loss: 8925.6006 - kl_loss: 395.3664\n",
      "Epoch 4198/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9335.5823 - reconstruction_loss: 8890.0479 - kl_loss: 395.3635\n",
      "Epoch 4199/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9351.4140 - reconstruction_loss: 8899.0957 - kl_loss: 394.4886\n",
      "Epoch 4200/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9346.9432 - reconstruction_loss: 8888.0459 - kl_loss: 394.5502\n",
      "Epoch 4201/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9354.4338 - reconstruction_loss: 8900.2402 - kl_loss: 394.8036\n",
      "Epoch 4202/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9352.9582 - reconstruction_loss: 8894.0869 - kl_loss: 394.6295\n",
      "Epoch 4203/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9371.9837 - reconstruction_loss: 8899.6514 - kl_loss: 395.0434\n",
      "Epoch 4204/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9442.2558 - reconstruction_loss: 8963.2139 - kl_loss: 394.3819\n",
      "Epoch 4205/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9419.7280 - reconstruction_loss: 8924.1885 - kl_loss: 394.7543\n",
      "Epoch 4206/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9338.6369 - reconstruction_loss: 8901.3369 - kl_loss: 394.1072\n",
      "Epoch 4207/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9389.4286 - reconstruction_loss: 8913.7510 - kl_loss: 393.5977\n",
      "Epoch 4208/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9360.1251 - reconstruction_loss: 8895.0059 - kl_loss: 394.3956\n",
      "Epoch 4209/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9322.0706 - reconstruction_loss: 8874.9951 - kl_loss: 394.1021\n",
      "Epoch 4210/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9424.1725 - reconstruction_loss: 8948.3125 - kl_loss: 394.6880\n",
      "Epoch 4211/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9372.2307 - reconstruction_loss: 8893.4951 - kl_loss: 394.6530\n",
      "Epoch 4212/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9393.8271 - reconstruction_loss: 8954.0605 - kl_loss: 393.7998\n",
      "Epoch 4213/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9452.5391 - reconstruction_loss: 8943.0684 - kl_loss: 393.4475\n",
      "Epoch 4214/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9372.6383 - reconstruction_loss: 8907.3594 - kl_loss: 393.8504\n",
      "Epoch 4215/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9390.0705 - reconstruction_loss: 8952.1084 - kl_loss: 395.4895\n",
      "Epoch 4216/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9485.8263 - reconstruction_loss: 8977.3145 - kl_loss: 394.3046\n",
      "Epoch 4217/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9363.5237 - reconstruction_loss: 8924.0186 - kl_loss: 394.6856\n",
      "Epoch 4218/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9398.9005 - reconstruction_loss: 8944.8535 - kl_loss: 393.6740\n",
      "Epoch 4219/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9364.1110 - reconstruction_loss: 8910.1338 - kl_loss: 393.9976\n",
      "Epoch 4220/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9336.6411 - reconstruction_loss: 8903.4111 - kl_loss: 394.7754\n",
      "Epoch 4221/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9428.2089 - reconstruction_loss: 8944.9609 - kl_loss: 394.0214\n",
      "Epoch 4222/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9398.3901 - reconstruction_loss: 8950.9766 - kl_loss: 393.4147\n",
      "Epoch 4223/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9392.0064 - reconstruction_loss: 8932.2197 - kl_loss: 393.7896\n",
      "Epoch 4224/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9400.6698 - reconstruction_loss: 8945.6055 - kl_loss: 394.1122\n",
      "Epoch 4225/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9352.7337 - reconstruction_loss: 8914.4980 - kl_loss: 394.0325\n",
      "Epoch 4226/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9364.1192 - reconstruction_loss: 8915.4502 - kl_loss: 394.3024\n",
      "Epoch 4227/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9384.0801 - reconstruction_loss: 8921.4053 - kl_loss: 393.1653\n",
      "Epoch 4228/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9359.2745 - reconstruction_loss: 8931.4092 - kl_loss: 392.6088\n",
      "Epoch 4229/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9411.5060 - reconstruction_loss: 8951.1162 - kl_loss: 392.2600\n",
      "Epoch 4230/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9345.6730 - reconstruction_loss: 8912.4287 - kl_loss: 393.6974\n",
      "Epoch 4231/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9377.4311 - reconstruction_loss: 8917.3984 - kl_loss: 393.3734\n",
      "Epoch 4232/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9332.3769 - reconstruction_loss: 8882.2871 - kl_loss: 393.3478\n",
      "Epoch 4233/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9346.6006 - reconstruction_loss: 8914.7041 - kl_loss: 391.8881\n",
      "Epoch 4234/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9367.3265 - reconstruction_loss: 8909.5684 - kl_loss: 392.5851\n",
      "Epoch 4235/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9330.2943 - reconstruction_loss: 8890.7627 - kl_loss: 393.1984\n",
      "Epoch 4236/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9367.9517 - reconstruction_loss: 8914.0186 - kl_loss: 392.7540\n",
      "Epoch 4237/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9362.3138 - reconstruction_loss: 8903.3936 - kl_loss: 392.1886\n",
      "Epoch 4238/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9395.7598 - reconstruction_loss: 8960.7754 - kl_loss: 392.7207\n",
      "Epoch 4239/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9390.7236 - reconstruction_loss: 8933.5518 - kl_loss: 392.4081\n",
      "Epoch 4240/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9349.4050 - reconstruction_loss: 8891.1016 - kl_loss: 393.0186\n",
      "Epoch 4241/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9360.7878 - reconstruction_loss: 8896.5762 - kl_loss: 392.3741\n",
      "Epoch 4242/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9367.1942 - reconstruction_loss: 8920.8760 - kl_loss: 391.7374\n",
      "Epoch 4243/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9368.9852 - reconstruction_loss: 8928.7422 - kl_loss: 392.6502\n",
      "Epoch 4244/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9351.2712 - reconstruction_loss: 8897.3848 - kl_loss: 391.9461\n",
      "Epoch 4245/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9327.6904 - reconstruction_loss: 8887.8643 - kl_loss: 391.7697\n",
      "Epoch 4246/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 9345.6497 - reconstruction_loss: 8904.7051 - kl_loss: 391.8139\n",
      "Epoch 4247/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9394.9567 - reconstruction_loss: 8931.8369 - kl_loss: 392.0005\n",
      "Epoch 4248/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9369.6691 - reconstruction_loss: 8926.0723 - kl_loss: 392.0393\n",
      "Epoch 4249/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9416.1829 - reconstruction_loss: 8941.7500 - kl_loss: 392.0429\n",
      "Epoch 4250/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9376.3885 - reconstruction_loss: 8919.9980 - kl_loss: 392.6922\n",
      "Epoch 4251/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9389.9406 - reconstruction_loss: 8931.9795 - kl_loss: 391.8438\n",
      "Epoch 4252/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9439.9712 - reconstruction_loss: 8973.0225 - kl_loss: 392.5324\n",
      "Epoch 4253/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9381.6558 - reconstruction_loss: 8947.3887 - kl_loss: 392.1661\n",
      "Epoch 4254/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9456.7150 - reconstruction_loss: 9004.0811 - kl_loss: 391.9761\n",
      "Epoch 4255/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9429.1937 - reconstruction_loss: 8971.8066 - kl_loss: 392.0365\n",
      "Epoch 4256/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9521.9062 - reconstruction_loss: 9068.1260 - kl_loss: 391.6633\n",
      "Epoch 4257/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9562.3471 - reconstruction_loss: 9118.0498 - kl_loss: 392.1833\n",
      "Epoch 4258/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9562.0393 - reconstruction_loss: 9106.9365 - kl_loss: 390.4615\n",
      "Epoch 4259/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9541.4051 - reconstruction_loss: 9098.4834 - kl_loss: 390.9184\n",
      "Epoch 4260/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9537.6296 - reconstruction_loss: 9095.9785 - kl_loss: 391.9798\n",
      "Epoch 4261/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9476.5011 - reconstruction_loss: 9047.5586 - kl_loss: 393.1980\n",
      "Epoch 4262/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9455.2959 - reconstruction_loss: 9041.7432 - kl_loss: 392.3617\n",
      "Epoch 4263/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9447.3962 - reconstruction_loss: 9028.3408 - kl_loss: 392.1105\n",
      "Epoch 4264/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9438.5128 - reconstruction_loss: 9022.8184 - kl_loss: 391.9734\n",
      "Epoch 4265/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9485.4947 - reconstruction_loss: 9068.1836 - kl_loss: 390.6277\n",
      "Epoch 4266/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9660.2336 - reconstruction_loss: 9204.3545 - kl_loss: 392.4057\n",
      "Epoch 4267/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9497.2473 - reconstruction_loss: 9077.2881 - kl_loss: 392.6223\n",
      "Epoch 4268/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9519.7792 - reconstruction_loss: 9077.8789 - kl_loss: 391.6976\n",
      "Epoch 4269/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9519.6388 - reconstruction_loss: 9086.7461 - kl_loss: 391.3539\n",
      "Epoch 4270/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9580.9065 - reconstruction_loss: 9134.0020 - kl_loss: 389.9409\n",
      "Epoch 4271/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9615.5890 - reconstruction_loss: 9157.0176 - kl_loss: 390.8781\n",
      "Epoch 4272/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9616.9617 - reconstruction_loss: 9156.6816 - kl_loss: 390.8844\n",
      "Epoch 4273/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9617.6491 - reconstruction_loss: 9163.8633 - kl_loss: 390.4663\n",
      "Epoch 4274/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9636.4794 - reconstruction_loss: 9172.9375 - kl_loss: 391.6347\n",
      "Epoch 4275/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9673.9236 - reconstruction_loss: 9210.7529 - kl_loss: 391.6166\n",
      "Epoch 4276/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9679.4526 - reconstruction_loss: 9215.0713 - kl_loss: 390.6807\n",
      "Epoch 4277/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9643.4156 - reconstruction_loss: 9208.5430 - kl_loss: 390.9742\n",
      "Epoch 4278/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9703.2998 - reconstruction_loss: 9261.6543 - kl_loss: 390.6790\n",
      "Epoch 4279/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9683.5406 - reconstruction_loss: 9221.7910 - kl_loss: 391.1405\n",
      "Epoch 4280/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9682.9806 - reconstruction_loss: 9234.3564 - kl_loss: 392.6565\n",
      "Epoch 4281/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9670.1371 - reconstruction_loss: 9217.7568 - kl_loss: 391.4003\n",
      "Epoch 4282/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9662.1282 - reconstruction_loss: 9225.3389 - kl_loss: 391.3277\n",
      "Epoch 4283/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9648.0810 - reconstruction_loss: 9215.9082 - kl_loss: 390.9586\n",
      "Epoch 4284/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9642.0077 - reconstruction_loss: 9192.8223 - kl_loss: 391.2874\n",
      "Epoch 4285/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9600.5285 - reconstruction_loss: 9188.4219 - kl_loss: 391.9463\n",
      "Epoch 4286/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9650.6156 - reconstruction_loss: 9204.0010 - kl_loss: 392.0026\n",
      "Epoch 4287/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9656.5723 - reconstruction_loss: 9209.5186 - kl_loss: 391.3406\n",
      "Epoch 4288/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9651.0095 - reconstruction_loss: 9213.1396 - kl_loss: 391.6324\n",
      "Epoch 4289/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9651.3381 - reconstruction_loss: 9212.2979 - kl_loss: 391.4560\n",
      "Epoch 4290/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9658.9567 - reconstruction_loss: 9220.5771 - kl_loss: 390.5274\n",
      "Epoch 4291/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9764.7257 - reconstruction_loss: 9301.3936 - kl_loss: 390.6395\n",
      "Epoch 4292/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9722.6549 - reconstruction_loss: 9262.3096 - kl_loss: 390.5647\n",
      "Epoch 4293/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9762.1473 - reconstruction_loss: 9299.5830 - kl_loss: 391.5177\n",
      "Epoch 4294/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9753.9851 - reconstruction_loss: 9284.5322 - kl_loss: 390.4618\n",
      "Epoch 4295/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9743.3402 - reconstruction_loss: 9286.7979 - kl_loss: 391.3504\n",
      "Epoch 4296/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9745.6536 - reconstruction_loss: 9293.4580 - kl_loss: 391.4776\n",
      "Epoch 4297/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9720.3435 - reconstruction_loss: 9281.8711 - kl_loss: 391.7997\n",
      "Epoch 4298/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9734.3175 - reconstruction_loss: 9295.8701 - kl_loss: 391.9418\n",
      "Epoch 4299/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9676.4762 - reconstruction_loss: 9248.8672 - kl_loss: 390.6557\n",
      "Epoch 4300/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9679.0493 - reconstruction_loss: 9256.9170 - kl_loss: 390.5508\n",
      "Epoch 4301/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9653.3082 - reconstruction_loss: 9221.7002 - kl_loss: 391.1676\n",
      "Epoch 4302/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9632.8411 - reconstruction_loss: 9231.9434 - kl_loss: 391.6724\n",
      "Epoch 4303/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9662.3438 - reconstruction_loss: 9240.2520 - kl_loss: 390.9107\n",
      "Epoch 4304/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9682.8884 - reconstruction_loss: 9262.3057 - kl_loss: 390.5884\n",
      "Epoch 4305/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9688.6442 - reconstruction_loss: 9268.9619 - kl_loss: 391.8042\n",
      "Epoch 4306/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9718.2950 - reconstruction_loss: 9311.4619 - kl_loss: 391.7507\n",
      "Epoch 4307/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9772.3713 - reconstruction_loss: 9343.0127 - kl_loss: 390.5497\n",
      "Epoch 4308/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9829.0044 - reconstruction_loss: 9364.6055 - kl_loss: 391.2014\n",
      "Epoch 4309/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9843.3942 - reconstruction_loss: 9393.4414 - kl_loss: 391.6843\n",
      "Epoch 4310/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9873.5066 - reconstruction_loss: 9420.3799 - kl_loss: 392.2523\n",
      "Epoch 4311/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9872.6085 - reconstruction_loss: 9405.8232 - kl_loss: 391.6968\n",
      "Epoch 4312/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9837.9068 - reconstruction_loss: 9385.8955 - kl_loss: 392.4045\n",
      "Epoch 4313/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9812.1909 - reconstruction_loss: 9340.1846 - kl_loss: 391.5512\n",
      "Epoch 4314/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9735.9329 - reconstruction_loss: 9290.2188 - kl_loss: 391.7557\n",
      "Epoch 4315/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9729.4393 - reconstruction_loss: 9293.8330 - kl_loss: 391.0592\n",
      "Epoch 4316/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9687.3812 - reconstruction_loss: 9241.6240 - kl_loss: 390.9287\n",
      "Epoch 4317/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9664.3858 - reconstruction_loss: 9218.2666 - kl_loss: 391.7772\n",
      "Epoch 4318/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9664.5380 - reconstruction_loss: 9219.0723 - kl_loss: 391.8203\n",
      "Epoch 4319/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9634.6975 - reconstruction_loss: 9190.3994 - kl_loss: 392.2451\n",
      "Epoch 4320/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9620.0131 - reconstruction_loss: 9187.7578 - kl_loss: 391.7134\n",
      "Epoch 4321/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9622.4158 - reconstruction_loss: 9187.6562 - kl_loss: 391.6170\n",
      "Epoch 4322/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9610.4738 - reconstruction_loss: 9177.0898 - kl_loss: 391.4305\n",
      "Epoch 4323/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9618.6113 - reconstruction_loss: 9170.4502 - kl_loss: 391.1848\n",
      "Epoch 4324/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9569.5978 - reconstruction_loss: 9143.4912 - kl_loss: 391.4091\n",
      "Epoch 4325/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9582.8365 - reconstruction_loss: 9150.6729 - kl_loss: 390.5496\n",
      "Epoch 4326/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9567.4844 - reconstruction_loss: 9132.3086 - kl_loss: 391.1068\n",
      "Epoch 4327/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9561.0370 - reconstruction_loss: 9133.5820 - kl_loss: 390.4037\n",
      "Epoch 4328/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9555.6418 - reconstruction_loss: 9118.0186 - kl_loss: 391.2742\n",
      "Epoch 4329/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9550.2358 - reconstruction_loss: 9111.5820 - kl_loss: 392.4678\n",
      "Epoch 4330/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9538.7396 - reconstruction_loss: 9118.9004 - kl_loss: 390.8426\n",
      "Epoch 4331/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9548.6786 - reconstruction_loss: 9113.7715 - kl_loss: 391.4078\n",
      "Epoch 4332/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9536.5141 - reconstruction_loss: 9116.1348 - kl_loss: 391.5577\n",
      "Epoch 4333/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9547.9218 - reconstruction_loss: 9111.3232 - kl_loss: 390.4510\n",
      "Epoch 4334/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9531.0909 - reconstruction_loss: 9104.7217 - kl_loss: 390.5442\n",
      "Epoch 4335/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9564.8298 - reconstruction_loss: 9125.4893 - kl_loss: 390.8710\n",
      "Epoch 4336/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9541.8622 - reconstruction_loss: 9112.1406 - kl_loss: 392.0995\n",
      "Epoch 4337/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9544.1636 - reconstruction_loss: 9118.1191 - kl_loss: 391.5479\n",
      "Epoch 4338/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9583.7069 - reconstruction_loss: 9136.1689 - kl_loss: 391.2909\n",
      "Epoch 4339/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10231.3442 - reconstruction_loss: 9492.5703 - kl_loss: 397.3064\n",
      "Epoch 4340/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9890.5939 - reconstruction_loss: 9310.8232 - kl_loss: 391.5536\n",
      "Epoch 4341/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9897.4038 - reconstruction_loss: 9392.8926 - kl_loss: 390.8015\n",
      "Epoch 4342/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9658.5325 - reconstruction_loss: 9226.4346 - kl_loss: 391.5976\n",
      "Epoch 4343/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9616.2032 - reconstruction_loss: 9226.6123 - kl_loss: 390.2825\n",
      "Epoch 4344/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9626.9185 - reconstruction_loss: 9236.0312 - kl_loss: 390.9412\n",
      "Epoch 4345/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9666.0377 - reconstruction_loss: 9255.6348 - kl_loss: 391.5170\n",
      "Epoch 4346/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9674.9983 - reconstruction_loss: 9270.5586 - kl_loss: 390.9268\n",
      "Epoch 4347/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9709.3145 - reconstruction_loss: 9317.1465 - kl_loss: 389.9208\n",
      "Epoch 4348/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9728.5549 - reconstruction_loss: 9339.8311 - kl_loss: 390.1144\n",
      "Epoch 4349/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9775.0394 - reconstruction_loss: 9394.6484 - kl_loss: 390.7359\n",
      "Epoch 4350/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9852.4451 - reconstruction_loss: 9459.6982 - kl_loss: 389.7180\n",
      "Epoch 4351/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9933.8164 - reconstruction_loss: 9554.6504 - kl_loss: 390.3831\n",
      "Epoch 4352/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 10037.3884 - reconstruction_loss: 9647.3320 - kl_loss: 390.9517\n",
      "Epoch 4353/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 10127.2764 - reconstruction_loss: 9756.1982 - kl_loss: 389.3314\n",
      "Epoch 4354/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 10214.9877 - reconstruction_loss: 9776.2988 - kl_loss: 390.4972\n",
      "Epoch 4355/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 10192.8940 - reconstruction_loss: 9788.5225 - kl_loss: 389.1353\n",
      "Epoch 4356/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 10238.0599 - reconstruction_loss: 9853.0400 - kl_loss: 390.5430\n",
      "Epoch 4357/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10274.3305 - reconstruction_loss: 9875.1924 - kl_loss: 391.1505\n",
      "Epoch 4358/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10278.2177 - reconstruction_loss: 9875.6387 - kl_loss: 390.6227\n",
      "Epoch 4359/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10279.9968 - reconstruction_loss: 9866.6055 - kl_loss: 390.6011\n",
      "Epoch 4360/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10270.4124 - reconstruction_loss: 9892.7607 - kl_loss: 391.4026\n",
      "Epoch 4361/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10359.3710 - reconstruction_loss: 9959.2666 - kl_loss: 390.4518\n",
      "Epoch 4362/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10294.0642 - reconstruction_loss: 9977.0381 - kl_loss: 390.5479\n",
      "Epoch 4363/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 10485.7613 - reconstruction_loss: 10136.0605 - kl_loss: 389.5889\n",
      "Epoch 4364/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10773.9190 - reconstruction_loss: 10388.7734 - kl_loss: 390.7903\n",
      "Epoch 4365/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 11152.2083 - reconstruction_loss: 10639.3564 - kl_loss: 388.7398\n",
      "Epoch 4366/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11589.9366 - reconstruction_loss: 10843.8418 - kl_loss: 389.6270\n",
      "Epoch 4367/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 11440.5301 - reconstruction_loss: 10633.3740 - kl_loss: 391.4226\n",
      "Epoch 4368/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11113.1900 - reconstruction_loss: 10426.8330 - kl_loss: 391.6078\n",
      "Epoch 4369/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10974.6036 - reconstruction_loss: 10245.0752 - kl_loss: 391.0660\n",
      "Epoch 4370/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10631.3832 - reconstruction_loss: 9983.8564 - kl_loss: 391.5007\n",
      "Epoch 4371/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10375.8016 - reconstruction_loss: 9801.0771 - kl_loss: 391.6598\n",
      "Epoch 4372/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10336.1522 - reconstruction_loss: 9734.0303 - kl_loss: 392.0762\n",
      "Epoch 4373/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10264.4949 - reconstruction_loss: 9696.7744 - kl_loss: 391.6241\n",
      "Epoch 4374/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10216.8545 - reconstruction_loss: 9648.2676 - kl_loss: 392.0554\n",
      "Epoch 4375/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 10177.7876 - reconstruction_loss: 9603.1709 - kl_loss: 391.4492\n",
      "Epoch 4376/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10104.0785 - reconstruction_loss: 9555.1748 - kl_loss: 391.9465\n",
      "Epoch 4377/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10101.1247 - reconstruction_loss: 9556.2471 - kl_loss: 392.6512\n",
      "Epoch 4378/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 10086.0866 - reconstruction_loss: 9522.9375 - kl_loss: 393.4708\n",
      "Epoch 4379/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10024.9547 - reconstruction_loss: 9490.9043 - kl_loss: 391.7026\n",
      "Epoch 4380/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10002.8135 - reconstruction_loss: 9470.6699 - kl_loss: 392.4491\n",
      "Epoch 4381/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9986.8122 - reconstruction_loss: 9445.0215 - kl_loss: 392.8350\n",
      "Epoch 4382/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9996.8637 - reconstruction_loss: 9442.2637 - kl_loss: 393.0636\n",
      "Epoch 4383/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9973.4795 - reconstruction_loss: 9439.6221 - kl_loss: 393.3482\n",
      "Epoch 4384/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9964.7071 - reconstruction_loss: 9419.1318 - kl_loss: 393.9716\n",
      "Epoch 4385/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9885.1731 - reconstruction_loss: 9357.6670 - kl_loss: 393.0286\n",
      "Epoch 4386/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9900.7934 - reconstruction_loss: 9378.8770 - kl_loss: 391.8680\n",
      "Epoch 4387/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9907.4829 - reconstruction_loss: 9377.8535 - kl_loss: 391.9800\n",
      "Epoch 4388/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9866.7559 - reconstruction_loss: 9333.8330 - kl_loss: 391.1281\n",
      "Epoch 4389/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9828.1307 - reconstruction_loss: 9306.5420 - kl_loss: 392.1363\n",
      "Epoch 4390/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9848.8371 - reconstruction_loss: 9336.1836 - kl_loss: 392.5734\n",
      "Epoch 4391/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9791.8885 - reconstruction_loss: 9280.3311 - kl_loss: 392.9358\n",
      "Epoch 4392/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9824.7517 - reconstruction_loss: 9316.0908 - kl_loss: 392.4338\n",
      "Epoch 4393/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9846.9553 - reconstruction_loss: 9314.0244 - kl_loss: 392.5803\n",
      "Epoch 4394/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9764.0613 - reconstruction_loss: 9248.8525 - kl_loss: 392.7523\n",
      "Epoch 4395/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9765.3447 - reconstruction_loss: 9269.1562 - kl_loss: 391.9440\n",
      "Epoch 4396/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9776.2353 - reconstruction_loss: 9254.5137 - kl_loss: 392.5139\n",
      "Epoch 4397/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9745.4102 - reconstruction_loss: 9247.3477 - kl_loss: 391.0563\n",
      "Epoch 4398/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9750.5274 - reconstruction_loss: 9244.2588 - kl_loss: 391.6483\n",
      "Epoch 4399/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9702.2261 - reconstruction_loss: 9206.6875 - kl_loss: 391.6836\n",
      "Epoch 4400/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9683.0394 - reconstruction_loss: 9184.3613 - kl_loss: 392.6997\n",
      "Epoch 4401/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9665.3766 - reconstruction_loss: 9163.6143 - kl_loss: 393.3158\n",
      "Epoch 4402/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9632.8156 - reconstruction_loss: 9155.7402 - kl_loss: 392.2718\n",
      "Epoch 4403/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9676.2162 - reconstruction_loss: 9181.5771 - kl_loss: 390.7851\n",
      "Epoch 4404/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9642.4031 - reconstruction_loss: 9158.1211 - kl_loss: 392.0121\n",
      "Epoch 4405/5000\n",
      "75/75 [==============================] - 3s 43ms/step - loss: 9600.9793 - reconstruction_loss: 9120.5791 - kl_loss: 391.8201\n",
      "Epoch 4406/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9580.6727 - reconstruction_loss: 9096.9736 - kl_loss: 392.3158\n",
      "Epoch 4407/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9570.8596 - reconstruction_loss: 9090.3311 - kl_loss: 391.7902\n",
      "Epoch 4408/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9571.9652 - reconstruction_loss: 9085.2783 - kl_loss: 392.9498\n",
      "Epoch 4409/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9571.8416 - reconstruction_loss: 9073.1963 - kl_loss: 392.5264\n",
      "Epoch 4410/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9570.2828 - reconstruction_loss: 9083.8457 - kl_loss: 392.2952\n",
      "Epoch 4411/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9577.9416 - reconstruction_loss: 9091.7910 - kl_loss: 392.5872\n",
      "Epoch 4412/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9512.5203 - reconstruction_loss: 9047.7979 - kl_loss: 392.1164\n",
      "Epoch 4413/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9528.8916 - reconstruction_loss: 9050.0088 - kl_loss: 391.5504\n",
      "Epoch 4414/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9580.8694 - reconstruction_loss: 9075.5215 - kl_loss: 391.0934\n",
      "Epoch 4415/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9528.8021 - reconstruction_loss: 9065.2969 - kl_loss: 392.0489\n",
      "Epoch 4416/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9538.4889 - reconstruction_loss: 9041.7041 - kl_loss: 393.4698\n",
      "Epoch 4417/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9484.4228 - reconstruction_loss: 8999.7520 - kl_loss: 392.6355\n",
      "Epoch 4418/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9486.5175 - reconstruction_loss: 9001.4062 - kl_loss: 392.6916\n",
      "Epoch 4419/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9483.8025 - reconstruction_loss: 8991.9033 - kl_loss: 391.7513\n",
      "Epoch 4420/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9451.4560 - reconstruction_loss: 8973.9092 - kl_loss: 392.5026\n",
      "Epoch 4421/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9434.7964 - reconstruction_loss: 8961.1777 - kl_loss: 391.8079\n",
      "Epoch 4422/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9448.3793 - reconstruction_loss: 8969.4043 - kl_loss: 391.8006\n",
      "Epoch 4423/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9460.1140 - reconstruction_loss: 8992.8154 - kl_loss: 390.5576\n",
      "Epoch 4424/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9461.5951 - reconstruction_loss: 8961.4951 - kl_loss: 390.8427\n",
      "Epoch 4425/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9430.2428 - reconstruction_loss: 8955.9482 - kl_loss: 390.8888\n",
      "Epoch 4426/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9413.2310 - reconstruction_loss: 8936.0391 - kl_loss: 392.1628\n",
      "Epoch 4427/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9413.7880 - reconstruction_loss: 8927.0332 - kl_loss: 391.6071\n",
      "Epoch 4428/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9369.2950 - reconstruction_loss: 8904.3721 - kl_loss: 391.8511\n",
      "Epoch 4429/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9390.8478 - reconstruction_loss: 8913.9551 - kl_loss: 391.0122\n",
      "Epoch 4430/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9362.9725 - reconstruction_loss: 8890.5225 - kl_loss: 390.8343\n",
      "Epoch 4431/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9353.1917 - reconstruction_loss: 8892.5312 - kl_loss: 391.6504\n",
      "Epoch 4432/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9367.4343 - reconstruction_loss: 8895.2969 - kl_loss: 391.3328\n",
      "Epoch 4433/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9331.8600 - reconstruction_loss: 8869.5049 - kl_loss: 390.8770\n",
      "Epoch 4434/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9360.1352 - reconstruction_loss: 8887.6934 - kl_loss: 390.1863\n",
      "Epoch 4435/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9343.1972 - reconstruction_loss: 8871.0029 - kl_loss: 392.4210\n",
      "Epoch 4436/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9335.3869 - reconstruction_loss: 8873.0527 - kl_loss: 391.9711\n",
      "Epoch 4437/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9386.7565 - reconstruction_loss: 8898.0586 - kl_loss: 392.0101\n",
      "Epoch 4438/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9321.9439 - reconstruction_loss: 8859.5039 - kl_loss: 391.3336\n",
      "Epoch 4439/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9347.4254 - reconstruction_loss: 8879.2852 - kl_loss: 391.4698\n",
      "Epoch 4440/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9353.0648 - reconstruction_loss: 8879.6143 - kl_loss: 390.7917\n",
      "Epoch 4441/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9396.1927 - reconstruction_loss: 8928.9541 - kl_loss: 392.5612\n",
      "Epoch 4442/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9363.6956 - reconstruction_loss: 8876.6221 - kl_loss: 391.2320\n",
      "Epoch 4443/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9299.6922 - reconstruction_loss: 8840.4355 - kl_loss: 391.1149\n",
      "Epoch 4444/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9297.0654 - reconstruction_loss: 8834.4961 - kl_loss: 390.9828\n",
      "Epoch 4445/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9301.0012 - reconstruction_loss: 8829.5479 - kl_loss: 391.0132\n",
      "Epoch 4446/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9285.0987 - reconstruction_loss: 8829.1943 - kl_loss: 391.4291\n",
      "Epoch 4447/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9323.1055 - reconstruction_loss: 8842.7021 - kl_loss: 390.2497\n",
      "Epoch 4448/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9278.7253 - reconstruction_loss: 8819.5215 - kl_loss: 390.0295\n",
      "Epoch 4449/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9322.7807 - reconstruction_loss: 8848.6904 - kl_loss: 390.4057\n",
      "Epoch 4450/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9295.8054 - reconstruction_loss: 8820.8008 - kl_loss: 390.1328\n",
      "Epoch 4451/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9265.2223 - reconstruction_loss: 8814.6514 - kl_loss: 389.9215\n",
      "Epoch 4452/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9344.3044 - reconstruction_loss: 8857.9990 - kl_loss: 390.1879\n",
      "Epoch 4453/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9312.9198 - reconstruction_loss: 8834.8047 - kl_loss: 389.6781\n",
      "Epoch 4454/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9298.6174 - reconstruction_loss: 8838.2236 - kl_loss: 389.5747\n",
      "Epoch 4455/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9297.4147 - reconstruction_loss: 8821.1885 - kl_loss: 389.9660\n",
      "Epoch 4456/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9263.8783 - reconstruction_loss: 8800.9746 - kl_loss: 390.1383\n",
      "Epoch 4457/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9328.0224 - reconstruction_loss: 8855.2705 - kl_loss: 391.1183\n",
      "Epoch 4458/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9391.7205 - reconstruction_loss: 8907.4385 - kl_loss: 390.1746\n",
      "Epoch 4459/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9281.6701 - reconstruction_loss: 8836.9199 - kl_loss: 389.2586\n",
      "Epoch 4460/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9326.3696 - reconstruction_loss: 8840.2539 - kl_loss: 390.1938\n",
      "Epoch 4461/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9253.7589 - reconstruction_loss: 8797.9775 - kl_loss: 389.9413\n",
      "Epoch 4462/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9299.4721 - reconstruction_loss: 8829.2920 - kl_loss: 391.3460\n",
      "Epoch 4463/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9312.1228 - reconstruction_loss: 8822.2910 - kl_loss: 389.7978\n",
      "Epoch 4464/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9286.9937 - reconstruction_loss: 8823.4141 - kl_loss: 389.6341\n",
      "Epoch 4465/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9260.0982 - reconstruction_loss: 8797.7734 - kl_loss: 389.3358\n",
      "Epoch 4466/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9289.5695 - reconstruction_loss: 8802.6162 - kl_loss: 390.5617\n",
      "Epoch 4467/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9277.2168 - reconstruction_loss: 8822.9600 - kl_loss: 389.9259\n",
      "Epoch 4468/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9243.3228 - reconstruction_loss: 8777.0576 - kl_loss: 389.7597\n",
      "Epoch 4469/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9232.6634 - reconstruction_loss: 8779.8262 - kl_loss: 389.4206\n",
      "Epoch 4470/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9238.4522 - reconstruction_loss: 8777.6182 - kl_loss: 390.1179\n",
      "Epoch 4471/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9222.5364 - reconstruction_loss: 8767.1719 - kl_loss: 389.3726\n",
      "Epoch 4472/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9240.6377 - reconstruction_loss: 8768.5088 - kl_loss: 388.5656\n",
      "Epoch 4473/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9211.1830 - reconstruction_loss: 8760.0400 - kl_loss: 388.8103\n",
      "Epoch 4474/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9232.9330 - reconstruction_loss: 8784.2656 - kl_loss: 389.4205\n",
      "Epoch 4475/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9213.8759 - reconstruction_loss: 8763.5732 - kl_loss: 389.7643\n",
      "Epoch 4476/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9206.8443 - reconstruction_loss: 8755.4121 - kl_loss: 389.2042\n",
      "Epoch 4477/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9242.0808 - reconstruction_loss: 8781.7861 - kl_loss: 389.5368\n",
      "Epoch 4478/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9255.0026 - reconstruction_loss: 8793.4775 - kl_loss: 389.9289\n",
      "Epoch 4479/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9257.8038 - reconstruction_loss: 8789.8809 - kl_loss: 389.5102\n",
      "Epoch 4480/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9264.7200 - reconstruction_loss: 8796.3857 - kl_loss: 389.1848\n",
      "Epoch 4481/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9226.1420 - reconstruction_loss: 8774.9590 - kl_loss: 388.9349\n",
      "Epoch 4482/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9228.7058 - reconstruction_loss: 8769.9023 - kl_loss: 388.2645\n",
      "Epoch 4483/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9259.6328 - reconstruction_loss: 8790.6953 - kl_loss: 387.9193\n",
      "Epoch 4484/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9244.9030 - reconstruction_loss: 8797.5488 - kl_loss: 389.1944\n",
      "Epoch 4485/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9232.1028 - reconstruction_loss: 8767.0059 - kl_loss: 388.5409\n",
      "Epoch 4486/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9197.5124 - reconstruction_loss: 8752.6992 - kl_loss: 387.7762\n",
      "Epoch 4487/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9279.9066 - reconstruction_loss: 8810.4072 - kl_loss: 388.5517\n",
      "Epoch 4488/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9254.9037 - reconstruction_loss: 8784.1133 - kl_loss: 387.8375\n",
      "Epoch 4489/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9228.5462 - reconstruction_loss: 8786.8184 - kl_loss: 387.8940\n",
      "Epoch 4490/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9313.7134 - reconstruction_loss: 8841.0400 - kl_loss: 388.2308\n",
      "Epoch 4491/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9305.7588 - reconstruction_loss: 8838.7227 - kl_loss: 388.1746\n",
      "Epoch 4492/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9415.4441 - reconstruction_loss: 8953.1533 - kl_loss: 389.4691\n",
      "Epoch 4493/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9365.7982 - reconstruction_loss: 8863.2305 - kl_loss: 388.6579\n",
      "Epoch 4494/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9281.0439 - reconstruction_loss: 8811.1787 - kl_loss: 388.3792\n",
      "Epoch 4495/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9334.6935 - reconstruction_loss: 8858.4512 - kl_loss: 388.3657\n",
      "Epoch 4496/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9335.4634 - reconstruction_loss: 8861.7637 - kl_loss: 387.9064\n",
      "Epoch 4497/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9358.4327 - reconstruction_loss: 8929.2959 - kl_loss: 387.8104\n",
      "Epoch 4498/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9387.1247 - reconstruction_loss: 8910.6729 - kl_loss: 388.4823\n",
      "Epoch 4499/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9323.9229 - reconstruction_loss: 8860.6885 - kl_loss: 387.5009\n",
      "Epoch 4500/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9354.7170 - reconstruction_loss: 8880.3242 - kl_loss: 386.9190\n",
      "Epoch 4501/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9330.0037 - reconstruction_loss: 8880.5918 - kl_loss: 387.2612\n",
      "Epoch 4502/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9382.2670 - reconstruction_loss: 8903.7637 - kl_loss: 388.4218\n",
      "Epoch 4503/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9374.1655 - reconstruction_loss: 8916.6562 - kl_loss: 387.6921\n",
      "Epoch 4504/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 9382.8289 - reconstruction_loss: 8902.8477 - kl_loss: 386.9221\n",
      "Epoch 4505/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9394.3359 - reconstruction_loss: 8919.5234 - kl_loss: 387.9358\n",
      "Epoch 4506/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9372.6954 - reconstruction_loss: 8895.4551 - kl_loss: 388.1772\n",
      "Epoch 4507/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9351.2729 - reconstruction_loss: 8880.3789 - kl_loss: 388.2845\n",
      "Epoch 4508/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9358.9394 - reconstruction_loss: 8871.2812 - kl_loss: 388.0937\n",
      "Epoch 4509/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9367.9212 - reconstruction_loss: 8883.2627 - kl_loss: 387.2064\n",
      "Epoch 4510/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9362.8949 - reconstruction_loss: 8889.0771 - kl_loss: 387.1102\n",
      "Epoch 4511/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9391.3772 - reconstruction_loss: 8912.0420 - kl_loss: 386.3664\n",
      "Epoch 4512/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9452.8036 - reconstruction_loss: 8950.3379 - kl_loss: 387.2226\n",
      "Epoch 4513/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9577.3826 - reconstruction_loss: 9028.7441 - kl_loss: 388.2327\n",
      "Epoch 4514/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9455.5434 - reconstruction_loss: 8947.4375 - kl_loss: 388.1929\n",
      "Epoch 4515/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9429.1329 - reconstruction_loss: 8923.0312 - kl_loss: 387.3734\n",
      "Epoch 4516/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9421.4458 - reconstruction_loss: 8947.1289 - kl_loss: 387.1288\n",
      "Epoch 4517/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9357.0669 - reconstruction_loss: 8899.0957 - kl_loss: 387.8131\n",
      "Epoch 4518/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9323.5306 - reconstruction_loss: 8876.3359 - kl_loss: 387.1095\n",
      "Epoch 4519/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9311.2404 - reconstruction_loss: 8852.0186 - kl_loss: 387.8661\n",
      "Epoch 4520/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9291.4538 - reconstruction_loss: 8839.5791 - kl_loss: 386.8957\n",
      "Epoch 4521/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9283.8395 - reconstruction_loss: 8835.8535 - kl_loss: 387.2769\n",
      "Epoch 4522/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9285.2793 - reconstruction_loss: 8831.5811 - kl_loss: 388.0097\n",
      "Epoch 4523/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9250.2104 - reconstruction_loss: 8809.3066 - kl_loss: 387.7758\n",
      "Epoch 4524/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9256.9426 - reconstruction_loss: 8803.7695 - kl_loss: 386.4069\n",
      "Epoch 4525/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9255.4963 - reconstruction_loss: 8811.3594 - kl_loss: 386.4695\n",
      "Epoch 4526/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9281.5020 - reconstruction_loss: 8822.5225 - kl_loss: 387.0040\n",
      "Epoch 4527/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9287.1227 - reconstruction_loss: 8825.7334 - kl_loss: 386.2814\n",
      "Epoch 4528/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9256.7380 - reconstruction_loss: 8801.3535 - kl_loss: 386.6158\n",
      "Epoch 4529/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9272.5988 - reconstruction_loss: 8825.0957 - kl_loss: 386.7108\n",
      "Epoch 4530/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9324.0412 - reconstruction_loss: 8849.5957 - kl_loss: 387.5457\n",
      "Epoch 4531/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9281.4865 - reconstruction_loss: 8828.8828 - kl_loss: 386.9081\n",
      "Epoch 4532/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9389.8886 - reconstruction_loss: 8932.2295 - kl_loss: 386.8728\n",
      "Epoch 4533/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9292.5048 - reconstruction_loss: 8821.8906 - kl_loss: 387.1829\n",
      "Epoch 4534/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9256.0782 - reconstruction_loss: 8804.7256 - kl_loss: 386.2698\n",
      "Epoch 4535/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9295.2285 - reconstruction_loss: 8830.8594 - kl_loss: 386.2059\n",
      "Epoch 4536/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9279.5957 - reconstruction_loss: 8809.0752 - kl_loss: 386.4549\n",
      "Epoch 4537/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9261.9145 - reconstruction_loss: 8807.1445 - kl_loss: 387.1650\n",
      "Epoch 4538/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9282.6184 - reconstruction_loss: 8815.5166 - kl_loss: 387.1387\n",
      "Epoch 4539/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9269.2446 - reconstruction_loss: 8812.2129 - kl_loss: 386.8174\n",
      "Epoch 4540/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9257.5821 - reconstruction_loss: 8802.4648 - kl_loss: 387.5838\n",
      "Epoch 4541/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9263.3260 - reconstruction_loss: 8801.4121 - kl_loss: 387.0743\n",
      "Epoch 4542/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9249.9941 - reconstruction_loss: 8810.7705 - kl_loss: 386.4055\n",
      "Epoch 4543/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9327.5875 - reconstruction_loss: 8857.2422 - kl_loss: 386.9753\n",
      "Epoch 4544/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9274.9175 - reconstruction_loss: 8821.8320 - kl_loss: 387.3814\n",
      "Epoch 4545/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9275.8146 - reconstruction_loss: 8822.2734 - kl_loss: 386.6468\n",
      "Epoch 4546/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9298.3771 - reconstruction_loss: 8828.9434 - kl_loss: 385.9793\n",
      "Epoch 4547/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9265.9936 - reconstruction_loss: 8826.4688 - kl_loss: 386.7515\n",
      "Epoch 4548/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9297.4507 - reconstruction_loss: 8841.0098 - kl_loss: 386.5454\n",
      "Epoch 4549/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9274.1309 - reconstruction_loss: 8823.3369 - kl_loss: 386.3913\n",
      "Epoch 4550/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9287.2961 - reconstruction_loss: 8860.5166 - kl_loss: 387.3437\n",
      "Epoch 4551/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9480.4220 - reconstruction_loss: 8979.5605 - kl_loss: 387.3329\n",
      "Epoch 4552/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9324.6144 - reconstruction_loss: 8879.1377 - kl_loss: 385.4007\n",
      "Epoch 4553/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9375.6929 - reconstruction_loss: 8908.1025 - kl_loss: 385.9928\n",
      "Epoch 4554/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9355.6324 - reconstruction_loss: 8910.7246 - kl_loss: 386.9724\n",
      "Epoch 4555/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9349.4536 - reconstruction_loss: 8899.2158 - kl_loss: 386.7492\n",
      "Epoch 4556/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9356.2864 - reconstruction_loss: 8905.8994 - kl_loss: 386.4993\n",
      "Epoch 4557/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9337.0485 - reconstruction_loss: 8902.5234 - kl_loss: 386.0251\n",
      "Epoch 4558/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9368.2501 - reconstruction_loss: 8904.4404 - kl_loss: 385.3547\n",
      "Epoch 4559/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9361.2280 - reconstruction_loss: 8918.2910 - kl_loss: 385.9277\n",
      "Epoch 4560/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9415.2465 - reconstruction_loss: 8960.9922 - kl_loss: 384.8323\n",
      "Epoch 4561/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9493.1996 - reconstruction_loss: 9030.0010 - kl_loss: 385.1236\n",
      "Epoch 4562/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9455.1341 - reconstruction_loss: 9015.8633 - kl_loss: 385.6577\n",
      "Epoch 4563/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9479.1627 - reconstruction_loss: 9034.5205 - kl_loss: 386.5295\n",
      "Epoch 4564/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9491.6730 - reconstruction_loss: 9046.9932 - kl_loss: 385.2724\n",
      "Epoch 4565/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9527.5577 - reconstruction_loss: 9068.9316 - kl_loss: 386.0621\n",
      "Epoch 4566/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9520.3365 - reconstruction_loss: 9057.6260 - kl_loss: 387.0301\n",
      "Epoch 4567/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9600.9780 - reconstruction_loss: 9131.1475 - kl_loss: 386.4295\n",
      "Epoch 4568/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9514.4952 - reconstruction_loss: 9041.5508 - kl_loss: 385.9197\n",
      "Epoch 4569/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9469.6307 - reconstruction_loss: 8995.4844 - kl_loss: 385.4197\n",
      "Epoch 4570/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9480.3113 - reconstruction_loss: 8997.6846 - kl_loss: 386.7828\n",
      "Epoch 4571/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9486.6895 - reconstruction_loss: 9001.5576 - kl_loss: 386.0837\n",
      "Epoch 4572/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9444.6120 - reconstruction_loss: 8987.4268 - kl_loss: 385.7506\n",
      "Epoch 4573/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9469.2274 - reconstruction_loss: 9000.3701 - kl_loss: 385.1253\n",
      "Epoch 4574/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9454.3719 - reconstruction_loss: 8993.1338 - kl_loss: 385.6372\n",
      "Epoch 4575/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9487.6182 - reconstruction_loss: 9040.1494 - kl_loss: 386.8108\n",
      "Epoch 4576/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9647.5075 - reconstruction_loss: 9130.4053 - kl_loss: 386.6368\n",
      "Epoch 4577/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9572.4140 - reconstruction_loss: 9091.0713 - kl_loss: 386.4600\n",
      "Epoch 4578/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9553.3262 - reconstruction_loss: 9125.0088 - kl_loss: 386.3833\n",
      "Epoch 4579/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9580.4290 - reconstruction_loss: 9126.3652 - kl_loss: 385.1780\n",
      "Epoch 4580/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9591.9995 - reconstruction_loss: 9159.1436 - kl_loss: 385.5447\n",
      "Epoch 4581/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9719.5182 - reconstruction_loss: 9227.8105 - kl_loss: 386.2789\n",
      "Epoch 4582/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9607.5866 - reconstruction_loss: 9142.0029 - kl_loss: 385.9603\n",
      "Epoch 4583/5000\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 9606.8669 - reconstruction_loss: 9143.6816 - kl_loss: 385.4626\n",
      "Epoch 4584/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9595.7125 - reconstruction_loss: 9145.3574 - kl_loss: 386.0595\n",
      "Epoch 4585/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9617.1631 - reconstruction_loss: 9142.4326 - kl_loss: 385.9000\n",
      "Epoch 4586/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9597.8557 - reconstruction_loss: 9118.7930 - kl_loss: 385.3965\n",
      "Epoch 4587/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9579.5030 - reconstruction_loss: 9105.5020 - kl_loss: 385.4402\n",
      "Epoch 4588/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9547.3703 - reconstruction_loss: 9111.4678 - kl_loss: 384.6823\n",
      "Epoch 4589/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9572.0726 - reconstruction_loss: 9122.6338 - kl_loss: 386.6703\n",
      "Epoch 4590/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9570.1713 - reconstruction_loss: 9127.4268 - kl_loss: 386.4889\n",
      "Epoch 4591/5000\n",
      "75/75 [==============================] - 2s 31ms/step - loss: 9574.8073 - reconstruction_loss: 9136.8936 - kl_loss: 385.7798\n",
      "Epoch 4592/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9662.0065 - reconstruction_loss: 9196.2881 - kl_loss: 387.4318\n",
      "Epoch 4593/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9618.4263 - reconstruction_loss: 9132.5791 - kl_loss: 387.3174\n",
      "Epoch 4594/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9591.1132 - reconstruction_loss: 9113.2412 - kl_loss: 386.4458\n",
      "Epoch 4595/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9545.2400 - reconstruction_loss: 9089.3799 - kl_loss: 385.9585\n",
      "Epoch 4596/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9597.3332 - reconstruction_loss: 9124.0225 - kl_loss: 385.2491\n",
      "Epoch 4597/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9528.0724 - reconstruction_loss: 9074.9668 - kl_loss: 386.0845\n",
      "Epoch 4598/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9553.7153 - reconstruction_loss: 9073.5586 - kl_loss: 385.5936\n",
      "Epoch 4599/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9478.5694 - reconstruction_loss: 9027.7432 - kl_loss: 385.1431\n",
      "Epoch 4600/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9510.7406 - reconstruction_loss: 9041.8613 - kl_loss: 384.6263\n",
      "Epoch 4601/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9475.0920 - reconstruction_loss: 8997.2158 - kl_loss: 385.5943\n",
      "Epoch 4602/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9459.9667 - reconstruction_loss: 8991.5859 - kl_loss: 385.9981\n",
      "Epoch 4603/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9445.4040 - reconstruction_loss: 8974.1328 - kl_loss: 385.8287\n",
      "Epoch 4604/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9401.4189 - reconstruction_loss: 8951.1953 - kl_loss: 386.6308\n",
      "Epoch 4605/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9410.8013 - reconstruction_loss: 8944.4121 - kl_loss: 386.1167\n",
      "Epoch 4606/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9381.9693 - reconstruction_loss: 8933.2227 - kl_loss: 385.6202\n",
      "Epoch 4607/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9373.2414 - reconstruction_loss: 8925.6670 - kl_loss: 386.2735\n",
      "Epoch 4608/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9358.4502 - reconstruction_loss: 8912.0029 - kl_loss: 385.4533\n",
      "Epoch 4609/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9345.8959 - reconstruction_loss: 8905.9443 - kl_loss: 385.3417\n",
      "Epoch 4610/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9332.3274 - reconstruction_loss: 8884.3164 - kl_loss: 386.7334\n",
      "Epoch 4611/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9339.1465 - reconstruction_loss: 8899.9385 - kl_loss: 385.8358\n",
      "Epoch 4612/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9325.1773 - reconstruction_loss: 8885.8555 - kl_loss: 385.8500\n",
      "Epoch 4613/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9330.1249 - reconstruction_loss: 8873.9863 - kl_loss: 385.6319\n",
      "Epoch 4614/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9336.6188 - reconstruction_loss: 8883.0322 - kl_loss: 384.9919\n",
      "Epoch 4615/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9323.4684 - reconstruction_loss: 8869.0215 - kl_loss: 385.6826\n",
      "Epoch 4616/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9316.3242 - reconstruction_loss: 8864.4092 - kl_loss: 385.5807\n",
      "Epoch 4617/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9344.1650 - reconstruction_loss: 8897.6475 - kl_loss: 384.4637\n",
      "Epoch 4618/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9339.6238 - reconstruction_loss: 8877.4111 - kl_loss: 384.8389\n",
      "Epoch 4619/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9290.7909 - reconstruction_loss: 8851.7900 - kl_loss: 386.3073\n",
      "Epoch 4620/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9295.0201 - reconstruction_loss: 8853.3877 - kl_loss: 386.0100\n",
      "Epoch 4621/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9297.4013 - reconstruction_loss: 8854.4092 - kl_loss: 386.0930\n",
      "Epoch 4622/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9304.7485 - reconstruction_loss: 8873.4619 - kl_loss: 386.0467\n",
      "Epoch 4623/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9335.0541 - reconstruction_loss: 8880.4248 - kl_loss: 385.8747\n",
      "Epoch 4624/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9309.0529 - reconstruction_loss: 8872.9355 - kl_loss: 385.3024\n",
      "Epoch 4625/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9430.8146 - reconstruction_loss: 8985.4521 - kl_loss: 385.1398\n",
      "Epoch 4626/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9373.4600 - reconstruction_loss: 8918.2061 - kl_loss: 386.9346\n",
      "Epoch 4627/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9325.0398 - reconstruction_loss: 8867.8809 - kl_loss: 384.6454\n",
      "Epoch 4628/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9371.5666 - reconstruction_loss: 8911.9131 - kl_loss: 384.5891\n",
      "Epoch 4629/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9394.5358 - reconstruction_loss: 8925.4238 - kl_loss: 385.2534\n",
      "Epoch 4630/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9347.1669 - reconstruction_loss: 8892.6826 - kl_loss: 385.4773\n",
      "Epoch 4631/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9367.7712 - reconstruction_loss: 8903.1152 - kl_loss: 384.6139\n",
      "Epoch 4632/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9326.2389 - reconstruction_loss: 8888.3916 - kl_loss: 383.9127\n",
      "Epoch 4633/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9351.1096 - reconstruction_loss: 8903.0869 - kl_loss: 383.8658\n",
      "Epoch 4634/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9342.8476 - reconstruction_loss: 8905.7363 - kl_loss: 384.7915\n",
      "Epoch 4635/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9326.4968 - reconstruction_loss: 8891.7139 - kl_loss: 384.7607\n",
      "Epoch 4636/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9330.4686 - reconstruction_loss: 8897.4355 - kl_loss: 384.4565\n",
      "Epoch 4637/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9335.4356 - reconstruction_loss: 8907.9385 - kl_loss: 384.7819\n",
      "Epoch 4638/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9369.2019 - reconstruction_loss: 8923.9600 - kl_loss: 385.5316\n",
      "Epoch 4639/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9351.5346 - reconstruction_loss: 8918.7129 - kl_loss: 384.9158\n",
      "Epoch 4640/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9354.3159 - reconstruction_loss: 8916.5693 - kl_loss: 384.9085\n",
      "Epoch 4641/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9357.2035 - reconstruction_loss: 8929.2539 - kl_loss: 383.7584\n",
      "Epoch 4642/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9359.0342 - reconstruction_loss: 8944.4287 - kl_loss: 383.7571\n",
      "Epoch 4643/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9434.7583 - reconstruction_loss: 8998.7363 - kl_loss: 384.0359\n",
      "Epoch 4644/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 9446.8127 - reconstruction_loss: 9031.3770 - kl_loss: 383.3693\n",
      "Epoch 4645/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9623.2356 - reconstruction_loss: 9174.0303 - kl_loss: 384.4527\n",
      "Epoch 4646/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9498.8842 - reconstruction_loss: 9098.8154 - kl_loss: 384.1261\n",
      "Epoch 4647/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9561.1162 - reconstruction_loss: 9159.5781 - kl_loss: 384.0347\n",
      "Epoch 4648/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9563.4952 - reconstruction_loss: 9149.3760 - kl_loss: 384.5171\n",
      "Epoch 4649/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9528.4396 - reconstruction_loss: 9133.3438 - kl_loss: 384.0194\n",
      "Epoch 4650/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9541.2387 - reconstruction_loss: 9135.2607 - kl_loss: 385.1041\n",
      "Epoch 4651/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9590.1967 - reconstruction_loss: 9194.7295 - kl_loss: 385.0170\n",
      "Epoch 4652/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9646.3873 - reconstruction_loss: 9233.1787 - kl_loss: 385.3694\n",
      "Epoch 4653/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9686.6366 - reconstruction_loss: 9278.8828 - kl_loss: 384.9018\n",
      "Epoch 4654/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 9691.3172 - reconstruction_loss: 9273.4307 - kl_loss: 385.4089\n",
      "Epoch 4655/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9724.8553 - reconstruction_loss: 9295.9453 - kl_loss: 384.4030\n",
      "Epoch 4656/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9707.4849 - reconstruction_loss: 9295.6084 - kl_loss: 384.2201\n",
      "Epoch 4657/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9797.8292 - reconstruction_loss: 9380.4990 - kl_loss: 383.2856\n",
      "Epoch 4658/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9893.2235 - reconstruction_loss: 9475.5410 - kl_loss: 383.5398\n",
      "Epoch 4659/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9957.2570 - reconstruction_loss: 9533.6807 - kl_loss: 384.5429\n",
      "Epoch 4660/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10000.5105 - reconstruction_loss: 9575.2637 - kl_loss: 385.0785\n",
      "Epoch 4661/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9912.2777 - reconstruction_loss: 9468.3428 - kl_loss: 384.9755\n",
      "Epoch 4662/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9824.8868 - reconstruction_loss: 9375.8496 - kl_loss: 384.8431\n",
      "Epoch 4663/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9723.6026 - reconstruction_loss: 9306.9717 - kl_loss: 385.2534\n",
      "Epoch 4664/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9719.0323 - reconstruction_loss: 9301.4639 - kl_loss: 384.4861\n",
      "Epoch 4665/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9707.0298 - reconstruction_loss: 9300.8086 - kl_loss: 383.7947\n",
      "Epoch 4666/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9765.8192 - reconstruction_loss: 9334.1582 - kl_loss: 384.5063\n",
      "Epoch 4667/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9772.7587 - reconstruction_loss: 9367.8604 - kl_loss: 385.0157\n",
      "Epoch 4668/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9848.0895 - reconstruction_loss: 9443.9326 - kl_loss: 385.7617\n",
      "Epoch 4669/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9883.2796 - reconstruction_loss: 9476.6914 - kl_loss: 384.2858\n",
      "Epoch 4670/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9987.6024 - reconstruction_loss: 9577.5244 - kl_loss: 384.3713\n",
      "Epoch 4671/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10034.2898 - reconstruction_loss: 9624.9932 - kl_loss: 384.1897\n",
      "Epoch 4672/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10094.9726 - reconstruction_loss: 9660.3252 - kl_loss: 382.6101\n",
      "Epoch 4673/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10031.9211 - reconstruction_loss: 9633.2637 - kl_loss: 383.0681\n",
      "Epoch 4674/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10197.2701 - reconstruction_loss: 9745.3076 - kl_loss: 382.9140\n",
      "Epoch 4675/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10229.0954 - reconstruction_loss: 9846.6436 - kl_loss: 384.5034\n",
      "Epoch 4676/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10575.5949 - reconstruction_loss: 10133.4824 - kl_loss: 383.7400\n",
      "Epoch 4677/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10745.4777 - reconstruction_loss: 10331.6484 - kl_loss: 383.1200\n",
      "Epoch 4678/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10719.3742 - reconstruction_loss: 10230.1924 - kl_loss: 383.9448\n",
      "Epoch 4679/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 10379.0378 - reconstruction_loss: 9892.6797 - kl_loss: 384.7786\n",
      "Epoch 4680/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 10111.1027 - reconstruction_loss: 9694.2002 - kl_loss: 384.9200\n",
      "Epoch 4681/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9994.8726 - reconstruction_loss: 9556.0889 - kl_loss: 385.4251\n",
      "Epoch 4682/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9878.4433 - reconstruction_loss: 9454.9180 - kl_loss: 386.6173\n",
      "Epoch 4683/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9804.1907 - reconstruction_loss: 9398.7354 - kl_loss: 386.0303\n",
      "Epoch 4684/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9757.6589 - reconstruction_loss: 9349.6953 - kl_loss: 384.8210\n",
      "Epoch 4685/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9709.7098 - reconstruction_loss: 9307.8652 - kl_loss: 384.4828\n",
      "Epoch 4686/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9702.6441 - reconstruction_loss: 9294.4062 - kl_loss: 384.9612\n",
      "Epoch 4687/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9699.5262 - reconstruction_loss: 9265.0840 - kl_loss: 385.8023\n",
      "Epoch 4688/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9647.6236 - reconstruction_loss: 9230.4932 - kl_loss: 386.0535\n",
      "Epoch 4689/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9634.4031 - reconstruction_loss: 9209.7344 - kl_loss: 385.1794\n",
      "Epoch 4690/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9608.4628 - reconstruction_loss: 9184.5469 - kl_loss: 384.6019\n",
      "Epoch 4691/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9581.3851 - reconstruction_loss: 9163.5332 - kl_loss: 385.4065\n",
      "Epoch 4692/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9582.4218 - reconstruction_loss: 9159.7539 - kl_loss: 385.7235\n",
      "Epoch 4693/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9575.6175 - reconstruction_loss: 9142.6191 - kl_loss: 386.6827\n",
      "Epoch 4694/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9538.5058 - reconstruction_loss: 9116.2256 - kl_loss: 385.9619\n",
      "Epoch 4695/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9530.9458 - reconstruction_loss: 9099.3535 - kl_loss: 385.8034\n",
      "Epoch 4696/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9519.0306 - reconstruction_loss: 9087.4150 - kl_loss: 385.4870\n",
      "Epoch 4697/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9527.8477 - reconstruction_loss: 9102.6748 - kl_loss: 386.2965\n",
      "Epoch 4698/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9502.5281 - reconstruction_loss: 9063.3965 - kl_loss: 386.0475\n",
      "Epoch 4699/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9488.1204 - reconstruction_loss: 9051.9727 - kl_loss: 385.9500\n",
      "Epoch 4700/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9453.2191 - reconstruction_loss: 9018.2021 - kl_loss: 386.4525\n",
      "Epoch 4701/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9425.9057 - reconstruction_loss: 8992.4014 - kl_loss: 385.7237\n",
      "Epoch 4702/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 9436.6646 - reconstruction_loss: 8984.6738 - kl_loss: 385.1465\n",
      "Epoch 4703/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 9407.0317 - reconstruction_loss: 8976.4570 - kl_loss: 385.0540\n",
      "Epoch 4704/5000\n",
      "75/75 [==============================] - 2s 28ms/step - loss: 9403.9952 - reconstruction_loss: 8962.7305 - kl_loss: 385.0902\n",
      "Epoch 4705/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 9387.2145 - reconstruction_loss: 8949.3818 - kl_loss: 384.7781\n",
      "Epoch 4706/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 9416.7297 - reconstruction_loss: 8973.1016 - kl_loss: 385.2942\n",
      "Epoch 4707/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 9359.8756 - reconstruction_loss: 8920.7119 - kl_loss: 385.8820\n",
      "Epoch 4708/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9372.9497 - reconstruction_loss: 8927.6465 - kl_loss: 386.1349\n",
      "Epoch 4709/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9399.1873 - reconstruction_loss: 8930.2900 - kl_loss: 385.8971\n",
      "Epoch 4710/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9311.5675 - reconstruction_loss: 8877.3857 - kl_loss: 385.6961\n",
      "Epoch 4711/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9360.3626 - reconstruction_loss: 8902.7285 - kl_loss: 386.2512\n",
      "Epoch 4712/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9317.2482 - reconstruction_loss: 8868.2812 - kl_loss: 386.4706\n",
      "Epoch 4713/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9319.1745 - reconstruction_loss: 8871.3535 - kl_loss: 386.3677\n",
      "Epoch 4714/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9307.8817 - reconstruction_loss: 8846.9395 - kl_loss: 386.1313\n",
      "Epoch 4715/5000\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 9272.3945 - reconstruction_loss: 8833.0215 - kl_loss: 386.4360\n",
      "Epoch 4716/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9330.1903 - reconstruction_loss: 8878.7803 - kl_loss: 386.4062\n",
      "Epoch 4717/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9260.9904 - reconstruction_loss: 8819.0918 - kl_loss: 386.1602\n",
      "Epoch 4718/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9278.0245 - reconstruction_loss: 8817.0273 - kl_loss: 386.4603\n",
      "Epoch 4719/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9258.4836 - reconstruction_loss: 8800.1660 - kl_loss: 386.1730\n",
      "Epoch 4720/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9240.3370 - reconstruction_loss: 8794.5459 - kl_loss: 385.9318\n",
      "Epoch 4721/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9287.8541 - reconstruction_loss: 8828.1445 - kl_loss: 385.7146\n",
      "Epoch 4722/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9222.9603 - reconstruction_loss: 8782.5381 - kl_loss: 385.3307\n",
      "Epoch 4723/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 9235.1394 - reconstruction_loss: 8776.7852 - kl_loss: 385.0397\n",
      "Epoch 4724/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9225.5444 - reconstruction_loss: 8773.5508 - kl_loss: 385.4364\n",
      "Epoch 4725/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9194.4927 - reconstruction_loss: 8754.6562 - kl_loss: 385.8733\n",
      "Epoch 4726/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 9205.3766 - reconstruction_loss: 8753.0596 - kl_loss: 384.7321\n",
      "Epoch 4727/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9205.3517 - reconstruction_loss: 8750.2832 - kl_loss: 384.5264\n",
      "Epoch 4728/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 9208.2821 - reconstruction_loss: 8750.1084 - kl_loss: 385.3312\n",
      "Epoch 4729/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 9179.6484 - reconstruction_loss: 8736.6748 - kl_loss: 385.3842\n",
      "Epoch 4730/5000\n",
      "75/75 [==============================] - 2s 25ms/step - loss: 9232.7238 - reconstruction_loss: 8770.6172 - kl_loss: 384.8895\n",
      "Epoch 4731/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9179.3884 - reconstruction_loss: 8725.9043 - kl_loss: 385.0740\n",
      "Epoch 4732/5000\n",
      "75/75 [==============================] - 2s 24ms/step - loss: 9180.3150 - reconstruction_loss: 8720.5615 - kl_loss: 384.7804\n",
      "Epoch 4733/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9162.9238 - reconstruction_loss: 8713.8652 - kl_loss: 385.4117\n",
      "Epoch 4734/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9139.7557 - reconstruction_loss: 8699.7363 - kl_loss: 384.8492\n",
      "Epoch 4735/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9174.1609 - reconstruction_loss: 8726.1816 - kl_loss: 385.1317\n",
      "Epoch 4736/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9166.8283 - reconstruction_loss: 8714.9814 - kl_loss: 385.4566\n",
      "Epoch 4737/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9184.4119 - reconstruction_loss: 8727.6309 - kl_loss: 385.0107\n",
      "Epoch 4738/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9181.7318 - reconstruction_loss: 8717.8115 - kl_loss: 384.3120\n",
      "Epoch 4739/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9187.1637 - reconstruction_loss: 8730.0127 - kl_loss: 386.4593\n",
      "Epoch 4740/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9243.2589 - reconstruction_loss: 8762.3467 - kl_loss: 386.5422\n",
      "Epoch 4741/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9202.3143 - reconstruction_loss: 8720.6934 - kl_loss: 384.6822\n",
      "Epoch 4742/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9224.3152 - reconstruction_loss: 8767.2930 - kl_loss: 384.6068\n",
      "Epoch 4743/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9224.1844 - reconstruction_loss: 8733.9102 - kl_loss: 384.8563\n",
      "Epoch 4744/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9139.5739 - reconstruction_loss: 8688.0488 - kl_loss: 384.5936\n",
      "Epoch 4745/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9208.8990 - reconstruction_loss: 8732.8301 - kl_loss: 386.1902\n",
      "Epoch 4746/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9176.4136 - reconstruction_loss: 8715.1055 - kl_loss: 385.5287\n",
      "Epoch 4747/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9144.0655 - reconstruction_loss: 8689.2402 - kl_loss: 384.2663\n",
      "Epoch 4748/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9134.9585 - reconstruction_loss: 8677.8223 - kl_loss: 384.6631\n",
      "Epoch 4749/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9113.2731 - reconstruction_loss: 8678.6494 - kl_loss: 384.2940\n",
      "Epoch 4750/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9165.9087 - reconstruction_loss: 8704.2881 - kl_loss: 383.2052\n",
      "Epoch 4751/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9098.3901 - reconstruction_loss: 8647.7930 - kl_loss: 384.8836\n",
      "Epoch 4752/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9113.3393 - reconstruction_loss: 8662.0674 - kl_loss: 384.0160\n",
      "Epoch 4753/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9111.9427 - reconstruction_loss: 8657.4580 - kl_loss: 384.2589\n",
      "Epoch 4754/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9101.1970 - reconstruction_loss: 8656.8877 - kl_loss: 384.1979\n",
      "Epoch 4755/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9106.2200 - reconstruction_loss: 8649.7227 - kl_loss: 383.6320\n",
      "Epoch 4756/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9101.2780 - reconstruction_loss: 8650.4395 - kl_loss: 384.6058\n",
      "Epoch 4757/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9108.2162 - reconstruction_loss: 8638.7637 - kl_loss: 384.4548\n",
      "Epoch 4758/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9093.3182 - reconstruction_loss: 8650.6367 - kl_loss: 383.3057\n",
      "Epoch 4759/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9108.0799 - reconstruction_loss: 8646.8320 - kl_loss: 385.0168\n",
      "Epoch 4760/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 9114.3621 - reconstruction_loss: 8662.3857 - kl_loss: 384.2496\n",
      "Epoch 4761/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 9092.5666 - reconstruction_loss: 8651.2412 - kl_loss: 383.1270\n",
      "Epoch 4762/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 9127.4597 - reconstruction_loss: 8666.5459 - kl_loss: 383.7760\n",
      "Epoch 4763/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9076.1689 - reconstruction_loss: 8629.5430 - kl_loss: 384.2832\n",
      "Epoch 4764/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9180.8809 - reconstruction_loss: 8712.7490 - kl_loss: 384.6002\n",
      "Epoch 4765/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9161.7598 - reconstruction_loss: 8675.9277 - kl_loss: 383.7110\n",
      "Epoch 4766/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9162.1907 - reconstruction_loss: 8694.5820 - kl_loss: 384.2990\n",
      "Epoch 4767/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9204.5802 - reconstruction_loss: 8692.8525 - kl_loss: 383.8875\n",
      "Epoch 4768/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9072.3855 - reconstruction_loss: 8632.5859 - kl_loss: 383.5283\n",
      "Epoch 4769/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 9115.5553 - reconstruction_loss: 8674.1582 - kl_loss: 384.0467\n",
      "Epoch 4770/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9108.6048 - reconstruction_loss: 8659.9551 - kl_loss: 383.4302\n",
      "Epoch 4771/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9126.0811 - reconstruction_loss: 8679.0303 - kl_loss: 382.3467\n",
      "Epoch 4772/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9125.5539 - reconstruction_loss: 8651.6338 - kl_loss: 382.7685\n",
      "Epoch 4773/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9057.6868 - reconstruction_loss: 8614.6143 - kl_loss: 383.3506\n",
      "Epoch 4774/5000\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 9167.8843 - reconstruction_loss: 8702.3037 - kl_loss: 383.2366\n",
      "Epoch 4775/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 9160.1906 - reconstruction_loss: 8696.1133 - kl_loss: 383.8173\n",
      "Epoch 4776/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9132.9788 - reconstruction_loss: 8661.8359 - kl_loss: 384.0944\n",
      "Epoch 4777/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9086.7325 - reconstruction_loss: 8643.9854 - kl_loss: 385.8152\n",
      "Epoch 4778/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9209.1808 - reconstruction_loss: 8695.8330 - kl_loss: 383.4429\n",
      "Epoch 4779/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9096.2838 - reconstruction_loss: 8652.2910 - kl_loss: 383.3153\n",
      "Epoch 4780/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9155.7851 - reconstruction_loss: 8676.2891 - kl_loss: 383.5922\n",
      "Epoch 4781/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9062.2793 - reconstruction_loss: 8615.2021 - kl_loss: 383.4627\n",
      "Epoch 4782/5000\n",
      "75/75 [==============================] - 2s 23ms/step - loss: 9097.0880 - reconstruction_loss: 8653.1572 - kl_loss: 383.0915\n",
      "Epoch 4783/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9077.3933 - reconstruction_loss: 8625.8838 - kl_loss: 382.4081\n",
      "Epoch 4784/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9085.3552 - reconstruction_loss: 8627.2178 - kl_loss: 382.1664\n",
      "Epoch 4785/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9091.0046 - reconstruction_loss: 8632.1338 - kl_loss: 382.2830\n",
      "Epoch 4786/5000\n",
      "75/75 [==============================] - 1s 19ms/step - loss: 9064.3722 - reconstruction_loss: 8619.8301 - kl_loss: 382.6668\n",
      "Epoch 4787/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9069.8898 - reconstruction_loss: 8626.8301 - kl_loss: 382.1527\n",
      "Epoch 4788/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9119.3144 - reconstruction_loss: 8663.5391 - kl_loss: 382.5015\n",
      "Epoch 4789/5000\n",
      "75/75 [==============================] - 2s 21ms/step - loss: 9088.3546 - reconstruction_loss: 8641.4883 - kl_loss: 382.6172\n",
      "Epoch 4790/5000\n",
      "75/75 [==============================] - 2s 19ms/step - loss: 9070.3190 - reconstruction_loss: 8607.8428 - kl_loss: 382.4509\n",
      "Epoch 4791/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9046.0555 - reconstruction_loss: 8595.8105 - kl_loss: 381.9615\n",
      "Epoch 4792/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9076.4883 - reconstruction_loss: 8631.6650 - kl_loss: 382.0844\n",
      "Epoch 4793/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9099.0875 - reconstruction_loss: 8645.0107 - kl_loss: 381.8611\n",
      "Epoch 4794/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9041.7237 - reconstruction_loss: 8599.9707 - kl_loss: 381.8904\n",
      "Epoch 4795/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9037.3424 - reconstruction_loss: 8592.9355 - kl_loss: 381.1805\n",
      "Epoch 4796/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9085.7236 - reconstruction_loss: 8624.4502 - kl_loss: 381.9125\n",
      "Epoch 4797/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9074.1857 - reconstruction_loss: 8622.8477 - kl_loss: 382.4896\n",
      "Epoch 4798/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9036.6771 - reconstruction_loss: 8590.1602 - kl_loss: 382.6624\n",
      "Epoch 4799/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9050.1251 - reconstruction_loss: 8614.9600 - kl_loss: 381.7840\n",
      "Epoch 4800/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9082.4916 - reconstruction_loss: 8631.9570 - kl_loss: 381.5280\n",
      "Epoch 4801/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9058.7291 - reconstruction_loss: 8610.4023 - kl_loss: 381.4511\n",
      "Epoch 4802/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9098.4218 - reconstruction_loss: 8649.6016 - kl_loss: 380.9362\n",
      "Epoch 4803/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9161.8478 - reconstruction_loss: 8695.7686 - kl_loss: 381.5005\n",
      "Epoch 4804/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9157.4889 - reconstruction_loss: 8689.7656 - kl_loss: 382.3868\n",
      "Epoch 4805/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9219.6675 - reconstruction_loss: 8709.6582 - kl_loss: 380.8783\n",
      "Epoch 4806/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9070.6330 - reconstruction_loss: 8618.4326 - kl_loss: 380.7941\n",
      "Epoch 4807/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9146.9418 - reconstruction_loss: 8674.5859 - kl_loss: 381.7281\n",
      "Epoch 4808/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9124.7040 - reconstruction_loss: 8642.0947 - kl_loss: 380.5040\n",
      "Epoch 4809/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9092.1873 - reconstruction_loss: 8636.5449 - kl_loss: 380.2395\n",
      "Epoch 4810/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9103.0769 - reconstruction_loss: 8632.3115 - kl_loss: 380.5535\n",
      "Epoch 4811/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9072.8152 - reconstruction_loss: 8622.0400 - kl_loss: 380.2289\n",
      "Epoch 4812/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 9063.5005 - reconstruction_loss: 8616.8174 - kl_loss: 381.0959\n",
      "Epoch 4813/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9040.7907 - reconstruction_loss: 8596.3848 - kl_loss: 382.2342\n",
      "Epoch 4814/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9036.1422 - reconstruction_loss: 8587.1846 - kl_loss: 381.6501\n",
      "Epoch 4815/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9067.3506 - reconstruction_loss: 8616.7373 - kl_loss: 381.4744\n",
      "Epoch 4816/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9111.0641 - reconstruction_loss: 8660.1689 - kl_loss: 382.1383\n",
      "Epoch 4817/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9110.0902 - reconstruction_loss: 8638.1211 - kl_loss: 381.1805\n",
      "Epoch 4818/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9075.1518 - reconstruction_loss: 8614.6982 - kl_loss: 381.1302\n",
      "Epoch 4819/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9063.6798 - reconstruction_loss: 8621.1895 - kl_loss: 380.9678\n",
      "Epoch 4820/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9075.5604 - reconstruction_loss: 8622.9453 - kl_loss: 381.3326\n",
      "Epoch 4821/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9109.9169 - reconstruction_loss: 8634.0557 - kl_loss: 380.9336\n",
      "Epoch 4822/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9098.2156 - reconstruction_loss: 8666.7285 - kl_loss: 379.5265\n",
      "Epoch 4823/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9148.7405 - reconstruction_loss: 8675.9199 - kl_loss: 381.3945\n",
      "Epoch 4824/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9268.8463 - reconstruction_loss: 8764.4062 - kl_loss: 382.4178\n",
      "Epoch 4825/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9233.3476 - reconstruction_loss: 8783.6816 - kl_loss: 379.8010\n",
      "Epoch 4826/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9256.0011 - reconstruction_loss: 8841.8184 - kl_loss: 378.2881\n",
      "Epoch 4827/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9303.4789 - reconstruction_loss: 8832.6914 - kl_loss: 379.7844\n",
      "Epoch 4828/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9180.7261 - reconstruction_loss: 8740.5391 - kl_loss: 380.4827\n",
      "Epoch 4829/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9170.6569 - reconstruction_loss: 8719.9277 - kl_loss: 380.1014\n",
      "Epoch 4830/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9153.8756 - reconstruction_loss: 8698.3682 - kl_loss: 379.5947\n",
      "Epoch 4831/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9122.9378 - reconstruction_loss: 8699.4141 - kl_loss: 381.0280\n",
      "Epoch 4832/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9129.3696 - reconstruction_loss: 8684.2344 - kl_loss: 380.2790\n",
      "Epoch 4833/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9073.5783 - reconstruction_loss: 8640.5898 - kl_loss: 379.8312\n",
      "Epoch 4834/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9105.3250 - reconstruction_loss: 8659.8828 - kl_loss: 380.3174\n",
      "Epoch 4835/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9143.1509 - reconstruction_loss: 8670.5693 - kl_loss: 380.4079\n",
      "Epoch 4836/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9080.0219 - reconstruction_loss: 8654.2734 - kl_loss: 380.4500\n",
      "Epoch 4837/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9129.7404 - reconstruction_loss: 8656.9863 - kl_loss: 380.5951\n",
      "Epoch 4838/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9054.8763 - reconstruction_loss: 8622.0654 - kl_loss: 378.8215\n",
      "Epoch 4839/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9082.5998 - reconstruction_loss: 8650.7852 - kl_loss: 380.5391\n",
      "Epoch 4840/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9087.9346 - reconstruction_loss: 8619.0195 - kl_loss: 381.1575\n",
      "Epoch 4841/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9031.2842 - reconstruction_loss: 8595.8760 - kl_loss: 379.9086\n",
      "Epoch 4842/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9040.4557 - reconstruction_loss: 8596.9268 - kl_loss: 379.9880\n",
      "Epoch 4843/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9031.7084 - reconstruction_loss: 8600.7979 - kl_loss: 379.3479\n",
      "Epoch 4844/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9042.4175 - reconstruction_loss: 8609.8359 - kl_loss: 379.2884\n",
      "Epoch 4845/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9046.7272 - reconstruction_loss: 8585.4053 - kl_loss: 379.4999\n",
      "Epoch 4846/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9023.8096 - reconstruction_loss: 8582.9404 - kl_loss: 379.3284\n",
      "Epoch 4847/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9011.2783 - reconstruction_loss: 8569.0645 - kl_loss: 379.7876\n",
      "Epoch 4848/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9002.4399 - reconstruction_loss: 8568.0332 - kl_loss: 380.0332\n",
      "Epoch 4849/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9056.3869 - reconstruction_loss: 8602.8467 - kl_loss: 380.2980\n",
      "Epoch 4850/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9050.2212 - reconstruction_loss: 8593.5205 - kl_loss: 379.9675\n",
      "Epoch 4851/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9019.1647 - reconstruction_loss: 8573.3984 - kl_loss: 379.3799\n",
      "Epoch 4852/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9048.5241 - reconstruction_loss: 8596.0391 - kl_loss: 379.0344\n",
      "Epoch 4853/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 8993.3533 - reconstruction_loss: 8557.2959 - kl_loss: 379.8358\n",
      "Epoch 4854/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9034.5362 - reconstruction_loss: 8584.2695 - kl_loss: 380.0026\n",
      "Epoch 4855/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9118.6254 - reconstruction_loss: 8634.0342 - kl_loss: 380.6957\n",
      "Epoch 4856/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9029.7898 - reconstruction_loss: 8581.5078 - kl_loss: 379.5948\n",
      "Epoch 4857/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9040.1344 - reconstruction_loss: 8573.9531 - kl_loss: 379.2233\n",
      "Epoch 4858/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 8987.6177 - reconstruction_loss: 8543.0850 - kl_loss: 379.0395\n",
      "Epoch 4859/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9006.1083 - reconstruction_loss: 8558.8477 - kl_loss: 379.4072\n",
      "Epoch 4860/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9003.1714 - reconstruction_loss: 8550.1230 - kl_loss: 379.1063\n",
      "Epoch 4861/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 8990.4533 - reconstruction_loss: 8554.5557 - kl_loss: 378.9946\n",
      "Epoch 4862/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9018.3688 - reconstruction_loss: 8567.9619 - kl_loss: 378.9402\n",
      "Epoch 4863/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 8965.7697 - reconstruction_loss: 8525.5264 - kl_loss: 378.7291\n",
      "Epoch 4864/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 8977.0873 - reconstruction_loss: 8541.9268 - kl_loss: 379.0039\n",
      "Epoch 4865/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9009.0244 - reconstruction_loss: 8571.4785 - kl_loss: 378.7056\n",
      "Epoch 4866/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 8984.2200 - reconstruction_loss: 8542.2295 - kl_loss: 378.8606\n",
      "Epoch 4867/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9005.5313 - reconstruction_loss: 8551.7256 - kl_loss: 378.4462\n",
      "Epoch 4868/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 8975.2400 - reconstruction_loss: 8533.0889 - kl_loss: 378.9619\n",
      "Epoch 4869/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9003.1230 - reconstruction_loss: 8563.4014 - kl_loss: 378.6906\n",
      "Epoch 4870/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9038.1577 - reconstruction_loss: 8589.9160 - kl_loss: 378.6945\n",
      "Epoch 4871/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 8984.4800 - reconstruction_loss: 8546.2910 - kl_loss: 378.5443\n",
      "Epoch 4872/5000\n",
      "75/75 [==============================] - 2s 22ms/step - loss: 9024.7947 - reconstruction_loss: 8573.1162 - kl_loss: 378.5997\n",
      "Epoch 4873/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9003.5812 - reconstruction_loss: 8559.0254 - kl_loss: 379.1802\n",
      "Epoch 4874/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 8989.5192 - reconstruction_loss: 8553.4941 - kl_loss: 379.1850\n",
      "Epoch 4875/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9034.7023 - reconstruction_loss: 8576.0322 - kl_loss: 378.1336\n",
      "Epoch 4876/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9013.3165 - reconstruction_loss: 8553.4062 - kl_loss: 377.8182\n",
      "Epoch 4877/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9028.9868 - reconstruction_loss: 8580.1064 - kl_loss: 378.2115\n",
      "Epoch 4878/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9086.9649 - reconstruction_loss: 8593.7725 - kl_loss: 379.1737\n",
      "Epoch 4879/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9015.1755 - reconstruction_loss: 8560.1807 - kl_loss: 378.1520\n",
      "Epoch 4880/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9038.3772 - reconstruction_loss: 8569.1045 - kl_loss: 378.3268\n",
      "Epoch 4881/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9038.6859 - reconstruction_loss: 8587.0576 - kl_loss: 378.0937\n",
      "Epoch 4882/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9087.8471 - reconstruction_loss: 8642.0967 - kl_loss: 377.6047\n",
      "Epoch 4883/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9023.0518 - reconstruction_loss: 8571.5117 - kl_loss: 378.2416\n",
      "Epoch 4884/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9041.1778 - reconstruction_loss: 8594.1963 - kl_loss: 377.4550\n",
      "Epoch 4885/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9045.1075 - reconstruction_loss: 8594.3379 - kl_loss: 377.7056\n",
      "Epoch 4886/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9061.7552 - reconstruction_loss: 8617.1016 - kl_loss: 378.5141\n",
      "Epoch 4887/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9107.9681 - reconstruction_loss: 8647.1045 - kl_loss: 378.1629\n",
      "Epoch 4888/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9148.6572 - reconstruction_loss: 8681.8916 - kl_loss: 378.5240\n",
      "Epoch 4889/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9196.8822 - reconstruction_loss: 8713.0410 - kl_loss: 378.6410\n",
      "Epoch 4890/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9218.3411 - reconstruction_loss: 8763.8516 - kl_loss: 377.6819\n",
      "Epoch 4891/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9194.7804 - reconstruction_loss: 8806.8105 - kl_loss: 376.8226\n",
      "Epoch 4892/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9394.6296 - reconstruction_loss: 8889.4014 - kl_loss: 377.1069\n",
      "Epoch 4893/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9449.1199 - reconstruction_loss: 8919.4326 - kl_loss: 377.9254\n",
      "Epoch 4894/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9421.4904 - reconstruction_loss: 8935.0439 - kl_loss: 377.2941\n",
      "Epoch 4895/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9351.4100 - reconstruction_loss: 8907.9668 - kl_loss: 376.9724\n",
      "Epoch 4896/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9287.4474 - reconstruction_loss: 8850.1699 - kl_loss: 377.0388\n",
      "Epoch 4897/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9266.9570 - reconstruction_loss: 8829.5049 - kl_loss: 378.5398\n",
      "Epoch 4898/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9207.4188 - reconstruction_loss: 8767.7236 - kl_loss: 378.1597\n",
      "Epoch 4899/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9188.8982 - reconstruction_loss: 8764.4434 - kl_loss: 376.6810\n",
      "Epoch 4900/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9176.8153 - reconstruction_loss: 8745.4434 - kl_loss: 377.1981\n",
      "Epoch 4901/5000\n",
      "75/75 [==============================] - 1s 18ms/step - loss: 9161.9800 - reconstruction_loss: 8736.7422 - kl_loss: 377.8672\n",
      "Epoch 4902/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9164.9356 - reconstruction_loss: 8733.8057 - kl_loss: 378.5019\n",
      "Epoch 4903/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9190.3276 - reconstruction_loss: 8745.6738 - kl_loss: 377.3203\n",
      "Epoch 4904/5000\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 9164.3384 - reconstruction_loss: 8730.2432 - kl_loss: 377.7230\n",
      "Epoch 4905/5000\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 9149.6082 - reconstruction_loss: 8711.7051 - kl_loss: 377.3625\n",
      "Epoch 4906/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9171.1943 - reconstruction_loss: 8735.9062 - kl_loss: 377.7130\n",
      "Epoch 4907/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9180.8999 - reconstruction_loss: 8734.9775 - kl_loss: 377.2777\n",
      "Epoch 4908/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9160.3840 - reconstruction_loss: 8727.9912 - kl_loss: 377.4843\n",
      "Epoch 4909/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9197.8111 - reconstruction_loss: 8739.4414 - kl_loss: 377.3186\n",
      "Epoch 4910/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9167.2173 - reconstruction_loss: 8731.8457 - kl_loss: 376.9366\n",
      "Epoch 4911/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9144.6436 - reconstruction_loss: 8713.6670 - kl_loss: 376.8949\n",
      "Epoch 4912/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9140.7045 - reconstruction_loss: 8705.8115 - kl_loss: 376.4486\n",
      "Epoch 4913/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9138.8254 - reconstruction_loss: 8715.2012 - kl_loss: 376.8102\n",
      "Epoch 4914/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9158.3621 - reconstruction_loss: 8719.8594 - kl_loss: 377.4489\n",
      "Epoch 4915/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9131.5295 - reconstruction_loss: 8697.9336 - kl_loss: 377.8388\n",
      "Epoch 4916/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9125.9713 - reconstruction_loss: 8695.9541 - kl_loss: 376.6021\n",
      "Epoch 4917/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9134.5372 - reconstruction_loss: 8696.3604 - kl_loss: 377.2655\n",
      "Epoch 4918/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9089.6630 - reconstruction_loss: 8669.8330 - kl_loss: 376.5164\n",
      "Epoch 4919/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9142.4372 - reconstruction_loss: 8703.4648 - kl_loss: 377.2907\n",
      "Epoch 4920/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9091.2492 - reconstruction_loss: 8668.1826 - kl_loss: 377.4116\n",
      "Epoch 4921/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9108.4608 - reconstruction_loss: 8667.0342 - kl_loss: 377.2768\n",
      "Epoch 4922/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9088.6378 - reconstruction_loss: 8671.6064 - kl_loss: 377.8152\n",
      "Epoch 4923/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9078.0381 - reconstruction_loss: 8640.5967 - kl_loss: 377.2662\n",
      "Epoch 4924/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9077.2554 - reconstruction_loss: 8650.9346 - kl_loss: 376.6143\n",
      "Epoch 4925/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9059.3294 - reconstruction_loss: 8636.8008 - kl_loss: 376.4880\n",
      "Epoch 4926/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9074.4561 - reconstruction_loss: 8634.7256 - kl_loss: 376.9365\n",
      "Epoch 4927/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9045.0687 - reconstruction_loss: 8628.2686 - kl_loss: 377.4109\n",
      "Epoch 4928/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9068.1301 - reconstruction_loss: 8644.2344 - kl_loss: 377.4389\n",
      "Epoch 4929/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9074.2716 - reconstruction_loss: 8640.9990 - kl_loss: 377.2496\n",
      "Epoch 4930/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9053.0019 - reconstruction_loss: 8625.1270 - kl_loss: 377.4081\n",
      "Epoch 4931/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9055.4486 - reconstruction_loss: 8613.2012 - kl_loss: 377.8750\n",
      "Epoch 4932/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9033.6424 - reconstruction_loss: 8607.1650 - kl_loss: 377.1211\n",
      "Epoch 4933/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9103.8360 - reconstruction_loss: 8659.8389 - kl_loss: 376.8933\n",
      "Epoch 4934/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9064.9874 - reconstruction_loss: 8627.9072 - kl_loss: 376.3853\n",
      "Epoch 4935/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9052.9197 - reconstruction_loss: 8618.4150 - kl_loss: 376.7665\n",
      "Epoch 4936/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9055.5577 - reconstruction_loss: 8627.1162 - kl_loss: 376.6059\n",
      "Epoch 4937/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 9036.1889 - reconstruction_loss: 8605.6846 - kl_loss: 377.3044\n",
      "Epoch 4938/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9071.1625 - reconstruction_loss: 8627.5986 - kl_loss: 376.8097\n",
      "Epoch 4939/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9081.1461 - reconstruction_loss: 8663.6699 - kl_loss: 377.3453\n",
      "Epoch 4940/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9063.6472 - reconstruction_loss: 8617.6250 - kl_loss: 378.1458\n",
      "Epoch 4941/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9039.6815 - reconstruction_loss: 8596.5469 - kl_loss: 377.3259\n",
      "Epoch 4942/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9041.7677 - reconstruction_loss: 8608.6084 - kl_loss: 377.0249\n",
      "Epoch 4943/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9017.3370 - reconstruction_loss: 8579.3926 - kl_loss: 376.5428\n",
      "Epoch 4944/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9013.4141 - reconstruction_loss: 8583.0596 - kl_loss: 375.7954\n",
      "Epoch 4945/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9039.2020 - reconstruction_loss: 8597.2773 - kl_loss: 376.8494\n",
      "Epoch 4946/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9025.4122 - reconstruction_loss: 8606.0732 - kl_loss: 377.0381\n",
      "Epoch 4947/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9027.8319 - reconstruction_loss: 8582.8975 - kl_loss: 376.1862\n",
      "Epoch 4948/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 8984.7387 - reconstruction_loss: 8558.7227 - kl_loss: 375.9078\n",
      "Epoch 4949/5000\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 8990.8935 - reconstruction_loss: 8562.6338 - kl_loss: 375.7087\n",
      "Epoch 4950/5000\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 8989.5366 - reconstruction_loss: 8558.8672 - kl_loss: 376.9206\n",
      "Epoch 4951/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9021.1274 - reconstruction_loss: 8585.0430 - kl_loss: 376.0718\n",
      "Epoch 4952/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9086.3917 - reconstruction_loss: 8619.0039 - kl_loss: 375.8104\n",
      "Epoch 4953/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9067.6745 - reconstruction_loss: 8598.1143 - kl_loss: 376.1935\n",
      "Epoch 4954/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9005.5030 - reconstruction_loss: 8598.3535 - kl_loss: 376.6295\n",
      "Epoch 4955/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9014.6883 - reconstruction_loss: 8572.4951 - kl_loss: 376.4763\n",
      "Epoch 4956/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9012.8765 - reconstruction_loss: 8568.7695 - kl_loss: 376.1710\n",
      "Epoch 4957/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9059.0697 - reconstruction_loss: 8623.7490 - kl_loss: 376.6359\n",
      "Epoch 4958/5000\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 9063.7080 - reconstruction_loss: 8590.8311 - kl_loss: 376.8359\n",
      "Epoch 4959/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9008.5573 - reconstruction_loss: 8586.2910 - kl_loss: 376.1038\n",
      "Epoch 4960/5000\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 9074.8422 - reconstruction_loss: 8627.9795 - kl_loss: 375.9947\n",
      "Epoch 4961/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9075.9455 - reconstruction_loss: 8609.1318 - kl_loss: 376.0875\n",
      "Epoch 4962/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9031.3651 - reconstruction_loss: 8575.6445 - kl_loss: 376.0430\n",
      "Epoch 4963/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 8997.1060 - reconstruction_loss: 8567.5078 - kl_loss: 374.7303\n",
      "Epoch 4964/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9054.8675 - reconstruction_loss: 8603.5615 - kl_loss: 377.1679\n",
      "Epoch 4965/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9030.2990 - reconstruction_loss: 8596.9922 - kl_loss: 375.4360\n",
      "Epoch 4966/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9002.4446 - reconstruction_loss: 8579.0928 - kl_loss: 376.0397\n",
      "Epoch 4967/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9043.8917 - reconstruction_loss: 8599.7490 - kl_loss: 375.5042\n",
      "Epoch 4968/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9025.8510 - reconstruction_loss: 8583.8516 - kl_loss: 376.3435\n",
      "Epoch 4969/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9037.8356 - reconstruction_loss: 8620.8164 - kl_loss: 376.2555\n",
      "Epoch 4970/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9048.7811 - reconstruction_loss: 8605.0869 - kl_loss: 376.3385\n",
      "Epoch 4971/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9044.0405 - reconstruction_loss: 8594.5361 - kl_loss: 375.1123\n",
      "Epoch 4972/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9036.1543 - reconstruction_loss: 8592.1982 - kl_loss: 374.6384\n",
      "Epoch 4973/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9028.7573 - reconstruction_loss: 8591.9209 - kl_loss: 374.8863\n",
      "Epoch 4974/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9058.4305 - reconstruction_loss: 8642.0732 - kl_loss: 375.7294\n",
      "Epoch 4975/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9050.9808 - reconstruction_loss: 8609.5107 - kl_loss: 375.7449\n",
      "Epoch 4976/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9042.3854 - reconstruction_loss: 8616.9697 - kl_loss: 375.0368\n",
      "Epoch 4977/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9106.5927 - reconstruction_loss: 8657.0586 - kl_loss: 375.2734\n",
      "Epoch 4978/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9111.3955 - reconstruction_loss: 8661.3926 - kl_loss: 375.5459\n",
      "Epoch 4979/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9145.4110 - reconstruction_loss: 8712.2822 - kl_loss: 375.9911\n",
      "Epoch 4980/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9114.7583 - reconstruction_loss: 8701.6250 - kl_loss: 375.4890\n",
      "Epoch 4981/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9119.4487 - reconstruction_loss: 8707.4072 - kl_loss: 375.3299\n",
      "Epoch 4982/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9130.9403 - reconstruction_loss: 8712.6777 - kl_loss: 375.4405\n",
      "Epoch 4983/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9121.2373 - reconstruction_loss: 8692.5732 - kl_loss: 374.6945\n",
      "Epoch 4984/5000\n",
      "75/75 [==============================] - 1s 11ms/step - loss: 9116.7528 - reconstruction_loss: 8689.2754 - kl_loss: 374.5020\n",
      "Epoch 4985/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9149.5428 - reconstruction_loss: 8696.8496 - kl_loss: 376.1194\n",
      "Epoch 4986/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9106.8875 - reconstruction_loss: 8680.8350 - kl_loss: 375.8822\n",
      "Epoch 4987/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9119.0143 - reconstruction_loss: 8703.9443 - kl_loss: 374.4280\n",
      "Epoch 4988/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9106.9164 - reconstruction_loss: 8683.3994 - kl_loss: 374.1999\n",
      "Epoch 4989/5000\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 9164.4749 - reconstruction_loss: 8715.7637 - kl_loss: 375.0890\n",
      "Epoch 4990/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9145.0622 - reconstruction_loss: 8699.5332 - kl_loss: 374.6839\n",
      "Epoch 4991/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9074.0388 - reconstruction_loss: 8673.3135 - kl_loss: 375.3620\n",
      "Epoch 4992/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9086.8530 - reconstruction_loss: 8656.0029 - kl_loss: 375.2761\n",
      "Epoch 4993/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9079.3385 - reconstruction_loss: 8657.7451 - kl_loss: 375.7343\n",
      "Epoch 4994/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9097.0402 - reconstruction_loss: 8674.1230 - kl_loss: 374.5754\n",
      "Epoch 4995/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9100.6658 - reconstruction_loss: 8671.2725 - kl_loss: 375.6664\n",
      "Epoch 4996/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9110.3412 - reconstruction_loss: 8671.3340 - kl_loss: 375.4375\n",
      "Epoch 4997/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9093.5935 - reconstruction_loss: 8683.7373 - kl_loss: 374.7200\n",
      "Epoch 4998/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9107.6784 - reconstruction_loss: 8680.2568 - kl_loss: 376.0650\n",
      "Epoch 4999/5000\n",
      "75/75 [==============================] - 1s 9ms/step - loss: 9099.6586 - reconstruction_loss: 8683.5479 - kl_loss: 375.1752\n",
      "Epoch 5000/5000\n",
      "75/75 [==============================] - 1s 10ms/step - loss: 9095.6320 - reconstruction_loss: 8694.0078 - kl_loss: 373.9924\n"
     ]
    }
   ],
   "source": [
    "hist = vae.fit(dataset, epochs=5000) # do 1K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x281c3eb20>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['kl_loss'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16939e490>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['kl_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1774820d0>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['kl_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16e4f48b0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['kl_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x177f96a60>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['kl_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x177c4fd00>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['kl_loss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15dc4c370>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['reconstruction_loss'])\n",
    "plt.plot(hist.history['kl_loss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75230.9609375, 74665.765625, 74096.4609375, 73539.375, 72998.53125, 72482.6015625, 71985.0078125, 71515.4140625, 71064.6015625, 70632.46875, 70216.8984375, 69816.0234375, 69429.546875, 69056.59375, 68692.1328125, 68339.1640625, 67993.5078125, 67657.4296875, 67329.9453125, 67009.2734375, 66695.9296875, 66391.3046875, 66086.6796875, 65796.3125, 65505.87109375, 65221.31640625, 64941.6953125, 64666.8046875, 64398.9921875, 64131.14453125]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnhUlEQVR4nO3dd3hUVf7H8fc3CQmEFjCho4Qui9ICoVcL2IBdC7ooIoIFC+o2113dvmsXFBAEUSyACiK7isgiIF0C0qQlhJbQgkgvIeT8/pgrv6wCCZDkZjKf1/PMw8yZeyff81zNJ3PPufeYcw4RERGAML8LEBGRokOhICIipykURETkNIWCiIicplAQEZHTIvwu4ELFxsa6WrVq+V2GiEhQWbZs2V7nXNzZ3g/aUKhVqxZJSUl+lyEiElTMbOu53tfpIxEROU2hICIipykURETkNIWCiIicplAQEZHTFAoiInKaQkFERE4LuVB4b8lW5ifv9bsMEZEiKaRCITMrm/cWb+Oet5cya91uv8sRESlyQioUIiPCeH9gIpdXKct97yzj01U7/S5JRKRICalQAIiJjuTdexNpdmkMD09YzuRlaX6XJCJSZIRcKACULVmCt+9pRds6sTzx4UreW3LOW4GIiISMkAwFgOjICMb0S6Bbw0o89fEaxsxL9bskERHfhWwoAJQsEc7Ivi24/oqq/O3Tdbz2ZbLfJYmI+Cpob52dXyIjwhjapylREWG88MVGjmae4tfXNsDM/C5NRKTQhXwoAESEh/HCLU0oGRnOiDmbOJp5imdubKRgEJGQo1DwhIUZf+/VmFIlwhk7fzMnsk7xt15XEB6mYBCR0KFQyMHM+MP1lxMdGc6rX6ZwLPMUL9zShIjwkB56EZEQolD4ETPjiWsaULJEOM/P2MCJrGyG9mlGZISCQUSKP/2mO4vBXeryxxsaMX3NLh54dxnHT57yuyQRkQKnUDiHAe3j+Vuvxsxav4eB45M4lqlgEJHiTaGQi76tL+P5m69kQcpe7h73NUdOZPldkohIgVEo5MEtCTV5pU8zkrZ+z51jl3Dw+Em/SxIRKRAKhTy6qUk1ht/RnNXpB+g7Zgn7j2b6XZKISL5TKJyH7o2rMPrOBNbvOkSf0YvZe/iE3yWJiOQrhcJ56tKwEm/2a8mW747QZ/Ridh887ndJIiL5RqFwAdrXi2X8PYns3H+M20YtIn3/Mb9LEhHJF7mGgpk1MLMVOR4HzWxIjvefMDNnZrHeazOzYWaWYmarzKx5jm37mVmy9+iXo72Fma329hlmQXDToVbxFXnn3kS+O5LJra8vYtt3R/0uSUTkouUaCs65Dc65ps65pkAL4CjwMYCZ1QSuAbbl2KUHUM97DAJGettWBJ4BEoFWwDNmVsHbZyQwMMd+3S+2Y4Wh+aUVmDCwNUczs7hl1EKSdx/yuyQRkYtyvqePugGbnHM/LFX2MvAbwOXYpicw3gUsBmLMrCpwLTDTObfPOfc9MBPo7r1Xzjm32DnngPFArwvvUuFqXL08Ewe1IdvBbaMXsyb9gN8liYhcsPMNhT7ABAAz6wmkO+dW/mib6sD2HK/TvLZztaedof0nzGyQmSWZWVJGRsZ5ll5wGlQpy4f3taFUiXBuH72YpC37/C5JROSC5DkUzCwSuAn40Myigd8DTxdUYWfinBvtnEtwziXExcUV5o/OVa3Y0nx4fxviykZx59ivmZdcdEJLRCSvzuebQg9guXNuN1AHiAdWmtkWoAaw3MyqAOlAzRz71fDaztVe4wztQadaTCk+uL8NtWJLM+CtJD5fs8vvkkREzsv5hMLteKeOnHOrnXOVnHO1nHO1CJzyae6c2wVMA+7yZiG1Bg4453YCM4BrzKyCN8B8DTDDe++gmbX2Zh3dBXySbz0sZLFlopg4sDWNq5dj8PvL+fibtNx3EhEpIvIUCmZWGrgamJKHzT8DUoEU4A3gQQDn3D7gr8BS7/EXrw1vmzHePpuA6XnvQtFTProE7wxIJDG+Io9NWsk7i7fmvpOISBFggQk/wSchIcElJSX5XcY5HT95iofeX85/1+3ht90b8kDnOn6XJCIhzsyWOecSzva+rmguQCVLhDOybwtualKNZz9fz/Mz1hOsISwioUHLcRawEuFhvHxbU0pHhTN89iaOnDjF0zc0IiysyF+0LSIhSKFQCMLDjH/0voIyURG8MW8zB46d5Lmbr6REuL6oiUjRolAoJGbG76+7nJjoSJ6fsYH9RzMZ8csWlIoM97s0EZHT9KdqITIzBnepyz96X8HcjRn0HavFekSkaFEo+OCOxEsDq7ilHeC2UYvZdUBrMohI0aBQ8EmPK6ryVv+WpH1/lJtfX8jmvUf8LklERKHgp7Z1Y5kwqDVHM09xy+sLdYdVEfGdQsFnV9aI4aP72xAVEU6f0YtZtOk7v0sSkRCmUCgCaseVYfIDbalaviT9xn3NjG91Iz0R8YdCoYioUr4kH97fhp9VK8cD7y5j0tJtue8kIpLPFApFSEx0JO/dm0iHenH8dvJqhs9O0W0xRKRQKRSKmOjICN64K4FeTavx/IwNPDV1DVmnsv0uS0RChK5oLoIiI8J46damVIspxYg5m9i5/xiv3dGc0lE6XCJSsPRNoYgKCzN+070hf+/dmLkbM7ht9CL2HNJFbiJSsBQKRdwvEy9jTL8EUjOO0Hv4QlL2HPK7JBEpxhQKQaBrw8pMGtSGE1nZ/HzEQhan6loGESkYCoUgcUWN8nz8YFsqlSvJXWO/5pMV6X6XJCLFkEIhiNSsGM3k+9vS7NIYHp24gpFzNmnKqojkK4VCkCkfXYLxA1pxo7fE5x80ZVVE8pHmOAahqIhwht7WlBoVSjFyziZ2HjjOq7c305RVEblo+qYQpMLCjN92b8jfegWmrN78+iJ27D/md1kiEuQUCkGub+vLePPulqTtO0rP4QtYsX2/3yWJSBBTKBQDnerHMfnBtkRFhHHbqEX8Z9UOv0sSkSClUCgm6lcuyyeD23FF9fI89P43vDorWTOTROS8KRSKkUvKRPHewER6N6vOizM38vgHKzmRdcrvskQkiGi6SjETFRHOS7c2oU5caV74YiPb9h1l1J0tiC0T5XdpIhIEcv2mYGYNzGxFjsdBMxtiZs+b2XozW2VmH5tZTI59njSzFDPbYGbX5mjv7rWlmNnvcrTHm9kSr32SmUXme09DiJnxUNd6DL+jOWvSD9Br+AI27tY9k0Qkd7mGgnNug3OuqXOuKdACOAp8DMwEGjvnrgQ2Ak8CmFkjoA/wM6A7MMLMws0sHBgO9AAaAbd72wI8C7zsnKsLfA8MyL8uhq7rr6zKpPsC90z6xYiFzN2Y4XdJIlLEne+YQjdgk3Nuq3PuC+dclte+GKjhPe8JTHTOnXDObQZSgFbeI8U5l+qcywQmAj3NzICuwEfe/m8DvS64R/I/mtaM4ZPB7ahRMZr+475m3ILNGoAWkbM631DoA0w4Q/s9wHTveXVge4730ry2s7VfAuzPETA/tP+EmQ0ysyQzS8rI0F+9eVUtphQf3d+GbpdX5s//XssTH67k+EkNQIvIT+U5FLzz/DcBH/6o/SkgC3gvf0v7KefcaOdcgnMuIS4urqB/XLFSOiqCUX1b8NhV9ZmyPJ2bX19I2vdH/S5LRIqY8/mm0ANY7pzb/UODmd0N3AD80v3/OYl0oGaO/Wp4bWdr/w6IMbOIH7VLPgsLMx69qh5j7kpg696j3PTaAhZu2ut3WSJShJxPKNxOjlNHZtYd+A1wk3Mu55+c04A+ZhZlZvFAPeBrYClQz5tpFEngVNQ0L0xmAzd7+/cDPrnQDknurmpUmakPtaNCdAnuHPs1Y+alapxBRIA8hoKZlQauBqbkaH4NKAvM9Kaqvg7gnPsW+ABYC3wODHbOnfLGDB4CZgDrgA+8bQF+CzxuZikExhjGXnTP5JzqxJVh6uB2dGtYib99uo4hk1ZwLFPjDCKhzoL1L8SEhASXlJTkdxlBLzvbMWJOCi/O3MjlVcox6s4W1KwY7XdZIlJAzGyZcy7hbO/rNhchLiwscKHbm/1asv37o9z42nzmJWtml0ioUigIAF0aVuLfD7WnUtko+r35Na/P1VKfIqFIoSCn1YotzccPtqN74yr8a/p67n93GQePn/S7LBEpRAoF+R+loyIYfkdz/nD95fx33R5ufHU+3+444HdZIlJIFAryE2bGvR1qM3FQa46fPEXvEQuZtHSbTieJhACFgpxVy1oV+fSRDrSsVYHfTl7Nrz9apWmrIsWcQkHOKbZMFOPvSeSRrnWZvDyN3iMWkJpx2O+yRKSAKBQkV+FhxuPXNGDc3S3ZdfA4N722gE9X7fS7LBEpAAoFybPODSrx6SMdqFupDIPfX86f//0tmVnZfpclIvlIoSDnpXpMKT64rw13t63FuAVbuG30InbsP+Z3WSKSTxQKct4iI8L4000/47U7mrFx1yGuGzaPmWt3576jiBR5CgW5YDdcWY1/P9ye6jGlGDg+iT9N+1aL94gEOYWCXJTacWWY8mBb7mkXz1sLt/DzEQvZpNlJIkFLoSAXLSoinKdvbMSYuxLYeeAYN746n8nL0vwuS0QugEJB8s1VjSrz2aMdaFy9PE98uJLHJq3g8Ims3HcUkSJDoSD5qmr5UkwY2JrHrqrPJyvSuWHYPNak695JIsFCoSD5LtxbC3rCwNacyMqm94gFvDl/s+6dJBIEFApSYBJrX8Jnj3SgU/1K/OU/a7n37ST2Hj7hd1kicg4KBSlQFUpH8sZdLfjTjY2Yl7KX7q/MY/b6PX6XJSJnoVCQAmdm3N0unmkPtSO2TCT931rK05+s0R1XRYoghYIUmoZVyjF1cDsGtI9n/KKt3PjafA1CixQxCgUpVCVLhPPHGxrx7oBEDh0/Se8RCxg5ZxOnsjUILVIUKBTEF+3rxTJjSEeublSZZz9fzx1vLCZdN9YT8Z1CQXwTEx3J8Dua88ItTViTfoDur3zFJyvS/S5LJKQpFMRXZsbNLWow/dGO1K9clkcnrmDIxG84cOyk36WJhCSFghQJl14SzaRBrXn86vr8e9VOerzyFfOT9/pdlkjIyTUUzKyBma3I8ThoZkPMrKKZzTSzZO/fCt72ZmbDzCzFzFaZWfMcn9XP2z7ZzPrlaG9hZqu9fYaZmRVMd6UoiwgP45Fu9ZjyQFtKRYbTd+wS/jh1DUczdf8kkcKSayg45zY455o655oCLYCjwMfA74BZzrl6wCzvNUAPoJ73GASMBDCzisAzQCLQCnjmhyDxthmYY7/u+dE5CU5Nasbw6SMduLd9PO8u2UqPofNI2rLP77JEQsL5nj7qBmxyzm0FegJve+1vA7285z2B8S5gMRBjZlWBa4GZzrl9zrnvgZlAd++9cs65xS5wc5zxOT5LQlTJEuH84YZGTBzYmmznuGXUIv752Tot4iNSwM43FPoAE7znlZ1zO73nu4DK3vPqwPYc+6R5bedqTztD+0+Y2SAzSzKzpIyMjPMsXYJRYu1L+PzRjtzR6lJGfZXKja/OZ3WaLngTKSh5DgUziwRuAj788XveX/gFfvWRc260cy7BOZcQFxdX0D9OiojSURH8vfcVvH1PKw4dz6LXiAW8PHMjJ09l+12aSLFzPt8UegDLnXM/rNC+2zv1g/fvD3c5Swdq5tivhtd2rvYaZ2gX+R+d6scxY0hHejapxtBZyfQavoANuw75XZZIsXI+oXA7/3/qCGAa8MMMon7AJzna7/JmIbUGDninmWYA15hZBW+A+RpghvfeQTNr7c06uivHZ4n8j/LRJXjptqa83rc5uw4c58ZX5/Pal8n61iCST/IUCmZWGrgamJKj+V/A1WaWDFzlvQb4DEgFUoA3gAcBnHP7gL8CS73HX7w2vG3GePtsAqZfeJckFHRvXJUZjwVuk/HCFxvp+doCvt2hsQaRi2XBuhpWQkKCS0pK8rsMKQI+X7OTP0z9lv1HM3mgcx0e6lqXqIhwv8sSKZLMbJlzLuFs7+uKZgl63RtX5b+Pd+SmptV49csUbhg2n2+2fe93WSJBSaEgxUJMdCQv3dqUcXe35PCJLH4xciH/0HUNIudNoSDFSpeGlfjisY70aXUpo79KpcfQeXy9WVdDi+SVQkGKnbIlS/CP3lfw3r2JZGVnc+uoRTz9yRoOn9A9lERyo1CQYqtd3cBCPv3b1eKdxVu59uWv+HL97tx3FAlhCgUp1qIjI3jmxp/x0f1tKB0Vzj1vJTH4/eXsOXTc79JEiiSFgoSEFpdV5D8Pd+CJq+sz89vdXPXiXCZ8vY1srQ0t8j8UChIyIiPCeLhbPaYP6cDlVcvx5JTV9Bm9mJQ9h/0uTaTIUChIyKkTV4aJg1rz3C+uZMPuQ1w3dB6v/HcjJ7I0fVVEoSAhycy4tWVNZj3RiR5XVOGV/yZz/bD5LNViPhLiFAoS0mLLRDG0TzPe6t+S4ydPccvri3hyymoOHD3pd2kivlAoiACdGwQuehvYIZ4PkrbT7aU5TP0mnWC9N5jIhVIoiHiiIyN46vpGTHuoHdUrRDNk0gr6jl1CaoYGoiV0KBREfuRn1coz5YG2/K1XY1alHaD7K/N4eeZG3UdJQoJCQeQMwsOMvq0vOz0QPXRWMj2GzmN+8l6/SxMpUAoFkXOoVLYkQ/s0490BiQD0HbuERyd+oyuipdhSKIjkQft6sUx/tAOPdqvH9NW76PbiXN5ZvFVXREuxo1AQyaOSJcJ57Or6TB/SgSuql+ePU9fQe8QCVm7f73dpIvlGoSBynurEleG9exN55bam7DhwnF4jFvDklNV8fyTT79JELppCQeQCmBm9mlXnyyc6cU+7wLUNXV6cw3tLtnJKp5QkiCkURC5C2ZIl+OMNjfjskQ40qFyWpz4OnFJaoVNKEqQUCiL5oEGVskwc1JqhfZqy68Bxeo9YwO8mr2KfTilJkFEoiOQTM6Nn0+rMeqIT97aP58NlaXR5YQ7vLtYpJQkeCgWRfFa2ZAmeur4R0x/twOVVy/KHqWvoOXw+y7Z+73dpIrlSKIgUkPqVyzJhYGuG3d6MvYcy+cXIhTw+aQV7DurCNym6FAoiBcjMuKlJNWY90YkHO9fhP6t20uWFOYyau4nMrGy/yxP5CYWCSCEoHRXBb7o35IvHOtKmziX8c/p6ur/yFbM37PG7NJH/kadQMLMYM/vIzNab2Toza2NmTc1ssZmtMLMkM2vlbWtmNszMUsxslZk1z/E5/cws2Xv0y9HewsxWe/sMMzPL/66K+K9WbGnG9GvJuP4tAeg/bikD3lrKlr1HfK5MJCCv3xSGAp875xoCTYB1wHPAn51zTYGnvdcAPYB63mMQMBLAzCoCzwCJQCvgGTOr4O0zEhiYY7/uF9UrkSKuS4NKfD6kI7+/riGLU7/jmpe/4tnP13PkRJbfpUmIyzUUzKw80BEYC+Ccy3TO7QccUM7brDyww3veExjvAhYDMWZWFbgWmOmc2+ec+x6YCXT33ivnnFvsAstcjQd65VcHRYqqyIgwBnWsw+xfdeaGJlUZOWcTXV+cw8ffpOlGe+KbvHxTiAcygHFm9o2ZjTGz0sAQ4Hkz2w68ADzpbV8d2J5j/zSv7VztaWdo/wkzG+SdqkrKyMjIQ+kiRV+lciV56damTHmwLZXLleSxSSv5+ciFLN+mKaxS+PISChFAc2Ckc64ZcAT4HfAA8JhzribwGN43iYLknBvtnEtwziXExcUV9I8TKVTNL63A1Afb8cItTdix/xg/H7GQRyd+w479x/wuTUJIXkIhDUhzzi3xXn9EICT6AVO8tg8JjBMApAM1c+xfw2s7V3uNM7SLhJywMOPmFjWY/avOPNy1Lp+v2UXXF+fw0syNHM3UeIMUvFxDwTm3C9huZg28pm7AWgJjCJ28tq5Asvd8GnCXNwupNXDAObcTmAFcY2YVvAHma4AZ3nsHzay1N+voLuCTfOqfSFAqHRXBE9c0YNYTnbi6URWGzUqmywtzmLJc4w1SsCwwtpvLRmZNgTFAJJAK9Ad+RmBWUgRwHHjQObfM+8X+GoEZREeB/s65JO9z7gF+733s351z47z2BOAtoBQwHXjY5VJYQkKCS0pKOp++igStpC37+Ot/1rIy7QBNapTn6Rsb0eKyin6XJUHIzJY55xLO+n5eQqEoUihIqMnOdkxdkc6zn69n98ET3HBlVX7bvSE1K0b7XZoEkdxCQVc0iwSJsDDj580D4w2PdK3Lf9ftptuLc/nnZ+s4cOyk3+VJMaFQEAky0ZERPH5NA2b/qjM3NqnG6HmpdHp+NuMWbNb9lOSiKRREglTV8qV48dYm/Puh9jSqWo4//3st177yFZ+v2UWwnhYW/ykURIJc4+rlee/eRMbd3ZKIMOP+d5dx66hFWhJULohCQaQYMDO6NKzE9Ec78I/eV7B57xF6DV/AwxO+Yfu+o36XJ0FEs49EiqHDJ7IYNXcTb8xLJTsb7m5Xi8Gd61I+uoTfpYnPNCVVJITtPHCMF7/YyOTlaZSNimBwl7r0a1uLkiXC/S5NfKIpqSIhrGr5UrxwSxM+e6QDzS+rwD+nr6fbi3OZvCyNU7oyWs5AoSASAi6vWo63+rfi/YGJXFImkic+XMn1w+YxZ8MezVSS/6FQEAkhbevEMvXBdrx6ezOOZGZx97il9B27hDXpB/wuTYoIhYJIiAkLM25sUo1Zj3fmmRsbsXbHQW54dT6PaKaSoIFmkZB38PhJRs3dxNj5mzmV7fhl4mU81LUusWWi/C5NCoBmH4lInuw6cJyhs5L5IGk7URFh3NuhNgM7xFO2pKaxFicKBRE5L5syDvPSFxv5dPVOKkSXYHCXuvRtfZmmsRYTCgURuSCr0vbz/IwNzEveS/WYUgy5qh4/b16D8DDzuzS5CLpOQUQuyJU1YnhnQCLv3ZtIbJlIfv3RKrq/8hUzvtUN94ozhYKInFO7urFMHdyOkb9szinnuO+dZfQesZCFm/b6XZoUAIWCiOTKzOhxRVW+GNKRZ39xBbsPHueON5bwyzGLWbb1e7/Lk3ykMQUROW/HT57i/SXbGDEnhb2HM+nasBKPX12fxtXL+12a5EIDzSJSYI6cyOLtRVsYNTeVA8dOct0VVXjsqvrUq1zW79LkLBQKIlLgDh4/ydh5mxk7fzNHMrPo1bQ6j3arR63Y0n6XJj+iUBCRQrPvSCajvtrE2wu3cPKU49aEGjzUtR7VY0r5XZp4FAoiUuj2HDrOiNmbeH/JNgDuSLyUB7vUoVLZkj5XJgoFEfFN+v5jvPZlMh8kpVEi3OjXthb3d6xDhdKRfpcWshQKIuK7LXuPMHRWMlNXpFM6MoIB7eMZ0CGecrqvUqFTKIhIkbFx9yFenrmR6Wt2Ub5UCe7rVJu729YiOjLC79JCRr7c5sLMYszsIzNbb2brzKyN1/6w1/atmT2XY/snzSzFzDaY2bU52rt7bSlm9rsc7fFmtsRrn2Rm+m4pUgzVr1yWkX1b8J+H29P80hie+3wDHZ+bzZvzN3P85Cm/yxPy+E3BzN4G5jnnxni/sKOBZsBTwPXOuRNmVsk5t8fMGgETgFZANeC/QH3vozYCVwNpwFLgdufcWjP7AJjinJtoZq8DK51zI89Vk74piAS/ZVv38cKMjSxK/Y4q5UoyuGtdbk2oQVSE7shaUC76m4KZlQc6AmMBnHOZzrn9wAPAv5xzJ7z2Pd4uPYGJzrkTzrnNQAqBgGgFpDjnUp1zmcBEoKeZGdAV+Mjb/22g1/l2VESCT4vLKjJhUGvevzeRajEl+ePUNXR6bg5vL9yibw4+ycvpo3ggAxhnZt+Y2RgzK03gr/8O3mmfuWbW0tu+OrA9x/5pXtvZ2i8B9jvnsn7ULiIhom3dWCY/0JZ3ByRSs2Ipnpn2LR2fm83Y+Zs5lqlwKEx5CYUIoDkw0jnXDDgC/M5rrwi0Bn4NfOD91V9gzGyQmSWZWVJGRkZB/igRKWRmRvt6sXxwXxsmDGxNnbgy/PU/a+nw3JeM/moTRzOzcv8QuWh5CYU0IM05t8R7/RGBkEgjMA7gnHNfA9lALJAO1Myxfw2v7Wzt3wExZhbxo/afcM6Nds4lOOcS4uLi8tI/EQkyZkabOpcwYVBrPrivDZdXLcc/PltP+2dnM2JOCodPKBwKUq6h4JzbBWw3swZeUzdgLTAV6AJgZvWBSGAvMA3oY2ZRZhYP1AO+JjCwXM+baRQJ9AGmucBI92zgZu/z+wGf5E/3RCSYtYqvyDsDEpn8QFuurFGe5z7fQPtnv+S1L5M5ePyk3+UVS3mdfdQUGEPgF38q0J/AaaQ3gaZAJvAr59yX3vZPAfcAWcAQ59x0r/064BUgHHjTOfd3r702gYHnisA3QN8fBrDPRrOPRELPyu37GTYrmVnr91CuZAT3tI+nf7t4ypfSRXB5pYvXRKTYWZN+gGGzkvli7W7KRkXQv10t7mkfT0y0LnHKjUJBRIqttTsO8trsZD5bvYvSkeH0a1uLezvUpqLurXRWCgURKfY27DrEq18m8+nqnZQqEc6drS9jYMfaxJaJ8ru0IkehICIhI2XPIV77MoVpK3cQGRFG38TLGNSxNpXK6ZbdP1AoiEjISc04zPDZm5i6Ip3wMKNPy5rc16mOFvtBoSAiIWzrd0d4fe4mPlqWhnPw8+bVeaBzXeJDeJlQhYKIhLwd+48x+qtUJny9jZOnsrn+ymoM7lKHhlXK+V1aoVMoiIh4Mg6dYMz8VN5dtJUjmae4ulFlHupSlyY1Y/wurdAoFEREfmT/0UzGLdjCuAWbOXg8iw71Ynm4az1axVf0u7QCp1AQETmLQ8dP8u7ibYyZl8p3RzJpWasCD3apS+f6cRTw/T19o1AQEcnFscxTTFq6jdFfpbLjwHEaVS3Hg13q0KNxVcLDilc4KBRERPIoMyubqSvSeX3uJlIzjhAfW5r7O9Wmd7MaREbkafXiIk+hICJynk5lO774dhfD56SwJv0gVcqVZGDH2tzeqibRkRG5f0ARplAQEblAzjnmJe9l+OwUlmzeR4XoEvRvF0+/NrUoHx2cd2ZVKIiI5INlW/cxYvYmZq3fQ3RkOHe0upQBHeKpWj64rpJWKIiI5KP1uw4yam4q01buIMygV9Pq3NepNnUrlfW7tDxRKIiIFIDt+44ydv5mJi7dxvGT2VzdqDIPdK5D80sr+F3aOSkUREQK0HeHT/D2oq2MX7SF/UdP0iq+Ig90qkPnBkXzWgeFgohIIThyIouJS7czdl7gWoeGVcpyX6fa3HBlNUqEF53prAoFEZFClJmVzbSVOxg1dxPJew5TrXxJ7mkfz20ta1K2pP8zlhQKIiI+yM52zN6wh9FfpbJk8z7KlozgjsRL6d82nirl/Vv0R6EgIuKzldv388a8VD5bvZPwMOOmJtUZ2DHel1t3KxRERIqIH2YsTVq6nWMnT9GxfhyDOtSmXd1LCm1QWqEgIlLE7D+ayXtLtjFuwRb2Hj5Bo6rlGNSxNtdfWbXAB6UVCiIiRdSJrFN88s0ORs9LJaWQBqUVCiIiRVx2tmPOxj2Mmlvwg9IKBRGRIJJzUDrMjJuaVmNQx9r5NiitUBARCUIFNSidWyjkaUTDzGLM7CMzW29m68ysTY73njAzZ2ax3mszs2FmlmJmq8yseY5t+5lZsvfol6O9hZmt9vYZZkXx2nARkUJUs2I0f7rpZyx6siu/vrYBa3ccpO/YJVw/bD57Dh4vsJ+b19UihgKfO+duNrNIIBrAzGoC1wDbcmzbA6jnPRKBkUCimVUEngESAAcsM7NpzrnvvW0GAkuAz4DuwPSL7JuISNCLiY5kcJe6DGgfzycr0vly/R5iy0QV2M/L9ZuCmZUHOgJjAZxzmc65/d7bLwO/IfBL/gc9gfEuYDEQY2ZVgWuBmc65fV4QzAS6e++Vc84tdoFzWeOBXvnSOxGRYqJkiXBua3kpo+5MIKwA143Oy+mjeCADGGdm35jZGDMrbWY9gXTn3MofbV8d2J7jdZrXdq72tDO0/4SZDTKzJDNLysjIyEPpIiJyPvISChFAc2Ckc64ZcAT4E/B74OmCK+2nnHOjnXMJzrmEuLi4wvzRIiIhIS+hkAakOeeWeK8/IhAS8cBKM9sC1ACWm1kVIB2omWP/Gl7budprnKFdREQKWa6h4JzbBWw3swZeUzdguXOuknOulnOuFoHgaO5tOw24y5uF1Bo44JzbCcwArjGzCmZWgcAA9QzvvYNm1tqbdXQX8El+d1RERHKX19lHDwPveTOPUoH+59j2M+A6IAU4+sO2zrl9ZvZXYKm33V+cc/u85w8CbwGlCMw60swjEREf6OI1EZEQki8Xr4mISGhQKIiIyGlBe/rIzDKArRe4eyywNx/L8Vtx6w8Uvz4Vt/5A8etTcesPnLlPlznnzjqnP2hD4WKYWdK5zqkFm+LWHyh+fSpu/YHi16fi1h+4sD7p9JGIiJymUBARkdNCNRRG+11APitu/YHi16fi1h8ofn0qbv2BC+hTSI4piIjImYXqNwURETkDhYKIiJwWUqFgZt3NbIO37Ofv/K4nP5jZFm8p0xVmFpT3/TCzN81sj5mtydFW0cxmeku3zvRuohgUztKfP5lZunecVpjZdX7WeD7MrKaZzTaztWb2rZk96rUH8zE6W5+C8jiZWUkz+9rMVnr9+bPXHm9mS7zfeZO8+9ed+7NCZUzBzMKBjcDVBO7quhS43Tm31tfCLpJ36/IE51zQXnRjZh2BwwRW7GvstT0H7HPO/csL8ArOud/6WWdenaU/fwIOO+de8LO2C+GtjljVObfczMoCywisjng3wXuMztanWwnC4+TdYbq0c+6wmZUA5gOPAo8DU5xzE83sdWClc27kuT4rlL4ptAJSnHOpzrlMYCKBpUPFZ865r4B9P2ruCbztPX+bIFqi9Sz9CVrOuZ3OueXe80PAOgKrIwbzMTpbn4KSt/zxYe9lCe/hgK4E1sCBPB6jUAqFsy0HGuwc8IWZLTOzQX4Xk48qe2ttAOwCKvtZTD55yMxWeaeXguZUS05mVgtoBiyhmByjH/UJgvQ4mVm4ma0A9gAzgU3AfudclrdJnn7nhVIoFFftnXPNgR7AYO/URbHiAuc4g/0850igDtAU2Am86Gs1F8DMygCTgSHOuYM53wvWY3SGPgXtcXLOnXLONSWwemUroOGFfE4ohcLZlgMNas65dO/fPcDHBP5jKA52e+d9fzj/u8fnei6Kc2639z9tNvAGQXacvPPUk4H3nHNTvOagPkZn6lOwHycA59x+YDbQBogxsx8WU8vT77xQCoWlQD1vND4S6ENg6dCgZWalvUEyzKw0gSVO15x7r6AxDejnPe9HkC/R+sMvT09vgug4eYOYY4F1zrmXcrwVtMfobH0K1uNkZnFmFuM9L0VgQs06AuFws7dZno5RyMw+AvCml70ChANvOuf+7m9FF8fMahP4dgCBpVXfD8Y+mdkEoDOB2/zuBp4BpgIfAJcSuEX6rTmWby3SztKfzgROSThgC3BfjvPxRZqZtQfmAauBbK/59wTOwQfrMTpbn24nCI+TmV1JYCA5nMAf+x845/7i/Y6YCFQEvgH6OudOnPOzQikURETk3ELp9JGIiORCoSAiIqcpFERE5DSFgoiInKZQEBGR0xQKIiJymkJBRERO+z8gFWuUCbTYxQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "\n",
    "print(hist.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ../workfiles/vae_model/assets\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.save('../workfiles/placeholder_model')\n",
    "vae.encoder.save('../workfiles/vae_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_path = '/Users/aygalic/OneDrive/polimi/Thesis/data/quant/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting entries ready\n",
    "# each couple of entries correspond to one patient\n",
    "\n",
    "entries = os.listdir(absolute_path)\n",
    "entries_transcripts = [e for e in entries if \"transcripts\" in e ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a TensorFlow input pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to build a tf.Dataset from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from filename to tensor\n",
    "\n",
    "def load_patient_data(filename):\n",
    "  #specify read types for our data\n",
    "  read_types = [ float()]\n",
    "  # get a first sample to base everything of\n",
    "  text = pathlib.Path(absolute_path + filename).read_text()\n",
    "  lines = text.split('\\n')[1:-1]\n",
    "  features = tf.io.decode_csv(lines, record_defaults=read_types, field_delim = \"\\t\", select_cols=[3]) \n",
    "  data = tf.convert_to_tensor(features)\n",
    "\n",
    "  return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed it into a net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we build a tf.dataset with all patients inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into a list using the first pipeline\n",
    "\n",
    "train_ds = [load_patient_data(e) for e in entries_transcripts]\n",
    "train_ds = [e for e in train_ds if e.shape == (1, 95309)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn it into a tf.data.Dataset object\n",
    "x_train = tf.data.Dataset.from_tensor_slices(train_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input are the same as the target\n",
    "zipped_boi = tf.data.Dataset.zip((x_train, x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x29a47a2b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(iter(zipped_boi))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "t_shape = (1, 95309)\n",
    "\n",
    "\n",
    "class Autoencoder(Model):\n",
    "  #layer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "  #layer.adapt(X_train)\n",
    "  def __init__(self, latent_dim, normalization = True):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.BatchNormalization(),\n",
    "      layers.Dense(latent_dim, activation='softplus'),\n",
    "      layers.Dense(latent_dim, activation='softplus'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(latent_dim, activation='softplus'),\n",
    "      layers.Dense(1 * 95309, activation='softplus'), # softplus so we can have value in the expected range\n",
    "      layers.Reshape(t_shape)\n",
    "    ])\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim)\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 95309)]   0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 95309)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           1524960     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 64)           1088        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 64)           1088        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 64)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,527,136\n",
      "Trainable params: 1,527,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "t_shape = (1, 95309)\n",
    "\n",
    "#encoder_inputs = keras.Input(shape=t_shape)\n",
    "#x = layers.Flatten()(encoder_inputs)\n",
    "\n",
    "encoder_inputs = layers.Flatten()\n",
    "\n",
    "\n",
    "\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3136)              203840    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 95309)             298984333 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,188,173\n",
      "Trainable params: 299,188,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "decoder_outputs = layers.Dense(1 * 95309, activation='softplus')(x), # softplus so we can have value in the expected range\n",
    "#decoder_outputs = layers.Reshape(t_shape)(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "#mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "#mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/var/folders/xr/0fvz4r2s4wx1hx13jlhxj2z00000gn/T/ipykernel_43545/2449247714.py\", line 22, in train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"encoder\" is incompatible with the layer: expected shape=(None, 1, 95309), found shape=(1, 95309)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#vae.fit(zipped_boi, epochs=30, batch_size=128)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vae\u001b[39m.\u001b[39;49mfit(x_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/xr/0fvz4r2s4wx1hx13jlhxj2z00000gn/T/__autograph_generated_filekw_ce12s.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32m/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb Cell 22\u001b[0m in \u001b[0;36mVAE.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         z_mean, z_log_var, z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         reconstruction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(z)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         reconstruction_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             tf\u001b[39m.\u001b[39mreduce_sum(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                 keras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mbinary_crossentropy(data, reconstruction), axis\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m             )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aygalic/Library/CloudStorage/OneDrive-Personal/polimi/Thesis/genome_analysis_parkinson/src/pipeline_1_VAE.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/var/folders/xr/0fvz4r2s4wx1hx13jlhxj2z00000gn/T/ipykernel_43545/2449247714.py\", line 22, in train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/homebrew/anaconda3/envs/thesis/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"encoder\" is incompatible with the layer: expected shape=(None, 1, 95309), found shape=(1, 95309)\n"
     ]
    }
   ],
   "source": [
    "#vae.fit(zipped_boi, epochs=30, batch_size=128)\n",
    "vae.fit(x_train, epochs=30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4755/4755 [==============================] - 256s 54ms/step - loss: 50037.5977\n",
      "Epoch 2/10\n",
      "4755/4755 [==============================] - 256s 54ms/step - loss: 49595.7070\n",
      "Epoch 3/10\n",
      "4755/4755 [==============================] - 296s 62ms/step - loss: 49558.0820\n",
      "Epoch 4/10\n",
      "4755/4755 [==============================] - 297s 62ms/step - loss: 49515.7422\n",
      "Epoch 5/10\n",
      "4755/4755 [==============================] - 268s 56ms/step - loss: 49461.5156\n",
      "Epoch 6/10\n",
      "4755/4755 [==============================] - 220s 46ms/step - loss: 49422.7031\n",
      "Epoch 7/10\n",
      "4755/4755 [==============================] - 206s 43ms/step - loss: 49384.5352\n",
      "Epoch 8/10\n",
      "4755/4755 [==============================] - 192s 40ms/step - loss: 49351.1133\n",
      "Epoch 9/10\n",
      "4755/4755 [==============================] - 193s 41ms/step - loss: 49327.9727\n",
      "Epoch 10/10\n",
      "4755/4755 [==============================] - 200s 42ms/step - loss: 49303.5312\n"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.fit(zipped_boi,\n",
    "                epochs=10,\n",
    "                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8458.9609375, 5196.03369140625, 3719.23828125, 3157.94580078125, 2965.247802734375, 2837.5986328125, 2734.477783203125, 2659.512939453125, 2532.032958984375, 2480.10498046875]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "\n",
    "print(hist.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../workfiles/placeholder_normalized_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../workfiles/placeholder_normalized_model/assets\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.save('../workfiles/placeholder_model')\n",
    "autoencoder.save('../workfiles/placeholder_normalized_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
